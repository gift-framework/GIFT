"""
Markdown report generator for Selection Principle benchmark results.
"""

from __future__ import annotations
import json
import os
from pathlib import Path


def generate_report(results_path: str, output_path: str | None = None) -> str:
    """Generate a markdown report from benchmark results JSON."""
    with open(results_path) as f:
        data = json.load(f)

    if output_path is None:
        output_path = os.path.join(os.path.dirname(results_path), "REPORT.md")

    lines = []
    lines.append("# GIFT Selection Principle: Benchmark Report\n")
    lines.append(f"**Observables analyzed:** {data['n_observables']}")
    lines.append(f"**Total runtime:** {data['total_time_s']:.1f}s\n")

    # Summary table
    lines.append("## Summary\n")
    lines.append("| Observable | Class | Formulas | GIFT Rank (err) | "
                 "GIFT Rank (composite) | On Pareto | p (random) | p (shuffled) |")
    lines.append("|---|---|---|---|---|---|---|---|")

    for r in data["results"]:
        rk = r["ranking"]
        nr = r.get("null_random", {})
        ns = r.get("null_shuffled", {})
        lines.append(
            f"| {r['observable']} | {r['obs_class']} | {r['n_enumerated']} "
            f"| {rk['rank_by_error']}/{rk['total_formulas']} "
            f"| {rk['rank_by_composite']}/{rk['total_formulas']} "
            f"| {'Yes' if rk['on_pareto'] else 'No'} "
            f"| {nr.get('p_value', 'N/A'):.4f} "
            f"| {ns.get('p_value', 'N/A'):.4f} |"
        )

    # Detailed sections
    for r in data["results"]:
        lines.append(f"\n---\n\n## {r['observable']} (Class {r['obs_class']})\n")
        lines.append(f"- **Experimental value:** {r['experimental']}")
        lines.append(f"- **Uncertainty:** {r['uncertainty']}")

        gs = r.get("gift_scores", {})
        lines.append(f"- **GIFT predicted:** {gs.get('predicted', 'N/A')}")
        lines.append(f"- **GIFT error score:** {gs.get('err', 'N/A')}")
        lines.append(f"- **GIFT complexity:** {gs.get('comp', 'N/A')}")
        lines.append(f"- **GIFT composite:** {gs.get('total', 'N/A')}")

        lines.append(f"\n### Enumeration\n")
        lines.append(f"- Formulas enumerated: **{r['n_enumerated']}**")
        lines.append(f"- Enumeration time: {r['t_enum_s']}s")
        lines.append(f"- Pareto frontier size: {r['frontier_size']}")

        rk = r["ranking"]
        lines.append(f"\n### Ranking\n")
        lines.append(f"| Metric | Rank | Total | Percentile |")
        lines.append(f"|---|---|---|---|")
        lines.append(f"| Error | {rk['rank_by_error']} | {rk['total_formulas']} "
                     f"| {rk['percentile_error']:.1%} |")
        lines.append(f"| Composite | {rk['rank_by_composite']} | {rk['total_formulas']} "
                     f"| {rk['percentile_composite']:.1%} |")
        lines.append(f"| Complexity | {rk['rank_by_complexity']} | {rk['total_formulas']} | - |")
        lines.append(f"| Pareto frontier | {'On frontier' if rk['on_pareto'] else 'Not on frontier'} "
                     f"| - | - |")

        nr = r.get("null_random", {})
        ns = r.get("null_shuffled", {})
        lines.append(f"\n### Null Models\n")
        lines.append(f"| Model | p-value | Valid samples | Mean error |")
        lines.append(f"|---|---|---|---|")
        if nr:
            lines.append(f"| Random | {nr.get('p_value', 'N/A'):.4f} "
                        f"| {nr.get('n_valid', 0)}/{nr.get('n_total', 0)} "
                        f"| {nr.get('mean_error', 'N/A'):.4f} |")
        if ns:
            lines.append(f"| Shuffled | {ns.get('p_value', 'N/A'):.4f} "
                        f"| {ns.get('n_valid', 0)}/{ns.get('n_total', 0)} "
                        f"| {ns.get('mean_error', 'N/A'):.4f} |")

        lines.append(f"\n### Plots\n")
        lines.append(f"- Pareto frontier: `{r['observable']}/pareto_plot.png`")
        lines.append(f"- Rank (error): `{r['observable']}/rank_err_plot.png`")
        lines.append(f"- Rank (composite): `{r['observable']}/rank_total_plot.png`")
        lines.append(f"- Null (random): `{r['observable']}/null_random_plot.png`")
        lines.append(f"- Null (shuffled): `{r['observable']}/null_shuffled_plot.png`")

    # Footer
    lines.append("\n---\n")
    lines.append("*Generated by `selection.benchmarks.report`*\n")

    report = "\n".join(lines)
    with open(output_path, "w") as f:
        f.write(report)

    return output_path


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1:
        results_path = sys.argv[1]
    else:
        results_path = str(
            Path(__file__).resolve().parent.parent / "results" / "benchmark_results.json"
        )
    out = generate_report(results_path)
    print(f"Report generated: {out}")
