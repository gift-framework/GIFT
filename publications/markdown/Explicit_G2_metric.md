# A Numerical Candidate for a Torsion-Free Gâ‚‚ Structure on a Compact TCS 7-Manifold

**Author**: Brieuc de La FourniÃ¨re

Independent researcher

**Abstract.** We construct a numerical candidate for a Riemannian metric with
holonomy contained in Gâ‚‚ on a compact 7-manifold Kâ‚‡ of twisted connected sum
(TCS) type, with Betti numbers bâ‚‚ = 21 and bâ‚ƒ = 77. The construction
proceeds in three stages: (i) an analytical target metric derived from the
Gâ‚‚ representation-theoretic decomposition Î›Â³(â„â·) = Î›Â¹â‚ƒ âŠ• Î›â·â‚ƒ âŠ• Î›Â²â·â‚ƒ and
period integrals on the moduli space of Gâ‚‚ structures; (ii) a
Cholesky-parameterized physics-informed neural network (PINN) that
reconstructs a spatially varying metric field g(x) on a local computational
model of the TCS neck region; (iii) verification against five geometric
criteria. The resulting 7Ã—7 metric satisfies a prescribed determinant
det(g) = 65/32 to 8 significant figures (4 Ã— 10â»â¸ % deviation), has
torsion â€–dÏ†â€– + â€–d*Ï†â€– of order 10â»â¶ (well within the perturbative regime
of Joyce's existence theorem [Theorem 11.6.1, Joyce 2000]), condition
number Îº = 1.0152, and matches 77 target period integrals at 5 scales
with RMS error 3.1 Ã— 10â»â´. The Cholesky warm-start technique
(initializing at the analytical target and learning only residual
perturbations) may be of independent interest for other special-holonomy
problems. All code and data are publicly available.

---

## 1. Introduction

### 1.1 Compact manifolds with holonomy contained in Gâ‚‚

A compact Riemannian 7-manifold (Mâ·, g) has holonomy contained in the
exceptional Lie group Gâ‚‚ âŠ‚ SO(7) if and only if it admits a torsion-free
Gâ‚‚-structure, i.e., a closed and coclosed 3-form Ï† âˆˆ Î©Â³(M) [1, 2].
(Full holonomy Gâ‚‚, as opposed to a proper subgroup, requires additionally
that M be simply connected and not a Riemannian product.)
Joyce [3, 4] proved the existence of compact examples by resolving
singularities of Tâ·/Î“ orbifolds. Kovalev [5] introduced the
twisted connected sum (TCS) construction, gluing two asymptotically
cylindrical (ACyl) Calabiâ€“Yau threefolds along a common K3 fiber.
Corti, Haskins, NordstrÃ¶m and Pacini [6] systematized the TCS method
and produced many topological types.

These existence results establish the metric to within a small (controlled)
error of an approximate solution, but do not yield pointwise numerical
values. To our knowledge, no explicit metric tensor g_ij(x) has been
computed numerically for a compact Gâ‚‚ manifold, though we note that
substantial numerical work exists for *non-compact* examples
(see e.g. Brandhuber et al. [15]).

### 1.2 The PINN approach

Physics-informed neural networks (PINNs) [7] parameterize solutions to
PDEs via neural networks whose loss function encodes the governing
equations. They have been successfully applied to fluid dynamics [8],
quantum mechanics [9], and general relativity [10], but not, to our
knowledge, to special holonomy geometry.

We apply PINNs to construct a candidate metric on a local model of the
neck region of Kâ‚‡, a compact TCS manifold with bâ‚‚ = 21 and bâ‚ƒ = 77
(the specific topological type studied in [11]). To be precise: we work
on a 7-dimensional domain that serves as a computational proxy for the
gluing region where the two ACyl Calabiâ€“Yau building blocks meet; a
complete global metric would require extending the solution into the
bulk of each building block.

The key technical contribution is a **Cholesky parameterization
with analytical warm-start**: the network outputs a lower-triangular
perturbation Î´L(x), and the metric is g(x) = (Lâ‚€ + Î´L(x))(Lâ‚€ + Î´L(x))áµ€,
where Lâ‚€ is the Cholesky factor of an analytically derived target. This
guarantees positive definiteness and symmetry by construction, and reduces
the learning task to small residual corrections.

### 1.3 Motivation from the GIFT framework

The analytical target and the period integrals used as training data derive
from the GIFT (Geometric Information Field Theory) framework [12], which
proposes that physical constants arise from the topology of Eâ‚ˆ Ã— Eâ‚ˆ
compactifications on Gâ‚‚ manifolds. While the physical claims of GIFT are
outside the scope of this paper, the mathematical objects it produces
(the Gâ‚‚ decomposition, the Mayerâ€“Vietoris splitting of moduli, and the
determinant formula det(g) = 65/32) are independently verifiable
statements in differential geometry. We use them as input data and
verify the output against standard geometric criteria.

### 1.4 Summary of results

| Criterion | Target | Achieved |
|-----------|--------|----------|
| det(g) = 65/32 | 2.03125 | 2.031250001 (4 Ã— 10â»â¸ %) |
| Positive definite | All Î»áµ¢ > 0 | Î»_min = 1.099 (Cholesky guarantee) |
| Condition number | 1.01518 | 1.01518 (7 significant figures) |
| Torsion â€–dÏ†â€–+â€–d*Ï†â€– | small | 7.2 Ã— 10â»â¶ |
| Period integrals | RMS < 0.005 | 0.000311 (16-fold below threshold) |
| Anisotropy | â€–g âˆ’ G_TARGETâ€–_F â†’ 0 | 1.76 Ã— 10â»â· (machine precision) |

Training time: 2.9 minutes on a single A100 GPU. Model: 202,857 parameters.

### 1.5 Outline

Section 2 recalls the Gâ‚‚ structure and the TCS construction. Section 3
describes the analytical derivation of the target metric. Section 4
presents the PINN architecture and training. Section 5 gives the explicit
metric and verification results. Section 6 discusses lessons learned,
limitations, and future directions.

---

## 2. The Gâ‚‚ Structure and TCS Construction

### 2.1 Holonomy contained in Gâ‚‚ and the associative 3-form

The exceptional Lie group Gâ‚‚ is the automorphism group of the octonion
algebra ğ•†. It acts on Im(ğ•†) â‰… â„â· and preserves the standard associative
3-form [1]:

$$
\varphi_0 = e^{012} + e^{034} + e^{056} + e^{135} - e^{146} - e^{236} - e^{245}
$$

where e^{ijk} = eâ± âˆ§ eÊ² âˆ§ eáµ and the indices correspond to the 7
imaginary octonion units. The 7 nonzero terms correspond to the 7 lines
of the Fano plane, encoding the octonion multiplication table.

Under Gâ‚‚, the space of 3-forms decomposes as:

$$
\Lambda^3(\mathbb{R}^7) = \Lambda^3_1 \oplus \Lambda^3_7 \oplus \Lambda^3_{27}
$$

with dimensions 1 + 7 + 27 = 35 = C(7,3). The Gâ‚‚ metric is recovered
from the 3-form via [2]:

$$
g_{ij} = \frac{1}{6} \sum_{k,l} \varphi_{ikl}\,\varphi_{jkl}
$$

For the standard Ï†â‚€, this gives g = Iâ‚‡. A rescaled form Ï† = c Â· Ï†â‚€ with
c = (65/32)^{1/14} yields g = cÂ² Â· Iâ‚‡ with det(g) = cÂ¹â´ = 65/32.

### 2.2 The TCS construction

The manifold Kâ‚‡ is constructed as a twisted connected sum [5, 6]:

$$
K_7 = M_1 \cup_\Phi M_2
$$

where Mâ‚ and Mâ‚‚ are asymptotically cylindrical Calabiâ€“Yau threefolds,
glued along their common asymptotic cross-section SÂ¹ Ã— K3:

| Building block | Construction | bâ‚‚ | bâ‚ƒ |
|---------------|-------------|-----|-----|
| Mâ‚ | ACyl CY from quintic in â„‚â„™â´ | 11 | 40 |
| Mâ‚‚ | ACyl CY from CI(2,2,2) in â„‚â„™â¶ | 10 | 37 |
| K3 (gluing) | K3 surface, bâ‚‚ = 22 | N/A | N/A |

The Mayerâ€“Vietoris sequence gives:

$$
b_2(K_7) = b_2(M_1) + b_2(M_2) = 11 + 10 = 21
$$
$$
b_3(K_7) = b_3(M_1) + b_3(M_2) = 40 + 37 = 77
$$

Since Kâ‚‡ is a compact orientable manifold of odd dimension, PoincarÃ©
duality (bâ‚– = b_{7âˆ’k}) implies Ï‡(Kâ‚‡) = 0. Explicitly:
bâ‚€ = bâ‚‡ = 1, bâ‚ = bâ‚† = 0, bâ‚‚ = bâ‚… = 21, bâ‚ƒ = bâ‚„ = 77, giving
Ï‡ = 1 âˆ’ 0 + 21 âˆ’ 77 + 77 âˆ’ 21 + 0 âˆ’ 1 = 0.

### 2.3 Pointwise representation theory

At each point of a 7-manifold with Gâ‚‚-structure, the space of 3-forms
decomposes under Gâ‚‚ as (cf. Â§2.1):

$$
\Lambda^3(\mathbb{R}^7) = \Lambda^3_1 \oplus \Lambda^3_7 \oplus \Lambda^3_{27},
\qquad 1 + 7 + 27 = 35 = \binom{7}{3}.
$$

This is a *pointwise* statement in representation theory: at each point
x âˆˆ Kâ‚‡, a 3-form has 35 components that transform in these three
irreducible Gâ‚‚-representations. Among the 35 directions, the 7 that are
aligned with the Fano-plane triples of the octonion multiplication table
generate volume-changing deformations (Tr(âˆ‚g/âˆ‚Î ) = Â±2.10), while the
remaining 28 in Î›Â³â‚‚â‚‡ are traceless (pure shape deformations). The vanishing
trace for non-Fano modes is exact, following from the orthogonality of
Î›Â³â‚‚â‚‡ to the trivial representation Î›Â³â‚.

### 2.4 Global moduli space

The moduli space of torsion-free Gâ‚‚ structures on Kâ‚‡ is a smooth manifold
of dimension bâ‚ƒ(Kâ‚‡) = 77 [3, 4]. This is a *global topological* statement,
independent of the pointwise decomposition above. The 77 moduli reflect
the space of closed and coclosed 3-forms modulo diffeomorphisms; their
count is determined by the third Betti number via the period map.

In the TCS construction, these global moduli receive contributions from
both building blocks and the gluing data:

| Contribution | Source |
|-------------|--------|
| HÂ³(Mâ‚) | 40 classes from the first ACyl CY threefold |
| HÂ³(Mâ‚‚) | 37 classes from the second ACyl CY threefold |
| **Total** | **bâ‚ƒ(Kâ‚‡) = 77** |

---

## 3. The Analytical Target Metric

### 3.1 Period integrals

Each modulus Î â‚– (k = 1, ..., 77) corresponds to a period integral of the
associative 3-form over a 3-cycle Câ‚– âˆˆ Hâ‚ƒ(Kâ‚‡, â„¤):

$$
\Pi_k = \int_{C_k} \varphi
$$

We use period data derived from the GIFT framework [12], where the 77
periods are computed from prime-number data at multiple energy scales T.
The specific values are determined by the torsion coupling constant
Îº_T = 1/61 and the adaptive cutoff function X(T) described in [13].

### 3.2 The metric Jacobian

The metric response to moduli variations is given by the Jacobian:

$$
\frac{\partial g_{ij}}{\partial \Pi_k}
= \frac{1}{3}\sum_l \left(\varphi_{ikl}\,\frac{\partial\varphi_{jkl}}{\partial\Pi_k}
+ \frac{\partial\varphi_{ikl}}{\partial\Pi_k}\,\varphi_{jkl}\right)
$$

Evaluating this for the 35 pointwise modes (Â§2.3), the 7 modes aligned with the Fano-plane triples
have Tr(âˆ‚g/âˆ‚Î ) = Â±2.10 (volume-changing), while all 28 non-Fano
modes have exactly vanishing trace (pure shape deformations).

### 3.3 The target metric G_TARGET

Evaluating the metric Jacobian at the reference periods yields a 7Ã—7
target metric with the following properties:

| Property | Value |
|----------|-------|
| Diagonal range | [1.1022, 1.1133] |
| Max off-diagonal | 0.00461 (gâ‚‚â‚ƒ) |
| Condition number Îº | 1.01518 |
| Determinant (after rescaling) | 65/32 = 2.03125 |
| Eigenvalue range | [1.0993, 1.1160] |

The anisotropy is small (~1.5% diagonal variation) but structurally
significant: it encodes the breaking of the isotropic Gâ‚‚ structure
by the TCS gluing map Î¦.

### 3.4 The Eâ‚ˆ/K3 lattice structure

The global modes are organized by the K3 lattice Î›_{K3} of signature
(3, 19) and rank 22, which contains two sublattices:

- Nâ‚ of rank 11, signature (1, 9): the polarization lattice of Mâ‚
- Nâ‚‚ of rank 10, signature (1, 8): the polarization lattice of Mâ‚‚

with Nâ‚ âˆ© Nâ‚‚ = {0} and rank(Nâ‚ + Nâ‚‚) = 21 = bâ‚‚(Kâ‚‡). The K3
intersection form is Î›_{K3} = 3H âŠ• 2(âˆ’Eâ‚ˆ), where H is the hyperbolic
lattice and Eâ‚ˆ is the positive-definite Eâ‚ˆ root lattice. The presence
of Eâ‚ˆ in the gluing data constrains the global moduli and connects the
metric to exceptional Lie algebra structure.

---

## 4. PINN Architecture and Training

### 4.1 The parameterization challenge

The goal is to find a spatially varying metric field g : Kâ‚‡ â†’ Symâºâ‚‡(â„)
satisfying simultaneously:

1. det(g(x)) = 65/32 at every point
2. g(x) > 0 (positive definite)
3. dÏ† â‰ˆ 0 and d*Ï† â‰ˆ 0 (torsion-free, where Ï† is reconstructed from g)
4. âˆ«_{Câ‚–} Ï† = Î â‚– for k = 1, ..., 77 at multiple scales
5. Spatial average âŸ¨gâŸ© â‰ˆ G_TARGET

This is a PDE-constrained optimization problem on a 7-dimensional
computational domain modelling the TCS neck region (cf. Â§1.2).

### 4.2 Failed approaches and lessons

Before describing the successful architecture, we briefly document two
failed approaches, as the failure modes are instructive.

**Attempt 1 (Gâ‚‚ adjoint parameterization):** A network outputs 14
parameters in the Gâ‚‚ Lie algebra, which are exponentiated to produce
a Gâ‚‚ rotation, applied to Ï†â‚€ via Lie derivatives to generate a deformed
3-form, from which the metric is extracted. *Failure mode:* the 14 â†’ 35
map via Lie derivatives has rank 6, creating a 6-dimensional bottleneck
in the 28-dimensional space of symmetric metric perturbations. The
network cannot access 22 of the 28 metric degrees of freedom.

**Attempt 2 (Anisotropy loss):** Same architecture as above with an
additional loss â€–âŸ¨gâŸ© âˆ’ G_TARGETâ€–Â²_F. *Failure mode:* 97.6% of the loss
gradient comes from the anisotropy term, but the rank-6 bottleneck
prevents the network from responding. The loss plateaus after ~100 steps
and remains constant for the remaining 4,900.

**Lesson:** When the architecture fundamentally cannot represent the
target (rank deficiency), no amount of training or hyperparameter tuning
will help. The bottleneck must be removed at the architectural level.

### 4.3 The Cholesky parameterization (successful)

We parameterize the metric directly via a Cholesky decomposition:

$$
g(x) = L(x) \cdot L(x)^\top, \qquad L(x) = L_0 + \delta L(x)
$$

where Lâ‚€ = chol(G_TARGET) is the Cholesky factor of the analytical target,
and Î´L(x) is a lower-triangular matrix output by the network.

| Property | Gâ‚‚ adjoint | Cholesky (this work) |
|----------|-------------------|---------------|
| Metric DOF per point | 6 (rank of Lie derivs) | **28** (full) |
| Initialization | cÂ²Â·Iâ‚‡ (far from target) | **G_TARGET** (at target) |
| Positive definiteness | Requires penalty loss | **Free** (LLáµ€ â‰¥ 0) |
| Symmetry | Via einsum contraction | **Free** (LLáµ€ = (LLáµ€)áµ€) |
| Gradient path | MLP â†’ adj â†’ Lie â†’ Ï† â†’ g | MLP â†’ Î´L â†’ g |

**Network architecture:**

```
Input: (xÂ¹, ..., xâ·, log T) âˆˆ â„â¸
  â†“
FourierFeatures(48 frequencies) â†’ â„â¹â¶
  â†“
MLP: 96 â†’ 256 â†’ 256 â†’ 256 â†’ 128 (ReLU activations)
  â†“
â”œâ”€â”€ Metric head: 128 â†’ 28 (lower triangular Î´L)
â”‚     g(x) = (Lâ‚€ + Î´L(x))(Lâ‚€ + Î´L(x))áµ€
â”‚
â””â”€â”€ 3-form heads: 128 â†’ 35 (local) + 42 (global)
      Ï†(x) = cÂ·Ï†â‚€ + 0.1Â·Î´Ï†(x)
```

Total parameters: 202,857.

### 4.4 Loss function

The loss has five terms:

| Term | Formula | Weight | Purpose |
|------|---------|--------|---------|
| L_det | (det(g) âˆ’ 65/32)Â² | 100 | Topological constraint |
| L_aniso | â€–âŸ¨gâŸ© âˆ’ G_TARGETâ€–Â²_F | 500 | Analytical target |
| L_period | Î£_T â€–âŸ¨Î´Ï†âŸ©_T âˆ’ Î (T)â€–Â² / 5 | 1000 | 77 periods Ã— 5 scales |
| L_torsion | â€–dÏ†â€–Â² + â€–d*Ï†â€–Â² (finite diff.) | 1 | Torsion-free condition |
| L_sparse | â€–Î´Lâ€–Â² | 0.01 | Regularization |

The period loss averages over 5 energy scales (T = 100, 1000, 10000,
40000, 75000), each activating a different number of effective moduli
(from 5 to all 77).

### 4.5 Training protocol

Training proceeds in two phases over 5,000 epochs on a single NVIDIA
A100-SXM4-80GB GPU:

**Phase 1 (epochs 0â€“2,500):** Learning rate 10â»Â³ with cosine annealing.
The warm-start means the determinant and anisotropy losses are already
near zero at initialization; the network primarily learns the period
integrals and torsion structure.

**Phase 2 (epochs 2,500â€“5,000):** Learning rate 10â»â´. Fine-tuning.
By epoch 3,500, the determinant and anisotropy losses reach machine
precision (10â»Â¹âµ to 10â»Â¹â¸), and the residual loss is dominated entirely
by the period term.

**Training dynamics:**

| Epoch | Total loss | L_det | L_aniso | L_period | L_torsion |
|-------|-----------|-------|---------|----------|-----------|
| 0 | 4.33Ã—10â»Â³ | 2.7Ã—10â»Â²Â¹ | 9.8Ã—10â»Â²âµ | 4.3Ã—10â»â¶ | 3.6Ã—10â»Â²Â³ |
| 100 | 1.51Ã—10â»Â³ | 4.9Ã—10â»â¶ | 3.2Ã—10â»â· | 8.6Ã—10â»â· | 9.5Ã—10â»Â¹â° |
| 500 | 6.28Ã—10â»â´ | 2.0Ã—10â»â¶ | 8.3Ã—10â»â¸ | 3.9Ã—10â»â· | 2.6Ã—10â»Â¹â° |
| 2000 | 4.37Ã—10â»â´ | 3.8Ã—10â»â· | 1.7Ã—10â»â¸ | 3.9Ã—10â»â· | 5.4Ã—10â»Â¹Â¹ |
| 3500 | 3.91Ã—10â»â´ | 1.1Ã—10â»Â¹â· | 8.9Ã—10â»Â¹âµ | 3.9Ã—10â»â· | 1.1Ã—10â»Â¹Â¹ |
| 5000 | 3.91Ã—10â»â´ | 3.8Ã—10â»Â¹â¸ | 2.9Ã—10â»Â¹âµ | 3.9Ã—10â»â· | 1.1Ã—10â»Â¹Â¹ |

At convergence, 100% of the residual loss is from the period integrals.
The metric constraints (determinant, anisotropy, positive definiteness)
are satisfied to machine precision.

Total training time: **2.9 minutes**.

---

## 5. The Explicit Metric

### 5.1 The 7Ã—7 metric tensor

The spatially averaged metric over 50,000 points on the TCS neck:

```
g_mean =
  â”Œ                                                                      â”
  â”‚ 1.11332  +0.00098  -0.00072  -0.00019  +0.00341  +0.00285  -0.00305 â”‚
  â”‚+0.00098   1.11055  -0.00081  +0.00123  -0.00419  +0.00018  -0.00325 â”‚
  â”‚-0.00072  -0.00081   1.10908  +0.00461  +0.00085  +0.00269  +0.00069 â”‚
  â”‚-0.00019  +0.00123  +0.00461   1.10430  -0.00069  +0.00010  -0.00135 â”‚
  â”‚+0.00341  -0.00419  +0.00085  -0.00069   1.10263  +0.00154  -0.00001 â”‚
  â”‚+0.00285  +0.00018  +0.00269  +0.00010  +0.00154   1.10385  -0.00066 â”‚
  â”‚-0.00305  -0.00325  +0.00069  -0.00135  -0.00001  -0.00066   1.10217 â”‚
  â””                                                                      â”˜
```

### 5.2 Comparison with analytical target

| Component | Target | Achieved | Absolute error |
|-----------|--------|----------|---------------|
| gâ‚€â‚€ | 1.113320 | 1.113320 | 1.5 Ã— 10â»â· |
| gâ‚â‚ | 1.110552 | 1.110552 | 1.6 Ã— 10â»â· |
| gâ‚‚â‚‚ | 1.109078 | 1.109078 | 2.5 Ã— 10â»â¸ |
| gâ‚ƒâ‚ƒ | 1.104300 | 1.104300 | 2.3 Ã— 10â»â· |
| gâ‚„â‚„ | 1.102633 | 1.102633 | 1.7 Ã— 10â»â· |
| gâ‚…â‚… | 1.103852 | 1.103852 | 1.4 Ã— 10â»â¸ |
| gâ‚†â‚† | 1.102167 | 1.102167 | 2.7 Ã— 10â»â· |
| gâ‚‚â‚ƒ (max off-diag) | +0.004613 | +0.004613 | 1.0 Ã— 10â»â¶ |
| **â€–g âˆ’ G_TARGETâ€–_F** | N/A | N/A | **1.76 Ã— 10â»â·** |

Relative error: 4.4 Ã— 10â»â¸ (maximum elementwise error / maximum entry).

### 5.3 Eigenvalues

| | Target | Achieved | Error |
|---|--------|----------|-------|
| Î»â‚ | 1.09926643 | 1.09926642 | 1 Ã— 10â»â¸ |
| Î»â‚‚ | 1.10004584 | 1.10004584 | < 10â»â¸ |
| Î»â‚ƒ | 1.10124313 | 1.10124311 | 2 Ã— 10â»â¸ |
| Î»â‚„ | 1.10334338 | 1.10334338 | < 10â»â¸ |
| Î»â‚… | 1.11246355 | 1.11246359 | 4 Ã— 10â»â¸ |
| Î»â‚† | 1.11358841 | 1.11358840 | 1 Ã— 10â»â¸ |
| Î»â‚‡ | 1.11595127 | 1.11595127 | < 10â»â¸ |

All seven eigenvalues matched to **8 significant figures**.

### 5.4 Determinant

$$
\det(g) = 2.031250001 \pm 9.5 \times 10^{-9}
$$

$$
\text{Target:}\; 65/32 = 2.031250000, \qquad
\text{Deviation:}\; 4 \times 10^{-8}\,\%
$$

### 5.5 Torsion

The torsion of a Gâ‚‚-structure Ï† is measured by the failure of Ï† to be
closed and coclosed. Following Joyce [4, Theorem 11.6.1], if a
compact 7-manifold admits a Gâ‚‚-structure Ï†â‚€ with â€–dÏ†â‚€â€–_{Câ°} + â€–d*Ï†â‚€â€–_{Câ°}
sufficiently small (below a constant Îµâ‚€ depending on the geometry), then
there exists a nearby torsion-free Gâ‚‚-structure Ï†Ìƒ with Hol(gÌƒ) âŠ† Gâ‚‚.

We evaluate the torsion of our candidate using finite-difference
approximations of dÏ† and d*Ï† on the computational domain:

| Quantity | Value |
|----------|-------|
| Mean â€–dÏ†â€– + â€–d*Ï†â€– | 3.3 Ã— 10â»â¶ |
| Max â€–dÏ†â€– + â€–d*Ï†â€– | 7.2 Ã— 10â»â¶ |

The absolute value of the torsion is small, but we emphasize two caveats:
(i) Joyce's Îµâ‚€ depends on the manifold and the approximate solution, and
we have not computed it for our specific setting; (ii) our computation
covers only the neck region, not the full compact manifold. We therefore
report the torsion as evidence that the candidate is a good *numerical*
approximation to a torsion-free structure, without claiming to have
verified the hypotheses of Joyce's theorem.

### 5.6 Scale invariance

The metric is evaluated at five energy scales T, at which different
numbers of moduli are active:

| Scale T | det deviation | Condition Îº | Active moduli |
|---------|---------------|-------------|---------------|
| 100 | 3.7 Ã— 10â»â¸ % | 1.0151782 | 5 |
| 1,000 | 4.5 Ã— 10â»â¸ % | 1.0151782 | 66 |
| 10,000 | 4.0 Ã— 10â»â¸ % | 1.0151782 | 77 |
| 40,000 | 3.9 Ã— 10â»â¸ % | 1.0151782 | 77 |
| 75,000 | 4.6 Ã— 10â»â¸ % | 1.0151782 | 77 |

The condition number is **identical to 7 significant figures** at every
scale. The metric structure is independent of the scale at which the
period data is supplied.

### 5.7 Period integrals

| Scale T | RMS error | Correlation (local) | Active modes |
|---------|-----------|---------------------|-------------|
| 100 | 0.00110 | 0.920 | 5 |
| 1,000 | 0.000358 | 0.999 | 66 |
| **10,000** | **0.000311** | **0.996** | **77** |
| 40,000 | 0.000479 | 0.995 | 77 |
| 75,000 | 0.000540 | 0.995 | 77 |

Best fit at T = 10,000 (RMS = 3.11 Ã— 10â»â´, 16-fold below threshold).

---

## 6. Discussion

### 6.1 Summary of contributions

1. **A numerical candidate metric on a compact Gâ‚‚ manifold.** Previous
   work established existence (Joyce [3]) and gave constructions
   (Kovalev [5], Corti-Haskins-NordstrÃ¶m-Pacini (CHNP) [6]), but, to our knowledge, explicit pointwise
   numerical values of g_ij(x) have not been reported for the compact case.
   We note that substantial numerical work exists for non-compact Gâ‚‚
   manifolds, and that our result covers only the TCS neck region
   (see Â§6.3).

2. **PINNs applied to special holonomy geometry.** The Cholesky warm-start
   technique may be applicable to other settings where an analytical
   approximation is available (e.g., Spin(7) manifolds, Calabiâ€“Yau metrics
   beyond the KÃ¤hler class).

### 6.2 The Cholesky warm-start technique

The key insight is to decompose the problem:

$$
g(x) = g_{\text{target}} + \delta g(x), \qquad
\delta g \text{ small}
$$

and parameterize via L(x) = Lâ‚€ + Î´L(x) where Lâ‚€ = chol(g_target). This
has three advantages:

1. **Guaranteed constraints**: positive definiteness and symmetry are
   automatic, eliminating two loss terms and simplifying the optimization
   landscape.
2. **Warm start**: the network begins at the analytical solution and only
   needs to learn corrections of order 10â»â·, not the full metric from
   scratch.
3. **Full rank**: unlike Lie-algebraic parameterizations which may have
   rank deficiencies (as demonstrated by our earlier attempts), the
   Cholesky approach has 28 independent degrees of freedom per point
   (the full dimension of Symâ‚‡(â„)).

### 6.3 Limitations

1. **Local model, not global**: Our metric is defined on a computational
   model of the TCS neck region. A complete global metric would require
   extending the solution into the bulk of Mâ‚ and Mâ‚‚, where it
   approaches the known Calabiâ€“Yau metrics.

2. **Period data from GIFT**: The training targets (77 period integrals)
   are derived from the GIFT framework. While the metric itself is
   independently verifiable (det, torsion, positive definiteness are geometric properties),
   the specific values of the periods inherit any limitations of GIFT.

3. **Determinant value**: The target det(g) = 65/32 is derived within GIFT
   from the formula det(g) = (dim(Eâ‚ˆ) + dim(Gâ‚‚) + rank(Eâ‚ˆ) + dim(Kâ‚‡))
   / (2âµ). An independent derivation from pure Gâ‚‚ geometry would
   strengthen the result.

4. **Neural network representation**: The metric is stored as a trained
   neural network, not a closed-form expression. While this is standard
   in the PINN literature, it limits analytical manipulation.

### 6.4 Future directions

1. **Extension to the bulk**: Solve the torsion-free equations dÏ† = 0,
   d*Ï† = 0 as a boundary-value problem, using the neck-region metric as
   a boundary condition and the known ACyl CY metrics on Mâ‚, Mâ‚‚ as
   asymptotic data.

2. **Other topological types**: Apply the same pipeline to other TCS
   manifolds from the CHNP classification, to understand how the metric
   depends on the topology (bâ‚‚, bâ‚ƒ).

3. **Spectral geometry**: Use the explicit metric to compute Laplacian
   eigenvalues, harmonic forms, and other spectral invariants that were
   previously inaccessible for compact Gâ‚‚ manifolds.

4. **Comparison with flow methods**: Compare the PINN metric with results
   from Laplacian flow [14] or Hitchin flow, which provide alternative
   computational approaches to Gâ‚‚ metrics.

---

## References

[1] Harvey, R. & Lawson, H.B. (1982). Calibrated geometries. *Acta Math.*
    148, 47â€“157.

[2] Bryant, R.L. (1987). Metrics with exceptional holonomy. *Ann. Math.*
    126(3), 525â€“576.

[3] Joyce, D.D. (1996). Compact Riemannian 7-manifolds with holonomy Gâ‚‚.
    I, II. *J. Diff. Geom.* 43(2), 291â€“328 and 329â€“375.

[4] Joyce, D.D. (2000). *Compact Manifolds with Special Holonomy*. Oxford
    University Press.

[5] Kovalev, A.G. (2003). Twisted connected sums and special Riemannian
    holonomy. *J. Reine Angew. Math.* 565, 125â€“160.

[6] Corti, A., Haskins, M., NordstrÃ¶m, J. & Pacini, T. (2015). Gâ‚‚-manifolds
    and associative submanifolds via semi-Fano 3-folds. *Duke Math. J.*
    164(10), 1971â€“2092.

[7] Raissi, M., Perdikaris, P. & Karniadakis, G.E. (2019). Physics-informed
    neural networks: A deep learning framework for solving forward and inverse
    problems involving nonlinear partial differential equations. *J. Comput.
    Phys.* 378, 686â€“707.

[8] Cai, S. et al. (2021). Physics-informed neural networks (PINNs) for
    fluid mechanics: A review. *Acta Mechanica Sinica* 37, 1727â€“1738.

[9] Hermann, J. et al. (2020). Deep-neural-network solution of the
    electronic SchrÃ¶dinger equation. *Nature Chemistry* 12, 891â€“897.

[10] Liao, S. & Petzold, L. (2023). Physics-informed neural networks for
     solving Einstein field equations. Preprint, arXiv:2302.10696.

[11] Braun, A.P., Del Zotto, M., Halverson, J., Larfors, M., Morrison, D.R.
     & SchÃ¤fer-Nameki, S. (2018). Infinitely many M2-instanton corrections
     to M-theory on Gâ‚‚-manifolds. *JHEP* 2018, 101.

[12] de La FourniÃ¨re, B. (2026). Geometric Information Field Theory v3.3.
     Technical report. github.com/gift-framework. (Companion paper:
     source of the analytical target and period data used here.)

[13] de La FourniÃ¨re, B. (2026). A parameter-free mollified approximation
     to the argument of the Riemann zeta function. Preprint. (Companion
     paper: source of the adaptive cutoff X(T).)

[14] Lotay, J.D. & Wei, Y. (2019). Laplacian flow for closed Gâ‚‚ structures:
     Shi-type estimates, uniqueness and compactness. *Geom. Funct. Anal.*
     29, 1048â€“1110.

[15] Brandhuber, A., Gomis, J., Gubser, S.S. & Gukov, S. (2001). Gauge
     theory at large N and new Gâ‚‚ holonomy metrics. *Nuclear Phys. B*
     611, 179â€“204.

---

## Appendix A. Topological Constants

All constants derive from the topology of Kâ‚‡ and related algebraic
structures. None are fitted.

| Symbol | Value | Definition |
|--------|-------|------------|
| dim(Kâ‚‡) | 7 | Manifold dimension |
| dim(Gâ‚‚) | 14 | Holonomy group dimension |
| dim(Eâ‚ˆ) | 248 | Exceptional Lie algebra |
| bâ‚‚(Kâ‚‡) | 21 | Second Betti number |
| bâ‚ƒ(Kâ‚‡) | 77 | Third Betti number (= dim moduli) |
| C(7,3) | 35 | dim Î›Â³(â„â·) (local modes) |
| Îº_T | 1/61 | Torsion coupling constant |
| det(g) | 65/32 | Metric determinant |

---

## Appendix B. Reproducibility

### B.1 Code and data

| Resource | Location |
|----------|----------|
| PINN notebook (v3) | `notebooks/K7_PINN_Step5_Reconstruction_v3.ipynb` |
| Pre-computed data | `notebooks/riemann/*.json` (Steps 1â€“4) |
| Repository | github.com/gift-framework/GIFT |

### B.2 Hardware

| | Specification |
|---|---------------|
| GPU | NVIDIA A100-SXM4-80GB |
| Training time | 2.9 minutes |
| Parameters | 202,857 |
| Epochs | 5,000 |
| Evaluation points | 50,000 |
| Peak memory | ~1â€“2 GB |

### B.3 Dependencies

```
torch >= 2.0 (float64 mode)
numpy, scipy, matplotlib, tqdm
cupy-cuda12x (optional, for spectral analysis)
```

### B.4 To reproduce

1. Open `notebooks/K7_PINN_Step5_Reconstruction_v3.ipynb` in Google Colab
2. Select A100 GPU runtime
3. Run all cells
4. Results exported to `k7_pinn_step5_results_v3.json`

No manual intervention required.

---

*Manuscript prepared February 2026.*
