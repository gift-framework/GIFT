\documentclass[11pt,a4paper]{article}

% ============================================
% ENCODING & FONTS
% ============================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

% ============================================
% PAGE LAYOUT (Golden Ratio)
% ============================================
\usepackage[margin=1.618cm, top=2.618cm, bottom=2.618cm]{geometry}

% ============================================
% ESSENTIAL PACKAGES
% ============================================
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{listings}

% ============================================
% LISTINGS CONFIGURATION (for code blocks)
% ============================================
\lstset{
    basicstyle=\small\ttfamily,
    breaklines=true,
    frame=single,
    keepspaces=true,
    showstringspaces=false,
    breakatwhitespace=true,
    aboveskip=0.8em,
    belowskip=0.8em,
    language=Python,
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    stringstyle=\color{red}
}

% Prevent page breaks inside listings
\lstnewenvironment{nopagebreakcode}[1][]
{
    \minipage{\linewidth}
    \lstset{#1}
}
{
    \endminipage
}

% For bash code
\lstnewenvironment{nopagebreakbash}[1][]
{
    \minipage{\linewidth}
    \lstset{language=bash,#1}
}
{
    \endminipage
}

% ============================================
% HEADER/FOOTER CONFIGURATION
% ============================================
\setlength{\headheight}{14pt}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{GIFT Framework - Supplement S6}
\fancyhead[R]{\thepage}
\renewcommand{\headrulewidth}{0.2pt}

% ============================================
% HYPERREF CONFIGURATION
% ============================================
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
    pdftitle={GIFT Supplement S6: Numerical Methods},
    pdfauthor={Brieuc de La Fournière}
}

% ============================================
% SPACING AND FORMATTING
% ============================================
\setstretch{1.2}
\setlength{\parskip}{0.4em}
\setlength{\parindent}{0pt}

% ============================================
% TITLE FORMATTING
% ============================================
\usepackage{titling}
\pretitle{\LARGE\bfseries}
\posttitle{\vspace{-0.4em}}
\preauthor{}
\postauthor{}
\predate{}
\postdate{}
\setlength{\droptitle}{-2.0em}

% ============================================
% CUSTOM COMMANDS
% ============================================
\newcommand{\E}{\mathrm{E}}
\newcommand{\Gtwo}{\mathrm{G}_2}
\newcommand{\Kseven}{K_7}
\newcommand{\AdS}{\mathrm{AdS}}
\newcommand{\dimE}{\mathrm{dim}}
\newcommand{\Weyl}{\mathrm{Weyl}}
\newcommand{\rk}{\mathrm{rank}}
\newcommand{\SM}{\mathrm{SM}}
\newcommand{\SU}{\mathrm{SU}}
\newcommand{\SO}{\mathrm{SO}}
\newcommand{\U}{\mathrm{U}}

% ============================================
% TITLE PAGE SETUP
% ============================================
\title{%
\LARGE\textbf{Supplement S6: Numerical Methods\\[0.5em]
\large Algorithms, Implementation, and Validation}
}
\author{}
\date{}

% ============================================
% DOCUMENT START
% ============================================
\begin{document}

% ============================================
% TITLE PAGE WITH CUSTOM LAYOUT
% ============================================
\maketitle
\noindent\rule{\textwidth}{0.2pt}

\vspace{0.5em}

{GIFT Framework v2.1\\
Geometric Information Field Theory}

\vfill

\begin{abstract}
This supplement documents the computational framework, algorithms, and validation procedures used in GIFT numerical calculations. We present the complete software stack, core algorithms for observable computation, statistical validation methods, K\textsubscript{7} metric reconstruction using neural networks, and comprehensive testing procedures. All code is open-source and reproducible.

\vspace{0.5em}

\textbf{Keywords}: Numerical methods, machine learning, validation, reproducibility, open-source
\end{abstract}

\vfill

\noindent\rule{\textwidth}{0.2pt}

\newpage

% ============================================
% TABLE OF CONTENTS
% ============================================
\tableofcontents
\newpage

% ============================================
% MAIN CONTENT
% ============================================

\section{Computational Framework}

\subsection{Software Stack}

The GIFT computational framework relies on standard scientific Python libraries:

\begin{nopagebreakcode}
# Core numerical libraries
numpy>=1.24.0      # Array operations
scipy>=1.10.0      # Scientific computing
sympy>=1.11.0      # Symbolic mathematics

# Machine learning
torch>=2.0.0       # Neural networks for K7 metric

# Visualization
matplotlib>=3.7.0  # Plotting
plotly>=5.14.0     # Interactive 3D

# Statistical analysis
pandas>=2.0.0      # Data manipulation
statsmodels>=0.14  # Statistical models
\end{nopagebreakcode}

\subsection{Hardware Requirements}

\textbf{Minimum configuration}:
\begin{itemize}
    \item CPU: 8 cores
    \item RAM: 32 GB
    \item Storage: 100 GB SSD
\end{itemize}

\textbf{Recommended for ML training}:
\begin{itemize}
    \item GPU: NVIDIA A100 (40GB) or equivalent
    \item RAM: 128 GB
    \item Storage: 1 TB NVMe
\end{itemize}

\subsection{Installation}

\begin{nopagebreakbash}
# Clone repository
git clone https://github.com/gift-framework/GIFT.git
cd GIFT

# Create virtual environment
python -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
\end{nopagebreakbash}

\section{Core Algorithms}

\subsection{Topological Parameter Computation}

All topological parameters are computed exactly from integer arithmetic:

\begin{nopagebreakcode}
import numpy as np

# E8 parameters
dim_E8 = 248
rank_E8 = 8

# K7 cohomology
b2_K7 = 21
b3_K7 = 77
H_star = b2_K7 + b3_K7 + 1  # = 99

# G2 parameters
dim_G2 = 14
dim_K7 = 7

# Derived parameters
p2 = dim_G2 / dim_K7  # = 2 (exact)
Wf = 5  # Weyl factor

# Base coupling
beta_0 = np.pi / rank_E8
xi = (Wf / p2) * beta_0  # = 5*pi/16
\end{nopagebreakcode}

\subsection{Observable Computation}

Example: Computing gauge couplings

\begin{nopagebreakcode}
def compute_gauge_couplings():
    """Compute the three gauge coupling constants."""
    
    # Fine structure constant inverse
    alpha_inv = (dim_E8 + rank_E8) / 2  # = 128
    
    # Weinberg angle
    zeta_3 = 1.2020569031595943  # Apery's constant
    gamma_euler = 0.5772156649015329
    M2 = 3  # Second Mersenne prime
    sin2_theta_W = zeta_3 * gamma_euler / M2
    
    # Strong coupling
    W_G2 = 12  # |W(G2)| Weyl group order
    alpha_s = np.sqrt(2) / W_G2
    
    return {
        'alpha_inv_MZ': alpha_inv,
        'sin2_theta_W': sin2_theta_W,
        'alpha_s_MZ': alpha_s
    }
\end{nopagebreakcode}

\subsection{Neutrino Mixing Angles}

\begin{nopagebreakcode}
def compute_neutrino_mixing():
    """Compute PMNS mixing parameters."""
    
    # Reactor angle (exact)
    theta_13 = np.pi / b2_K7  # = pi/21
    
    # Atmospheric angle
    theta_23_rad = (rank_E8 + b3_K7) / H_star  # = 85/99
    theta_23 = np.degrees(theta_23_rad)
    
    # Solar angle
    delta = 2 * np.pi / (Wf ** 2)  # = 2pi/25
    gamma_GIFT = 511 / 884
    theta_12 = np.degrees(
        np.arctan(np.sqrt(delta / gamma_GIFT))
    )
    
    # CP phase (exact)
    delta_CP = dim_K7 * dim_G2 + H_star  # = 197 degrees
    
    return {
        'theta_12': theta_12,
        'theta_13': np.degrees(theta_13),
        'theta_23': theta_23,
        'delta_CP': delta_CP
    }
\end{nopagebreakcode}

\subsection{Heat Kernel Coefficient}

The GIFT heat kernel coefficient \(\gamma_{\text{GIFT}}\) is computed as:

\begin{nopagebreakcode}
def compute_gamma_GIFT():
    """Compute heat kernel coefficient gamma_GIFT."""
    numerator = 2 * rank_E8 + 5 * H_star
    denominator = 10 * dim_G2 + 3 * dim_E8
    return numerator / denominator  # = 511/884

# Verification
gamma_GIFT = 511 / 884
gamma_euler = 0.5772156649015329
print(f"gamma_GIFT = {gamma_GIFT:.16f}")
print(f"gamma_Euler = {gamma_euler:.16f}")
print(f"Difference = {abs(gamma_GIFT - gamma_euler):.6f}")
# Difference = 0.000839 (0.145%)
\end{nopagebreakcode}

\section{Statistical Validation}

\subsection{Monte Carlo Uncertainty Propagation}

\begin{nopagebreakcode}
def monte_carlo_validation(n_samples=1_000_000):
    """
    Monte Carlo propagation of experimental uncertainties.
    """
    import numpy as np
    
    # Experimental values with uncertainties
    exp_values = {
        'alpha_inv': (127.955, 0.016),
        'sin2_theta_W': (0.23122, 0.00004),
        'alpha_s': (0.1179, 0.0010)
    }
    
    results = {}
    for name, (mean, sigma) in exp_values.items():
        # Sample from Gaussian distribution
        samples = np.random.normal(mean, sigma, n_samples)
        
        # Compute statistics
        results[name] = {
            'mean': np.mean(samples),
            'std': np.std(samples),
            'median': np.median(samples),
            'percentile_16': np.percentile(samples, 16),
            'percentile_84': np.percentile(samples, 84)
        }
    
    return results
\end{nopagebreakcode}

\subsection{Chi-Square Analysis}

\begin{nopagebreakcode}
def chi_square_test(gift_values, exp_values, 
                    exp_uncertainties):
    """
    Compute chi-square statistic for GIFT predictions.
    """
    chi2 = 0
    n_obs = len(gift_values)
    
    for obs in gift_values:
        gift = gift_values[obs]
        exp = exp_values[obs]
        sigma = exp_uncertainties[obs]
        chi2 += ((gift - exp) / sigma) ** 2
    
    dof = n_obs - 3  # 3 free parameters
    p_value = 1 - scipy.stats.chi2.cdf(chi2, dof)
    
    return chi2, dof, p_value
\end{nopagebreakcode}

\subsection{Sobol Sensitivity Analysis}

Global sensitivity analysis identifies which parameters most affect predictions:

\begin{nopagebreakcode}
from SALib.sample import sobol as sobol_sample
from SALib.analyze import sobol as sobol_analyze

def sobol_analysis():
    """
    Sobol global sensitivity analysis for GIFT parameters.
    """
    problem = {
        'num_vars': 3,
        'names': ['p2', 'rank_E8', 'Wf'],
        'bounds': [[1.9, 2.1], [7.9, 8.1], [4.9, 5.1]]
    }
    
    # Generate samples
    param_values = sobol_sample.sample(problem, 2048)
    
    # Evaluate model at each sample point
    Y = np.array([evaluate_model(p) for p in param_values])
    
    # Analyze sensitivity
    Si = sobol_analyze.analyze(problem, Y)
    
    return Si
\end{nopagebreakcode}

\section{K\textsubscript{7} Metric Computation}

\subsection{Neural Network Architecture}

The K\textsubscript{7} metric is approximated using neural networks:

\begin{nopagebreakcode}
import torch
import torch.nn as nn

class K7MetricNetwork(nn.Module):
    """Neural network for K7 metric tensor components."""
    
    def __init__(self, hidden_dim=256):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(7, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, 28)  # 7x7 symmetric
        )
    
    def forward(self, x):
        """
        Args:
            x: Coordinates on K7, shape (batch, 7)
        Returns:
            Metric tensor components, shape (batch, 28)
        """
        return self.net(x)
    
    def get_metric(self, x):
        """Reconstruct full metric tensor."""
        components = self.forward(x)
        # Unpack to symmetric 7x7 matrix
        metric = torch.zeros(x.shape[0], 7, 7)
        idx = 0
        for i in range(7):
            for j in range(i, 7):
                metric[:, i, j] = components[:, idx]
                metric[:, j, i] = components[:, idx]
                idx += 1
        return metric
\end{nopagebreakcode}

\subsection{Training Procedure}

\begin{nopagebreakcode}
def train_k7_metric(model, dataloader, epochs=1000):
    """Train K7 metric network with G2 holonomy."""
    
    optimizer = torch.optim.Adam(
        model.parameters(), lr=1e-4
    )
    
    for epoch in range(epochs):
        for batch in dataloader:
            coords = batch['coordinates']
            
            # Get predicted metric
            g = model.get_metric(coords)
            
            # Loss 1: Ricci-flat condition
            loss_ricci = compute_ricci_loss(g, coords)
            
            # Loss 2: G2 holonomy constraint
            loss_g2 = compute_g2_loss(g, coords)
            
            # Loss 3: Determinant = p2 = 2
            det_g = torch.det(g)
            loss_det = ((det_g - 2.0) ** 2).mean()
            
            # Total loss
            loss = loss_ricci + 0.1 * loss_g2 + 0.01 * loss_det
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
\end{nopagebreakcode}

\subsection{Harmonic Form Extraction}

\begin{nopagebreakcode}
def extract_harmonic_forms(metric_network, n_points=10000):
    """
    Extract harmonic 2-forms and 3-forms from trained metric.
    
    Returns:
        h2: Array of shape (21, n_points, 21) for b2=21
        h3: Array of shape (77, n_points, 35) for b3=77
    """
    # Sample points on K7
    coords = sample_k7_manifold(n_points)
    
    # Get metric at each point
    g = metric_network.get_metric(coords)
    
    # Compute Hodge star operator
    hodge = compute_hodge_star(g)
    
    # Solve eigenvalue problem for harmonic forms
    # Laplacian eigenvalue = 0 for harmonic forms
    
    # 2-forms: 21 harmonic forms
    h2 = solve_harmonic_eigenvalue(
        hodge, degree=2, n_forms=21
    )
    
    # 3-forms: 77 harmonic forms
    h3 = solve_harmonic_eigenvalue(
        hodge, degree=3, n_forms=77
    )
    
    return h2, h3
\end{nopagebreakcode}

\section{Validation Suite}

\subsection{Unit Tests}

\begin{nopagebreakcode}
import pytest

class TestTopologicalConstants:
    """Unit tests for topological constants."""
    
    def test_betti_numbers(self):
        assert b2_K7 == 21
        assert b3_K7 == 77
        assert b2_K7 + b3_K7 == 98
    
    def test_dimensions(self):
        assert dim_E8 == 248
        assert rank_E8 == 8
        assert dim_G2 == 14
        assert dim_K7 == 7
    
    def test_p2_dual_origin(self):
        p2_local = dim_G2 / dim_K7
        p2_global = 496 / 248
        assert p2_local == 2
        assert p2_global == 2
        assert p2_local == p2_global
    
    def test_generation_number(self):
        N_gen = 168 / 56
        assert N_gen == 3
\end{nopagebreakcode}

\begin{nopagebreakcode}
class TestExactRelations:
    """Unit tests for exact topological relations."""
    
    def test_tau_electron_ratio(self):
        ratio = 7 + 10*248 + 10*99
        assert ratio == 3477
    
    def test_strange_down_ratio(self):
        ratio = 4 * 5  # p2^2 * Wf
        assert ratio == 20
    
    def test_koide_parameter(self):
        Q = 14 / 21
        assert Q == pytest.approx(2/3, rel=1e-10)
    
    def test_cp_phase(self):
        delta_CP = 7 * 14 + 99
        assert delta_CP == 197
\end{nopagebreakcode}

\subsection{Integration Tests}

\begin{nopagebreakcode}
class TestFullPipeline:
    """Integration tests for complete pipeline."""
    
    def test_gauge_sector(self):
        results = compute_gauge_couplings()
        assert results['alpha_inv_MZ'] == 128
        assert abs(results['sin2_theta_W'] - 0.23122) < 0.001
        assert abs(results['alpha_s_MZ'] - 0.1179) < 0.001
    
    def test_neutrino_sector(self):
        results = compute_neutrino_mixing()
        assert abs(results['theta_12'] - 33.44) < 0.5
        assert abs(results['theta_13'] - 8.57) < 0.1
        assert abs(results['theta_23'] - 49.2) < 0.5
        assert results['delta_CP'] == 197
    
    def test_all_observables(self):
        """Verify all 37 observables compute without error."""
        results = compute_all_observables()
        assert len(results) == 37
        for name, value in results.items():
            assert np.isfinite(value), f"{name} not finite"
\end{nopagebreakcode}

\subsection{Numerical Stability}

\begin{nopagebreakcode}
def test_numerical_stability():
    """Test numerical stability across precisions."""
    
    # Single precision
    result_32 = compute_observables(dtype=np.float32)
    
    # Double precision
    result_64 = compute_observables(dtype=np.float64)
    
    # Extended precision (if available)
    result_128 = compute_observables(dtype=np.float128)
    
    # Check consistency
    for obs in result_64:
        rel_diff = abs(result_64[obs] - result_128[obs])
        rel_diff /= result_128[obs]
        assert rel_diff < 1e-10, f"{obs} unstable"
\end{nopagebreakcode}

\section{Performance Benchmarks}

\subsection{Computation Times}

\begin{table}[H]
\centering
\begin{tabular}{lll}
\toprule
\textbf{Operation} & \textbf{Time (ms)} & \textbf{Notes} \\
\midrule
Topological constants & \(< 0.1\) & Integer arithmetic \\
Gauge couplings & \(< 1\) & Simple formulas \\
All 37 observables & \(< 10\) & Full computation \\
Monte Carlo (\(10^6\)) & \(\sim 5000\) & Statistical validation \\
K\textsubscript{7} metric training & \(\sim 3{,}600{,}000\) & 1 hour on A100 \\
\bottomrule
\end{tabular}
\caption{Computation time benchmarks}
\end{table}

\subsection{Memory Usage}

\begin{table}[H]
\centering
\begin{tabular}{ll}
\toprule
\textbf{Dataset} & \textbf{Memory (MB)} \\
\midrule
Topological parameters & \(< 1\) \\
Full observable set & \(< 10\) \\
K\textsubscript{7} metric network & \(\sim 100\) \\
Training batch & \(\sim 1000\) \\
\bottomrule
\end{tabular}
\caption{Memory usage}
\end{table}

\subsection{Scaling}

The Monte Carlo validation scales linearly with sample size:
\begin{itemize}
    \item \(10^4\) samples: 50 ms
    \item \(10^5\) samples: 500 ms
    \item \(10^6\) samples: 5 s
    \item \(10^7\) samples: 50 s
\end{itemize}

\section{Reproducibility}

\subsection{Random Seed Management}

\begin{nopagebreakcode}
def set_reproducibility(seed=42):
    """Set all random seeds for reproducibility."""
    import random
    import numpy as np
    import torch
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
\end{nopagebreakcode}

\subsection{Version Control}

All numerical results are tagged with:
\begin{itemize}
    \item Git commit hash
    \item Python version
    \item Library versions
    \item Hardware specification
    \item Timestamp
\end{itemize}

\subsection{Result Caching}

\begin{nopagebreakcode}
import hashlib
import json

def cache_result(params, result, cache_dir='./cache'):
    """Cache computation result with parameter hash."""
    param_hash = hashlib.md5(
        json.dumps(params, sort_keys=True).encode()
    ).hexdigest()
    
    cache_file = f"{cache_dir}/{param_hash}.json"
    with open(cache_file, 'w') as f:
        json.dump({'params': params, 'result': result}, f)
\end{nopagebreakcode}
\vfill

\noindent\hrulefill
\begin{thebibliography}{99}

\bibitem{numpy}
Harris, C.R., et al. (2020). Array programming with NumPy. \textit{Nature}, \textbf{585}, 357–362.

\bibitem{pytorch}
Paszke, A., et al. (2019). PyTorch: An imperative style, high-performance deep learning library. \textit{NeurIPS}.

\bibitem{scipy}
Virtanen, P., et al. (2020). SciPy 1.0: fundamental algorithms for scientific computing in Python. \textit{Nature Methods}, \textbf{17}, 261–272.

\bibitem{salib}
Herman, J., Usher, W. (2017). SALib: An open-source Python library for Sensitivity Analysis. \textit{JOSS}, \textbf{2}(9), 97.

\bibitem{gift_2025}
de la Fournière, B. (2025). \textit{Geometric Information Field Theory}. Zenodo. \url{https://doi.org/10.5281/zenodo.17434034}

\end{thebibliography}

\vfill

\noindent\hrulefill

\vspace{0.5em}

\noindent\textit{GIFT Framework v2.1 - Supplement S6}

\noindent\textit{Numerical Methods}


\end{document}
