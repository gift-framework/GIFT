{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete G₂ Metric Training - v0.2\n",
        "\n",
        "## Torsion-Free φ-Based Architecture\n",
        "\n",
        "**Key Improvements Over v0.1:**\n",
        "\n",
        "1. **φ-based representation**: Learn 3-form φ(x) directly instead of metric\n",
        "2. **True torsion-free conditions**: dφ = 0 and d*φ = 0 via proper exterior derivatives\n",
        "3. **T⁷ manifold**: Periodic boundary conditions on 7-torus\n",
        "4. **Dual encodings**: Both Fourier features and SIREN architectures\n",
        "5. **Curriculum learning**: Progressive emphasis on torsion-free condition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# INSTALLATION AND SETUP\n",
        "# ==============================================================================\n",
        "\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"Running on Google Colab\")\n",
        "    import subprocess\n",
        "    subprocess.run(['pip', 'install', '-q', 'torch', 'matplotlib', 'scipy', 'scikit-learn'])\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import os\n",
        "import json\n",
        "\n",
        "print(f\"\\nPyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f} GB\")\n",
        "\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "# Create output directory\n",
        "OUTPUT_DIR = 'g2_outputs'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "print(f\"Output directory: {OUTPUT_DIR}/\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# MODULE 1: MANIFOLD (T⁷ TORUS)\n",
        "# ==============================================================================\n",
        "\n",
        "class TorusT7:\n",
        "    \"\"\"7-dimensional torus with periodic boundaries.\"\"\"\n",
        "\n",
        "    def __init__(self, radii=None, device='cpu'):\n",
        "        if radii is None:\n",
        "            radii = [2.0 * np.pi] * 7\n",
        "        self.radii = torch.tensor(radii, dtype=torch.float32, device=device)\n",
        "        self.device = device\n",
        "        self.dim = 7\n",
        "\n",
        "    def sample_points(self, n_batch):\n",
        "        \"\"\"Sample random points on T^7.\"\"\"\n",
        "        return torch.rand(n_batch, 7, device=self.device) * self.radii.unsqueeze(0)\n",
        "\n",
        "    def volume(self):\n",
        "        \"\"\"Compute volume.\"\"\"\n",
        "        return torch.prod(self.radii).item()\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# MODULE 2: NEURAL NETWORK (φ-NETWORK)\n",
        "# ==============================================================================\n",
        "\n",
        "class FourierFeatures(nn.Module):\n",
        "    \"\"\"Random Fourier features.\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim=7, n_modes=16, scale=1.0):\n",
        "        super().__init__()\n",
        "        B = torch.randn(input_dim, n_modes) * scale\n",
        "        self.register_buffer('B', B)\n",
        "\n",
        "    def forward(self, x):\n",
        "        proj = 2 * np.pi * torch.matmul(x, self.B)\n",
        "        return torch.cat([torch.cos(proj), torch.sin(proj)], dim=-1)\n",
        "\n",
        "\n",
        "class G2PhiNetwork(nn.Module):\n",
        "    \"\"\"Neural network for G2 3-form φ.\"\"\"\n",
        "\n",
        "    def __init__(self, hidden_dims=[256, 256, 128], fourier_modes=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoding = FourierFeatures(input_dim=7, n_modes=fourier_modes)\n",
        "        encoding_dim = 2 * fourier_modes\n",
        "\n",
        "        layers = []\n",
        "        prev_dim = encoding_dim\n",
        "        for h_dim in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Linear(prev_dim, h_dim),\n",
        "                nn.SiLU(),\n",
        "                nn.LayerNorm(h_dim)\n",
        "            ])\n",
        "            prev_dim = h_dim\n",
        "\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self.output_layer = nn.Linear(prev_dim, 35)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.output_layer.weight.mul_(0.01)\n",
        "            self.output_layer.bias.zero_()\n",
        "\n",
        "    def forward(self, coords):\n",
        "        x = self.encoding(coords)\n",
        "        x = self.mlp(x)\n",
        "        phi = self.output_layer(x)\n",
        "\n",
        "        phi_norm = torch.norm(phi, dim=-1, keepdim=True)\n",
        "        phi = phi * (np.sqrt(7.0) / (phi_norm + 1e-8))\n",
        "\n",
        "        return phi\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# MODULE 3: GEOMETRY OPERATIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def project_spd(metric, epsilon=1e-6):\n",
        "    \"\"\"Project to positive definite.\"\"\"\n",
        "    metric = 0.5 * (metric + metric.transpose(-2, -1))\n",
        "    eigenvalues, eigenvectors = torch.linalg.eigh(metric)\n",
        "    eigenvalues = torch.clamp(eigenvalues, min=epsilon)\n",
        "    return eigenvectors @ torch.diag_embed(eigenvalues) @ eigenvectors.transpose(-2, -1)\n",
        "\n",
        "\n",
        "def metric_from_phi_approximate(phi):\n",
        "    \"\"\"Reconstruct metric from phi.\"\"\"\n",
        "    batch_size, device = phi.shape[0], phi.device\n",
        "    metric = torch.zeros(batch_size, 7, 7, device=device)\n",
        "\n",
        "    triple_to_idx = {}\n",
        "    idx = 0\n",
        "    for i in range(7):\n",
        "        for j in range(i+1, 7):\n",
        "            for k in range(j+1, 7):\n",
        "                triple_to_idx[(i, j, k)] = idx\n",
        "                idx += 1\n",
        "\n",
        "    phi_norm = torch.norm(phi, dim=1, keepdim=True)\n",
        "    for i in range(7):\n",
        "        metric[:, i, i] = phi_norm.squeeze() / np.sqrt(7.0)\n",
        "\n",
        "    for i in range(7):\n",
        "        for j in range(i+1, 7):\n",
        "            contrib, count = 0.0, 0\n",
        "            for k in range(7):\n",
        "                if k != i and k != j:\n",
        "                    triple = tuple(sorted([i, j, k]))\n",
        "                    if triple in triple_to_idx:\n",
        "                        contrib += phi[:, triple_to_idx[triple]]**2\n",
        "                        count += 1\n",
        "            if count > 0:\n",
        "                metric[:, i, j] = torch.sqrt(contrib / count + 1e-8) * 0.1\n",
        "                metric[:, j, i] = metric[:, i, j]\n",
        "\n",
        "    return metric\n",
        "\n",
        "\n",
        "def hodge_star(phi, metric):\n",
        "    \"\"\"Compute Hodge dual.\"\"\"\n",
        "    det_g = torch.det(metric)\n",
        "    vol = torch.sqrt(torch.abs(det_g) + 1e-10).unsqueeze(-1)\n",
        "    phi_dual = phi * vol\n",
        "    phi_dual_norm = torch.norm(phi_dual, dim=1, keepdim=True)\n",
        "    return phi_dual / (phi_dual_norm + 1e-8) * np.sqrt(7.0)\n",
        "\n",
        "\n",
        "def exterior_derivative_3form(phi, coords):\n",
        "    \"\"\"Compute exterior derivative.\"\"\"\n",
        "    batch_size, device = phi.shape[0], phi.device\n",
        "\n",
        "    if not coords.requires_grad:\n",
        "        coords = coords.requires_grad_(True)\n",
        "\n",
        "    d_phi = torch.zeros(batch_size, 35, device=device)\n",
        "\n",
        "    for comp_idx in range(35):\n",
        "        grads = torch.autograd.grad(\n",
        "            phi[:, comp_idx].sum(), coords,\n",
        "            create_graph=True, retain_graph=True, allow_unused=True\n",
        "        )[0]\n",
        "        if grads is not None:\n",
        "            d_phi[:, comp_idx] = torch.norm(grads, dim=1)\n",
        "\n",
        "    return d_phi, torch.sum(d_phi ** 2, dim=1)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# MODULE 4: LOSS FUNCTIONS\n",
        "# ==============================================================================\n",
        "\n",
        "def torsion_loss(phi, metric, coords):\n",
        "    \"\"\"Torsion-free condition.\"\"\"\n",
        "    d_phi, d_phi_norm_sq = exterior_derivative_3form(phi, coords)\n",
        "    phi_dual = hodge_star(phi, metric)\n",
        "    d_phi_dual, d_phi_dual_norm_sq = exterior_derivative_3form(phi_dual, coords)\n",
        "\n",
        "    loss = d_phi_norm_sq.mean() + d_phi_dual_norm_sq.mean()\n",
        "    return loss, {'torsion': loss.item()}\n",
        "\n",
        "\n",
        "def volume_loss(metric):\n",
        "    \"\"\"Volume normalization.\"\"\"\n",
        "    det_g = torch.det(metric)\n",
        "    loss = torch.mean((det_g - 1.0) ** 2)\n",
        "    return loss, {'det_g': det_g.mean().item()}\n",
        "\n",
        "\n",
        "def phi_normalization_loss(phi):\n",
        "    \"\"\"Phi norm.\"\"\"\n",
        "    phi_norm_sq = torch.sum(phi ** 2, dim=1)\n",
        "    loss = torch.mean((phi_norm_sq - 7.0) ** 2)\n",
        "    return loss, {'phi_norm_sq': phi_norm_sq.mean().item()}\n",
        "\n",
        "\n",
        "def metric_positivity_loss(metric):\n",
        "    \"\"\"Positive definiteness.\"\"\"\n",
        "    eigenvalues = torch.linalg.eigvalsh(metric)\n",
        "    negative_part = torch.relu(1e-6 - eigenvalues)\n",
        "    loss = torch.mean(negative_part ** 2)\n",
        "    return loss, {'min_eig': eigenvalues.min().item()}\n",
        "\n",
        "\n",
        "class CurriculumScheduler:\n",
        "    \"\"\"Curriculum learning.\"\"\"\n",
        "\n",
        "    def __init__(self, phase_epochs=[500, 2000, 3000],\n",
        "                 torsion_w=[0.1, 1.0, 10.0], volume_w=[10.0, 1.0, 0.1]):\n",
        "        self.phase_epochs = phase_epochs\n",
        "        self.torsion_w = torsion_w\n",
        "        self.volume_w = volume_w\n",
        "\n",
        "    def get_weights(self, epoch):\n",
        "        phase = 0\n",
        "        for i, end in enumerate(self.phase_epochs):\n",
        "            if epoch < end:\n",
        "                phase = i\n",
        "                break\n",
        "        return {'torsion': self.torsion_w[phase], 'volume': self.volume_w[phase]}\n",
        "\n",
        "\n",
        "class G2TotalLoss(nn.Module):\n",
        "    \"\"\"Total loss.\"\"\"\n",
        "\n",
        "    def __init__(self, scheduler):\n",
        "        super().__init__()\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "    def forward(self, phi, metric, coords, epoch=0):\n",
        "        w = self.scheduler.get_weights(epoch)\n",
        "\n",
        "        l_torsion, i_torsion = torsion_loss(phi, metric, coords)\n",
        "        l_volume, i_volume = volume_loss(metric)\n",
        "        l_norm, i_norm = phi_normalization_loss(phi)\n",
        "        l_pos, i_pos = metric_positivity_loss(metric)\n",
        "\n",
        "        total = w['torsion'] * l_torsion + w['volume'] * l_volume + l_norm + l_pos\n",
        "\n",
        "        info = {'total': total.item(), **i_torsion, **i_volume, **i_norm, **i_pos}\n",
        "        return total, info\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SAVING UTILITIES\n",
        "# ==============================================================================\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, config, history, filename, verbose=True):\n",
        "    \"\"\"Save training checkpoint.\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'config': config,\n",
        "        'history': history\n",
        "    }\n",
        "    path = os.path.join(OUTPUT_DIR, filename)\n",
        "    torch.save(checkpoint, path)\n",
        "    if verbose:\n",
        "        print(f\"  Checkpoint saved: {filename}\")\n",
        "    return path\n",
        "\n",
        "\n",
        "def save_history_csv(history, filename='training_history.csv'):\n",
        "    \"\"\"Save training history to CSV.\"\"\"\n",
        "    import csv\n",
        "    path = os.path.join(OUTPUT_DIR, filename)\n",
        "\n",
        "    with open(path, 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['epoch', 'loss', 'torsion', 'phi_norm_sq', 'det_g'])\n",
        "\n",
        "        for i in range(len(history['epoch'])):\n",
        "            writer.writerow([\n",
        "                history['epoch'][i],\n",
        "                history['loss'][i],\n",
        "                history['torsion'][i],\n",
        "                history['phi_norm'][i],\n",
        "                history['det_g'][i]\n",
        "            ])\n",
        "\n",
        "    print(f\"  History saved: {filename}\")\n",
        "    return path\n",
        "\n",
        "\n",
        "def save_final_plots(history, filename='training_plots.png'):\n",
        "    \"\"\"Save final training plots.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    fig.suptitle('G₂ Training Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "    axes[0,0].plot(history['epoch'], history['loss'], 'b-', lw=2)\n",
        "    axes[0,0].set_yscale('log')\n",
        "    axes[0,0].set_xlabel('Epoch')\n",
        "    axes[0,0].set_ylabel('Total Loss')\n",
        "    axes[0,0].set_title('Total Loss')\n",
        "    axes[0,0].grid(alpha=0.3)\n",
        "\n",
        "    axes[0,1].plot(history['epoch'], history['torsion'], 'r-', lw=2)\n",
        "    axes[0,1].set_yscale('log')\n",
        "    axes[0,1].set_xlabel('Epoch')\n",
        "    axes[0,1].set_ylabel('Torsion')\n",
        "    axes[0,1].set_title('Torsion: ||dφ||² + ||d*φ||²')\n",
        "    axes[0,1].axhline(1e-6, color='g', ls='--', label='Target: 1e-6')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(alpha=0.3)\n",
        "\n",
        "    axes[1,0].plot(history['epoch'], history['phi_norm'], 'g-', lw=2)\n",
        "    axes[1,0].axhline(7.0, color='k', ls='--', lw=1)\n",
        "    axes[1,0].set_xlabel('Epoch')\n",
        "    axes[1,0].set_ylabel('||φ||²')\n",
        "    axes[1,0].set_title('||φ||² (target: 7.0)')\n",
        "    axes[1,0].grid(alpha=0.3)\n",
        "\n",
        "    axes[1,1].plot(history['epoch'], history['det_g'], 'purple', lw=2)\n",
        "    axes[1,1].axhline(1.0, color='k', ls='--', lw=1)\n",
        "    axes[1,1].set_xlabel('Epoch')\n",
        "    axes[1,1].set_ylabel('det(g)')\n",
        "    axes[1,1].set_title('det(g) (target: 1.0)')\n",
        "    axes[1,1].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    path = os.path.join(OUTPUT_DIR, filename)\n",
        "    plt.savefig(path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"  Plots saved: {filename}\")\n",
        "\n",
        "    plt.show()\n",
        "    return path\n",
        "\n",
        "\n",
        "def download_all_results():\n",
        "    \"\"\"Download all results from Colab.\"\"\"\n",
        "    if IN_COLAB:\n",
        "        from google.colab import files\n",
        "        import glob\n",
        "\n",
        "        print(\"\\nDownloading all results...\")\n",
        "\n",
        "        all_files = glob.glob(os.path.join(OUTPUT_DIR, '*'))\n",
        "\n",
        "        for file_path in all_files:\n",
        "            if os.path.isfile(file_path):\n",
        "                filename = os.path.basename(file_path)\n",
        "                print(f\"  Downloading: {filename}\")\n",
        "                files.download(file_path)\n",
        "\n",
        "        print(\"All files downloaded!\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# TRAINING CONFIGURATION\n",
        "# ==============================================================================\n",
        "\n",
        "config = {\n",
        "    'hidden_dims': [256, 256, 128],\n",
        "    'fourier_modes': 16,\n",
        "    'batch_size': 512,\n",
        "    'epochs': 3000,  # FULL TRAINING\n",
        "    'lr': 1e-4,\n",
        "    'weight_decay': 1e-4,\n",
        "    'grad_clip': 1.0,\n",
        "    'plot_interval': 50,\n",
        "    'checkpoint_interval': 500,  # Save every 500 epochs\n",
        "    'seed': 42\n",
        "}\n",
        "\n",
        "torch.manual_seed(config['seed'])\n",
        "np.random.seed(config['seed'])\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Configuration\")\n",
        "print(\"=\"*70)\n",
        "for k, v in config.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save configuration\n",
        "config_path = os.path.join(OUTPUT_DIR, 'config.json')\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "print(f\"\\nConfig saved: {config_path}\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# CREATE MODEL AND OPTIMIZER\n",
        "# ==============================================================================\n",
        "\n",
        "manifold = TorusT7(device=device)\n",
        "model = G2PhiNetwork(config['hidden_dims'], config['fourier_modes']).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
        "scheduler_lr = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=500, eta_min=1e-7)\n",
        "\n",
        "curriculum = CurriculumScheduler([500, 2000, 3000], [0.1, 1.0, 10.0], [10.0, 1.0, 0.1])\n",
        "loss_fn = G2TotalLoss(curriculum)\n",
        "\n",
        "n_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"\\nModel: {n_params:,} parameters\")\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Checkpoints every: {config['checkpoint_interval']} epochs\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# TRAINING LOOP WITH AUTOMATIC SAVING\n",
        "# ==============================================================================\n",
        "\n",
        "history = {'epoch': [], 'loss': [], 'torsion': [], 'phi_norm': [], 'det_g': []}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Starting Training with Automatic Saving\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "start_time = time.time()\n",
        "best_loss = float('inf')\n",
        "\n",
        "for epoch in range(config['epochs']):\n",
        "    model.train()\n",
        "\n",
        "    # Sample batch\n",
        "    coords = manifold.sample_points(config['batch_size']).requires_grad_(True)\n",
        "\n",
        "    # Forward\n",
        "    phi = model(coords)\n",
        "    metric = metric_from_phi_approximate(phi)\n",
        "    metric = project_spd(metric)\n",
        "\n",
        "    # Loss\n",
        "    total_loss, info = loss_fn(phi, metric, coords, epoch)\n",
        "\n",
        "    # Backward\n",
        "    optimizer.zero_grad()\n",
        "    total_loss.backward()\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
        "    optimizer.step()\n",
        "    scheduler_lr.step()\n",
        "\n",
        "    # Record\n",
        "    history['epoch'].append(epoch)\n",
        "    history['loss'].append(info['total'])\n",
        "    history['torsion'].append(info['torsion'])\n",
        "    history['phi_norm'].append(info['phi_norm_sq'])\n",
        "    history['det_g'].append(info['det_g'])\n",
        "\n",
        "    # Save checkpoint (silently except for major milestones)\n",
        "    if (epoch + 1) % config['checkpoint_interval'] == 0:\n",
        "        filename = f'checkpoint_epoch_{epoch+1}.pt'\n",
        "        save_checkpoint(model, optimizer, epoch, config, history, filename, verbose=False)\n",
        "\n",
        "    # Save best model (silently)\n",
        "    if info['total'] < best_loss:\n",
        "        best_loss = info['total']\n",
        "        save_checkpoint(model, optimizer, epoch, config, history, 'best_model.pt', verbose=False)\n",
        "\n",
        "    # Plot\n",
        "    if epoch % config['plot_interval'] == 0 or epoch == config['epochs'] - 1:\n",
        "        clear_output(wait=True)\n",
        "\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "        fig.suptitle(f'Training - Epoch {epoch}/{config[\"epochs\"]}', fontsize=14, fontweight='bold')\n",
        "\n",
        "        axes[0,0].plot(history['epoch'], history['loss'], 'b-', lw=2)\n",
        "        axes[0,0].set_yscale('log')\n",
        "        axes[0,0].set_title('Total Loss')\n",
        "        axes[0,0].grid(alpha=0.3)\n",
        "\n",
        "        axes[0,1].plot(history['epoch'], history['torsion'], 'r-', lw=2)\n",
        "        axes[0,1].set_yscale('log')\n",
        "        axes[0,1].set_title('Torsion')\n",
        "        axes[0,1].axhline(1e-6, color='g', ls='--', alpha=0.5)\n",
        "        axes[0,1].grid(alpha=0.3)\n",
        "\n",
        "        axes[1,0].plot(history['epoch'], history['phi_norm'], 'g-', lw=2)\n",
        "        axes[1,0].axhline(7.0, color='k', ls='--', lw=1)\n",
        "        axes[1,0].set_title('||φ||² (target: 7.0)')\n",
        "        axes[1,0].grid(alpha=0.3)\n",
        "\n",
        "        axes[1,1].plot(history['epoch'], history['det_g'], 'purple', lw=2)\n",
        "        axes[1,1].axhline(1.0, color='k', ls='--', lw=1)\n",
        "        axes[1,1].set_title('det(g) (target: 1.0)')\n",
        "        axes[1,1].grid(alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"\\nEpoch {epoch}/{config['epochs']} | Time: {elapsed/60:.1f}min\")\n",
        "        print(f\"  Loss: {info['total']:.6e} | Torsion: {info['torsion']:.6e}\")\n",
        "        print(f\"  ||φ||²: {info['phi_norm_sq']:.6f} | det(g): {info['det_g']:.6f}\")\n",
        "\n",
        "elapsed_total = time.time() - start_time\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"Training complete! Time: {elapsed_total/60:.2f} min\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Print checkpoint summary\n",
        "import glob\n",
        "checkpoints = glob.glob(os.path.join(OUTPUT_DIR, 'checkpoint_*.pt'))\n",
        "print(f\"\\nCheckpoints saved: {len(checkpoints)}\")\n",
        "print(f\"Best model saved: best_model.pt\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# SAVE ALL RESULTS\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Saving All Results\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save final model\n",
        "save_checkpoint(model, optimizer, config['epochs']-1, config, history, 'final_model.pt')\n",
        "\n",
        "# Save history\n",
        "save_history_csv(history)\n",
        "\n",
        "# Save history as JSON too\n",
        "history_json_path = os.path.join(OUTPUT_DIR, 'training_history.json')\n",
        "with open(history_json_path, 'w') as f:\n",
        "    json.dump(history, f, indent=2)\n",
        "print(f\"  History JSON saved: training_history.json\")\n",
        "\n",
        "# Save final plots\n",
        "save_final_plots(history)\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# FINAL VALIDATION\n",
        "# ==============================================================================\n",
        "\n",
        "model.eval()\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Final Validation\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "with torch.no_grad():\n",
        "    coords = manifold.sample_points(2000)\n",
        "    phi = model(coords)\n",
        "    metric = metric_from_phi_approximate(phi)\n",
        "    metric = project_spd(metric)\n",
        "\n",
        "    phi_norm_sq = torch.sum(phi ** 2, dim=1)\n",
        "    det_g = torch.det(metric)\n",
        "    eigenvalues = torch.linalg.eigvalsh(metric)\n",
        "\n",
        "    validation_results = {\n",
        "        'phi_norm_sq_mean': phi_norm_sq.mean().item(),\n",
        "        'phi_norm_sq_std': phi_norm_sq.std().item(),\n",
        "        'det_g_mean': det_g.mean().item(),\n",
        "        'det_g_std': det_g.std().item(),\n",
        "        'eigenvalue_min': eigenvalues.min().item(),\n",
        "        'eigenvalue_max': eigenvalues.max().item(),\n",
        "        'final_torsion': history['torsion'][-1],\n",
        "        'final_loss': history['loss'][-1]\n",
        "    }\n",
        "\n",
        "    print(f\"\\n||φ||²: {validation_results['phi_norm_sq_mean']:.6f} ± {validation_results['phi_norm_sq_std']:.6f} (target: 7.0)\")\n",
        "    print(f\"det(g): {validation_results['det_g_mean']:.6f} ± {validation_results['det_g_std']:.6f} (target: 1.0)\")\n",
        "    print(f\"Eigenvalues: [{validation_results['eigenvalue_min']:.6f}, {validation_results['eigenvalue_max']:.6f}]\")\n",
        "    print(f\"Final Torsion: {validation_results['final_torsion']:.6e}\")\n",
        "    print(f\"Positive definite: {validation_results['eigenvalue_min'] > 0}\")\n",
        "\n",
        "# Save validation results\n",
        "validation_path = os.path.join(OUTPUT_DIR, 'validation_results.json')\n",
        "with open(validation_path, 'w') as f:\n",
        "    json.dump(validation_results, f, indent=2)\n",
        "print(f\"\\n  Validation saved: validation_results.json\")\n",
        "\n",
        "\n",
        "# ==============================================================================\n",
        "# DOWNLOAD ALL FILES (COLAB)\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Summary of Saved Files\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "import glob\n",
        "all_files = glob.glob(os.path.join(OUTPUT_DIR, '*'))\n",
        "print(f\"\\nTotal files saved: {len(all_files)}\")\n",
        "for file_path in all_files:\n",
        "    if os.path.isfile(file_path):\n",
        "        size_mb = os.path.getsize(file_path) / (1024*1024)\n",
        "        filename = os.path.basename(file_path)\n",
        "        print(f\"  {filename} ({size_mb:.2f} MB)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DOWNLOAD RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nTo download all files, run:\")\n",
        "print(\"  download_all_results()\")\n",
        "print(\"\\nOr download manually from the 'g2_outputs/' folder\")\n",
        "\n",
        "if IN_COLAB:\n",
        "    print(\"\\nImportant: Run this before closing Colab!\")\n",
        "    user_input = input(\"\\nDownload all files now? (y/n): \")\n",
        "    if user_input.lower() == 'y':\n",
        "        download_all_results()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"Complete!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nGIFT Project - Geometric Inference Framework Theory\")\n",
        "print(\"Version 0.2 - Torsion-Free φ-Based Architecture\")\n",
        "print(f\"\\nResults saved in: {OUTPUT_DIR}/\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
