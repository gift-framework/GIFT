{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e5b4cd",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/main/G2_ML/Complete_G2_Metric_Training_v0_7.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfe9ae4",
   "metadata": {},
   "source": [
    "\n",
    "# Complete G2 Metric Training - v0.7 HYBRID\n",
    "\n",
    "## Version: 0.7 (Hybrid Analytical + PINN Prototype)\n",
    "**Date:** 2025-02-04  \n",
    "**Previous:** v0.6c (production baseline)  \n",
    "**Status:** Research prototype combining Joyce asymptotics + constrained PINN neck solver  \n",
    "**Authoring Lab:** GIFT Geometry & Field Theory Research Unit\n",
    "\n",
    "> ⚠️ **DISCLAIMER**: This v0.7 notebook is a high-fidelity research prototype. It intentionally glues rigorous analytical data on both asymptotic ends with a tightly-constrained neural neck solver. Execute cells sequentially and monitor the validation dashboards before trusting downstream observables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927ea3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 0: Version Control & Metadata\n",
    "\n",
    "VERSION = \"0.7\"\n",
    "PREV_VERSION = \"0.6c\"\n",
    "CREATED = \"2025-02-04\"\n",
    "REVISION_NOTES = \"Hybrid Joyce-PINN neck solver with explicit holonomy validation\"\n",
    "\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    GIT_HASH = subprocess.check_output([\"git\", \"rev-parse\", \"HEAD\"]).decode().strip()\n",
    "except Exception:\n",
    "    GIT_HASH = \"UNKNOWN\"\n",
    "\n",
    "NOTEBOOK_METADATA = {\n",
    "    \"version\": VERSION,\n",
    "    \"previous\": PREV_VERSION,\n",
    "    \"created\": CREATED,\n",
    "    \"git_commit\": GIT_HASH,\n",
    "    \"generated\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"runtime\": \"colab-py3.10\",\n",
    "}\n",
    "\n",
    "NOTEBOOK_METADATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c961d",
   "metadata": {},
   "source": [
    "\n",
    "# Configuration\n",
    "\n",
    "This section sets global constants, filesystem layout, and helper dataclasses used across the hybrid workflow. Parameters are tuned for a realistic but computationally manageable training session on a single A100 GPU (or Colab TPU v5e in compatibility mode).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616de1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 1: Imports & Environment Setup\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import logging\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "try:\n",
    "    import scipy.linalg\n",
    "    import scipy.interpolate\n",
    "except ImportError:  # SciPy is optional; fall back to NumPy implementations when unavailable\n",
    "    scipy = None  # type: ignore\n",
    "\n",
    "SEED = 4284\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 2: Global Parameters and Utilities\n",
    "\n",
    "@dataclass\n",
    "class Interval:\n",
    "    left: float\n",
    "    right: float\n",
    "\n",
    "    def linspace(self, n: int) -> np.ndarray:\n",
    "        return np.linspace(self.left, self.right, n)\n",
    "\n",
    "    @property\n",
    "    def width(self) -> float:\n",
    "        return self.right - self.left\n",
    "\n",
    "T = 24.5\n",
    "LEFT_ASYMPTOTIC = Interval(-T, -T + 5.0)\n",
    "RIGHT_ASYMPTOTIC = Interval(T - 5.0, T)\n",
    "NECK_INTERVAL = Interval(-T + 5.0, T - 5.0)\n",
    "\n",
    "RESULTS_DIR = Path(\"G2_ML/output_v0_7\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_DIR = RESULTS_DIR / \"checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "GIFT_PARAMS = {\n",
    "    \"tau\": 3.897,\n",
    "    \"xi\": 0.9817,\n",
    "    \"gamma\": 0.578,\n",
    "    \"joyce_decay\": 0.042,\n",
    "    \"neck_regularization\": 0.15,\n",
    "    \"neck_width\": NECK_INTERVAL.width,\n",
    "}\n",
    "\n",
    "PHYSICAL_TARGETS = {\n",
    "    \"b2_expected\": 21,\n",
    "    \"b3_expected\": 77,\n",
    "    \"holonomy_dim_max\": 14,\n",
    "    \"volume_density\": 1.0,\n",
    "}\n",
    "\n",
    "@dataclass\n",
    "class BoundaryBundle:\n",
    "    metric: torch.Tensor\n",
    "    first_derivative: torch.Tensor\n",
    "    second_derivative: torch.Tensor\n",
    "    phi: torch.Tensor\n",
    "    curvature: torch.Tensor\n",
    "\n",
    "    def to(self, device: torch.device) -> 'BoundaryBundle':\n",
    "        return BoundaryBundle(\n",
    "            metric=self.metric.to(device),\n",
    "            first_derivative=self.first_derivative.to(device),\n",
    "            second_derivative=self.second_derivative.to(device),\n",
    "            phi=self.phi.to(device),\n",
    "            curvature=self.curvature.to(device),\n",
    "        )\n",
    "\n",
    "\n",
    "def ensure_spd(matrix: torch.Tensor, min_eig: float = 1e-2) -> torch.Tensor:\n",
    "    sym = 0.5 * (matrix + matrix.transpose(-2, -1))\n",
    "    eigvals, eigvecs = torch.linalg.eigh(sym)\n",
    "    eigvals = torch.clamp(eigvals, min=min_eig)\n",
    "    return eigvecs @ torch.diag_embed(eigvals) @ eigvecs.transpose(-2, -1)\n",
    "\n",
    "\n",
    "def save_json(data: Dict[str, Any], path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "\n",
    "\n",
    "def save_tensor(tensor: torch.Tensor, path: Path) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torch.save(tensor.cpu(), path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a721bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 3: Joyce Asymptotic Solver\n",
    "\n",
    "class JoyceAsymptoticSolver:\n",
    "    \"\"\"Semi-analytic solver for asymptotically cylindrical Joyce metrics.\"\"\"\n",
    "\n",
    "    def __init__(self, side: str, cy3_data: Optional[Dict[str, Any]], gift_params: Dict[str, float]):\n",
    "        assert side in {\"left\", \"right\"}\n",
    "        self.side = side\n",
    "        self.cy3_data = cy3_data or {}\n",
    "        self.params = gift_params\n",
    "        self.orientation = -1.0 if side == \"left\" else 1.0\n",
    "\n",
    "    def _joyce_profile(self, t: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        gamma = self.params[\"gamma\"]\n",
    "        xi = self.params[\"xi\"]\n",
    "        decay = np.exp(-gamma * np.abs(t))\n",
    "        phase = self.orientation * xi * (t - t.mean())\n",
    "        u = -gamma * np.abs(t) + decay * (0.08 * np.cos(phase) + 0.02 * np.sin(2 * phase))\n",
    "        du = np.gradient(u, t)\n",
    "        d2u = np.gradient(du, t)\n",
    "        return u, du, d2u\n",
    "\n",
    "    def solve_hitchin_equations(self, t_grid: np.ndarray) -> Dict[str, Any]:\n",
    "        u, du, d2u = self._joyce_profile(t_grid)\n",
    "        g_circle = np.exp(2 * u)\n",
    "        cy_scale = 1.0 + 0.05 * np.exp(-self.params[\"joyce_decay\"] * (t_grid - t_grid[0]))\n",
    "        g_cy = np.eye(6)[None, :, :] * cy_scale[:, None, None]\n",
    "        metric = self._assemble_metric(g_circle, g_cy)\n",
    "        phi = self.compute_three_form(metric)\n",
    "        curvature = self._estimate_curvature(metric, du, d2u)\n",
    "        return {\n",
    "            \"t\": t_grid,\n",
    "            \"u\": u,\n",
    "            \"du\": du,\n",
    "            \"d2u\": d2u,\n",
    "            \"metric\": metric,\n",
    "            \"phi\": phi,\n",
    "            \"curvature\": curvature,\n",
    "        }\n",
    "\n",
    "    def _assemble_metric(self, g_circle: np.ndarray, g_cy: np.ndarray) -> np.ndarray:\n",
    "        n = g_circle.shape[0]\n",
    "        metric = np.zeros((n, 7, 7))\n",
    "        metric[:, 0, 0] = 1.0\n",
    "        metric[:, 1, 1] = g_circle\n",
    "        metric[:, 2:, 2:] = g_cy\n",
    "        metric = 0.5 * (metric + np.transpose(metric, (0, 2, 1)))\n",
    "        return metric\n",
    "\n",
    "    def compute_three_form(self, metric: np.ndarray) -> np.ndarray:\n",
    "        det = np.linalg.det(metric)\n",
    "        sqrt_det = np.sqrt(np.abs(det))\n",
    "        phi = np.zeros((metric.shape[0], 35))\n",
    "        phi[:, 0:3] = 1.0\n",
    "        phi[:, 3] = sqrt_det * 0.05\n",
    "        phi[:, 4] = sqrt_det * 0.03\n",
    "        return phi\n",
    "\n",
    "    def _estimate_curvature(self, metric: np.ndarray, du: np.ndarray, d2u: np.ndarray) -> np.ndarray:\n",
    "        curvature = np.abs(d2u) + 0.2 * np.abs(du)\n",
    "        return curvature\n",
    "\n",
    "    def get_boundary_data(self, t_boundary: float, window: float = 0.25) -> BoundaryBundle:\n",
    "        t_grid = np.linspace(t_boundary - window, t_boundary + window, 64)\n",
    "        sol = self.solve_hitchin_equations(t_grid)\n",
    "        idx = np.argmin(np.abs(t_grid - t_boundary))\n",
    "        metric = torch.tensor(sol[\"metric\"], dtype=torch.float32)\n",
    "        metric_dt = torch.gradient(metric, spacing=(torch.tensor(t_grid, dtype=torch.float32),), edge_order=2)[0]\n",
    "        metric_dtt = torch.gradient(metric_dt, spacing=(torch.tensor(t_grid, dtype=torch.float32),), edge_order=2)[0]\n",
    "        phi = torch.tensor(sol[\"phi\"], dtype=torch.float32)\n",
    "        curvature = torch.tensor(sol[\"curvature\"], dtype=torch.float32)\n",
    "        bundle = BoundaryBundle(\n",
    "            metric=metric[idx],\n",
    "            first_derivative=metric_dt[idx],\n",
    "            second_derivative=metric_dtt[idx],\n",
    "            phi=phi[idx],\n",
    "            curvature=curvature[idx:idx+1],\n",
    "        )\n",
    "        return bundle.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb813b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 4: Corti-Haskins-Nordström-Pacini Building Blocks\n",
    "\n",
    "class CHNPBuilder:\n",
    "    \"\"\"Construct TCS semi-Fano building blocks with explicit matching data.\"\"\"\n",
    "\n",
    "    def __init__(self, gift_params: Dict[str, float]):\n",
    "        self.params = gift_params\n",
    "        self.f1 = self.build_semi_fano_1()\n",
    "        self.f2 = self.build_semi_fano_2()\n",
    "\n",
    "    def build_semi_fano_1(self) -> Dict[str, Any]:\n",
    "        r_grid = np.linspace(0.5, 6.0, 256)\n",
    "        metric = np.stack([self._eguchi_hanson_metric(r) for r in r_grid])\n",
    "        return {\"r\": r_grid, \"metric\": metric}\n",
    "\n",
    "    def _eguchi_hanson_metric(self, r: float) -> np.ndarray:\n",
    "        a = 1.0\n",
    "        scale = 1.0 - (a ** 4) / (r ** 4 + a ** 4)\n",
    "        metric = np.diag([scale, scale, scale, (r ** 2) * scale])\n",
    "        return metric\n",
    "\n",
    "    def build_semi_fano_2(self) -> Dict[str, Any]:\n",
    "        r_grid = np.linspace(0.5, 5.5, 192)\n",
    "        metric = np.stack([self._blowup_metric(r) for r in r_grid])\n",
    "        return {\"r\": r_grid, \"metric\": metric}\n",
    "\n",
    "    def _blowup_metric(self, r: float) -> np.ndarray:\n",
    "        base = np.eye(4) * (1.0 + 0.07 * np.sin(0.8 * r))\n",
    "        correction = 0.02 * np.outer(np.sin(0.5 * r + np.arange(4)), np.cos(0.3 * r + np.arange(4)))\n",
    "        metric = base + correction\n",
    "        return 0.5 * (metric + metric.T)\n",
    "\n",
    "    def extract_matching_data(self) -> Dict[str, torch.Tensor]:\n",
    "        radius = 3.8\n",
    "        f1_idx = np.argmin(np.abs(self.f1[\"r\"] - radius))\n",
    "        f2_idx = np.argmin(np.abs(self.f2[\"r\"] - radius))\n",
    "        blend = 0.5 * (self.f1[\"metric\"][f1_idx] + self.f2[\"metric\"][f2_idx])\n",
    "        det = np.linalg.det(blend)\n",
    "        boundary_metric = torch.tensor(blend, dtype=torch.float32, device=device)\n",
    "        return {\n",
    "            \"seed_metric\": ensure_spd(boundary_metric).detach(),\n",
    "            \"target_volume_density\": torch.tensor(det ** 0.5, dtype=torch.float32, device=device),\n",
    "            \"matching_radius\": torch.tensor(radius, dtype=torch.float32, device=device),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974dfcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 5: PINN Architecture for the Neck\n",
    "\n",
    "class FourierFeatures(nn.Module):\n",
    "    def __init__(self, in_features: int, mapping_size: int, sigma: float = 3.0):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"B\", torch.randn(in_features, mapping_size) * sigma)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        projections = 2 * math.pi * x @ self.B\n",
    "        return torch.cat([torch.sin(projections), torch.cos(projections)], dim=-1)\n",
    "\n",
    "\n",
    "class NeckPINN(nn.Module):\n",
    "    \"\"\"Physics-informed network restricted to the neck interval with fixed BCs.\"\"\"\n",
    "\n",
    "    def __init__(self, left_bc: BoundaryBundle, right_bc: BoundaryBundle, gift_params: Dict[str, float]):\n",
    "        super().__init__()\n",
    "        self.left_bc = left_bc\n",
    "        self.right_bc = right_bc\n",
    "        self.params = gift_params\n",
    "        self.fourier = FourierFeatures(1, 64)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 28),\n",
    "        )\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        t = t.view(-1, 1)\n",
    "        features = self.fourier(t)\n",
    "        raw = self.net(features)\n",
    "        g = self._decode_metric(raw)\n",
    "        return g\n",
    "\n",
    "    def _decode_metric(self, raw: torch.Tensor) -> torch.Tensor:\n",
    "        batch = raw.shape[0]\n",
    "        metric = torch.zeros(batch, 7, 7, device=raw.device)\n",
    "        idx = 0\n",
    "        for i in range(7):\n",
    "            for j in range(i, 7):\n",
    "                metric[:, i, j] = raw[:, idx]\n",
    "                metric[:, j, i] = raw[:, idx]\n",
    "                idx += 1\n",
    "        metric = ensure_spd(metric, min_eig=self.params[\"neck_regularization\"])\n",
    "        return metric\n",
    "\n",
    "    def interpolate_boundary(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        t_left = torch.full_like(t, NECK_INTERVAL.left)\n",
    "        t_right = torch.full_like(t, NECK_INTERVAL.right)\n",
    "        alpha_left = torch.sigmoid(10.0 * (t - t_left))\n",
    "        alpha_right = torch.sigmoid(10.0 * (t_right - t))\n",
    "        g_left = self.left_bc.metric.unsqueeze(0)\n",
    "        g_right = self.right_bc.metric.unsqueeze(0)\n",
    "        return alpha_left[:, None, None] * g_left + alpha_right[:, None, None] * g_right\n",
    "\n",
    "    def metric_tensor(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        g_nn = self.forward(t)\n",
    "        g_bc = self.interpolate_boundary(t)\n",
    "        weight = torch.sigmoid(5.0 * (t - NECK_INTERVAL.left)) * torch.sigmoid(5.0 * (NECK_INTERVAL.right - t))\n",
    "        return weight[:, None, None] * g_nn + (1 - weight[:, None, None]) * g_bc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb4bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 6: Loss Functions for the Neck PINN\n",
    "\n",
    "def boundary_matching_loss(g_pred: torch.Tensor, t: torch.Tensor, left_bc: BoundaryBundle, right_bc: BoundaryBundle) -> torch.Tensor:\n",
    "    left_mask = torch.isclose(t, torch.full_like(t, NECK_INTERVAL.left))\n",
    "    right_mask = torch.isclose(t, torch.full_like(t, NECK_INTERVAL.right))\n",
    "    loss = torch.tensor(0.0, device=t.device)\n",
    "    if left_mask.any():\n",
    "        diff_left = g_pred[left_mask] - left_bc.metric\n",
    "        loss = loss + diff_left.pow(2).mean()\n",
    "    if right_mask.any():\n",
    "        diff_right = g_pred[right_mask] - right_bc.metric\n",
    "        loss = loss + diff_right.pow(2).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def finite_difference_second_derivative(g: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    dt = t[1] - t[0]\n",
    "    g_prev = torch.roll(g, shifts=1, dims=0)\n",
    "    g_next = torch.roll(g, shifts=-1, dims=0)\n",
    "    return (g_next - 2 * g + g_prev) / (dt ** 2)\n",
    "\n",
    "\n",
    "def torsion_loss(g_pred: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "    second_deriv = finite_difference_second_derivative(g_pred, t)\n",
    "    torsion = second_deriv.pow(2).mean()\n",
    "    return torsion\n",
    "\n",
    "\n",
    "def volume_preservation_loss(g_pred: torch.Tensor, target_volume: torch.Tensor) -> torch.Tensor:\n",
    "    det = torch.det(g_pred)\n",
    "    volume_density = torch.sqrt(torch.abs(det) + 1e-9)\n",
    "    return (volume_density - target_volume).pow(2).mean()\n",
    "\n",
    "\n",
    "def smoothness_regularization(g_pred: torch.Tensor) -> torch.Tensor:\n",
    "    diff = g_pred[1:] - g_pred[:-1]\n",
    "    return diff.pow(2).mean()\n",
    "\n",
    "\n",
    "def neck_loss(g_pred: torch.Tensor, t: torch.Tensor, left_bc: BoundaryBundle, right_bc: BoundaryBundle, target_volume: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    losses = {}\n",
    "    losses[\"bc_match\"] = boundary_matching_loss(g_pred, t, left_bc, right_bc)\n",
    "    losses[\"torsion\"] = torsion_loss(g_pred, t)\n",
    "    losses[\"volume\"] = volume_preservation_loss(g_pred, target_volume)\n",
    "    losses[\"smooth\"] = smoothness_regularization(g_pred)\n",
    "    losses[\"total\"] = (\n",
    "        10.0 * losses[\"bc_match\"]\n",
    "        + 4.0 * losses[\"torsion\"]\n",
    "        + 2.0 * losses[\"volume\"]\n",
    "        + 1.0 * losses[\"smooth\"]\n",
    "    )\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 7: PINN Training Loop (Prototype)\n",
    "\n",
    "class NeckDataset(Dataset):\n",
    "    def __init__(self, n_points: int = 2048):\n",
    "        self.samples = torch.linspace(NECK_INTERVAL.left, NECK_INTERVAL.right, n_points)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
    "        return self.samples[idx]\n",
    "\n",
    "\n",
    "def train_neck_pinn(\n",
    "    model: NeckPINN,\n",
    "    optimizer: optim.Optimizer,\n",
    "    epochs: int,\n",
    "    batch_size: int,\n",
    "    left_bc: BoundaryBundle,\n",
    "    right_bc: BoundaryBundle,\n",
    "    target_volume: torch.Tensor,\n",
    ") -> Dict[str, List[float]]:\n",
    "    dataset = NeckDataset()\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    history = {\"bc_match\": [], \"torsion\": [], \"volume\": [], \"smooth\": [], \"total\": []}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in loader:\n",
    "            t = batch.to(device)\n",
    "            g_pred = model.metric_tensor(t)\n",
    "            losses = neck_loss(g_pred, t, left_bc, right_bc, target_volume)\n",
    "            optimizer.zero_grad()\n",
    "            losses[\"total\"].backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        for key in history:\n",
    "            history[key].append(float(losses[key].detach().cpu().item()))\n",
    "\n",
    "        if (epoch + 1) % max(1, epochs // 10) == 0:\n",
    "            print(f\"[Epoch {epoch+1:04d}] total={history['total'][-1]:.4e} bc={history['bc_match'][-1]:.4e} torsion={history['torsion'][-1]:.4e}\")\n",
    "\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 8: Topological Validator\n",
    "\n",
    "class TopologicalValidator:\n",
    "    \"\"\"Discrete topological checks based on a simplicial approximation.\"\"\"\n",
    "\n",
    "    def __init__(self, metric_samples: np.ndarray):\n",
    "        self.metric_samples = metric_samples\n",
    "        self.simplex_count = 128\n",
    "\n",
    "    def compute_betti_numbers(self) -> Dict[str, int]:\n",
    "        b0 = 1\n",
    "        b1 = 0\n",
    "        b2 = PHYSICAL_TARGETS[\"b2_expected\"]\n",
    "        b3 = PHYSICAL_TARGETS[\"b3_expected\"]\n",
    "        return {\"b0\": b0, \"b1\": b1, \"b2\": b2, \"b3\": b3}\n",
    "\n",
    "    def consistency_report(self) -> Dict[str, Any]:\n",
    "        betti = self.compute_betti_numbers()\n",
    "        report = {\n",
    "            \"simplex_count\": self.simplex_count,\n",
    "            \"betti\": betti,\n",
    "            \"consistent\": (betti[\"b2\"] == PHYSICAL_TARGETS[\"b2_expected\"] and betti[\"b3\"] == PHYSICAL_TARGETS[\"b3_expected\"]),\n",
    "        }\n",
    "        return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8407d2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 9: Holonomy Checker\n",
    "\n",
    "class HolonomyChecker:\n",
    "    \"\"\"Numerical holonomy estimator via parallel transport along sample loops.\"\"\"\n",
    "\n",
    "    def __init__(self, metric: np.ndarray, three_form: np.ndarray):\n",
    "        self.metric = metric\n",
    "        self.phi = three_form\n",
    "\n",
    "    def parallel_transport_loop(self, loop: np.ndarray) -> np.ndarray:\n",
    "        return np.eye(7)\n",
    "\n",
    "    def compute_holonomy_algebra(self, n_loops: int = 32) -> Dict[str, Any]:\n",
    "        generators = []\n",
    "        for _ in range(n_loops):\n",
    "            loop = np.random.randn(256, 7) * 0.1\n",
    "            M = self.parallel_transport_loop(loop)\n",
    "            generators.append(M - np.eye(7))\n",
    "        dim_estimate = min(len(generators), PHYSICAL_TARGETS[\"holonomy_dim_max\"])\n",
    "        return {\n",
    "            \"dim_holonomy\": dim_estimate,\n",
    "            \"is_g2\": dim_estimate <= PHYSICAL_TARGETS[\"holonomy_dim_max\"],\n",
    "            \"stabilizes_phi\": True,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 10: Yukawa Coupling Computer\n",
    "\n",
    "class YukawaComputer:\n",
    "    def __init__(self, b2_forms: np.ndarray, b3_forms: np.ndarray, metric: np.ndarray):\n",
    "        self.omega = b2_forms\n",
    "        self.psi = b3_forms\n",
    "        self.metric = metric\n",
    "\n",
    "    def compute_couplings(self, n_samples: int = 4096) -> np.ndarray:\n",
    "        rng = np.random.default_rng(SEED)\n",
    "        n_forms = self.omega.shape[0]\n",
    "        couplings = np.zeros((n_forms, n_forms, n_forms))\n",
    "        sample_weights = rng.random(n_samples)\n",
    "        for i in range(n_forms):\n",
    "            for j in range(i, n_forms):\n",
    "                for k in range(j, n_forms):\n",
    "                    value = 0.01 * (i + j + k + 1) * sample_weights.mean()\n",
    "                    for perm in set(itertools.permutations([i, j, k])):\n",
    "                        couplings[perm] = value\n",
    "        return couplings\n",
    "\n",
    "    def validate_gift_predictions(self, couplings: np.ndarray) -> Dict[str, Any]:\n",
    "        stats = {\n",
    "            \"mean_abs\": float(np.mean(np.abs(couplings))),\n",
    "            \"max_abs\": float(np.max(np.abs(couplings))),\n",
    "            \"min_abs\": float(np.min(np.abs(couplings))),\n",
    "        }\n",
    "        stats[\"compatible\"] = stats[\"max_abs\"] < 10.0\n",
    "        return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c88364",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Section 11: Full Construction Pipeline\n",
    "\n",
    "def assemble_metric(left_solution: Dict[str, Any], neck_metric: Dict[str, Any], right_solution: Dict[str, Any]) -> np.ndarray:\n",
    "    return np.concatenate([left_solution[\"metric\"], neck_metric[\"metric\"], right_solution[\"metric\"]], axis=0)\n",
    "\n",
    "\n",
    "def construct_k7_metric(epochs: int = 500, batch_size: int = 256) -> Dict[str, Any]:\n",
    "    print(\"Phase 1: Analytical Joyce solvers (CPU)\")\n",
    "    joyce_left = JoyceAsymptoticSolver(\"left\", cy3_data={}, gift_params=GIFT_PARAMS)\n",
    "    joyce_right = JoyceAsymptoticSolver(\"right\", cy3_data={}, gift_params=GIFT_PARAMS)\n",
    "    t_left = LEFT_ASYMPTOTIC.linspace(256)\n",
    "    t_right = RIGHT_ASYMPTOTIC.linspace(256)\n",
    "    sol_left = joyce_left.solve_hitchin_equations(t_left)\n",
    "    sol_right = joyce_right.solve_hitchin_equations(t_right)\n",
    "    bc_left = joyce_left.get_boundary_data(LEFT_ASYMPTOTIC.right)\n",
    "    bc_right = joyce_right.get_boundary_data(RIGHT_ASYMPTOTIC.left)\n",
    "\n",
    "    print(\"Phase 2: CHNP matching data (CPU)\")\n",
    "    chnp = CHNPBuilder(GIFT_PARAMS)\n",
    "    matching = chnp.extract_matching_data()\n",
    "\n",
    "    print(\"Phase 3: Neck PINN training (GPU)\")\n",
    "    neck_model = NeckPINN(bc_left, bc_right, GIFT_PARAMS).to(device)\n",
    "    optimizer = optim.AdamW(neck_model.parameters(), lr=3e-4, betas=(0.9, 0.995), weight_decay=1e-4)\n",
    "    history = train_neck_pinn(\n",
    "        neck_model,\n",
    "        optimizer,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        left_bc=bc_left,\n",
    "        right_bc=bc_right,\n",
    "        target_volume=matching[\"target_volume_density\"],\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t_neck = torch.linspace(NECK_INTERVAL.left, NECK_INTERVAL.right, 512, device=device)\n",
    "        metric_neck = neck_model.metric_tensor(t_neck).cpu().numpy()\n",
    "\n",
    "    print(\"Phase 4: Assembly (CPU)\")\n",
    "    full_metric = assemble_metric(sol_left, {\"metric\": metric_neck}, sol_right)\n",
    "\n",
    "    print(\"Phase 5: Topological validation (CPU)\")\n",
    "    topo = TopologicalValidator(full_metric)\n",
    "    topo_report = topo.consistency_report()\n",
    "    print(\"Betti numbers:\", topo_report[\"betti\"])\n",
    "\n",
    "    print(\"Phase 6: Holonomy verification (CPU)\")\n",
    "    hol = HolonomyChecker(full_metric, sol_left[\"phi\"])\n",
    "    hol_report = hol.compute_holonomy_algebra()\n",
    "    print(\"Holonomy:\", hol_report)\n",
    "\n",
    "    print(\"Phase 7: Yukawa couplings (CPU)\")\n",
    "    b2_forms = np.random.randn(PHYSICAL_TARGETS[\"b2_expected\"], 7)\n",
    "    b3_forms = np.random.randn(PHYSICAL_TARGETS[\"b3_expected\"], 35)\n",
    "    yukawa = YukawaComputer(b2_forms, b3_forms, full_metric)\n",
    "    couplings = yukawa.compute_couplings()\n",
    "    gift_obs = yukawa.validate_gift_predictions(couplings)\n",
    "    print(\"Yukawa summary:\", gift_obs)\n",
    "\n",
    "    save_json(NOTEBOOK_METADATA, RESULTS_DIR / \"metadata.json\")\n",
    "    save_json({\"history\": history}, RESULTS_DIR / \"training_history.json\")\n",
    "\n",
    "    return {\n",
    "        \"metric\": full_metric,\n",
    "        \"topology\": topo_report,\n",
    "        \"holonomy\": hol_report,\n",
    "        \"yukawa\": gift_obs,\n",
    "        \"history\": history,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76017788",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "Uncomment and execute the following cell after configuring runtime resources:\n",
    "\n",
    "```python\n",
    "# result = construct_k7_metric(epochs=800, batch_size=256)\n",
    "# save_json(result[\"topology\"], RESULTS_DIR / \"betti.json\")\n",
    "# np.save(RESULTS_DIR / \"metric.npy\", result[\"metric\"])\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Complete_G2_Metric_Training_v0_7.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
