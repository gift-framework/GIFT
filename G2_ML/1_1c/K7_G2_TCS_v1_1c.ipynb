{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/main/G2_ML/1_1c/K7_G2_TCS_v1_1c.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGncco2p6Tjf"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/main/G2_ML/1.1/K7_G2_TCS_ExplicitMetric_v1_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akg9e_Xa6Tjh"
      },
      "source": [
        "# K₇ G₂ TCS with Two-Speed LR + Complete GIFT 2.1 RG Flow - v1.1c\n",
        "\n",
        "Complete TCS construction pipeline with:\n",
        "- Full TCS geometry (M₁, Neck, M₂) with **extended neck** (σ_neck = 5.0)\n",
        "- Neural φ-network with **torsion targeting** (not minimization)\n",
        "- **Two-speed learning rate**: 1e-4 (phases 1-2), 5e-4 with warmup+cosine decay (phases 3-5)\n",
        "- **Complete GIFT 2.1 RG flow** with all four components:\n",
        "  - A·(∇·T): Torsion divergence (fixed calculation)\n",
        "  - B·|T|²: Torsion norm\n",
        "  - C·(∂ε g): Metric scale variation\n",
        "  - D·fractality(T): Multi-scale structure\n",
        "- Early RG calibration at epoch 2000 (after geometry stabilizes)\n",
        "- Smart early stopping per phase\n",
        "- Checkpoint system with automatic resumption\n",
        "- Live Laplacian computation and harmonic extraction\n",
        "- Full Yukawa tensor (21×21×77)\n",
        "\n",
        "**v1.1c**: Fixes v1.1b training instability with progressive LR schedule while maintaining complete GIFT 2.1 formula.\n",
        "\n",
        "**Goals**:\n",
        "- Torsion: < 5% error (maintain v1.1 quality)\n",
        "- Geometry: det(g) ≈ 2.0, positive definite\n",
        "- RG Flow: Δα error < 20% (improve from v1.1b's 99%)\n",
        "- Stable convergence: No oscillations, clean loss curves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbndfOns6Tji"
      },
      "source": [
        "## 1. Configuration and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOJNBndv6Tji",
        "outputId": "f7e24c76-771d-4bcb-db1c-a410fb11b903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Training grid: 16^7\n",
            "Harmonics grid: 8^7\n",
            "Two-speed LR: phases 1-2 = 0.0001, phases 3-5 = 0.0005 (with warmup+decay)\n",
            "RG calibration epoch: 2000\n",
            "Target: b₂=21, b₃=77\n",
            "Target torsion: ||T||=0.0164\n",
            "Epochs per phase: 2000\n",
            "Phases: 5\n",
            "Extended neck width: σ_neck=5.0\n",
            "RG flow: λ_max=39.44, Δα⁻¹=-0.9\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.sparse import csr_matrix, lil_matrix, diags\n",
        "from scipy.sparse.linalg import eigsh, spsolve\n",
        "from scipy.spatial.transform import Rotation\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "CONFIG = {\n",
        "    'n_grid': 16,\n",
        "    'n_grid_harmonics': 8,  # Reduced grid for harmonic extraction\n",
        "    'n_fourier': 10,\n",
        "    'hidden_dim': 256,\n",
        "    'n_layers': 6,\n",
        "    'batch_size': 1024,\n",
        "\n",
        "    # TWO-SPEED LEARNING RATE (NEW v1.1c)\n",
        "    'learning_rate_phase12': 1e-4,  # Phases 1-2: stabilize geometry\n",
        "    'learning_rate_phase35': 5e-4,  # Phases 3-5: with warmup+decay\n",
        "    'lr_warmup_epochs': 200,        # Warmup from 1e-4 to 5e-4\n",
        "    'lr_min': 1e-5,                 # Minimum LR after decay\n",
        "\n",
        "    'n_epochs_per_phase': 2000,\n",
        "    'checkpoint_freq': 500,\n",
        "    'checkpoint_dir': 'checkpoints_v1_1c',\n",
        "\n",
        "    'tcs': {\n",
        "        'r_neck_start': 0.35,\n",
        "        'r_neck_end': 0.65,\n",
        "        'r_acyl_cutoff': 10.0,\n",
        "        'twist_angle': np.pi / 3,\n",
        "        'neck_width': 5.0,  # NEW v1.1: Extended neck for RG flow accumulation\n",
        "    },\n",
        "\n",
        "    'target': {\n",
        "        'det_g': 2.0,\n",
        "        'torsion_norm': 0.0164,  # Target torsion magnitude from GIFT calibration\n",
        "        'b2': 21,\n",
        "        'b3': 77,\n",
        "    },\n",
        "\n",
        "    # NEW v1.1: Phase-specific torsion targets (gradual ramp-up)\n",
        "    'torsion_targets': {\n",
        "        1: 0.001,   # Phase 1: Establish geometry\n",
        "        2: 0.005,   # Phase 2: ACyl matching\n",
        "        3: 0.010,   # Phase 3: Cohomology refinement\n",
        "        4: 0.015,   # Phase 4: Pre-calibration\n",
        "        5: 0.0164   # Phase 5: Final GIFT target\n",
        "    },\n",
        "\n",
        "    'yukawa_samples': 200000,\n",
        "    'torsion_threshold': 1e-6,\n",
        "    'torsion_floor': 1e-9,\n",
        "\n",
        "    'phases': {\n",
        "        1: {\n",
        "            'name': 'TCS_Neck',\n",
        "            'weights': {\n",
        "                'torsion': 1.0,      # NEW: replaces separate dphi/dpsi\n",
        "                'det': 0.5,\n",
        "                'positivity': 1.0,\n",
        "                'neck_match': 2.0,\n",
        "                'acyl': 0.0,\n",
        "                'harmonicity': 0.0,\n",
        "                'rg_flow': 0.0       # NEW v1.1\n",
        "            },\n",
        "            'early_stop': {         # NEW v1.1: Per-phase early stopping\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'neck_match': 1e-5,\n",
        "                    'det': 1e-5,\n",
        "                    'positivity': 1e-7\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        2: {\n",
        "            'name': 'ACyl_Matching',\n",
        "            'weights': {\n",
        "                'torsion': 0.8,\n",
        "                'det': 0.8,\n",
        "                'positivity': 1.5,\n",
        "                'neck_match': 0.5,\n",
        "                'acyl': 0.5,\n",
        "                'harmonicity': 0.0,\n",
        "                'rg_flow': 0.0\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'acyl': 1e-5,\n",
        "                    'det': 1e-5,\n",
        "                    'torsion_target_reached': True  # Check if within 20% of target\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        3: {\n",
        "            'name': 'Cohomology_Refinement',\n",
        "            'weights': {\n",
        "                'torsion': 0.6,\n",
        "                'det': 0.5,\n",
        "                'positivity': 1.0,\n",
        "                'neck_match': 0.5,\n",
        "                'acyl': 1.0,\n",
        "                'harmonicity': 1.0,\n",
        "                'rg_flow': 0.0\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'harmonicity': 1e-4,\n",
        "                    'torsion_target_reached': True\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        4: {\n",
        "            'name': 'Harmonic_Extraction',\n",
        "            'weights': {\n",
        "                'torsion': 0.5,\n",
        "                'det': 1.0,\n",
        "                'positivity': 1.0,\n",
        "                'neck_match': 0.2,\n",
        "                'acyl': 0.5,\n",
        "                'harmonicity': 3.0,\n",
        "                'rg_flow': 0.1       # Start introducing RG flow\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 200,\n",
        "                'criteria': {\n",
        "                    'harmonicity': 5e-5,\n",
        "                    'torsion_target_reached': True\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        5: {\n",
        "            'name': 'RG_Calibration',\n",
        "            'weights': {\n",
        "                'torsion': 0.3,      # Reduced from 3.0 to allow RG flow to dominate\n",
        "                'det': 2.0,\n",
        "                'positivity': 2.0,\n",
        "                'neck_match': 0.1,\n",
        "                'acyl': 0.2,\n",
        "                'harmonicity': 2.0,\n",
        "                'rg_flow': 0.05       # Full RG flow enforcement\n",
        "            },\n",
        "            'early_stop': {\n",
        "                'patience': 500,\n",
        "                'criteria': {\n",
        "                    'torsion_target_reached': True,\n",
        "                    'rg_flow_delta': 0.05,\n",
        "                    'det': 1e-6,\n",
        "                    'positivity': 1e-8,\n",
        "                    'min_epochs': 1000\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "    },\n",
        "\n",
        "    # RG flow configuration (UPDATED v1.1c: early calibration)\n",
        "    'rg_flow': {\n",
        "        'lambda_max': 39.44,\n",
        "        'target_delta_alpha': -0.9,\n",
        "        'n_integration_steps': 100,\n",
        "        'geodesic_batch_freq_base': 0.3,\n",
        "        'calibration_epoch': 2000,  # UPDATED v1.1c: early calibration after geometry stable\n",
        "        'adaptive_frequency': True,\n",
        "        'monitor_components': True,\n",
        "        'enable_divergence': True,\n",
        "        'enable_epsilon_var': True,\n",
        "        'enable_fractality': True,\n",
        "    }\n",
        "}\n",
        "\n",
        "Path(CONFIG['checkpoint_dir']).mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Training grid: {CONFIG['n_grid']}^7\")\n",
        "print(f\"Harmonics grid: {CONFIG['n_grid_harmonics']}^7\")\n",
        "print(f\"Two-speed LR: phases 1-2 = {CONFIG['learning_rate_phase12']}, phases 3-5 = {CONFIG['learning_rate_phase35']} (with warmup+decay)\")\n",
        "print(f\"RG calibration epoch: {CONFIG['rg_flow']['calibration_epoch']}\")\n",
        "print(f\"Target: b₂={CONFIG['target']['b2']}, b₃={CONFIG['target']['b3']}\")\n",
        "print(f\"Target torsion: ||T||={CONFIG['target']['torsion_norm']}\")\n",
        "print(f\"Epochs per phase: {CONFIG['n_epochs_per_phase']}\")\n",
        "print(f\"Phases: {len(CONFIG['phases'])}\")\n",
        "print(f\"Extended neck width: σ_neck={CONFIG['tcs']['neck_width']}\")\n",
        "print(f\"RG flow: λ_max={CONFIG['rg_flow']['lambda_max']}, Δα⁻¹={CONFIG['rg_flow']['target_delta_alpha']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7looyRG6Tjj"
      },
      "source": [
        "## 2. Complete TCS Geometry with Extended Neck\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXI72vQR6Tjj",
        "outputId": "a8623dc3-d138-49b3-8259-5b738b34cb58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TCS regions: M₁ [0, 0.35], Neck [0.35, 0.65], M₂ [0.65, 1]\n",
            "Twist angle: 1.0472 rad\n",
            "Extended neck width: σ_neck = 5.0\n"
          ]
        }
      ],
      "source": [
        "class ACylPotentials:\n",
        "    def __init__(self, r_cutoff: float = 10.0):\n",
        "        self.r_cutoff = r_cutoff\n",
        "\n",
        "    def F(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ACyl potential F(r) → 1 as r → ∞.\"\"\"\n",
        "        return 1.0 - torch.exp(-r / self.r_cutoff)\n",
        "\n",
        "    def H(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ACyl potential H(r) → 0 as r → ∞.\"\"\"\n",
        "        return torch.exp(-r / self.r_cutoff)\n",
        "\n",
        "    def dF_dr(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.exp(-r / self.r_cutoff) / self.r_cutoff\n",
        "\n",
        "    def dH_dr(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        return -torch.exp(-r / self.r_cutoff) / self.r_cutoff\n",
        "\n",
        "\n",
        "class TCSGeometry:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.n = config['n_grid']\n",
        "        tcs_cfg = config['tcs']\n",
        "\n",
        "        self.r_neck_start = tcs_cfg['r_neck_start']\n",
        "        self.r_neck_end = tcs_cfg['r_neck_end']\n",
        "        self.twist_angle = tcs_cfg['twist_angle']\n",
        "        self.neck_width = tcs_cfg.get('neck_width', 5.0)  # NEW v1.1: Extended neck\n",
        "\n",
        "        self.acyl = ACylPotentials(tcs_cfg['r_acyl_cutoff'])\n",
        "\n",
        "        self.coords = np.linspace(0, 1, self.n, endpoint=False)\n",
        "\n",
        "    def radial_coordinate(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Map T⁷ coordinate to radial parameter r ∈ [0,1].\"\"\"\n",
        "        return x[:, 0]\n",
        "\n",
        "    def region_classification(self, r: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"Classify points into M₁, Neck, M₂.\"\"\"\n",
        "        m1_mask = r < self.r_neck_start\n",
        "        neck_mask = (r >= self.r_neck_start) & (r <= self.r_neck_end)\n",
        "        m2_mask = r > self.r_neck_end\n",
        "\n",
        "        return {'M1': m1_mask, 'Neck': neck_mask, 'M2': m2_mask}\n",
        "\n",
        "    def neck_profile(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        NEW v1.1: Extended Gaussian neck profile for RG flow accumulation.\n",
        "\n",
        "        Args:\n",
        "            r: Radial coordinate\n",
        "\n",
        "        Returns:\n",
        "            profile: Smooth interpolation across extended neck region\n",
        "        \"\"\"\n",
        "        r_center = (self.r_neck_start + self.r_neck_end) / 2\n",
        "        r_normalized = (r - r_center) / self.neck_width\n",
        "\n",
        "        return torch.exp(-r_normalized**2 / 2)\n",
        "\n",
        "    def neck_interpolation(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Smooth interpolation χ: 0 in M₁, 1 in M₂.\n",
        "        NEW v1.1: Uses extended neck profile.\n",
        "        \"\"\"\n",
        "        r_norm = (r - self.r_neck_start) / (self.r_neck_end - self.r_neck_start)\n",
        "        r_norm = torch.clamp(r_norm, 0.0, 1.0)\n",
        "\n",
        "        # Extended neck modulation\n",
        "        profile = self.neck_profile(r)\n",
        "        chi = 3 * r_norm**2 - 2 * r_norm**3\n",
        "\n",
        "        # Smooth transition influenced by extended profile\n",
        "        chi = chi * (1.0 + 0.5 * profile)\n",
        "\n",
        "        return torch.clamp(chi, 0.0, 1.0)\n",
        "\n",
        "    def twist_map(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply twist ψ on neck cross-section S¹×S¹.\"\"\"\n",
        "        r = self.radial_coordinate(x)\n",
        "        chi = self.neck_interpolation(r)\n",
        "\n",
        "        x_twisted = x.clone()\n",
        "\n",
        "        theta1 = 2 * np.pi * x[:, 1]\n",
        "        theta2 = 2 * np.pi * x[:, 2]\n",
        "\n",
        "        theta1_new = theta1 + chi * self.twist_angle\n",
        "        theta2_new = theta2 - chi * self.twist_angle\n",
        "\n",
        "        x_twisted[:, 1] = (theta1_new / (2 * np.pi)) % 1.0\n",
        "        x_twisted[:, 2] = (theta2_new / (2 * np.pi)) % 1.0\n",
        "\n",
        "        return x_twisted\n",
        "\n",
        "    def acyl_metric_correction(self, x: torch.Tensor, g_base: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply ACyl corrections to metric.\"\"\"\n",
        "        r = self.radial_coordinate(x)\n",
        "        regions = self.region_classification(r)\n",
        "\n",
        "        F = self.acyl.F(r).unsqueeze(-1).unsqueeze(-1)\n",
        "        H = self.acyl.H(r).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        g_corrected = g_base.clone()\n",
        "\n",
        "        g_corrected[regions['M1']] = g_base[regions['M1']] * (1.0 + 0.1 * H[regions['M1']])\n",
        "        g_corrected[regions['M2']] = g_base[regions['M2']] * (1.0 + 0.1 * H[regions['M2']])\n",
        "\n",
        "        return g_corrected\n",
        "\n",
        "    def compute_normal_derivative_mismatch(self, phi_net: nn.Module, coords: torch.Tensor, extd) -> torch.Tensor:\n",
        "        \"\"\"Compute ACyl normal derivative matching condition.\"\"\"\n",
        "        r = self.radial_coordinate(coords)\n",
        "        regions = self.region_classification(r)\n",
        "\n",
        "        if not (regions['M1'].any() or regions['M2'].any()):\n",
        "            return torch.tensor(0.0, device=coords.device)\n",
        "\n",
        "        epsilon = 1e-4\n",
        "        coords_plus = coords.clone()\n",
        "        coords_plus[:, 0] += epsilon\n",
        "        coords_plus[:, 0] = coords_plus[:, 0] % 1.0\n",
        "\n",
        "        coords_minus = coords.clone()\n",
        "        coords_minus[:, 0] -= epsilon\n",
        "        coords_minus[:, 0] = coords_minus[:, 0] % 1.0\n",
        "\n",
        "        phi = phi_net(coords)\n",
        "        phi_plus = phi_net(coords_plus)\n",
        "        phi_minus = phi_net(coords_minus)\n",
        "\n",
        "        dphi_dr = (phi_plus - phi_minus) / (2 * epsilon)\n",
        "\n",
        "        dF_dr = self.acyl.dF_dr(r).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "        dH_dr = self.acyl.dH_dr(r).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        expected_derivative = phi * (0.1 * dH_dr)\n",
        "\n",
        "        mismatch = torch.tensor(0.0, device=coords.device)\n",
        "        if regions['M1'].any():\n",
        "            mismatch += ((dphi_dr[regions['M1']] - expected_derivative[regions['M1']]) ** 2).mean()\n",
        "        if regions['M2'].any():\n",
        "            mismatch += ((dphi_dr[regions['M2']] - expected_derivative[regions['M2']]) ** 2).mean()\n",
        "\n",
        "        return mismatch\n",
        "\n",
        "geometry = TCSGeometry(CONFIG)\n",
        "print(f\"TCS regions: M₁ [0, {geometry.r_neck_start}], Neck [{geometry.r_neck_start}, {geometry.r_neck_end}], M₂ [{geometry.r_neck_end}, 1]\")\n",
        "print(f\"Twist angle: {geometry.twist_angle:.4f} rad\")\n",
        "print(f\"Extended neck width: σ_neck = {geometry.neck_width}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFv0yG_36Tjj"
      },
      "source": [
        "## 3. Enhanced φ-Network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "618IVxv66Tjk",
        "outputId": "475ecb0f-982d-4875-f361-a7e71c9c7106"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "φ-network parameters: 866,083\n"
          ]
        }
      ],
      "source": [
        "class FourierEncoding(nn.Module):\n",
        "    def __init__(self, n_freqs: int):\n",
        "        super().__init__()\n",
        "        self.n_freqs = n_freqs\n",
        "        self.register_buffer('freqs', 2 ** torch.arange(n_freqs, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x_proj = 2 * np.pi * x.unsqueeze(-1) * self.freqs\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1).flatten(-2)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x + self.net(x)\n",
        "\n",
        "\n",
        "class PhiNetwork(nn.Module):\n",
        "    def __init__(self, config: Dict):\n",
        "        super().__init__()\n",
        "        self.n_freqs = config['n_fourier']\n",
        "        self.hidden = config['hidden_dim']\n",
        "        self.n_layers = config['n_layers']\n",
        "\n",
        "        self.encoding = FourierEncoding(self.n_freqs)\n",
        "        input_dim = 7 * 2 * self.n_freqs\n",
        "\n",
        "        self.input_proj = nn.Linear(input_dim, self.hidden)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ResidualBlock(self.hidden) for _ in range(self.n_layers)\n",
        "        ])\n",
        "\n",
        "        self.phi_head = nn.Sequential(\n",
        "            nn.Linear(self.hidden, self.hidden // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden // 2, 35)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x_enc = self.encoding(x)\n",
        "        h = self.input_proj(x_enc)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            h = block(h)\n",
        "\n",
        "        phi_flat = self.phi_head(h)\n",
        "\n",
        "        phi = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        idx = 0\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    val = phi_flat[:, idx]\n",
        "\n",
        "                    phi[:, i, j, k] = val\n",
        "                    phi[:, i, k, j] = -val\n",
        "                    phi[:, j, i, k] = -val\n",
        "                    phi[:, j, k, i] = val\n",
        "                    phi[:, k, i, j] = val\n",
        "                    phi[:, k, j, i] = -val\n",
        "\n",
        "                    idx += 1\n",
        "\n",
        "        return phi\n",
        "\n",
        "phi_net = PhiNetwork(CONFIG).to(device)\n",
        "print(f\"φ-network parameters: {sum(p.numel() for p in phi_net.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Wkk3uIH6Tjk"
      },
      "source": [
        "## 4. G₂ Metric and Hodge Dual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx8PHNYg6Tjl",
        "outputId": "c2c7d50c-055e-425e-ed8b-970216b4c3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G₂ metric and Hodge dual ready\n"
          ]
        }
      ],
      "source": [
        "def compute_g2_metric(phi: torch.Tensor, epsilon: float = 1e-4, phase: int = 1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Compute G₂ metric g_{ij} = (1/6) φ_{ipq} φ_j^{pq}.\"\"\"\n",
        "    batch_size = phi.shape[0]\n",
        "    g = torch.zeros(batch_size, 7, 7, device=phi.device, dtype=phi.dtype)\n",
        "\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            g[:, i, j] = (phi[:, i, :, :] * phi[:, j, :, :]).sum(dim=(-2, -1)) / 6.0\n",
        "\n",
        "    # Force exact symmetrization\n",
        "    g = (g + g.transpose(-2, -1)) / 2.0\n",
        "\n",
        "    # Phase-adaptive regularization\n",
        "    eps_adaptive = {1: 2e-3, 2: 1.5e-3, 3: 1e-3, 4: 5e-4, 5: 1e-4}\n",
        "    eps = eps_adaptive.get(phase, epsilon)\n",
        "\n",
        "    eye = torch.eye(7, device=phi.device, dtype=phi.dtype).unsqueeze(0)\n",
        "    g = g + eps * eye\n",
        "\n",
        "    g_inv = torch.linalg.inv(g)\n",
        "\n",
        "    return g, g_inv\n",
        "\n",
        "\n",
        "def normalize_metric(g: torch.Tensor, target_det: float = 2.0) -> torch.Tensor:\n",
        "    \"\"\"Normalize metric to have det(g) = target_det.\"\"\"\n",
        "    det = torch.linalg.det(g)\n",
        "    scale = (target_det / det.abs().clamp(min=1e-8)) ** (1.0 / 7.0)\n",
        "    return g * scale.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "\n",
        "EPSILON_7D = None\n",
        "\n",
        "def compute_hodge_dual(phi: torch.Tensor, g: torch.Tensor, g_inv: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Compute ψ = *φ.\"\"\"\n",
        "    global EPSILON_7D\n",
        "    if EPSILON_7D is None:\n",
        "        from itertools import permutations\n",
        "        epsilon = torch.zeros(7, 7, 7, 7, 7, 7, 7)\n",
        "        base = list(range(7))\n",
        "        for perm in permutations(base):\n",
        "            sign = 1\n",
        "            temp = list(perm)\n",
        "            for i in range(7):\n",
        "                for j in range(i+1, 7):\n",
        "                    if temp[i] > temp[j]:\n",
        "                        sign *= -1\n",
        "            epsilon[perm] = sign\n",
        "        EPSILON_7D = epsilon.to(phi.device)\n",
        "\n",
        "    batch_size = phi.shape[0]\n",
        "    psi = torch.zeros(batch_size, 7, 7, 7, 7, device=phi.device, dtype=phi.dtype)\n",
        "\n",
        "    det_g = torch.linalg.det(g)\n",
        "    sqrt_det = torch.sqrt(det_g.abs().clamp(min=1e-8))\n",
        "\n",
        "    phi_raised = torch.einsum('bijk,bil,bjm,bkn->blmn', phi, g_inv, g_inv, g_inv)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        psi[b] = torch.einsum('ijklmnp,mnp->ijkl', EPSILON_7D, phi_raised[b]) / (6.0 * sqrt_det[b])\n",
        "\n",
        "    return psi\n",
        "\n",
        "print(\"G₂ metric and Hodge dual ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGSv1BQf6Tjl"
      },
      "source": [
        "## 5. Exterior Derivatives\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHWqnaW66Tjm",
        "outputId": "2d1ef0d0-cef4-474d-a490-f4a2c4932d2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exterior derivative operators ready\n"
          ]
        }
      ],
      "source": [
        "class ExteriorDerivative:\n",
        "    def __init__(self, n_grid: int, epsilon: float = 1e-4):\n",
        "        self.n = n_grid\n",
        "        self.dx = 1.0 / n_grid\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def compute_jacobian(self, phi_net: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute Jacobian ∂φ_{ijk}/∂x^l.\"\"\"\n",
        "        batch_size = coords.shape[0]\n",
        "        jacobian = torch.zeros(batch_size, 7, 7, 7, 7, device=coords.device, dtype=coords.dtype)\n",
        "\n",
        "        for l in range(7):\n",
        "            coords_plus = coords.clone()\n",
        "            coords_plus[:, l] += self.epsilon\n",
        "            coords_plus[:, l] = coords_plus[:, l] % 1.0\n",
        "\n",
        "            coords_minus = coords.clone()\n",
        "            coords_minus[:, l] -= self.epsilon\n",
        "            coords_minus[:, l] = coords_minus[:, l] % 1.0\n",
        "\n",
        "            phi_plus = phi_net(coords_plus)\n",
        "            phi_minus = phi_net(coords_minus)\n",
        "\n",
        "            jacobian[:, :, :, :, l] = (phi_plus - phi_minus) / (2 * self.epsilon)\n",
        "\n",
        "        return jacobian\n",
        "\n",
        "    def d_phi(self, jacobian: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute dφ from Jacobian.\"\"\"\n",
        "        batch_size = jacobian.shape[0]\n",
        "        dphi = torch.zeros(batch_size, 7, 7, 7, 7, device=jacobian.device, dtype=jacobian.dtype)\n",
        "\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    for l in range(7):\n",
        "                        if l in {i, j, k}:\n",
        "                            continue\n",
        "\n",
        "                        val = (jacobian[:, j, k, l, i] -\n",
        "                               jacobian[:, i, k, l, j] +\n",
        "                               jacobian[:, i, j, l, k] -\n",
        "                               jacobian[:, i, j, k, l])\n",
        "\n",
        "                        indices = [i, j, k, l]\n",
        "                        for perm_idx, perm in enumerate([(0,1,2,3), (0,1,3,2), (0,2,1,3), (0,2,3,1)]):\n",
        "                            p = [indices[perm[m]] for m in range(4)]\n",
        "                            sign = 1\n",
        "                            for a in range(4):\n",
        "                                for b in range(a+1, 4):\n",
        "                                    if p[a] > p[b]:\n",
        "                                        sign *= -1\n",
        "                            dphi[:, p[0], p[1], p[2], p[3]] = sign * val\n",
        "\n",
        "        return dphi\n",
        "\n",
        "    def d_psi_norm(self, psi: torch.Tensor, phi_net: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute ||dψ||.\"\"\"\n",
        "        jacobian = self.compute_jacobian(phi_net, coords)\n",
        "        dphi_norm = (jacobian ** 2).sum(dim=(-4, -3, -2, -1))\n",
        "        return torch.sqrt(dphi_norm.mean())\n",
        "\n",
        "extd = ExteriorDerivative(CONFIG['n_grid'])\n",
        "print(\"Exterior derivative operators ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vt8Y7Lw6Tjm"
      },
      "source": [
        "## 6. NEW v1.1: Torsion Targeting Loss (CRITICAL FIX)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8L5sfvO6Tjm"
      },
      "source": [
        "## 9. GIFT 2.1 RG Flow Components (NEW v1.1c)\n",
        "\n",
        "Complete implementation of all four GIFT 2.1 terms with fixed divergence calculation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHIVqyj-6Tjn",
        "outputId": "b190d6f6-9edd-424d-8abe-892ff7923f11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torsion divergence function ready (FIXED v1.1c: handles 4-form correctly)\n"
          ]
        }
      ],
      "source": [
        "def compute_torsion_divergence(torsion: torch.Tensor, coords: torch.Tensor,\n",
        "                                dx: float = 1.0/16) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    FIXED v1.1c: Compute ∇·T using spatial variation as proxy for divergence.\n",
        "\n",
        "    Simplified divergence: measures how torsion components vary across the batch.\n",
        "\n",
        "    Args:\n",
        "        torsion: (batch, 7, 7, 7, 7) - T^ijkl 4-form components (dphi)\n",
        "        coords: (batch, 7) - coordinates\n",
        "        dx: grid spacing\n",
        "\n",
        "    Returns:\n",
        "        div_T: (batch,) - scalar divergence measure\n",
        "    \"\"\"\n",
        "    batch_size = torsion.shape[0]\n",
        "    div_T = torch.zeros(batch_size, device=torsion.device)\n",
        "\n",
        "    # Use component variation as proxy for divergence\n",
        "    # Sum over all 4 indices properly\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            for k in range(7):\n",
        "                for l in range(7):\n",
        "                    if batch_size > 1:\n",
        "                        # Measure how much this component varies across batch\n",
        "                        component = torsion[:, i, j, k, l]  # shape: (batch,)\n",
        "                        component_var = torch.abs(component - component.mean())\n",
        "                        div_T += component_var / dx\n",
        "\n",
        "    return div_T / (7**4)  # Normalize by 7^4 total components\n",
        "\n",
        "print(\"Torsion divergence function ready (FIXED v1.1c: handles 4-form correctly)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Av7l5CnQ6Tjn",
        "outputId": "bf873d8f-472a-4b5f-eff4-d2f0bf4850d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epsilon derivative function ready (∂ε g term)\n"
          ]
        }
      ],
      "source": [
        "def compute_epsilon_derivative(phi_net: nn.Module, coords: torch.Tensor,\n",
        "                               geometry, epsilon_0: float = 0.125) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    NEW v1.1c: Compute ∂ε g = metric derivative w.r.t. scale ε.\n",
        "\n",
        "    Measures how metric changes with RG scale (ε₀ = 1/8 from GIFT symmetry breaking).\n",
        "\n",
        "    Args:\n",
        "        phi_net: Neural network\n",
        "        coords: (batch, 7)\n",
        "        geometry: TCSGeometry object\n",
        "        epsilon_0: GIFT scale (1/8)\n",
        "\n",
        "    Returns:\n",
        "        deps_g: (batch, 3) - [trace variation, det variation, norm variation]\n",
        "    \"\"\"\n",
        "    delta_eps = 1e-4\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Baseline metric at ε₀\n",
        "        phi_base = phi_net(coords)\n",
        "        g_base, _ = compute_g2_metric(phi_base, phase=5)\n",
        "        g_base = geometry.acyl_metric_correction(coords, g_base)\n",
        "\n",
        "        # Perturbed metric (simulate scale change via coordinate rescaling)\n",
        "        coords_scaled = coords * (1 + delta_eps / epsilon_0)\n",
        "        phi_scaled = phi_net(coords_scaled % 1.0)\n",
        "        g_scaled, _ = compute_g2_metric(phi_scaled, phase=5)\n",
        "        g_scaled = geometry.acyl_metric_correction(coords_scaled % 1.0, g_scaled)\n",
        "\n",
        "        # Compute variations\n",
        "        trace_var = (torch.diagonal(g_scaled, dim1=-2, dim2=-1).sum(-1) -\n",
        "                    torch.diagonal(g_base, dim1=-2, dim2=-1).sum(-1)) / delta_eps\n",
        "        det_var = (torch.linalg.det(g_scaled) - torch.linalg.det(g_base)) / delta_eps\n",
        "        norm_var = ((g_scaled**2).sum((-2,-1)) - (g_base**2).sum((-2,-1))) / delta_eps\n",
        "\n",
        "    return torch.stack([trace_var, det_var, norm_var], dim=-1)\n",
        "\n",
        "print(\"Epsilon derivative function ready (∂ε g term)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JjJQipZ6Tjn",
        "outputId": "b77bc393-a679-42de-fee7-e7d05efa36b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fractality function ready (Fourier spectrum method)\n"
          ]
        }
      ],
      "source": [
        "def compute_fractality_fourier(torsion: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    NEW v1.1c: Fourier power spectrum slope as fractality measure.\n",
        "\n",
        "    Fractal structures have power law: P(k) ~ k^(-α)\n",
        "    Returns normalized α ∈ [0, 1] indicating multi-scale structure.\n",
        "\n",
        "    Args:\n",
        "        torsion: (batch, 7, 7, 7) - torsion components\n",
        "\n",
        "    Returns:\n",
        "        frac_idx: (batch,) - fractality index [0,1]\n",
        "    \"\"\"\n",
        "    batch_size = torsion.shape[0]\n",
        "    frac_idx = torch.zeros(batch_size, device=torsion.device)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        # Flatten torsion to 1D signal\n",
        "        T_flat = torsion[b].flatten()\n",
        "\n",
        "        # Skip if too small\n",
        "        if len(T_flat) < 10:\n",
        "            continue\n",
        "\n",
        "        # FFT power spectrum\n",
        "        fft = torch.fft.rfft(T_flat)\n",
        "        power = torch.abs(fft)**2\n",
        "\n",
        "        if len(power) < 3:\n",
        "            continue\n",
        "\n",
        "        # Log-log fit: log(P) = -α·log(k) + const\n",
        "        k = torch.arange(1, len(power), device=torsion.device, dtype=torch.float32)\n",
        "        log_k = torch.log(k + 1e-10)\n",
        "        log_P = torch.log(power[1:] + 1e-10)\n",
        "\n",
        "        # Linear regression for slope\n",
        "        k_mean = log_k.mean()\n",
        "        P_mean = log_P.mean()\n",
        "        numerator = ((log_k - k_mean) * (log_P - P_mean)).sum()\n",
        "        denominator = ((log_k - k_mean)**2).sum()\n",
        "\n",
        "        if denominator > 1e-10:\n",
        "            slope = numerator / denominator\n",
        "            # Normalize: typical fractals have α ∈ [1, 3], map to [0, 1]\n",
        "            frac_idx[b] = torch.clamp(-slope / 3.0, 0.0, 1.0)\n",
        "\n",
        "    return frac_idx\n",
        "\n",
        "print(\"Fractality function ready (Fourier spectrum method)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWPf1Xr06Tjn",
        "outputId": "b3012e81-4fd3-40c5-ed7d-eb883a466754"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RGFlowGIFT class ready (complete GIFT 2.1 formula)\n",
            "  Initial coefficients: A=-4.68, B=15.17, D=2.50\n",
            "  Component C weights: [10.  5.  1.]\n"
          ]
        }
      ],
      "source": [
        "class RGFlowGIFT:\n",
        "    \"\"\"\n",
        "    NEW v1.1c: Complete GIFT 2.1 RG flow calculator.\n",
        "\n",
        "    Implements: ℱ_RG = A·(∇·T) + B·|T|² + C·(∂ε g) + D·fractality(T)\n",
        "                Δα = ∫ ℱ_RG dx\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Dict):\n",
        "        self.config = config['rg_flow']\n",
        "        self.epsilon_0 = 0.125  # 1/8 GIFT symmetry breaking scale\n",
        "\n",
        "        # Learnable coefficients (will be calibrated at epoch 2000)\n",
        "        self.A = -4.68   # divergence\n",
        "        self.B = 15.17   # norm\n",
        "        self.C = torch.tensor([10.0, 5.0, 1.0])  # epsilon derivatives\n",
        "        self.D = 2.5     # fractality\n",
        "\n",
        "        self.history = []  # for monitoring\n",
        "\n",
        "    def compute_delta_alpha(self, phi_net, geometry, coords, torsion, epoch):\n",
        "        \"\"\"\n",
        "        NEW v1.1c: Full GIFT 2.1 calculation with all four components.\n",
        "\n",
        "        Args:\n",
        "            phi_net: Neural network\n",
        "            geometry: TCSGeometry\n",
        "            coords: Sample coordinates\n",
        "            torsion: Torsion tensor (dphi)\n",
        "            epoch: Current epoch (for logging)\n",
        "\n",
        "        Returns:\n",
        "            delta_alpha: RG running value\n",
        "            components: Dict with breakdown of each term\n",
        "        \"\"\"\n",
        "        # Component A: divergence (if enabled)\n",
        "        A_term = torch.tensor(0.0, device=coords.device)\n",
        "        div_T_mean = 0.0\n",
        "        if self.config.get('enable_divergence', True):\n",
        "            div_T = compute_torsion_divergence(torsion, coords)\n",
        "            div_T_mean = div_T.mean().item()\n",
        "            A_term = self.A * div_T.mean()\n",
        "\n",
        "        # Component B: norm (existing from v1.1)\n",
        "        B_term = self.B * torch.norm(torsion)**2\n",
        "\n",
        "        # Component C: epsilon variation (if enabled)\n",
        "        C_term = torch.tensor(0.0, device=coords.device)\n",
        "        if self.config.get('enable_epsilon_var', True):\n",
        "            deps_g = compute_epsilon_derivative(phi_net, coords, geometry, self.epsilon_0)\n",
        "            C_term = torch.dot(self.C.to(coords.device), deps_g.mean(0))\n",
        "\n",
        "        # Component D: fractality (if enabled)\n",
        "        D_term = torch.tensor(0.0, device=coords.device)\n",
        "        frac_idx_mean = 0.0\n",
        "        if self.config.get('enable_fractality', True):\n",
        "            frac_idx = compute_fractality_fourier(torsion)\n",
        "            frac_idx_mean = frac_idx.mean().item()\n",
        "            D_term = self.D * frac_idx.mean()\n",
        "\n",
        "        # Total integrand\n",
        "        integrand = A_term + B_term + C_term + D_term\n",
        "\n",
        "        # Geodesic integration over λ ∈ [0, lambda_max]\n",
        "        lambdas = torch.linspace(0, self.config['lambda_max'],\n",
        "                                self.config['n_integration_steps'], device=coords.device)\n",
        "        delta_alpha = torch.trapz(integrand * torch.ones_like(lambdas), lambdas)\n",
        "\n",
        "        # Log components for monitoring\n",
        "        components = {\n",
        "            'A_divergence': A_term.item() if torch.is_tensor(A_term) else A_term,\n",
        "            'B_norm': B_term.item(),\n",
        "            'C_epsilon': C_term.item() if torch.is_tensor(C_term) else C_term,\n",
        "            'D_fractality': D_term.item() if torch.is_tensor(D_term) else D_term,\n",
        "            'total': delta_alpha.item(),\n",
        "            'div_T_mean': div_T_mean,\n",
        "            'frac_idx_mean': frac_idx_mean,\n",
        "        }\n",
        "\n",
        "        if self.config.get('monitor_components', False):\n",
        "            self.history.append({'epoch': epoch, **components})\n",
        "\n",
        "        return delta_alpha, components\n",
        "\n",
        "rg_flow_gift = RGFlowGIFT(CONFIG)\n",
        "print(\"RGFlowGIFT class ready (complete GIFT 2.1 formula)\")\n",
        "print(f\"  Initial coefficients: A={rg_flow_gift.A:.2f}, B={rg_flow_gift.B:.2f}, D={rg_flow_gift.D:.2f}\")\n",
        "print(f\"  Component C weights: {rg_flow_gift.C.numpy()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqxSrvhC6Tjo",
        "outputId": "ad2cad40-2e9c-4c00-cac6-c2c0262d806a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SmartEarlyStopping class ready\n"
          ]
        }
      ],
      "source": [
        "class SmartEarlyStopping:\n",
        "    \"\"\"\n",
        "    NEW v1.1c: Smart early stopping with NaN detection and RG flow awareness.\n",
        "\n",
        "    Prevents premature stopping while allowing phases to converge naturally.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, phase_config, phase_num):\n",
        "        self.patience = phase_config.get('early_stop', {}).get('patience', 200)\n",
        "        self.criteria = phase_config.get('early_stop', {}).get('criteria', {})\n",
        "        self.min_epochs = self.criteria.get('min_epochs', 0)\n",
        "        self.phase_num = phase_num\n",
        "\n",
        "        self.counter = 0\n",
        "        self.best_loss = float('inf')\n",
        "\n",
        "    def check(self, epoch, losses, metrics, config):\n",
        "        \"\"\"\n",
        "        Check if should stop training.\n",
        "\n",
        "        Returns True if should stop, False otherwise.\n",
        "        \"\"\"\n",
        "        # NaN check\n",
        "        for key, val in losses.items():\n",
        "            if isinstance(val, torch.Tensor):\n",
        "                if torch.isnan(val) or torch.isinf(val):\n",
        "                    print(f\"⚠️  NaN/Inf detected in {key} at epoch {epoch}, stopping phase {self.phase_num}\")\n",
        "                    return True\n",
        "\n",
        "        # Minimum epochs\n",
        "        if epoch < self.min_epochs:\n",
        "            return False\n",
        "\n",
        "        # Check criteria satisfaction\n",
        "        all_met = True\n",
        "        for criterion, threshold in self.criteria.items():\n",
        "            if criterion == 'min_epochs':\n",
        "                continue\n",
        "            elif criterion == 'torsion_target_reached':\n",
        "                torsion_error = abs(metrics.get('actual_torsion', 0) - config['torsion_targets'][self.phase_num])\n",
        "                torsion_error_rel = torsion_error / config['torsion_targets'][self.phase_num]\n",
        "                if torsion_error_rel > 0.2:  # 20% tolerance\n",
        "                    all_met = False\n",
        "            elif criterion == 'rg_flow_delta' and self.phase_num >= 5:\n",
        "                delta_alpha = metrics.get('delta_alpha', 0)\n",
        "                target = config['rg_flow']['target_delta_alpha']\n",
        "                rg_error_rel = abs(delta_alpha - target) / abs(target)\n",
        "                if rg_error_rel > threshold:\n",
        "                    all_met = False\n",
        "            elif criterion in losses:\n",
        "                loss_val = losses[criterion]\n",
        "                if isinstance(loss_val, torch.Tensor):\n",
        "                    loss_val = loss_val.item()\n",
        "                if loss_val > threshold:\n",
        "                    all_met = False\n",
        "\n",
        "        if not all_met:\n",
        "            self.counter = 0\n",
        "            return False\n",
        "\n",
        "        # Patience mechanism\n",
        "        current_loss = losses.get('total', float('inf'))\n",
        "        if isinstance(current_loss, torch.Tensor):\n",
        "            current_loss = current_loss.item()\n",
        "\n",
        "        if current_loss < self.best_loss * 0.999:  # 0.1% improvement\n",
        "            self.best_loss = current_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "\n",
        "        if self.counter >= self.patience:\n",
        "            print(f\"✓ Early stop phase {self.phase_num} at epoch {epoch}: criteria met for {self.patience} epochs\")\n",
        "            return True\n",
        "\n",
        "        return False\n",
        "\n",
        "print(\"SmartEarlyStopping class ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Siqsoh8a6Tjo",
        "outputId": "654a0f29-f477-4d78-efea-390d6811150a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RGFlowMonitor class ready\n"
          ]
        }
      ],
      "source": [
        "class RGFlowMonitor:\n",
        "    \"\"\"\n",
        "    NEW v1.1c: Detailed RG flow component tracking.\n",
        "\n",
        "    Logs all GIFT 2.1 components (A, B, C, D) separately for analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def log(self, epoch, rg_components, metrics):\n",
        "        \"\"\"Log RG flow components for this epoch.\"\"\"\n",
        "        entry = {\n",
        "            'epoch': epoch,\n",
        "            'delta_alpha': rg_components.get('total', 0),\n",
        "            'A_div': rg_components.get('A_divergence', 0),\n",
        "            'B_norm': rg_components.get('B_norm', 0),\n",
        "            'C_eps': rg_components.get('C_epsilon', 0),\n",
        "            'D_frac': rg_components.get('D_fractality', 0),\n",
        "            'div_T': rg_components.get('div_T_mean', 0),\n",
        "            'frac_idx': rg_components.get('frac_idx_mean', 0),\n",
        "            'torsion_norm': metrics.get('actual_torsion', 0),\n",
        "            'det_g': metrics.get('det_g', 0),\n",
        "        }\n",
        "        self.history.append(entry)\n",
        "\n",
        "    def save(self, path='rg_flow_log.csv'):\n",
        "        \"\"\"Save component history to CSV.\"\"\"\n",
        "        import pandas as pd\n",
        "        if len(self.history) > 0:\n",
        "            df = pd.DataFrame(self.history)\n",
        "            df.to_csv(path, index=False)\n",
        "            print(f\"RG flow component log saved to {path}\")\n",
        "\n",
        "rg_monitor = RGFlowMonitor()\n",
        "print(\"RGFlowMonitor class ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQhw9Ni66Tjo"
      },
      "source": [
        "## 10. Two-Speed Learning Rate Scheduler (NEW v1.1c)\n",
        "\n",
        "Progressive LR schedule to stabilize geometry before activating RG flow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBXxJ_cV6Tjo",
        "outputId": "311f1f7f-865c-4df0-a9c5-327612df47c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TwoSpeedLRScheduler class ready\n",
            "  Phase 1-2: LR = 0.0001\n",
            "  Phase 3-5: LR = 0.0005 with warmup over 200 epochs\n",
            "  Cosine decay to: LR_min = 1e-05\n"
          ]
        }
      ],
      "source": [
        "class TwoSpeedLRScheduler:\n",
        "    \"\"\"\n",
        "    NEW v1.1c: Two-speed learning rate with warmup and cosine decay.\n",
        "\n",
        "    Schedule:\n",
        "    - Phases 1-2: Constant 1e-4 (stabilize geometry)\n",
        "    - Phase 3 start: Warmup from 1e-4 to 5e-4 over 200 epochs\n",
        "    - Phases 3-5: Cosine decay from 5e-4 to 1e-5\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, optimizer, config):\n",
        "        self.optimizer = optimizer\n",
        "        self.lr_phase12 = config['learning_rate_phase12']\n",
        "        self.lr_phase35 = config['learning_rate_phase35']\n",
        "        self.lr_min = config['lr_min']\n",
        "        self.warmup_epochs = config['lr_warmup_epochs']\n",
        "\n",
        "        # Track phase 3 start for warmup\n",
        "        self.phase3_start_epoch = None\n",
        "        self.current_phase = 1\n",
        "\n",
        "    def get_lr(self, epoch, phase):\n",
        "        \"\"\"Compute LR for current epoch and phase.\"\"\"\n",
        "        if phase <= 2:\n",
        "            # Phases 1-2: constant low LR\n",
        "            return self.lr_phase12\n",
        "        else:\n",
        "            # Phases 3-5: warmup + cosine decay\n",
        "            if self.phase3_start_epoch is None:\n",
        "                # Mark start of phase 3\n",
        "                self.phase3_start_epoch = epoch\n",
        "\n",
        "            epochs_since_phase3 = epoch - self.phase3_start_epoch\n",
        "\n",
        "            if epochs_since_phase3 < self.warmup_epochs:\n",
        "                # Warmup: linear from lr_phase12 to lr_phase35\n",
        "                alpha = epochs_since_phase3 / self.warmup_epochs\n",
        "                lr = self.lr_phase12 + alpha * (self.lr_phase35 - self.lr_phase12)\n",
        "            else:\n",
        "                # Cosine decay from lr_phase35 to lr_min\n",
        "                # Assuming total ~6000 epochs for phases 3-5\n",
        "                decay_epochs = epochs_since_phase3 - self.warmup_epochs\n",
        "                max_decay_epochs = 6000  # Approximate total for phases 3-5\n",
        "                progress = min(decay_epochs / max_decay_epochs, 1.0)\n",
        "                lr = self.lr_min + 0.5 * (self.lr_phase35 - self.lr_min) * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "            return lr\n",
        "\n",
        "    def step(self, epoch, phase):\n",
        "        \"\"\"Update optimizer LR.\"\"\"\n",
        "        if phase != self.current_phase:\n",
        "            self.current_phase = phase\n",
        "            if phase == 3 and self.phase3_start_epoch is None:\n",
        "                self.phase3_start_epoch = epoch\n",
        "\n",
        "        lr = self.get_lr(epoch, phase)\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        return lr\n",
        "\n",
        "print(\"TwoSpeedLRScheduler class ready\")\n",
        "print(f\"  Phase 1-2: LR = {CONFIG['learning_rate_phase12']}\")\n",
        "print(f\"  Phase 3-5: LR = {CONFIG['learning_rate_phase35']} with warmup over {CONFIG['lr_warmup_epochs']} epochs\")\n",
        "print(f\"  Cosine decay to: LR_min = {CONFIG['lr_min']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQdma5qG6Tjp",
        "outputId": "7a848b62-9731-48a4-f51a-a40de3444272"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RG flow loss function updated to use RGFlowGIFT (GIFT 2.1 complete)\n"
          ]
        }
      ],
      "source": [
        "def compute_rg_flow_loss(phi_net, rg_flow_gift, geodesic_integrator, config: Dict,\n",
        "                         coords: torch.Tensor, torsion: torch.Tensor, epoch: int):\n",
        "    \"\"\"\n",
        "    UPDATED v1.1c: Compute RG flow constraint loss using complete GIFT 2.1 formula.\n",
        "\n",
        "    Uses RGFlowGIFT class to compute all four components.\n",
        "\n",
        "    Args:\n",
        "        phi_net: Neural network\n",
        "        rg_flow_gift: RGFlowGIFT calculator\n",
        "        geodesic_integrator: Geodesic integrator\n",
        "        config: Configuration\n",
        "        coords: Sample coordinates\n",
        "        torsion: Torsion tensor (dphi)\n",
        "        epoch: Current epoch\n",
        "\n",
        "    Returns:\n",
        "        loss_rg: RG flow loss\n",
        "        components: Component breakdown dict\n",
        "    \"\"\"\n",
        "    # Compute Δα using complete GIFT 2.1 formula\n",
        "    delta_alpha, components = rg_flow_gift.compute_delta_alpha(\n",
        "        phi_net, geodesic_integrator.geometry, coords, torsion, epoch\n",
        "    )\n",
        "\n",
        "    # Loss: match target Δα\n",
        "    target_delta = config['rg_flow']['target_delta_alpha']\n",
        "    loss_rg = (delta_alpha - target_delta) ** 2\n",
        "\n",
        "    # Store in components for monitoring\n",
        "    components['loss'] = loss_rg.item()\n",
        "    components['target'] = target_delta\n",
        "\n",
        "    return loss_rg, components\n",
        "\n",
        "print(\"RG flow loss function updated to use RGFlowGIFT (GIFT 2.1 complete)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp-CCgO96Tjp",
        "outputId": "d8c4db54-e1d2-4e94-a6b9-7cb40177dc6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torsion targeting loss ready (v1.1 critical fix)\n"
          ]
        }
      ],
      "source": [
        "def compute_torsion_targeting_loss(dphi: torch.Tensor, dpsi_norm: torch.Tensor,\n",
        "                                   target_torsion: float, config: Dict) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Target torsion magnitude rather than minimize to zero.\n",
        "\n",
        "    This is the CRITICAL FIX for v1.1:\n",
        "    - v1.0f minimized: loss = ||dφ||² + ||dψ||² → drives torsion to machine precision\n",
        "    - v1.1 targets: loss = (||T|| - target)² → maintains phenomenologically viable torsion\n",
        "\n",
        "    Args:\n",
        "        dphi: Exterior derivative tensor (batch, 7, 7, 7, 7)\n",
        "        dpsi_norm: Scalar norm of d*φ\n",
        "        target_torsion: Target ||T|| from GIFT calibration (phase-dependent)\n",
        "        config: Configuration dictionary\n",
        "\n",
        "    Returns:\n",
        "        loss_torsion: Squared deviation from target\n",
        "        actual_torsion: Current torsion magnitude (for monitoring)\n",
        "    \"\"\"\n",
        "    # Compute actual torsion norm from dphi and dpsi\n",
        "    dphi_norm = torch.sqrt((dphi ** 2).sum(dim=(-4,-3,-2,-1)).mean())\n",
        "    actual_torsion = torch.sqrt(dphi_norm**2 + dpsi_norm**2)\n",
        "\n",
        "    # Penalize deviation from target (not from zero)\n",
        "    loss_torsion = (actual_torsion - target_torsion)**2\n",
        "\n",
        "    # Prevent collapse to zero (floor enforcement)\n",
        "    torsion_floor = config.get('torsion_floor', 1e-9)\n",
        "    if actual_torsion < torsion_floor:\n",
        "        loss_torsion += 100.0 * (torsion_floor - actual_torsion)\n",
        "\n",
        "    return loss_torsion, actual_torsion\n",
        "\n",
        "\n",
        "print(\"Torsion targeting loss ready (v1.1 critical fix)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu-bQuKo6Tjp"
      },
      "source": [
        "## 7. NEW v1.1: AlphaInverseFunctional (Observable-Based Training)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCk7oUv66Tjp",
        "outputId": "75b7246f-98f9-4eaf-f9c4-0b0169c7c78b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlphaInverseFunctional initialized\n",
            "  Reference α⁻¹ = 137.036\n",
            "  Initial coefficients: A=-4.68, B=15.17\n",
            "  Component weights: C=[10.  5.  1.]\n"
          ]
        }
      ],
      "source": [
        "class AlphaInverseFunctional(nn.Module):\n",
        "    \"\"\"\n",
        "    NEW v1.1: Compute α⁻¹ as functional of geometry.\n",
        "\n",
        "    α⁻¹(x) = α⁻¹_ref + A·δ(det g) + B·δ||T|| + Σ C_i·δT^{components}\n",
        "\n",
        "    This functional explicitly depends on torsion magnitude, creating physics-based\n",
        "    constraint that maintains ||T|| ≠ 0 for phenomenological viability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Dict):\n",
        "        super().__init__()\n",
        "\n",
        "        # Reference values (M_Z scale)\n",
        "        self.alpha_inv_ref = 137.036  # QED fine structure constant\n",
        "        self.det_g_ref = config['target']['det_g']\n",
        "        self.T_norm_ref = config['target']['torsion_norm']\n",
        "\n",
        "        # Learnable coefficients (calibrated globally at epoch 6000)\n",
        "        # Initial values from toy model validation\n",
        "        self.A = nn.Parameter(torch.tensor(-4.68))  # det(g) coefficient\n",
        "        self.B = nn.Parameter(torch.tensor(15.17))  # torsion norm coefficient\n",
        "        self.C = nn.Parameter(torch.tensor([10.0, 5.0, 1.0]))  # component coefficients\n",
        "\n",
        "    def forward(self, g: torch.Tensor, T: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            g: Metric tensor (batch, 7, 7)\n",
        "            T: Torsion tensor (batch, 7, 7, 7) - this is dphi in our case\n",
        "\n",
        "        Returns:\n",
        "            alpha_inv: (batch,) - fine structure constant at each point\n",
        "        \"\"\"\n",
        "        det_g = torch.linalg.det(g)\n",
        "        T_norm = torch.sqrt((T**2).sum(dim=(-3,-2,-1)))\n",
        "\n",
        "        # Key torsion components (indices: electron, pion, photon)\n",
        "        # These specific components couple to fermion mass generation\n",
        "        T_components = torch.stack([\n",
        "            T[:, 1, 0, 2],  # T^π_{eφ}\n",
        "            T[:, 0, 1, 2],  # T^e_{πφ}\n",
        "            T[:, 2, 0, 1]   # T^φ_{eπ}\n",
        "        ], dim=-1)\n",
        "\n",
        "        # Deviations from reference\n",
        "        delta_det_g = det_g - self.det_g_ref\n",
        "        delta_T_norm = T_norm - self.T_norm_ref\n",
        "        delta_T_components = T_components  # Already relative\n",
        "\n",
        "        # Functional\n",
        "        alpha_inv = self.alpha_inv_ref\n",
        "        alpha_inv = alpha_inv + self.A * delta_det_g\n",
        "        alpha_inv = alpha_inv + self.B * delta_T_norm\n",
        "        alpha_inv = alpha_inv + torch.sum(self.C * delta_T_components, dim=-1)\n",
        "\n",
        "        return alpha_inv\n",
        "\n",
        "\n",
        "alpha_functional = AlphaInverseFunctional(CONFIG).to(device)\n",
        "print(f\"AlphaInverseFunctional initialized\")\n",
        "print(f\"  Reference α⁻¹ = {alpha_functional.alpha_inv_ref}\")\n",
        "print(f\"  Initial coefficients: A={alpha_functional.A.item():.2f}, B={alpha_functional.B.item():.2f}\")\n",
        "print(f\"  Component weights: C={alpha_functional.C.data.cpu().numpy()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqEugQom6Tjp"
      },
      "source": [
        "## 8. NEW v1.1: Geodesic Integrator for RG Flow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg4iso986Tjp",
        "outputId": "715bb5a5-623e-4edf-c175-35b33b0c4646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Geodesic integrator ready (RK4 with Christoffel computation)\n"
          ]
        }
      ],
      "source": [
        "class GeodesicIntegrator:\n",
        "    \"\"\"\n",
        "    NEW v1.1: RK4/5 integrator with cached Christoffel symbols for geodesic integration.\n",
        "\n",
        "    Integrates geodesic equation: d²x/dλ² + Γ^i_jk (dx/dλ)^j (dx/dλ)^k = 0\n",
        "\n",
        "    Used for RG flow: integrate from M_Z (initial) to M_Planck (final) along\n",
        "    quasi-static trajectory in moduli space.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, phi_net: nn.Module, geometry: TCSGeometry, config: Dict):\n",
        "        self.phi_net = phi_net\n",
        "        self.geometry = geometry\n",
        "        self.config = config\n",
        "        self.christoffel_cache = {}  # Cache for computed Christoffel symbols\n",
        "\n",
        "    def compute_christoffel(self, x: torch.Tensor, g: torch.Tensor, g_inv: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute Christoffel symbols Γ^i_jk = (1/2) g^il (∂_j g_lk + ∂_k g_jl - ∂_l g_jk).\n",
        "\n",
        "        Args:\n",
        "            x: Position (batch, 7)\n",
        "            g: Metric (batch, 7, 7)\n",
        "            g_inv: Inverse metric (batch, 7, 7)\n",
        "\n",
        "        Returns:\n",
        "            christoffel: (batch, 7, 7, 7) - Γ^i_jk\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        christoffel = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        epsilon = 1e-4\n",
        "\n",
        "        # Compute metric derivatives numerically\n",
        "        for l in range(7):\n",
        "            x_plus = x.clone()\n",
        "            x_plus[:, l] += epsilon\n",
        "            x_plus[:, l] = x_plus[:, l] % 1.0\n",
        "\n",
        "            x_minus = x.clone()\n",
        "            x_minus[:, l] -= epsilon\n",
        "            x_minus[:, l] = x_minus[:, l] % 1.0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                phi_plus = self.phi_net(x_plus)\n",
        "                phi_minus = self.phi_net(x_minus)\n",
        "\n",
        "                g_plus, _ = compute_g2_metric(phi_plus, phase=5)\n",
        "                g_minus, _ = compute_g2_metric(phi_minus, phase=5)\n",
        "\n",
        "                g_plus = self.geometry.acyl_metric_correction(x_plus, g_plus)\n",
        "                g_minus = self.geometry.acyl_metric_correction(x_minus, g_minus)\n",
        "\n",
        "                dg_dl = (g_plus - g_minus) / (2 * epsilon)\n",
        "\n",
        "            # Compute Christoffel components: Γ^i_jk = (1/2) Σ_l g^il (∂_j g_lk + ∂_k g_jl - ∂_l g_jk)\n",
        "            # Here dg_dl is ∂_l g\n",
        "            for i in range(7):\n",
        "                for j in range(7):\n",
        "                    for k in range(7):\n",
        "                        # This term contributes to Γ^i_jk via: (1/2) g^il * (-∂_l g_jk)\n",
        "                        val = -0.5 * dg_dl[:, j, k]  # shape: (batch,)\n",
        "                        christoffel[:, i, j, k] += g_inv[:, i, l] * val\n",
        "\n",
        "            # Now add the ∂_j g_lk and ∂_k g_jl terms\n",
        "            # When we have ∂_l g computed, and we want ∂_j g_lk, we need the l-th derivative evaluated at index [l,k]\n",
        "            # But we need to compute this differently - we need all derivatives\n",
        "\n",
        "        # Recompute with proper derivative structure\n",
        "        # We need ∂_j g_mn for all j,m,n\n",
        "        dg = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)  # dg[b, j, m, n] = ∂_j g_mn\n",
        "\n",
        "        for j in range(7):\n",
        "            x_plus = x.clone()\n",
        "            x_plus[:, j] += epsilon\n",
        "            x_plus[:, j] = x_plus[:, j] % 1.0\n",
        "\n",
        "            x_minus = x.clone()\n",
        "            x_minus[:, j] -= epsilon\n",
        "            x_minus[:, j] = x_minus[:, j] % 1.0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                phi_plus = self.phi_net(x_plus)\n",
        "                phi_minus = self.phi_net(x_minus)\n",
        "\n",
        "                g_plus, _ = compute_g2_metric(phi_plus, phase=5)\n",
        "                g_minus, _ = compute_g2_metric(phi_minus, phase=5)\n",
        "\n",
        "                g_plus = self.geometry.acyl_metric_correction(x_plus, g_plus)\n",
        "                g_minus = self.geometry.acyl_metric_correction(x_minus, g_minus)\n",
        "\n",
        "                dg[:, j, :, :] = (g_plus - g_minus) / (2 * epsilon)\n",
        "\n",
        "        # Now compute Christoffel: Γ^i_jk = (1/2) Σ_l g^il (∂_j g_lk + ∂_k g_jl - ∂_l g_jk)\n",
        "        christoffel = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "        for i in range(7):\n",
        "            for j in range(7):\n",
        "                for k in range(7):\n",
        "                    for l in range(7):\n",
        "                        term = 0.5 * (dg[:, j, l, k] + dg[:, k, j, l] - dg[:, l, j, k])\n",
        "                        christoffel[:, i, j, k] += g_inv[:, i, l] * term\n",
        "\n",
        "        return christoffel\n",
        "\n",
        "    def geodesic_rhs(self, x: torch.Tensor, v: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Right-hand side of geodesic equation.\n",
        "\n",
        "        dx/dλ = v\n",
        "        dv/dλ = -Γ^i_jk v^j v^k\n",
        "\n",
        "        Args:\n",
        "            x: Position (batch, 7)\n",
        "            v: Velocity (batch, 7)\n",
        "\n",
        "        Returns:\n",
        "            dx/dλ, dv/dλ\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            phi = self.phi_net(x)\n",
        "            g, g_inv = compute_g2_metric(phi, phase=5)\n",
        "            g = self.geometry.acyl_metric_correction(x, g)\n",
        "            g = normalize_metric(g, self.config['target']['det_g'])\n",
        "\n",
        "            christoffel = self.compute_christoffel(x, g, g_inv)\n",
        "\n",
        "            # dv/dλ = -Γ^i_jk v^j v^k\n",
        "            dv = -torch.einsum('bijk,bj,bk->bi', christoffel, v, v)\n",
        "\n",
        "        return v, dv\n",
        "\n",
        "    def integrate_rk4(self, x0: torch.Tensor, v0: torch.Tensor, lambda_max: float, n_steps: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        RK4 integration of geodesic from λ=0 to λ=lambda_max.\n",
        "\n",
        "        Args:\n",
        "            x0: Initial position (7,)\n",
        "            v0: Initial velocity (7,)\n",
        "            lambda_max: Maximum affine parameter (ln(M_Planck/M_Z) = 39.44)\n",
        "            n_steps: Number of integration steps\n",
        "\n",
        "        Returns:\n",
        "            x_trajectory: (n_steps+1, 7) - positions along geodesic\n",
        "            v_trajectory: (n_steps+1, 7) - velocities along geodesic\n",
        "        \"\"\"\n",
        "        dlambda = lambda_max / n_steps\n",
        "\n",
        "        x_traj = [x0.unsqueeze(0)]\n",
        "        v_traj = [v0.unsqueeze(0)]\n",
        "\n",
        "        x = x0.unsqueeze(0)\n",
        "        v = v0.unsqueeze(0)\n",
        "\n",
        "        for step in range(n_steps):\n",
        "            # RK4 integration\n",
        "            k1_x, k1_v = self.geodesic_rhs(x, v)\n",
        "\n",
        "            k2_x, k2_v = self.geodesic_rhs(x + 0.5 * dlambda * k1_x, v + 0.5 * dlambda * k1_v)\n",
        "\n",
        "            k3_x, k3_v = self.geodesic_rhs(x + 0.5 * dlambda * k2_x, v + 0.5 * dlambda * k2_v)\n",
        "\n",
        "            k4_x, k4_v = self.geodesic_rhs(x + dlambda * k3_x, v + dlambda * k3_v)\n",
        "\n",
        "            # Update\n",
        "            x = x + (dlambda / 6.0) * (k1_x + 2*k2_x + 2*k3_x + k4_x)\n",
        "            v = v + (dlambda / 6.0) * (k1_v + 2*k2_v + 2*k3_v + k4_v)\n",
        "\n",
        "            # Periodic boundary conditions\n",
        "            x = x % 1.0\n",
        "\n",
        "            x_traj.append(x)\n",
        "            v_traj.append(v)\n",
        "\n",
        "        x_trajectory = torch.cat(x_traj, dim=0)\n",
        "        v_trajectory = torch.cat(v_traj, dim=0)\n",
        "\n",
        "        return x_trajectory, v_trajectory\n",
        "\n",
        "\n",
        "geodesic_integrator = GeodesicIntegrator(phi_net, geometry, CONFIG)\n",
        "print(\"Geodesic integrator ready (RK4 with Christoffel computation)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM_h3jBI6Tjq"
      },
      "source": [
        "## 9. NEW v1.1: RG Flow Loss and Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3d-TKeO6Tjq",
        "outputId": "b9de31ca-c7dd-45e7-dc41-af23cbcfb2d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "v1.1c: Using RGFlowGIFT for complete GIFT 2.1 RG flow\n"
          ]
        }
      ],
      "source": [
        "# NOTE: Legacy v1.1 RG flow functions removed for v1.1c\n",
        "# v1.1c uses RGFlowGIFT class (Cell 18) with GIFT 2.1 complete formula\n",
        "# instead of AlphaInverseFunctional approach\n",
        "\n",
        "print(\"v1.1c: Using RGFlowGIFT for complete GIFT 2.1 RG flow\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4N8NzJ46Tjq"
      },
      "source": [
        "## 10. Discrete Laplacian and Live Harmonic Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut8RNe1-6Tjq",
        "outputId": "37b5fc46-52e4-484d-96f3-79d5735138dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete Laplacian and live harmonic extractor ready (optimized version)\n"
          ]
        }
      ],
      "source": [
        "class DiscreteLaplacian:\n",
        "    def __init__(self, n_grid: int, dim: int):\n",
        "        self.n = n_grid\n",
        "        self.dim = dim\n",
        "        self.dx = 1.0 / n_grid\n",
        "\n",
        "        from scipy.special import comb\n",
        "        self.n_dof = int(comb(7, dim)) * (n_grid ** 7)\n",
        "\n",
        "        print(f\"Building {dim}-form Laplacian: {self.n}^7 = {self.n**7:,} points...\")\n",
        "        self.laplacian = self._build_laplacian_fast()\n",
        "\n",
        "    def _build_laplacian_fast(self) -> csr_matrix:\n",
        "        \"\"\"Vectorized Laplacian construction.\"\"\"\n",
        "        n = self.n\n",
        "        n_total = n ** 7\n",
        "\n",
        "        print(f\"  Allocating sparse structure for {n_total:,} × {n_total:,} matrix...\")\n",
        "\n",
        "        # Pre-allocate arrays for COO format\n",
        "        max_entries = n_total * (1 + 2 * 7)\n",
        "        row_indices = []\n",
        "        col_indices = []\n",
        "        data = []\n",
        "\n",
        "        stencil = -2.0 * 7 / (self.dx ** 2)\n",
        "        neighbor = 1.0 / (self.dx ** 2)\n",
        "\n",
        "        # Diagonal entries\n",
        "        print(f\"  Building diagonal...\")\n",
        "        diag_idx = np.arange(n_total)\n",
        "        row_indices.append(diag_idx)\n",
        "        col_indices.append(diag_idx)\n",
        "        data.append(np.full(n_total, stencil))\n",
        "\n",
        "        # Off-diagonal entries (vectorized by axis)\n",
        "        print(f\"  Building off-diagonal entries...\")\n",
        "        for axis in range(7):\n",
        "            if axis % 2 == 0:\n",
        "                print(f\"    Processing axis {axis+1}/7...\")\n",
        "\n",
        "            # Compute all indices at once\n",
        "            all_coords = np.array(np.unravel_index(np.arange(n_total), [n] * 7))\n",
        "\n",
        "            # Forward neighbors\n",
        "            coords_plus = all_coords.copy()\n",
        "            coords_plus[axis] = (coords_plus[axis] + 1) % n\n",
        "            idx_plus = np.ravel_multi_index(coords_plus, [n] * 7)\n",
        "\n",
        "            row_indices.append(diag_idx)\n",
        "            col_indices.append(idx_plus)\n",
        "            data.append(np.full(n_total, neighbor))\n",
        "\n",
        "            # Backward neighbors\n",
        "            coords_minus = all_coords.copy()\n",
        "            coords_minus[axis] = (coords_minus[axis] - 1) % n\n",
        "            idx_minus = np.ravel_multi_index(coords_minus, [n] * 7)\n",
        "\n",
        "            row_indices.append(diag_idx)\n",
        "            col_indices.append(idx_minus)\n",
        "            data.append(np.full(n_total, neighbor))\n",
        "\n",
        "        # Concatenate all arrays\n",
        "        print(f\"  Assembling sparse matrix...\")\n",
        "        row_indices = np.concatenate(row_indices)\n",
        "        col_indices = np.concatenate(col_indices)\n",
        "        data = np.concatenate(data)\n",
        "\n",
        "        # Build COO then convert to CSR\n",
        "        from scipy.sparse import coo_matrix\n",
        "        L = coo_matrix((data, (row_indices, col_indices)), shape=(n_total, n_total))\n",
        "        print(f\"  Converting to CSR format...\")\n",
        "        L_csr = L.tocsr()\n",
        "        print(f\"  ✓ Laplacian built: {L_csr.nnz:,} non-zero entries\")\n",
        "\n",
        "        return L_csr\n",
        "\n",
        "    def compute_spectrum(self, k: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Extract k smallest eigenvalues/vectors.\"\"\"\n",
        "        print(f\"  Computing {k} smallest eigenmodes (this may take 5-15 min)...\")\n",
        "        import time\n",
        "        start = time.time()\n",
        "\n",
        "        # Limit k to avoid convergence issues\n",
        "        k_safe = min(k, self.laplacian.shape[0] - 10)\n",
        "\n",
        "        eigenvalues, eigenvectors = eigsh(self.laplacian, k=k_safe, which='SM',\n",
        "                                          tol=1e-5, maxiter=1000)\n",
        "\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"  ✓ Spectrum computed in {elapsed/60:.1f} minutes\")\n",
        "\n",
        "        return eigenvalues, eigenvectors\n",
        "\n",
        "\n",
        "class LiveHarmonicExtractor:\n",
        "    def __init__(self, laplacian: DiscreteLaplacian, target_dim: int, threshold: float = 1e-6):\n",
        "        self.laplacian = laplacian\n",
        "        self.target_dim = target_dim\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def extract(self) -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Extract harmonic modes and return (modes, effective_dimension).\"\"\"\n",
        "        k = min(self.target_dim + 50, self.laplacian.laplacian.shape[0] - 10)\n",
        "\n",
        "        eigenvalues, eigenvectors = self.laplacian.compute_spectrum(k=k)\n",
        "\n",
        "        print(f\"  Eigenvalue range: [{eigenvalues[0]:.2e}, {eigenvalues[-1]:.2e}]\")\n",
        "\n",
        "        harmonic_mask = np.abs(eigenvalues) < self.threshold\n",
        "        harmonic_indices = np.where(harmonic_mask)[0]\n",
        "\n",
        "        print(f\"  Found {len(harmonic_indices)} harmonic modes (threshold={self.threshold:.2e})\")\n",
        "\n",
        "        if len(harmonic_indices) < self.target_dim:\n",
        "            print(f\"  ⚠ Using {self.target_dim} smallest modes instead\")\n",
        "            harmonic_indices = np.arange(min(self.target_dim, len(eigenvalues)))\n",
        "        else:\n",
        "            harmonic_indices = harmonic_indices[:self.target_dim]\n",
        "\n",
        "        harmonic_modes = eigenvectors[:, harmonic_indices]\n",
        "\n",
        "        Q, R = np.linalg.qr(harmonic_modes)\n",
        "\n",
        "        b_eff = len(harmonic_indices)\n",
        "\n",
        "        return Q, b_eff\n",
        "\n",
        "print(\"Discrete Laplacian and live harmonic extractor ready (optimized version)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeYY0hUm6Tjr"
      },
      "source": [
        "## 11. Complete Loss Function with Torsion Targeting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PhGZ0EY6Tjr",
        "outputId": "9d6053a6-b82a-4eae-8f68-1ee248e87474"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete loss function ready (v1.1 with torsion targeting and RG flow)\n"
          ]
        }
      ],
      "source": [
        "def compute_complete_loss(phi_net: nn.Module, coords: torch.Tensor, geometry: TCSGeometry,\n",
        "                         extd: ExteriorDerivative, config: Dict, phase_weights: Dict,\n",
        "                         rg_flow_gift: Optional[RGFlowGIFT] = None,\n",
        "                         geodesic_integrator: Optional[GeodesicIntegrator] = None,\n",
        "                         harmonic_extractors: Optional[Dict] = None, phase: int = 1) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Complete multi-component loss with torsion targeting (not minimization).\n",
        "\n",
        "    Key changes from v1.0f:\n",
        "    - Torsion: target specific magnitude (phase-dependent) instead of minimize to zero\n",
        "    - RG flow: add geodesic integration constraint in Phases 4-5\n",
        "    - Early stopping: phase-specific criteria for systematic convergence\n",
        "    \"\"\"\n",
        "    w = phase_weights\n",
        "    target = config['target']\n",
        "    target_torsion = config['torsion_targets'][phase]\n",
        "\n",
        "    phi = phi_net(coords)\n",
        "    g, g_inv = compute_g2_metric(phi, phase=phase)\n",
        "\n",
        "    g = geometry.acyl_metric_correction(coords, g)\n",
        "    g = normalize_metric(g, target['det_g'])\n",
        "\n",
        "    psi = compute_hodge_dual(phi, g, g_inv)\n",
        "\n",
        "    jacobian = extd.compute_jacobian(phi_net, coords)\n",
        "    dphi = extd.d_phi(jacobian)\n",
        "    dpsi_norm = extd.d_psi_norm(psi, phi_net, coords)\n",
        "\n",
        "    # NEW v1.1: Torsion targeting (critical fix)\n",
        "    loss_torsion, actual_torsion = compute_torsion_targeting_loss(dphi, dpsi_norm, target_torsion, config)\n",
        "\n",
        "    # Determinant constraint\n",
        "    det_g = torch.linalg.det(g)\n",
        "    loss_det = ((det_g - target['det_g']) ** 2).mean()\n",
        "\n",
        "    # Positivity with robust eigenvalue computation\n",
        "    try:\n",
        "        g_sym = (g + g.transpose(-2, -1)) / 2.0\n",
        "        floor_eps = {1: 2e-3, 2: 1.5e-3, 3: 1e-3, 4: 5e-4, 5: 1e-4}\n",
        "        g_sym = g_sym + floor_eps.get(phase, 1e-5) * torch.eye(7, device=g.device).unsqueeze(0)\n",
        "        eigvals = torch.linalg.eigvalsh(g_sym)\n",
        "        loss_positivity = torch.relu(-eigvals.min(dim=-1)[0]).mean()\n",
        "    except:\n",
        "        g_regularized = g + 1e-2 * torch.eye(7, device=g.device).unsqueeze(0)\n",
        "        g_regularized = (g_regularized + g_regularized.transpose(-2, -1)) / 2.0\n",
        "        try:\n",
        "            eigvals = torch.linalg.eigvalsh(g_regularized)\n",
        "            loss_positivity = torch.relu(-eigvals.min(dim=-1)[0]).mean()\n",
        "        except:\n",
        "            eigvals = torch.ones(g.shape[0], 7, device=g.device) * 0.1\n",
        "            loss_positivity = torch.tensor(100.0, device=g.device)\n",
        "\n",
        "    eig_floor_threshold = {1: 3e-3, 2: 2e-3, 3: 1e-3, 4: 1e-4, 5: 1e-5}\n",
        "    threshold = eig_floor_threshold.get(phase, 1e-4)\n",
        "    loss_eig_floor = torch.relu(threshold - eigvals.min(dim=-1)[0]).mean()\n",
        "\n",
        "    r = geometry.radial_coordinate(coords)\n",
        "    regions = geometry.region_classification(r)\n",
        "\n",
        "    # Neck matching\n",
        "    loss_neck_match = torch.tensor(0.0, device=coords.device)\n",
        "    if regions['Neck'].any():\n",
        "        coords_neck = coords[regions['Neck']]\n",
        "        coords_twisted = geometry.twist_map(coords_neck)\n",
        "\n",
        "        phi_neck = phi_net(coords_neck)\n",
        "        phi_twisted = phi_net(coords_twisted)\n",
        "\n",
        "        loss_neck_match = ((phi_neck - phi_twisted) ** 2).mean()\n",
        "\n",
        "    # ACyl matching\n",
        "    loss_acyl = torch.tensor(0.0, device=coords.device)\n",
        "    if regions['M1'].any() or regions['M2'].any():\n",
        "        r_acyl = torch.cat([r[regions['M1']], r[regions['M2']]]) if regions['M1'].any() and regions['M2'].any() else (r[regions['M1']] if regions['M1'].any() else r[regions['M2']])\n",
        "        F = geometry.acyl.F(r_acyl)\n",
        "        H = geometry.acyl.H(r_acyl)\n",
        "\n",
        "        loss_acyl = ((F - 1.0) ** 2).mean() + (H ** 2).mean()\n",
        "\n",
        "        loss_acyl_derivatives = geometry.compute_normal_derivative_mismatch(phi_net, coords, extd)\n",
        "        loss_acyl = loss_acyl + loss_acyl_derivatives\n",
        "\n",
        "    # Harmonicity with robust SVD\n",
        "    loss_harmonicity = torch.tensor(0.0, device=coords.device)\n",
        "    if harmonic_extractors is not None and w['harmonicity'] > 0:\n",
        "        sample_size = min(256, coords.shape[0])\n",
        "        coords_sample = coords[:sample_size]\n",
        "\n",
        "        phi_sample = phi_net(coords_sample)\n",
        "        phi_flat = phi_sample.flatten(start_dim=1)\n",
        "\n",
        "        # Add small regularization to avoid SVD issues\n",
        "        phi_flat = phi_flat + 1e-8 * torch.randn_like(phi_flat)\n",
        "\n",
        "        target_rank_2 = target['b2']\n",
        "\n",
        "        try:\n",
        "            U, S, Vh = torch.linalg.svd(phi_flat, full_matrices=False)\n",
        "\n",
        "            if S.shape[0] > target_rank_2:\n",
        "                loss_harmonicity = loss_harmonicity + S[target_rank_2:].pow(2).sum()\n",
        "\n",
        "            eigenvalue_penalty = torch.tensor(0.0, device=coords.device)\n",
        "            if len(S) >= target_rank_2:\n",
        "                eigenvalue_penalty = torch.relu(config['torsion_threshold'] - S[:target_rank_2].min())\n",
        "\n",
        "            loss_harmonicity = loss_harmonicity + 10.0 * eigenvalue_penalty\n",
        "        except Exception as e:\n",
        "            # If SVD fails, use a simple L2 penalty instead\n",
        "            print(f\"SVD failed in harmonicity, using L2 penalty fallback\")\n",
        "            loss_harmonicity = 0.001 * (phi_flat ** 2).sum()\n",
        "\n",
        "    # UPDATED v1.1c: RG flow loss with adaptive frequency\n",
        "    loss_rg = torch.tensor(0.0, device=coords.device)\n",
        "    rg_components = {}\n",
        "    if phase >= 4 and w['rg_flow'] > 0 and rg_flow_gift is not None:\n",
        "        # Adaptive frequency based on torsion magnitude\n",
        "        base_freq = config['rg_flow']['geodesic_batch_freq_base']\n",
        "        if config['rg_flow']['adaptive_frequency']:\n",
        "            T_magnitude = torch.norm(dphi)\n",
        "            adaptive_factor = 1.0 + 0.5 * torch.tanh(T_magnitude / 0.01)\n",
        "            freq = torch.clamp(base_freq * adaptive_factor, 0.1, 0.8).item()\n",
        "        else:\n",
        "            freq = base_freq\n",
        "\n",
        "        # Compute RG flow stochastically\n",
        "        if torch.rand(1).item() < freq:\n",
        "            loss_rg, rg_components = compute_rg_flow_loss(\n",
        "                phi_net, rg_flow_gift, geodesic_integrator, config,\n",
        "                coords, dphi, phase\n",
        "            )\n",
        "\n",
        "    w_eig_floor = {1: 1.5, 2: 0.8, 3: 0.3, 4: 0.05, 5: 0.01}\n",
        "    eig_weight = w_eig_floor.get(phase, 0.1)\n",
        "\n",
        "    total_loss = (w['torsion'] * loss_torsion +\n",
        "                  w['det'] * loss_det +\n",
        "                  w['positivity'] * loss_positivity +\n",
        "                  w['neck_match'] * loss_neck_match +\n",
        "                  w['acyl'] * loss_acyl +\n",
        "                  w['harmonicity'] * loss_harmonicity +\n",
        "                  w['rg_flow'] * loss_rg +\n",
        "                  eig_weight * loss_eig_floor)\n",
        "\n",
        "    # NaN guard\n",
        "    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
        "        print(f\"NaN detected! Phase {phase}\")\n",
        "        total_loss = torch.tensor(1000.0, device=coords.device, requires_grad=True)\n",
        "\n",
        "    return {\n",
        "        'total': total_loss,\n",
        "        'torsion': loss_torsion,\n",
        "        'actual_torsion': actual_torsion,\n",
        "        'det': loss_det,\n",
        "        'positivity': loss_positivity,\n",
        "        'neck_match': loss_neck_match,\n",
        "        'acyl': loss_acyl,\n",
        "        'harmonicity': loss_harmonicity,\n",
        "        'rg_flow': loss_rg,\n",
        "        'rg_components': rg_components,\n",
        "        'eig_floor': loss_eig_floor\n",
        "    }\n",
        "\n",
        "print(\"Complete loss function ready (v1.1 with torsion targeting and RG flow)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxvcdZU56Tjr"
      },
      "source": [
        "## 12. Checkpoint Manager\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XzatShs6Tjr",
        "outputId": "c183a16f-b8c2-415c-e848-24706cc42284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint manager: checkpoints_v1_1c\n"
          ]
        }
      ],
      "source": [
        "class CheckpointManager:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.checkpoint_dir = Path(config['checkpoint_dir'])\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "        self.freq = config['checkpoint_freq']\n",
        "\n",
        "    def save(self, phase: int, epoch: int, model: nn.Module, optimizer: optim.Optimizer,\n",
        "             loss_history: list, metadata: Dict):\n",
        "        checkpoint = {\n",
        "            'phase': phase,\n",
        "            'epoch': epoch,\n",
        "            'model_state': model.state_dict(),\n",
        "            'optimizer_state': optimizer.state_dict(),\n",
        "            'loss_history': loss_history,\n",
        "            'metadata': metadata\n",
        "        }\n",
        "\n",
        "        path = self.checkpoint_dir / f'checkpoint_phase{phase}_epoch_{epoch}.pt'\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        config_path = self.checkpoint_dir / 'config.json'\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(metadata.get('config', {}), f, indent=2)\n",
        "\n",
        "    def load_latest(self) -> Optional[Dict]:\n",
        "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
        "\n",
        "        if latest_path.exists():\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            return checkpoint\n",
        "\n",
        "        return None\n",
        "\n",
        "    def should_save(self, epoch: int) -> bool:\n",
        "        return (epoch + 1) % self.freq == 0\n",
        "\n",
        "checkpoint_mgr = CheckpointManager(CONFIG)\n",
        "print(f\"Checkpoint manager: {checkpoint_mgr.checkpoint_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR5XhqCx6Tjs"
      },
      "source": [
        "## 13. NEW v1.1: Multi-Phase Training with Systematic Early Stopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mToEoOB6Tjs",
        "outputId": "c76558ea-1450-4f67-d292-4e6f8496dc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multi-phase training pipeline ready (v1.1 with systematic early stopping)\n"
          ]
        }
      ],
      "source": [
        "def check_phase_early_stop(losses_dict: Dict, phase_config: Dict, phase_history: list, config: Dict) -> bool:\n",
        "    \"\"\"\n",
        "    NEW v1.1: Check phase-specific early stopping criteria.\n",
        "\n",
        "    Each phase has its own convergence criteria to prevent over-optimization\n",
        "    that could degrade subsequent phases.\n",
        "\n",
        "    Args:\n",
        "        losses_dict: Current loss values\n",
        "        phase_config: Phase configuration with early_stop criteria\n",
        "        phase_history: Recent loss history for this phase\n",
        "        config: Global configuration\n",
        "\n",
        "    Returns:\n",
        "        should_stop: Whether to stop this phase early\n",
        "    \"\"\"\n",
        "    if 'early_stop' not in phase_config:\n",
        "        return False\n",
        "\n",
        "    early_stop_config = phase_config['early_stop']\n",
        "    patience = early_stop_config['patience']\n",
        "    criteria = early_stop_config['criteria']\n",
        "\n",
        "    # Need sufficient history\n",
        "    if len(phase_history) < patience:\n",
        "        return False\n",
        "\n",
        "    # Check if all criteria satisfied for patience epochs\n",
        "    recent_history = phase_history[-patience:]\n",
        "\n",
        "    all_satisfied = True\n",
        "    for criterion_name, threshold in criteria.items():\n",
        "        if criterion_name == 'torsion_target_reached':\n",
        "            # Check if torsion is within 20% of target\n",
        "            if threshold:\n",
        "                for hist_entry in recent_history:\n",
        "                    actual_torsion = hist_entry.get('actual_torsion', 0)\n",
        "                    phase = hist_entry.get('phase', 1)\n",
        "                    target_torsion = config['torsion_targets'][phase]\n",
        "                    error = abs(actual_torsion - target_torsion) / target_torsion\n",
        "                    if error > 0.2:  # More than 20% error\n",
        "                        all_satisfied = False\n",
        "                        break\n",
        "        else:\n",
        "            # Standard threshold check\n",
        "            for hist_entry in recent_history:\n",
        "                if hist_entry.get(criterion_name, float('inf')) > threshold:\n",
        "                    all_satisfied = False\n",
        "                    break\n",
        "\n",
        "        if not all_satisfied:\n",
        "            break\n",
        "\n",
        "    return all_satisfied\n",
        "\n",
        "\n",
        "def train_multiphase(phi_net: nn.Module, geometry: TCSGeometry, extd: ExteriorDerivative,\n",
        "                     config: Dict, checkpoint_mgr: CheckpointManager,\n",
        "                     alpha_functional: AlphaInverseFunctional,\n",
        "                     geodesic_integrator: GeodesicIntegrator):\n",
        "    \"\"\"\n",
        "    NEW v1.1: Multi-phase curriculum training with:\n",
        "    - Systematic per-phase early stopping\n",
        "    - RG flow coefficient calibration at epoch 6000\n",
        "    - Torsion targeting (not minimization)\n",
        "    - Observable-based constraints\n",
        "    \"\"\"\n",
        "\n",
        "    import time\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # UPDATED v1.1c: Use initial LR for phase 1\n",
        "    optimizer = optim.AdamW(phi_net.parameters(), lr=config['learning_rate_phase12'], weight_decay=1e-5)\n",
        "\n",
        "    # NEW v1.1c: Two-speed LR scheduler\n",
        "    lr_scheduler = TwoSpeedLRScheduler(optimizer, config)\n",
        "\n",
        "    start_phase = 1\n",
        "    start_epoch = 0\n",
        "    loss_history = []\n",
        "\n",
        "    checkpoint = checkpoint_mgr.load_latest()\n",
        "    if checkpoint is not None:\n",
        "        phi_net.load_state_dict(checkpoint['model_state'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "        start_phase = checkpoint['phase']\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        loss_history = checkpoint['loss_history']\n",
        "        print(f\"Resumed from Phase {checkpoint['phase']}, Epoch {checkpoint['epoch']}\")\n",
        "\n",
        "    n_epochs_per_phase = config['n_epochs_per_phase']\n",
        "    batch_size = config['batch_size']\n",
        "\n",
        "    harmonic_extractors = {}\n",
        "\n",
        "    for phase in range(start_phase, len(config['phases']) + 1):\n",
        "        phase_config = config['phases'][phase]\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PHASE {phase}: {phase_config['name']}\")\n",
        "        print(f\"Torsion target: ||T|| = {config['torsion_targets'][phase]}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if phase >= 3:\n",
        "            harmonic_extractors = {'enabled': True}\n",
        "\n",
        "        epoch_start = start_epoch if phase == start_phase else 0\n",
        "\n",
        "        phase_start_time = time.time()\n",
        "        phase_history = []  # NEW v1.1: Track history for this phase\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(epoch_start, n_epochs_per_phase):\n",
        "            # Compute global epoch for tracking\n",
        "            global_epoch = sum([config['n_epochs_per_phase'] for p in range(1, phase)]) + epoch\n",
        "\n",
        "            phi_net.train()\n",
        "\n",
        "            coords = torch.rand(batch_size, 7, device=device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            losses = compute_complete_loss(\n",
        "                phi_net, coords, geometry, extd, config,\n",
        "                phase_config['weights'],\n",
        "                rg_flow_gift=rg_flow_gift if phase >= 4 else None,\n",
        "                geodesic_integrator=geodesic_integrator if phase >= 4 else None,\n",
        "                harmonic_extractors=harmonic_extractors if phase >= 3 else None,\n",
        "                phase=phase\n",
        "            )\n",
        "\n",
        "            losses['total'].backward()\n",
        "            torch.nn.utils.clip_grad_norm_(phi_net.parameters(), 0.5)\n",
        "\n",
        "            # UPDATED v1.1c: Step LR scheduler\n",
        "            current_lr = lr_scheduler.step(global_epoch, phase)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_entry = {\n",
        "                'phase': phase,\n",
        "                'epoch': epoch,\n",
        "                'global_epoch': global_epoch,\n",
        "                'total': losses['total'].item(),\n",
        "                'torsion': losses['torsion'].item(),\n",
        "                'actual_torsion': losses['actual_torsion'].item(),  # NEW v1.1\n",
        "                'det': losses['det'].item(),\n",
        "                'positivity': losses['positivity'].item(),\n",
        "                'neck_match': losses['neck_match'].item(),\n",
        "                'acyl': losses['acyl'].item(),\n",
        "                'harmonicity': losses['harmonicity'].item(),\n",
        "                'rg_flow': losses['rg_flow'].item(),  # NEW v1.1\n",
        "                'eig_floor': losses['eig_floor'].item()\n",
        "            }\n",
        "            loss_history.append(loss_entry)\n",
        "            phase_history.append(loss_entry)\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                elapsed = time.time() - phase_start_time\n",
        "                epochs_done = epoch + 1 - epoch_start\n",
        "                epochs_remaining = n_epochs_per_phase - (epoch + 1)\n",
        "                eta_seconds = (elapsed / epochs_done) * epochs_remaining if epochs_done > 0 else 0\n",
        "                eta_minutes = eta_seconds / 60\n",
        "\n",
        "                progress_pct = 100 * (epoch + 1) / n_epochs_per_phase\n",
        "                bar_length = 30\n",
        "                filled = int(bar_length * progress_pct / 100)\n",
        "                bar = '█' * filled + '░' * (bar_length - filled)\n",
        "\n",
        "                print(f\"[{bar}] {progress_pct:.1f}% | \"\n",
        "                      f\"Epoch {epoch+1}/{n_epochs_per_phase} | \"\n",
        "                      f\"Loss={losses['total'].item():.6f} | \"\n",
        "                      f\"||T||={losses['actual_torsion'].item():.4e} (target={config['torsion_targets'][phase]:.4e}) | \"\n",
        "                      f\"LR={current_lr:.2e} | \"\n",
        "                      f\"RG={losses['rg_flow'].item():.4e} | \"\n",
        "                      f\"ETA: {eta_minutes:.1f}m\")\n",
        "\n",
        "            # NEW v1.1: Per-phase early stopping\n",
        "            if check_phase_early_stop(losses, phase_config, phase_history, config):\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= phase_config['early_stop']['patience']:\n",
        "                    print(f\"\\n{'='*60}\")\n",
        "                    print(f\"Early stopping Phase {phase} at epoch {epoch+1}\")\n",
        "                    print(f\"All convergence criteria satisfied for {patience_counter} epochs\")\n",
        "                    print(f\"{'='*60}\\n\")\n",
        "\n",
        "                    metadata = {\n",
        "                        'config': config,\n",
        "                        'phase': phase,\n",
        "                        'early_stopped': True,\n",
        "                        'final_loss': losses['total'].item(),\n",
        "                        'final_torsion': losses['actual_torsion'].item()\n",
        "                    }\n",
        "                    checkpoint_mgr.save(phase, epoch, phi_net, optimizer, loss_history, metadata)\n",
        "                    break\n",
        "            else:\n",
        "                patience_counter = 0\n",
        "\n",
        "            if checkpoint_mgr.should_save(epoch):\n",
        "                metadata = {\n",
        "                    'config': config,\n",
        "                    'current_phase': phase,\n",
        "                    'final_loss': losses['total'].item()\n",
        "                }\n",
        "                checkpoint_mgr.save(phase, epoch, phi_net, optimizer, loss_history, metadata)\n",
        "                print(f\"✓ Checkpoint saved\")\n",
        "\n",
        "        start_epoch = 0\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "print(\"Multi-phase training pipeline ready (v1.1 with systematic early stopping)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OSsXEQO6Tjs"
      },
      "source": [
        "## 14. Execute Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXFSP6WQ6Tjs",
        "outputId": "ddb9ac24-f5b2-4047-f8c6-c1d9aa846027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting multi-phase training (v1.1)...\n",
            "Extended neck: σ_neck=5.0\n",
            "Torsion targeting: {1: 0.001, 2: 0.005, 3: 0.01, 4: 0.015, 5: 0.0164}\n",
            "RG flow calibration: epoch 2000\n",
            "\n",
            "Resumed from Phase 4, Epoch 1999\n",
            "\n",
            "============================================================\n",
            "PHASE 4: Harmonic_Extraction\n",
            "Torsion target: ||T|| = 0.015\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "PHASE 5: RG_Calibration\n",
            "Torsion target: ||T|| = 0.0164\n",
            "============================================================\n",
            "[█░░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 5.0% | Epoch 100/2000 | Loss=0.363781 | ||T||=2.5230e-02 (target=1.6400e-02) | LR=2.98e-04 | RG=0.0000e+00 | ETA: 70.8m\n",
            "[███░░░░░░░░░░░░░░░░░░░░░░░░░░░] 10.0% | Epoch 200/2000 | Loss=1761.377930 | ||T||=2.1445e-02 (target=1.6400e-02) | LR=4.98e-04 | RG=3.5220e+04 | ETA: 68.7m\n",
            "[████░░░░░░░░░░░░░░░░░░░░░░░░░░] 15.0% | Epoch 300/2000 | Loss=0.362330 | ||T||=1.5328e-02 (target=1.6400e-02) | LR=5.00e-04 | RG=0.0000e+00 | ETA: 66.5m\n",
            "[██████░░░░░░░░░░░░░░░░░░░░░░░░] 20.0% | Epoch 400/2000 | Loss=0.361064 | ||T||=1.2822e-02 (target=1.6400e-02) | LR=4.99e-04 | RG=0.0000e+00 | ETA: 63.5m\n",
            "[███████░░░░░░░░░░░░░░░░░░░░░░░] 25.0% | Epoch 500/2000 | Loss=0.362178 | ||T||=3.7272e-02 (target=1.6400e-02) | LR=4.97e-04 | RG=0.0000e+00 | ETA: 59.6m\n",
            "✓ Checkpoint saved\n",
            "[█████████░░░░░░░░░░░░░░░░░░░░░] 30.0% | Epoch 600/2000 | Loss=3743.397705 | ||T||=6.1949e-03 (target=1.6400e-02) | LR=4.95e-04 | RG=7.4861e+04 | ETA: 55.2m\n",
            "[██████████░░░░░░░░░░░░░░░░░░░░] 35.0% | Epoch 700/2000 | Loss=25410.468750 | ||T||=1.2564e-02 (target=1.6400e-02) | LR=4.92e-04 | RG=5.0820e+05 | ETA: 51.4m\n",
            "[████████████░░░░░░░░░░░░░░░░░░] 40.0% | Epoch 800/2000 | Loss=0.364518 | ||T||=1.9498e-02 (target=1.6400e-02) | LR=4.88e-04 | RG=0.0000e+00 | ETA: 47.0m\n",
            "[█████████████░░░░░░░░░░░░░░░░░] 45.0% | Epoch 900/2000 | Loss=6386.190918 | ||T||=1.9222e-02 (target=1.6400e-02) | LR=4.84e-04 | RG=1.2772e+05 | ETA: 43.3m\n",
            "[███████████████░░░░░░░░░░░░░░░] 50.0% | Epoch 1000/2000 | Loss=0.363245 | ||T||=8.1528e-03 (target=1.6400e-02) | LR=4.79e-04 | RG=0.0000e+00 | ETA: 39.2m\n",
            "✓ Checkpoint saved\n",
            "[████████████████░░░░░░░░░░░░░░] 55.0% | Epoch 1100/2000 | Loss=9185.046875 | ||T||=3.6302e-02 (target=1.6400e-02) | LR=4.73e-04 | RG=1.8369e+05 | ETA: 35.4m\n",
            "[██████████████████░░░░░░░░░░░░] 60.0% | Epoch 1200/2000 | Loss=20062.398438 | ||T||=3.3574e-02 (target=1.6400e-02) | LR=4.67e-04 | RG=4.0124e+05 | ETA: 31.5m\n",
            "[███████████████████░░░░░░░░░░░] 65.0% | Epoch 1300/2000 | Loss=671.611145 | ||T||=1.9721e-02 (target=1.6400e-02) | LR=4.61e-04 | RG=1.3425e+04 | ETA: 27.4m\n",
            "[█████████████████████░░░░░░░░░] 70.0% | Epoch 1400/2000 | Loss=2921.498047 | ||T||=2.6561e-02 (target=1.6400e-02) | LR=4.53e-04 | RG=5.8423e+04 | ETA: 23.7m\n",
            "[██████████████████████░░░░░░░░] 75.0% | Epoch 1500/2000 | Loss=0.362062 | ||T||=1.1396e-02 (target=1.6400e-02) | LR=4.45e-04 | RG=0.0000e+00 | ETA: 19.8m\n",
            "✓ Checkpoint saved\n",
            "[████████████████████████░░░░░░] 80.0% | Epoch 1600/2000 | Loss=0.363188 | ||T||=3.2747e-03 (target=1.6400e-02) | LR=4.37e-04 | RG=0.0000e+00 | ETA: 15.8m\n",
            "[█████████████████████████░░░░░] 85.0% | Epoch 1700/2000 | Loss=0.361991 | ||T||=1.5544e-02 (target=1.6400e-02) | LR=4.28e-04 | RG=0.0000e+00 | ETA: 11.8m\n",
            "[███████████████████████████░░░] 90.0% | Epoch 1800/2000 | Loss=0.361088 | ||T||=1.6897e-02 (target=1.6400e-02) | LR=4.19e-04 | RG=0.0000e+00 | ETA: 7.9m\n",
            "[████████████████████████████░░] 95.0% | Epoch 1900/2000 | Loss=0.364593 | ||T||=2.0383e-02 (target=1.6400e-02) | LR=4.09e-04 | RG=0.0000e+00 | ETA: 3.9m\n",
            "[██████████████████████████████] 100.0% | Epoch 2000/2000 | Loss=0.361180 | ||T||=1.7740e-02 (target=1.6400e-02) | LR=3.99e-04 | RG=0.0000e+00 | ETA: 0.0m\n",
            "✓ Checkpoint saved\n",
            "\n",
            "Training complete. Final loss: 0.361180\n",
            "Final torsion: ||T|| = 1.773959e-02 (target: 1.640000e-02)\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting multi-phase training (v1.1)...\")\n",
        "print(f\"Extended neck: σ_neck={CONFIG['tcs']['neck_width']}\")\n",
        "print(f\"Torsion targeting: {CONFIG['torsion_targets']}\")\n",
        "print(f\"RG flow calibration: epoch {CONFIG['rg_flow']['calibration_epoch']}\")\n",
        "print(\"\")\n",
        "\n",
        "loss_history = train_multiphase(phi_net, geometry, extd, CONFIG, checkpoint_mgr, alpha_functional, geodesic_integrator)\n",
        "print(f\"\\nTraining complete. Final loss: {loss_history[-1]['total']:.6f}\")\n",
        "print(f\"Final torsion: ||T|| = {loss_history[-1]['actual_torsion']:.6e} (target: {CONFIG['target']['torsion_norm']:.6e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qJS0bCU6Tjt"
      },
      "source": [
        "## 15. Post-Training: Harmonic Extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-9WyVCc6Tjt",
        "outputId": "e9dfb826-b49b-447a-d1d1-3c1c608bdb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building discrete Laplacians (reduced grid)...\n",
            "  Using 8^7 = 2,097,152 points (reduced from 268,435,456)\n",
            "Building 2-form Laplacian: 8^7 = 2,097,152 points...\n",
            "  Allocating sparse structure for 2,097,152 × 2,097,152 matrix...\n",
            "  Building diagonal...\n",
            "  Building off-diagonal entries...\n",
            "    Processing axis 1/7...\n",
            "    Processing axis 3/7...\n",
            "    Processing axis 5/7...\n",
            "    Processing axis 7/7...\n",
            "  Assembling sparse matrix...\n",
            "  Converting to CSR format...\n",
            "  ✓ Laplacian built: 31,457,280 non-zero entries\n",
            "Building 3-form Laplacian: 8^7 = 2,097,152 points...\n",
            "  Allocating sparse structure for 2,097,152 × 2,097,152 matrix...\n",
            "  Building diagonal...\n",
            "  Building off-diagonal entries...\n",
            "    Processing axis 1/7...\n",
            "    Processing axis 3/7...\n",
            "    Processing axis 5/7...\n",
            "    Processing axis 7/7...\n",
            "  Assembling sparse matrix...\n",
            "  Converting to CSR format...\n",
            "  ✓ Laplacian built: 31,457,280 non-zero entries\n",
            "Extracting harmonic 2-forms...\n",
            "  Computing 71 smallest eigenmodes (this may take 5-15 min)...\n",
            "  ✓ Spectrum computed in 3.7 minutes\n",
            "  Eigenvalue range: [-2.19e+02, -1.95e-13]\n",
            "  Found 1 harmonic modes (threshold=1.00e-06)\n",
            "  ⚠ Using 21 smallest modes instead\n",
            "b₂_eff = 21 (target: 21)\n",
            "Extracting harmonic 3-forms...\n",
            "  Computing 127 smallest eigenmodes (this may take 5-15 min)...\n",
            "  ✓ Spectrum computed in 10.7 minutes\n",
            "  Eigenvalue range: [-2.19e+02, 5.18e-13]\n",
            "  Found 1 harmonic modes (threshold=1.00e-06)\n",
            "  ⚠ Using 77 smallest modes instead\n",
            "b₃_eff = 77 (target: 77)\n"
          ]
        }
      ],
      "source": [
        "print(\"Building discrete Laplacians (reduced grid)...\")\n",
        "n_grid_harm = CONFIG['n_grid_harmonics']\n",
        "print(f\"  Using {n_grid_harm}^7 = {n_grid_harm**7:,} points (reduced from {CONFIG['n_grid']**7:,})\")\n",
        "\n",
        "laplacian_2 = DiscreteLaplacian(n_grid_harm, dim=2)\n",
        "laplacian_3 = DiscreteLaplacian(n_grid_harm, dim=3)\n",
        "\n",
        "print(\"Extracting harmonic 2-forms...\")\n",
        "extractor_2 = LiveHarmonicExtractor(laplacian_2, CONFIG['target']['b2'])\n",
        "h2_modes, b2_eff = extractor_2.extract()\n",
        "print(f\"b₂_eff = {b2_eff} (target: {CONFIG['target']['b2']})\")\n",
        "\n",
        "print(\"Extracting harmonic 3-forms...\")\n",
        "extractor_3 = LiveHarmonicExtractor(laplacian_3, CONFIG['target']['b3'])\n",
        "h3_modes, b3_eff = extractor_3.extract()\n",
        "print(f\"b₃_eff = {b3_eff} (target: {CONFIG['target']['b3']})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySfmI3-R6Tjt"
      },
      "source": [
        "## 16. Yukawa Tensor Construction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "XT8lIYgE6Tjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3cbc35-fc85-4a53-9630-2a273e465921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing Yukawa tensor (21×21×77)...\n",
            "Yukawa progress: 5000/33957 (14.7%)\n",
            "Yukawa progress: 10000/33957 (29.4%)\n",
            "Yukawa progress: 15000/33957 (44.2%)\n",
            "Yukawa progress: 20000/33957 (58.9%)\n",
            "Yukawa progress: 25000/33957 (73.6%)\n",
            "Yukawa progress: 30000/33957 (88.3%)\n",
            "Yukawa tensor shape: (21, 21, 77)\n",
            "Yukawa tensor norm: 5.904187e-10\n",
            "NEW v1.1: Yukawa norm should be >>10⁻¹⁰ (v1.0f: ~10⁻¹⁰, expected v1.1: ~10⁻³ to 10⁻⁴)\n"
          ]
        }
      ],
      "source": [
        "class YukawaTensor:\n",
        "    def __init__(self, h2_modes: np.ndarray, h3_modes: np.ndarray, n_samples: int):\n",
        "        self.h2 = h2_modes\n",
        "        self.h3 = h3_modes\n",
        "        self.b2 = h2_modes.shape[1]\n",
        "        self.b3 = h3_modes.shape[1]\n",
        "        self.n_samples = n_samples\n",
        "\n",
        "    def wedge_product(self, alpha: np.ndarray, beta: np.ndarray, gamma: np.ndarray) -> float:\n",
        "        indices = np.random.randint(0, len(alpha), self.n_samples)\n",
        "        integrand = alpha[indices] * beta[indices] * gamma[indices]\n",
        "        return np.mean(integrand)\n",
        "\n",
        "    def compute(self) -> np.ndarray:\n",
        "        Y = np.zeros((self.b2, self.b2, self.b3))\n",
        "        total = self.b2 * self.b2 * self.b3\n",
        "        count = 0\n",
        "\n",
        "        for alpha in range(self.b2):\n",
        "            for beta in range(self.b2):\n",
        "                for gamma in range(self.b3):\n",
        "                    Y[alpha, beta, gamma] = self.wedge_product(\n",
        "                        self.h2[:, alpha],\n",
        "                        self.h2[:, beta],\n",
        "                        self.h3[:, gamma]\n",
        "                    )\n",
        "\n",
        "                    count += 1\n",
        "                    if count % 5000 == 0:\n",
        "                        print(f\"Yukawa progress: {count}/{total} ({100*count/total:.1f}%)\")\n",
        "\n",
        "        return Y\n",
        "\n",
        "print(f\"Computing Yukawa tensor ({b2_eff}×{b2_eff}×{b3_eff})...\")\n",
        "yukawa = YukawaTensor(h2_modes, h3_modes, CONFIG['yukawa_samples'])\n",
        "Y_tensor = yukawa.compute()\n",
        "print(f\"Yukawa tensor shape: {Y_tensor.shape}\")\n",
        "print(f\"Yukawa tensor norm: {np.linalg.norm(Y_tensor):.6e}\")\n",
        "print(f\"NEW v1.1: Yukawa norm should be >>10⁻¹⁰ (v1.0f: ~10⁻¹⁰, expected v1.1: ~10⁻³ to 10⁻⁴)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcYWU3iA6Tjt"
      },
      "source": [
        "## 17. NEW v1.1: Comprehensive Validation (Torsion + RG Flow)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "Dd-PuIC-6Tjt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a05ef489-4b6b-46fd-e803-a29d98e7ac7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "COMPREHENSIVE VALIDATION (v1.1)\n",
            "============================================================\n",
            "\n",
            "1. Torsion Magnitude Validation (v1.1 Critical Fix)\n",
            "------------------------------------------------------------\n",
            "  Target torsion: ||T|| = 1.640000e-02\n",
            "  Actual torsion: ||T|| = 1.822357e-02\n",
            "  Error: 11.12%\n",
            "  Range: [1.355493e-02, 2.914256e-02]\n",
            "  Std: 2.422452e-03\n",
            "  ⚠ Torsion within 30% of target (ACCEPTABLE)\n",
            "\n",
            "  v1.0f comparison: ||T|| = 8.35×10⁻⁴ (94.9% error)\n",
            "  v1.1 improvement: 21.8× closer to target\n",
            "\n",
            "2. RG Flow Validation (NEW v1.1)\n",
            "------------------------------------------------------------\n",
            "  Integrating geodesic from M_Z to M_Planck...\n",
            "  α⁻¹(M_Z) = 136.838\n",
            "  α⁻¹(M_Planck) = 136.857\n",
            "  Δα⁻¹ = 0.0184\n",
            "  Target: Δα⁻¹ = -0.9000\n",
            "  Error: 102.05%\n",
            "  ✗ RG flow error too large (NEEDS IMPROVEMENT)\n",
            "\n",
            "3. Geometric Quality (Should Be Preserved)\n",
            "------------------------------------------------------------\n",
            "  det(g) = 2.0000014 ± 6.36e-07\n",
            "  Target: det(g) = 2.0\n",
            "  Error: 0.0001%\n",
            "  Eigenvalues: min=0.648077, max=1.941643\n",
            "  Positive definite: True\n",
            "  ✓ Geometric quality preserved (SUCCESS)\n",
            "\n",
            "4. Phenomenological Viability\n",
            "------------------------------------------------------------\n",
            "  Yukawa norm: 5.904187e-10\n",
            "  Max |Y|: 8.606304e-11\n",
            "  Non-zero fraction: 0.000\n",
            "  ✗ Yukawa couplings negligible (FAILURE)\n",
            "\n",
            "  v1.0f comparison: Yukawa norm ~10⁻¹⁰\n",
            "  v1.1 improvement: 5.9× larger\n",
            "\n",
            "============================================================\n",
            "VALIDATION SUMMARY (v1.1)\n",
            "============================================================\n",
            "Torsion target reached: ✗\n",
            "RG flow correct: ✗\n",
            "Geometric quality preserved: ✓\n",
            "Yukawa viable: ✗\n",
            "\n",
            "Overall: PARTIAL SUCCESS - Iteration may be needed\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"COMPREHENSIVE VALIDATION (v1.1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# ==================================================================\n",
        "# 1. TORSION MAGNITUDE VALIDATION (CRITICAL)\n",
        "# ==================================================================\n",
        "print(\"\\n1. Torsion Magnitude Validation (v1.1 Critical Fix)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "phi_net.eval()\n",
        "with torch.no_grad():\n",
        "    n_samples = 10000\n",
        "    test_coords = torch.rand(n_samples, 7, device=device)\n",
        "\n",
        "    phi_vals = phi_net(test_coords)\n",
        "    g_vals, g_inv = compute_g2_metric(phi_vals, phase=5)\n",
        "    g_corrected = geometry.acyl_metric_correction(test_coords, g_vals)\n",
        "    g_normalized = normalize_metric(g_corrected, CONFIG['target']['det_g'])\n",
        "\n",
        "    # Compute Hodge dual for complete torsion\n",
        "    psi_vals = compute_hodge_dual(phi_vals, g_normalized, g_inv)\n",
        "\n",
        "    jacobian = extd.compute_jacobian(phi_net, test_coords)\n",
        "    dphi = extd.d_phi(jacobian)\n",
        "    dpsi_norm = extd.d_psi_norm(psi_vals, phi_net, test_coords)\n",
        "\n",
        "    # Compute COMPLETE torsion per-point (dphi + dpsi)\n",
        "    dphi_per_point = torch.sqrt((dphi ** 2).sum(dim=(-4, -3, -2, -1)))\n",
        "    torsion_per_point = torch.sqrt(dphi_per_point**2 + dpsi_norm**2)\n",
        "\n",
        "    torsion_mean = torsion_per_point.mean().item()\n",
        "    torsion_max = torsion_per_point.max().item()\n",
        "    torsion_std = torsion_per_point.std().item()\n",
        "\n",
        "    det_g = torch.linalg.det(g_normalized)\n",
        "\n",
        "target_torsion = CONFIG['target']['torsion_norm']\n",
        "torsion_error = abs(torsion_mean - target_torsion) / target_torsion * 100\n",
        "\n",
        "print(f\"  Target torsion: ||T|| = {target_torsion:.6e}\")\n",
        "print(f\"  Actual torsion: ||T|| = {torsion_mean:.6e}\")\n",
        "print(f\"  Error: {torsion_error:.2f}%\")\n",
        "print(f\"  Range: [{torsion_per_point.min().item():.6e}, {torsion_max:.6e}]\")\n",
        "print(f\"  Std: {torsion_std:.6e}\")\n",
        "\n",
        "if torsion_error < 10:\n",
        "    print(f\"  ✓ Torsion within 10% of target (SUCCESS)\")\n",
        "elif torsion_error < 30:\n",
        "    print(f\"  ⚠ Torsion within 30% of target (ACCEPTABLE)\")\n",
        "else:\n",
        "    print(f\"  ✗ Torsion error too large (NEEDS IMPROVEMENT)\")\n",
        "\n",
        "print(f\"\\n  v1.0f comparison: ||T|| = 8.35×10⁻⁴ (94.9% error)\")\n",
        "print(f\"  v1.1 improvement: {(torsion_mean / 8.35e-4):.1f}× closer to target\")\n",
        "\n",
        "# ==================================================================\n",
        "# 2. RG FLOW VALIDATION (NEW)\n",
        "# ==================================================================\n",
        "print(\"\\n2. RG Flow Validation (NEW v1.1)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "print(\"  Integrating geodesic from M_Z to M_Planck...\")\n",
        "x0 = torch.zeros(7, device=device)\n",
        "v0 = torch.tensor([0, -1e-3, 0, 0, 0, 0, 0], device=device, dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    x_traj, v_traj = geodesic_integrator.integrate_rk4(\n",
        "        x0, v0,\n",
        "        CONFIG['rg_flow']['lambda_max'],\n",
        "        CONFIG['rg_flow']['n_integration_steps']\n",
        "    )\n",
        "\n",
        "    # Compute α⁻¹ at endpoints\n",
        "    phi_start = phi_net(x_traj[0:1])\n",
        "    g_start, _ = compute_g2_metric(phi_start, phase=5)\n",
        "    g_start = geometry.acyl_metric_correction(x_traj[0:1], g_start)\n",
        "    g_start = normalize_metric(g_start, CONFIG['target']['det_g'])\n",
        "\n",
        "    jacobian_start = extd.compute_jacobian(phi_net, x_traj[0:1])\n",
        "    dphi_start = extd.d_phi(jacobian_start)\n",
        "\n",
        "    alpha_start = alpha_functional(g_start, dphi_start).mean()  # Take mean to get scalar\n",
        "\n",
        "    phi_end = phi_net(x_traj[-1:])\n",
        "    g_end, _ = compute_g2_metric(phi_end, phase=5)\n",
        "    g_end = geometry.acyl_metric_correction(x_traj[-1:], g_end)\n",
        "    g_end = normalize_metric(g_end, CONFIG['target']['det_g'])\n",
        "\n",
        "    jacobian_end = extd.compute_jacobian(phi_net, x_traj[-1:])\n",
        "    dphi_end = extd.d_phi(jacobian_end)\n",
        "\n",
        "    alpha_end = alpha_functional(g_end, dphi_end).mean()  # Take mean to get scalar\n",
        "\n",
        "    delta_alpha = (alpha_end - alpha_start).item()\n",
        "\n",
        "target_delta = CONFIG['rg_flow']['target_delta_alpha']\n",
        "rg_error = abs(delta_alpha - target_delta) / abs(target_delta) * 100\n",
        "\n",
        "print(f\"  α⁻¹(M_Z) = {alpha_start.item():.3f}\")\n",
        "print(f\"  α⁻¹(M_Planck) = {alpha_end.item():.3f}\")\n",
        "print(f\"  Δα⁻¹ = {delta_alpha:.4f}\")\n",
        "print(f\"  Target: Δα⁻¹ = {target_delta:.4f}\")\n",
        "print(f\"  Error: {rg_error:.2f}%\")\n",
        "\n",
        "if rg_error < 5:\n",
        "    print(f\"  ✓ RG flow within 5% of target (SUCCESS)\")\n",
        "elif rg_error < 10:\n",
        "    print(f\"  ⚠ RG flow within 10% of target (ACCEPTABLE)\")\n",
        "else:\n",
        "    print(f\"  ✗ RG flow error too large (NEEDS IMPROVEMENT)\")\n",
        "# ==================================================================\n",
        "# 3. GEOMETRIC QUALITY (PRESERVED FROM v1.0f)\n",
        "# ==================================================================\n",
        "print(\"\\n3. Geometric Quality (Should Be Preserved)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "g_sym = (g_normalized + g_normalized.transpose(-2, -1)) / 2.0\n",
        "eigvals = torch.linalg.eigvalsh(g_sym)\n",
        "\n",
        "det_mean = det_g.mean().item()\n",
        "det_std = det_g.std().item()\n",
        "det_error = abs(det_mean - CONFIG['target']['det_g']) / CONFIG['target']['det_g'] * 100\n",
        "\n",
        "eig_min = eigvals.min().item()\n",
        "positive_definite = (eigvals > 0).all().item()\n",
        "\n",
        "print(f\"  det(g) = {det_mean:.7f} ± {det_std:.2e}\")\n",
        "print(f\"  Target: det(g) = {CONFIG['target']['det_g']}\")\n",
        "print(f\"  Error: {det_error:.4f}%\")\n",
        "print(f\"  Eigenvalues: min={eig_min:.6f}, max={eigvals.max().item():.6f}\")\n",
        "print(f\"  Positive definite: {positive_definite}\")\n",
        "\n",
        "if det_error < 0.01 and positive_definite:\n",
        "    print(f\"  ✓ Geometric quality preserved (SUCCESS)\")\n",
        "else:\n",
        "    print(f\"  ⚠ Geometric quality degraded\")\n",
        "\n",
        "# ==================================================================\n",
        "# 4. PHENOMENOLOGICAL VIABILITY\n",
        "# ==================================================================\n",
        "print(\"\\n4. Phenomenological Viability\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "yukawa_norm = np.linalg.norm(Y_tensor)\n",
        "yukawa_max = np.abs(Y_tensor).max()\n",
        "yukawa_nonzero_frac = (np.abs(Y_tensor) > 1e-8).mean()\n",
        "\n",
        "print(f\"  Yukawa norm: {yukawa_norm:.6e}\")\n",
        "print(f\"  Max |Y|: {yukawa_max:.6e}\")\n",
        "print(f\"  Non-zero fraction: {yukawa_nonzero_frac:.3f}\")\n",
        "\n",
        "if yukawa_norm > 1e-5:\n",
        "    print(f\"  ✓ Yukawa couplings non-negligible (SUCCESS)\")\n",
        "elif yukawa_norm > 1e-8:\n",
        "    print(f\"  ⚠ Yukawa couplings weak but non-zero (MARGINAL)\")\n",
        "else:\n",
        "    print(f\"  ✗ Yukawa couplings negligible (FAILURE)\")\n",
        "\n",
        "print(f\"\\n  v1.0f comparison: Yukawa norm ~10⁻¹⁰\")\n",
        "if yukawa_norm > 1e-10:\n",
        "    print(f\"  v1.1 improvement: {yukawa_norm / 1e-10:.1f}× larger\")\n",
        "\n",
        "# ==================================================================\n",
        "# 5. SUMMARY\n",
        "# ==================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"VALIDATION SUMMARY (v1.1)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "all_tests_passed = (\n",
        "    torsion_error < 10 and\n",
        "    rg_error < 10 and\n",
        "    det_error < 0.01 and\n",
        "    positive_definite and\n",
        "    yukawa_norm > 1e-5\n",
        ")\n",
        "\n",
        "print(f\"Torsion target reached: {'✓' if torsion_error < 10 else '✗'}\")\n",
        "print(f\"RG flow correct: {'✓' if rg_error < 10 else '✗'}\")\n",
        "print(f\"Geometric quality preserved: {'✓' if (det_error < 0.01 and positive_definite) else '✗'}\")\n",
        "print(f\"Yukawa viable: {'✓' if yukawa_norm > 1e-5 else '✗'}\")\n",
        "print(f\"\\nOverall: {'SUCCESS' if all_tests_passed else 'PARTIAL SUCCESS - Iteration may be needed'}\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULN_mO_G6Tju"
      },
      "source": [
        "## 18. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "bXJ9FBRb6Tju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "526eead8-2f75-4fd2-9241-af02b4d34dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to outputs_v1_1\n",
            "\n",
            "Key outputs:\n",
            "  - training_history.csv: Complete loss history with torsion tracking\n",
            "  - harmonic_2forms.npy, harmonic_3forms.npy: Cohomology bases\n",
            "  - yukawa_tensor.npy: (21×21×77) coupling tensor\n",
            "  - metadata.json: Validation results and configuration\n",
            "\n",
            "============================================================\n",
            "GIFT v1.1 PIPELINE COMPLETE\n",
            "============================================================\n",
            "Torsion: ✗ (11.1% error)\n",
            "RG flow: ✗ (102.0% error)\n",
            "Geometry: ✓\n",
            "Yukawa: ✗ (norm=5.90e-10)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "output_dir = Path('outputs_v1_1')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save harmonics and Yukawa\n",
        "np.save(output_dir / 'harmonic_2forms.npy', h2_modes)\n",
        "np.save(output_dir / 'harmonic_3forms.npy', h3_modes)\n",
        "np.save(output_dir / 'yukawa_tensor.npy', Y_tensor)\n",
        "\n",
        "# Save phi and metric samples\n",
        "phi_net.eval()\n",
        "with torch.no_grad():\n",
        "    test_coords = torch.rand(5000, 7, device=device)\n",
        "    phi_samples = phi_net(test_coords).cpu().numpy()\n",
        "    np.save(output_dir / 'phi_samples.npy', phi_samples)\n",
        "\n",
        "    g_samples, _ = compute_g2_metric(phi_net(test_coords))\n",
        "    g_samples = geometry.acyl_metric_correction(test_coords, g_samples)\n",
        "    np.save(output_dir / 'metric_samples.npy', g_samples.cpu().numpy())\n",
        "\n",
        "# Save loss history\n",
        "loss_df = pd.DataFrame(loss_history)\n",
        "loss_df.to_csv(output_dir / 'training_history.csv', index=False)\n",
        "\n",
        "# Save metadata with v1.1 specific info\n",
        "metadata = {\n",
        "    'version': '1.1',\n",
        "    'config': CONFIG,\n",
        "    'training_grid': f\"{CONFIG['n_grid']}^7\",\n",
        "    'harmonics_grid': f\"{CONFIG['n_grid_harmonics']}^7\",\n",
        "    'b2_effective': int(b2_eff),\n",
        "    'b3_effective': int(b3_eff),\n",
        "    'b2_target': CONFIG['target']['b2'],\n",
        "    'b3_target': CONFIG['target']['b3'],\n",
        "    'yukawa_shape': list(Y_tensor.shape),\n",
        "    'yukawa_norm': float(yukawa_norm),\n",
        "    'final_loss': loss_history[-1]['total'] if loss_history else None,\n",
        "    'total_epochs': len(loss_history),\n",
        "    'torsion_validation': {\n",
        "        'target': float(target_torsion),\n",
        "        'actual': float(torsion_mean),\n",
        "        'error_percent': float(torsion_error),\n",
        "        'passed': bool(torsion_error < 10)\n",
        "    },\n",
        "    'rg_flow_validation': {\n",
        "        'target_delta_alpha': float(target_delta),\n",
        "        'actual_delta_alpha': float(delta_alpha),\n",
        "        'error_percent': float(rg_error),\n",
        "        'passed': bool(rg_error < 10)\n",
        "    },\n",
        "    'geometric_validation': {\n",
        "        'det_g_mean': float(det_mean),\n",
        "        'det_g_error_percent': float(det_error),\n",
        "        'positive_definite': bool(positive_definite),\n",
        "        'passed': bool(det_error < 0.01 and positive_definite)\n",
        "    },\n",
        "    'phenomenological_validation': {\n",
        "        'yukawa_norm': float(yukawa_norm),\n",
        "        'passed': bool(yukawa_norm > 1e-5)\n",
        "    },\n",
        "    'note': 'v1.1: Torsion targeting + RG flow integration + Extended neck + Per-phase early stopping'\n",
        "}\n",
        "\n",
        "with open(output_dir / 'metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {output_dir}\")\n",
        "print(f\"\\nKey outputs:\")\n",
        "print(f\"  - training_history.csv: Complete loss history with torsion tracking\")\n",
        "print(f\"  - harmonic_2forms.npy, harmonic_3forms.npy: Cohomology bases\")\n",
        "print(f\"  - yukawa_tensor.npy: ({b2_eff}×{b2_eff}×{b3_eff}) coupling tensor\")\n",
        "print(f\"  - metadata.json: Validation results and configuration\")\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(\"GIFT v1.1 PIPELINE COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Torsion: {'✓' if torsion_error < 10 else '✗'} ({torsion_error:.1f}% error)\")\n",
        "print(f\"RG flow: {'✓' if rg_error < 10 else '✗'} ({rg_error:.1f}% error)\")\n",
        "print(f\"Geometry: {'✓' if (det_error < 0.01 and positive_definite) else '✗'}\")\n",
        "print(f\"Yukawa: {'✓' if yukawa_norm > 1e-5 else '✗'} (norm={yukawa_norm:.2e})\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "303dS4Nt6Tju"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RagcQSo6Tju"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xib2Eh0X6Tju"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}