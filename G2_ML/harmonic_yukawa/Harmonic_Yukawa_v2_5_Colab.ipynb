{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# GIFT Harmonic-Yukawa Pipeline v2.5\n",
    "\n",
    "**Key improvements from v2.3/v2.4:**\n",
    "1. **Longer training** (1000 epochs) → target L < 0.01\n",
    "2. **Torsional loss term**: $\\|T \\wedge \\omega\\|^2$ with $\\kappa_T = 1/61$\n",
    "3. **L-weighted Yukawa**: Use form loss as localization proxy\n",
    "4. **Full b₃ = 77** (or scalable subset)\n",
    "\n",
    "**Insight**: Final loss L encodes localization:\n",
    "- Low L → localized (light modes: $m_e, m_d$)\n",
    "- High L → delocalized (heavy modes: $m_\\tau, m_t$)\n",
    "\n",
    "$$y_{ijk} \\propto \\prod_n \\frac{1}{1 + L_n} \\quad \\Rightarrow \\quad \\tau \\approx 3.90$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup\n",
    "!pip install torch numpy matplotlib --quiet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Tuple, List, Dict\n",
    "from itertools import combinations\n",
    "from functools import lru_cache\n",
    "import math, json\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title GIFT v2.2 Constants\n",
    "@dataclass\n",
    "class Config:\n",
    "    # Betti numbers\n",
    "    b2: int = 21                   # dim H²(K₇)\n",
    "    b3: int = 77                   # dim H³(K₇)\n",
    "    b3_local: int = 35             # Local modes (Λ³ℝ⁷)\n",
    "    b3_global: int = 42            # Global modes (TCS gluing)\n",
    "    \n",
    "    # Form dimensions\n",
    "    dim_3form: int = 35            # C(7,3)\n",
    "    \n",
    "    # Topological constants\n",
    "    det_g_target: float = 65/32    # = 2.03125\n",
    "    kappa_T: float = 1/61          # Torsion magnitude\n",
    "    tau: float = 3472/891          # = 3.8968...\n",
    "    \n",
    "    # Physical scales\n",
    "    v_higgs: float = 246.0         # GeV\n",
    "    \n",
    "    # Visible/hidden split\n",
    "    n_visible: int = 43\n",
    "    n_hidden: int = 34\n",
    "    \n",
    "    # Training\n",
    "    epochs: int = 1000             # Longer for L < 0.01\n",
    "    batch_size: int = 256\n",
    "\n",
    "cfg = Config()\n",
    "print(f\"Target: det(g) = {cfg.det_g_target:.5f}\")\n",
    "print(f\"κ_T = {cfg.kappa_T:.6f}\")\n",
    "print(f\"τ = {cfg.tau:.6f}\")\n",
    "print(f\"b₃ = {cfg.b3} ({cfg.b3_local} local + {cfg.b3_global} global)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Metric with Torsion Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title G₂ Structure Constants\n",
    "\n",
    "# The associative 3-form φ defines G₂ structure\n",
    "# φ = dx^{123} + dx^{145} + dx^{167} + dx^{246} - dx^{257} - dx^{347} - dx^{356}\n",
    "# (standard G₂ 3-form in ℝ⁷)\n",
    "\n",
    "G2_PHI_INDICES = [\n",
    "    ((0,1,2), +1),\n",
    "    ((0,3,4), +1),\n",
    "    ((0,5,6), +1),\n",
    "    ((1,3,5), +1),\n",
    "    ((1,4,6), -1),\n",
    "    ((2,3,6), -1),\n",
    "    ((2,4,5), -1),\n",
    "]\n",
    "\n",
    "def g2_phi_at_point(device='cpu'):\n",
    "    \"\"\"Return the standard G₂ 3-form φ as tensor.\"\"\"\n",
    "    phi = torch.zeros(35, device=device)\n",
    "    i3 = list(combinations(range(7), 3))\n",
    "    for (idx, sign) in G2_PHI_INDICES:\n",
    "        c = i3.index(idx)\n",
    "        phi[c] = sign\n",
    "    return phi\n",
    "\n",
    "PHI_G2 = g2_phi_at_point(device)\n",
    "print(f\"G₂ 3-form φ: {PHI_G2.nonzero().squeeze().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Metric Network (Cholesky SPD + G₂ constraint)\n",
    "\n",
    "class MetricNetwork(nn.Module):\n",
    "    \"\"\"g = L @ L.T with G₂ structure regularization.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden=128, layers=4):\n",
    "        super().__init__()\n",
    "        self.B = nn.Parameter(torch.randn(7, 32) * 2, requires_grad=False)\n",
    "        \n",
    "        net = []\n",
    "        d = 7 + 64\n",
    "        for _ in range(layers-1):\n",
    "            net += [nn.Linear(d, hidden), nn.SiLU()]\n",
    "            d = hidden\n",
    "        net.append(nn.Linear(hidden, 28))\n",
    "        self.net = nn.Sequential(*net)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            bias = torch.zeros(28)\n",
    "            bias[:7] = (65/32) ** (1/14)\n",
    "            self.net[-1].bias.copy_(bias)\n",
    "            self.net[-1].weight.mul_(0.01)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        proj = 2 * math.pi * x @ self.B\n",
    "        feat = torch.cat([x, torch.sin(proj), torch.cos(proj)], -1)\n",
    "        out = self.net(feat)\n",
    "        \n",
    "        L = torch.zeros(x.shape[0], 7, 7, device=x.device)\n",
    "        L[:, range(7), range(7)] = F.softplus(out[:, :7]) + 0.1\n",
    "        \n",
    "        idx = 7\n",
    "        for i in range(1, 7):\n",
    "            for j in range(i):\n",
    "                L[:, i, j] = out[:, idx] * 0.1\n",
    "                idx += 1\n",
    "        \n",
    "        return L @ L.transpose(-1, -2)\n",
    "\n",
    "metric_net = MetricNetwork().to(device)\n",
    "print(f\"Metric params: {sum(p.numel() for p in metric_net.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": "# @title Train Metric\n\ndef train_metric(net, epochs=2000):\n    opt = torch.optim.Adam(net.parameters(), lr=1e-3)\n    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, epochs)\n\n    for ep in range(epochs):\n        opt.zero_grad()\n        x = torch.rand(512, 7, device=device)\n        g = net(x)\n        det = torch.det(g)\n\n        # det(g) = 65/32\n        loss_det = ((det.mean() - cfg.det_g_target)**2) + 0.1 * det.var()\n\n        # Encourage near-identity (G₂ holonomy ~ flat + torsion)\n        eye = torch.eye(7, device=device).unsqueeze(0)\n        scale = det.mean().pow(1.0/7.0)  # Fix: use .pow() instead of **\n        loss_id = ((g - eye * scale.view(1,1,1))**2).mean()\n\n        loss = loss_det + 0.01 * loss_id\n        loss.backward()\n        opt.step()\n        sched.step()\n\n        if (ep+1) % 500 == 0:\n            print(f\"Ep {ep+1}: det={det.mean():.4f}±{det.std():.4f}\")\n\n    return net\n\nprint(\"Training metric...\")\nmetric_net = train_metric(metric_net)\n\nwith torch.no_grad():\n    det_val = torch.det(metric_net(torch.rand(1000,7,device=device)))\n    print(f\"\\nFinal: det(g)={det_val.mean():.6f} (target {cfg.det_g_target:.6f})\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Harmonic Forms with Torsional Loss\n",
    "\n",
    "Key insight: Add torsional coupling to break degeneracy:\n",
    "$$\\mathcal{L} = \\|d\\omega\\|^2 + \\|\\delta\\omega\\|^2 + \\kappa_T^2 \\|T \\wedge \\omega\\|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Index Tables\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def idx3(): return list(combinations(range(7), 3))\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def idx4(): return list(combinations(range(7), 4))\n",
    "\n",
    "print(f\"3-form indices: {len(idx3())}\")\n",
    "print(f\"4-form indices: {len(idx4())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Exterior Derivative and Hodge Operations\n",
    "\n",
    "def exterior_d_3form(omega_fn, x, eps=1e-4):\n",
    "    \"\"\"d: Ω³ → Ω⁴\"\"\"\n",
    "    batch = x.shape[0]\n",
    "    d_omega = torch.zeros(batch, 35, device=x.device)\n",
    "    \n",
    "    i3 = idx3()\n",
    "    i4 = idx4()\n",
    "    \n",
    "    for c4, (i, j, k, l) in enumerate(i4):\n",
    "        indices = [i, j, k, l]\n",
    "        for pos, m in enumerate(indices):\n",
    "            three = tuple(idx for idx in indices if idx != m)\n",
    "            if three in i3:\n",
    "                c3 = i3.index(three)\n",
    "                sign = (-1) ** pos\n",
    "                \n",
    "                x_p = x.clone(); x_p[:, m] += eps\n",
    "                x_m = x.clone(); x_m[:, m] -= eps\n",
    "                \n",
    "                omega_p = omega_fn(x_p)[:, c3]\n",
    "                omega_m = omega_fn(x_m)[:, c3]\n",
    "                \n",
    "                d_omega[:, c4] += sign * (omega_p - omega_m) / (2*eps)\n",
    "    \n",
    "    return d_omega\n",
    "\n",
    "def hodge_star_3(omega, det_g):\n",
    "    \"\"\"Simplified Hodge *: Ω³ → Ω⁴ (diagonal metric approx).\"\"\"\n",
    "    vol = torch.sqrt(det_g.abs().clamp(min=1e-10))\n",
    "    i3 = idx3()\n",
    "    i4 = idx4()\n",
    "    \n",
    "    star = torch.zeros(omega.shape[0], 35, device=omega.device)\n",
    "    for c3, (i,j,k) in enumerate(i3):\n",
    "        comp = tuple(m for m in range(7) if m not in (i,j,k))\n",
    "        c4 = i4.index(comp)\n",
    "        full = (i,j,k) + comp\n",
    "        inv = sum(1 for a in range(7) for b in range(a+1,7) if full[a] > full[b])\n",
    "        star[:, c4] = ((-1)**inv) * vol * omega[:, c3]\n",
    "    \n",
    "    return star\n",
    "\n",
    "def codiff_norm_3form(omega_fn, x, det_g, eps=1e-4):\n",
    "    \"\"\"||δω||² via gradient of *ω.\"\"\"\n",
    "    delta_sq = torch.zeros(x.shape[0], device=x.device)\n",
    "    \n",
    "    for i in range(7):\n",
    "        x_p = x.clone(); x_p[:, i] += eps\n",
    "        x_m = x.clone(); x_m[:, i] -= eps\n",
    "        \n",
    "        star_p = hodge_star_3(omega_fn(x_p), det_g)\n",
    "        star_m = hodge_star_3(omega_fn(x_m), det_g)\n",
    "        \n",
    "        d_star = (star_p - star_m) / (2*eps)\n",
    "        delta_sq += (d_star ** 2).sum(dim=-1)\n",
    "    \n",
    "    return delta_sq\n",
    "\n",
    "print(\"Exterior calculus defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Torsion Coupling\n",
    "\n",
    "def torsion_coupling(omega, phi_g2):\n",
    "    \"\"\"||T ∧ ω||² where T ~ κ_T * dφ.\n",
    "    \n",
    "    Approximation: |<ω, φ>|² measures alignment with G₂ structure.\n",
    "    Forms aligned with φ are \"torsion-coupled\" (heavier).\n",
    "    \"\"\"\n",
    "    # Inner product with G₂ 3-form\n",
    "    inner = (omega * phi_g2.unsqueeze(0)).sum(dim=-1)\n",
    "    return inner ** 2\n",
    "\n",
    "print(f\"Torsion scale: κ_T = {cfg.kappa_T:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Harmonic 3-Form Network\n",
    "\n",
    "class Harmonic3FormNet(nn.Module):\n",
    "    def __init__(self, hidden=64, layers=3, form_id=0):\n",
    "        super().__init__()\n",
    "        self.form_id = form_id\n",
    "        \n",
    "        torch.manual_seed(1000 + form_id)\n",
    "        self.B = nn.Parameter(torch.randn(7, 16) * 2, requires_grad=False)\n",
    "        \n",
    "        net = []\n",
    "        d = 7 + 32\n",
    "        for _ in range(layers-1):\n",
    "            net += [nn.Linear(d, hidden), nn.Tanh()]\n",
    "            d = hidden\n",
    "        net.append(nn.Linear(hidden, 35))\n",
    "        self.net = nn.Sequential(*net)\n",
    "        \n",
    "        torch.manual_seed(2000 + form_id)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        proj = 2 * math.pi * x @ self.B\n",
    "        feat = torch.cat([x, torch.sin(proj), torch.cos(proj)], -1)\n",
    "        return self.net(feat)\n",
    "\n",
    "print(\"Harmonic 3-form network defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Training with Torsional Loss\n",
    "\n",
    "def train_harmonic_form_v25(form_id, metric_net, prev_nets, prev_losses, \n",
    "                            epochs=1000, verbose=True):\n",
    "    \"\"\"Train harmonic 3-form with torsional coupling.\n",
    "    \n",
    "    Loss = λ_d||dω||² + λ_δ||δω||² + λ_T κ_T²||T∧ω||² + λ_n(||ω||-1)² + λ_o Σ<ω,ω_prev>²\n",
    "    \"\"\"\n",
    "    net = Harmonic3FormNet(form_id=form_id).to(device)\n",
    "    opt = torch.optim.Adam(net.parameters(), lr=3e-4)\n",
    "    sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, epochs)\n",
    "    \n",
    "    # Adaptive weights based on form_id (later forms need stronger ortho)\n",
    "    lambda_d = 5.0\n",
    "    lambda_delta = 5.0\n",
    "    lambda_T = 10.0 * cfg.kappa_T**2  # Torsion coupling\n",
    "    lambda_n = 10.0\n",
    "    lambda_o = 20.0 + form_id * 2  # Increase for later forms\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for ep in range(epochs):\n",
    "        opt.zero_grad()\n",
    "        \n",
    "        x = torch.rand(cfg.batch_size, 7, device=device)\n",
    "        with torch.no_grad():\n",
    "            g = metric_net(x)\n",
    "            det_g = torch.det(g)\n",
    "            vol = torch.sqrt(det_g.abs().clamp(min=1e-10))\n",
    "        \n",
    "        omega = net(x)\n",
    "        \n",
    "        # Closedness\n",
    "        d_omega = exterior_d_3form(net, x)\n",
    "        loss_d = (d_omega ** 2).sum(dim=-1).mean()\n",
    "        \n",
    "        # Coclosedness\n",
    "        loss_delta = codiff_norm_3form(net, x, det_g).mean()\n",
    "        \n",
    "        # Torsion coupling (alignment with φ)\n",
    "        loss_T = torsion_coupling(omega, PHI_G2).mean()\n",
    "        \n",
    "        # Normalization\n",
    "        norm_sq = ((omega ** 2).sum(dim=-1) * vol).mean()\n",
    "        loss_n = (norm_sq - 1.0) ** 2\n",
    "        \n",
    "        # Orthogonality to previous forms\n",
    "        loss_o = torch.tensor(0.0, device=device)\n",
    "        for prev in prev_nets:\n",
    "            with torch.no_grad():\n",
    "                omega_prev = prev(x)\n",
    "            inner = ((omega * omega_prev).sum(dim=-1) * vol).mean()\n",
    "            loss_o = loss_o + inner ** 2\n",
    "        \n",
    "        loss = (lambda_d * loss_d + lambda_delta * loss_delta + \n",
    "                lambda_T * loss_T + lambda_n * loss_n + lambda_o * loss_o)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        sched.step()\n",
    "        \n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "        \n",
    "        if verbose and (ep+1) % 250 == 0:\n",
    "            print(f\"  Ep {ep+1}: L={loss.item():.4f} \"\n",
    "                  f\"(d={loss_d.item():.4f}, δ={loss_delta.item():.4f}, \"\n",
    "                  f\"T={loss_T.item():.4f}, n={loss_n.item():.4f}, o={loss_o.item():.4f})\")\n",
    "    \n",
    "    return net, best_loss\n",
    "\n",
    "print(\"Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Train All Harmonic Forms\n",
    "\n",
    "n_forms = 35  # Local modes (increase to 77 for full)\n",
    "harmonic_nets = []\n",
    "form_losses = []  # Track L for Yukawa weighting\n",
    "\n",
    "print(f\"Training {n_forms} harmonic 3-forms with torsional loss...\\n\")\n",
    "\n",
    "for i in range(n_forms):\n",
    "    print(f\"Form {i+1}/{n_forms}:\")\n",
    "    net, final_loss = train_harmonic_form_v25(\n",
    "        i, metric_net, harmonic_nets, form_losses,\n",
    "        epochs=cfg.epochs, verbose=True\n",
    "    )\n",
    "    harmonic_nets.append(net)\n",
    "    form_losses.append(final_loss)\n",
    "    print(f\"  → Final L = {final_loss:.4f}\\n\")\n",
    "\n",
    "print(f\"\\nTrained {len(harmonic_nets)} harmonic 3-forms\")\n",
    "print(f\"Loss range: [{min(form_losses):.4f}, {max(form_losses):.4f}]\")\n",
    "print(f\"Loss std: {np.std(form_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: L-Weighted Yukawa Extraction\n",
    "\n",
    "Key insight: Final loss L encodes localization.\n",
    "$$y_{ijk} = \\text{scale} \\times \\prod_n \\frac{1}{1 + L_n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Sort Forms by Loss (Localization)\n",
    "\n",
    "# Sort indices by loss (low L = light, high L = heavy)\n",
    "sorted_indices = np.argsort(form_losses)\n",
    "sorted_losses = np.array(form_losses)[sorted_indices]\n",
    "\n",
    "print(\"Forms sorted by loss (low=light, high=heavy):\")\n",
    "print(f\"Lightest: Form {sorted_indices[0]} (L={sorted_losses[0]:.4f})\")\n",
    "print(f\"Heaviest: Form {sorted_indices[-1]} (L={sorted_losses[-1]:.4f})\")\n",
    "print(f\"\\nTop 5 light: {sorted_indices[:5].tolist()}\")\n",
    "print(f\"Top 5 heavy: {sorted_indices[-5:].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title L-Weighted Yukawa\n",
    "\n",
    "def l_weighted_yukawa(i, j, k, losses, scale=1.0):\n",
    "    \"\"\"Compute Yukawa y_ijk using L as localization proxy.\n",
    "    \n",
    "    y_ijk ∝ ∏ 1/(1 + L_n) = exp(-Σ log(1 + L_n))\n",
    "    \"\"\"\n",
    "    L_sum = np.log(1 + losses[i]) + np.log(1 + losses[j]) + np.log(1 + losses[k])\n",
    "    return scale * np.exp(-L_sum)\n",
    "\n",
    "def compute_yukawa_matrix(losses, n_gen=3):\n",
    "    \"\"\"Compute effective Yukawa matrix for n_gen generations.\n",
    "    \n",
    "    Uses lightest forms for down-type, heaviest for up-type.\n",
    "    \"\"\"\n",
    "    n = len(losses)\n",
    "    sorted_idx = np.argsort(losses)\n",
    "    \n",
    "    # Assign generations: light → electron, medium → muon, heavy → tau\n",
    "    gen_indices = [\n",
    "        sorted_idx[:n//3],           # Generation 1 (light)\n",
    "        sorted_idx[n//3:2*n//3],     # Generation 2 (medium)\n",
    "        sorted_idx[2*n//3:],         # Generation 3 (heavy)\n",
    "    ]\n",
    "    \n",
    "    # Effective Yukawa per generation (average over modes)\n",
    "    Y = np.zeros((n_gen, n_gen))\n",
    "    for a in range(n_gen):\n",
    "        for b in range(n_gen):\n",
    "            yukawas = []\n",
    "            for i in gen_indices[a]:\n",
    "                for j in gen_indices[b]:\n",
    "                    for k in range(n):  # Sum over all third index\n",
    "                        yukawas.append(l_weighted_yukawa(i, j, k, losses))\n",
    "            Y[a, b] = np.mean(yukawas) if yukawas else 0\n",
    "    \n",
    "    return Y\n",
    "\n",
    "Y_eff = compute_yukawa_matrix(form_losses)\n",
    "print(\"Effective Yukawa matrix (3 generations):\")\n",
    "print(Y_eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Mass Hierarchy from L-Weighting\n",
    "\n",
    "# Diagonal Yukawas give masses\n",
    "y_diag = np.diag(Y_eff)\n",
    "masses_yukawa = cfg.v_higgs * np.sqrt(y_diag) * cfg.kappa_T\n",
    "\n",
    "print(\"L-weighted masses (diagonal Yukawa):\")\n",
    "for i, m in enumerate(masses_yukawa):\n",
    "    print(f\"  Gen {i+1}: {m:.4f} GeV\")\n",
    "\n",
    "# Compute tau parameter\n",
    "if len(form_losses) >= 2:\n",
    "    L_arr = np.array(form_losses)\n",
    "    sorted_L = np.sort(L_arr)\n",
    "    \n",
    "    # τ = (sum of heavy modes) / (sum of light modes)\n",
    "    n_vis = min(cfg.n_visible, len(sorted_L))\n",
    "    heavy_sum = np.sum(1/(1 + sorted_L[-n_vis:]))\n",
    "    light_sum = np.sum(1/(1 + sorted_L[:n_vis]))\n",
    "    \n",
    "    if light_sum > 1e-10:\n",
    "        tau_computed = heavy_sum / light_sum\n",
    "    else:\n",
    "        tau_computed = float('inf')\n",
    "    \n",
    "    print(f\"\\nComputed τ = {tau_computed:.4f}\")\n",
    "    print(f\"Target τ = {cfg.tau:.4f}\")\n",
    "    print(f\"Error: {abs(tau_computed - cfg.tau)/cfg.tau * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Lepton Mass Ratios\n",
    "\n",
    "L_arr = np.array(form_losses)\n",
    "sorted_L = np.sort(L_arr)\n",
    "\n",
    "# Use sorted losses to compute mass ratios\n",
    "# m ∝ 1/(1 + L), so m_heavy/m_light = (1+L_light)/(1+L_heavy)\n",
    "\n",
    "n = len(sorted_L)\n",
    "if n >= 9:\n",
    "    # tau = heaviest, mu = middle, e = lightest\n",
    "    L_e = sorted_L[0]      # Lightest\n",
    "    L_mu = sorted_L[n//3]  # ~1/3 point\n",
    "    L_tau = sorted_L[-1]   # Heaviest\n",
    "    \n",
    "    m_tau_m_mu = (1 + L_mu) / (1 + L_tau)\n",
    "    m_mu_m_e = (1 + L_e) / (1 + L_mu)\n",
    "    m_tau_m_e = (1 + L_e) / (1 + L_tau)\n",
    "    \n",
    "    print(\"Lepton mass ratios from L-weighting:\")\n",
    "    print(f\"  m_τ/m_μ = {1/m_tau_m_mu:.1f} (PDG: 16.8)\")\n",
    "    print(f\"  m_μ/m_e = {1/m_mu_m_e:.1f} (PDG: 207)\")\n",
    "    print(f\"  m_τ/m_e = {1/m_tau_m_e:.1f} (PDG: 3477)\")\n",
    "else:\n",
    "    print(f\"Need more forms for mass ratios (have {n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Full Mass Spectrum\n",
    "\n",
    "# Convert L to masses: m ∝ v_H * κ_T / (1 + L)\n",
    "L_arr = np.array(form_losses)\n",
    "masses_full = cfg.v_higgs * cfg.kappa_T / (1 + L_arr)\n",
    "masses_sorted = np.sort(masses_full)[::-1]  # Descending\n",
    "\n",
    "print(\"Full mass spectrum (sorted, GeV):\")\n",
    "print(masses_sorted[:12])\n",
    "\n",
    "# Compare with PDG\n",
    "pdg_masses = np.array([172.69, 4.18, 1.777, 1.27, 0.10566, 0.0934, 0.00467, 0.00216, 0.000511])\n",
    "\n",
    "print(f\"\\nHierarchy ratio (max/min): {masses_sorted[0]/masses_sorted[-1]:.1f}\")\n",
    "print(f\"PDG hierarchy (t/e): {pdg_masses[0]/pdg_masses[-1]:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Visualization\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Loss distribution\n",
    "ax = axes[0, 0]\n",
    "ax.bar(range(len(form_losses)), form_losses, color='steelblue', alpha=0.7)\n",
    "ax.axhline(np.mean(form_losses), color='red', linestyle='--', label=f'Mean: {np.mean(form_losses):.3f}')\n",
    "ax.set_xlabel('Form ID')\n",
    "ax.set_ylabel('Final Loss L')\n",
    "ax.set_title('Form Losses (Low L = Light Mode)')\n",
    "ax.legend()\n",
    "\n",
    "# 2. Loss histogram\n",
    "ax = axes[0, 1]\n",
    "ax.hist(form_losses, bins=15, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(np.mean(form_losses), color='red', linestyle='--', label='Mean')\n",
    "ax.set_xlabel('Loss L')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Loss Distribution')\n",
    "ax.legend()\n",
    "\n",
    "# 3. Effective Yukawa matrix\n",
    "ax = axes[1, 0]\n",
    "im = ax.imshow(Y_eff, cmap='viridis')\n",
    "ax.set_xlabel('Generation')\n",
    "ax.set_ylabel('Generation')\n",
    "ax.set_title('Effective Yukawa Y_ab')\n",
    "ax.set_xticks([0,1,2])\n",
    "ax.set_yticks([0,1,2])\n",
    "ax.set_xticklabels(['e', 'μ', 'τ'])\n",
    "ax.set_yticklabels(['e', 'μ', 'τ'])\n",
    "plt.colorbar(im, ax=ax)\n",
    "\n",
    "# 4. Mass comparison\n",
    "ax = axes[1, 1]\n",
    "n_show = min(9, len(masses_sorted))\n",
    "ax.semilogy(range(n_show), masses_sorted[:n_show], 'bo-', label='L-weighted', markersize=8)\n",
    "ax.semilogy(range(len(pdg_masses)), pdg_masses, 'r^-', label='PDG', markersize=10)\n",
    "ax.set_xlabel('Rank (heavy → light)')\n",
    "ax.set_ylabel('Mass (GeV)')\n",
    "ax.set_title('Mass Hierarchy Comparison')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('harmonic_yukawa_v25.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"Saved: harmonic_yukawa_v25.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Export Results\n",
    "\n",
    "results = {\n",
    "    \"version\": \"2.5\",\n",
    "    \"n_forms\": len(harmonic_nets),\n",
    "    \"epochs\": cfg.epochs,\n",
    "    \"form_losses\": form_losses,\n",
    "    \"loss_stats\": {\n",
    "        \"mean\": float(np.mean(form_losses)),\n",
    "        \"std\": float(np.std(form_losses)),\n",
    "        \"min\": float(np.min(form_losses)),\n",
    "        \"max\": float(np.max(form_losses))\n",
    "    },\n",
    "    \"yukawa_effective\": Y_eff.tolist(),\n",
    "    \"masses_GeV\": masses_sorted.tolist(),\n",
    "    \"tau\": {\n",
    "        \"computed\": float(tau_computed) if 'tau_computed' in dir() else None,\n",
    "        \"target\": cfg.tau\n",
    "    },\n",
    "    \"config\": {\n",
    "        \"det_g\": cfg.det_g_target,\n",
    "        \"kappa_T\": cfg.kappa_T,\n",
    "        \"v_higgs\": cfg.v_higgs\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('harmonic_yukawa_v25_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Exported: harmonic_yukawa_v25_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "**v2.5 key improvements:**\n",
    "1. **Longer training** (1000 epochs) for L < 0.1\n",
    "2. **Torsional loss** $\\kappa_T^2 |\\langle\\omega, \\phi\\rangle|^2$ breaks degeneracy\n",
    "3. **L-weighted Yukawa**: $y_{ijk} \\propto \\prod 1/(1+L_n)$\n",
    "4. **G₂ 3-form** $\\phi$ for proper structure\n",
    "\n",
    "**Expected:**\n",
    "- Loss spread induces mass hierarchy\n",
    "- τ ≈ 3.90 from visible/hidden split\n",
    "- Mass ratios approach PDG values\n",
    "\n",
    "**Next steps:**\n",
    "- Scale to full b₃ = 77 (add global TCS modes)\n",
    "- Compute proper wedge integrals\n",
    "- Validate against CKM/PMNS mixing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}