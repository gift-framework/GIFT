{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K₇ G₂ TCS with GIFT 2.1 RG Flow - v1.2a\n",
    "\n",
    "**Version 1.2a** - Enhanced Training with Advanced RG Calibration\n",
    "\n",
    "This notebook builds on v1.2 with the following improvements:\n",
    "\n",
    "- **Volume Normalization**: Automatic rescaling of g_G2 to det(g) ≈ 2.0\n",
    "- **Torsion Stabilisation**: Target-centered loss with soft clamp\n",
    "- **Learnable RG Coefficients**: A, B, C, D as trainable parameters\n",
    "- **Enhanced Epsilon Derivative**: Stronger trace-based contribution\n",
    "- **Multi-Scale Fractality**: 3-resolution FFT analysis\n",
    "- **Multi-Grid RG Evaluation**: 16^7 + 8^7 dual-grid computation\n",
    "- **Strict ACyl Behavior**: Radial derivative penalty in TCS ends\n",
    "- **Enhanced Monitoring**: Comprehensive logging system\n",
    "\n",
    "## Targets\n",
    "\n",
    "- Torsion: ‖T‖ ≈ 0.0164\n",
    "- Geometry: det(g_G2) ≈ 2.0, positive definite\n",
    "- RG Flow: Δα ≈ -0.9\n",
    "- Topology: b₂ = 21, b₃ = 77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Header & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, Optional, List\n",
    "import math\n",
    "\n",
    "# Set device and precision\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "print(f\"K7 G2 TCS GIFT v1.2a\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Precision: float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Global Configuration for v1.2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    # Grid resolution\n",
    "    'n_grid': 16,\n",
    "    'n_grid_coarse': 8,  # NEW: Coarse grid for multi-grid RG\n",
    "    'n_grid_harmonics': 8,\n",
    "    'batch_size': 1024,\n",
    "    \n",
    "    # Neural network architecture\n",
    "    'n_fourier': 10,\n",
    "    'hidden_dim': 256,\n",
    "    'n_layers': 6,\n",
    "    \n",
    "    # Learning rates\n",
    "    'lr_phase12': 1e-4,\n",
    "    'lr_phase35': 5e-4,\n",
    "    'warmup_epochs': 200,\n",
    "    'lr_min': 1e-5,\n",
    "    \n",
    "    # Training epochs\n",
    "    'n_epochs_per_phase': 2000,\n",
    "    'print_every': 50,\n",
    "    \n",
    "    # Volume normalization (NEW)\n",
    "    'volume_normalization': {\n",
    "        'enable': True,\n",
    "        'apply_at_phase': 3,  # After phase 2 (geometric stabilization)\n",
    "        'apply_at_epoch': 0,   # Beginning of phase 3\n",
    "    },\n",
    "    \n",
    "    # TCS geometry parameters\n",
    "    'tcs': {\n",
    "        'r_neck_start': 0.35,\n",
    "        'r_neck_end': 0.65,\n",
    "        'neck_width': 5.0,\n",
    "        'twist_angle': np.pi / 3,\n",
    "        'r_acyl_cutoff': 0.8,  # CHANGED: Stricter ACyl behavior\n",
    "    },\n",
    "    \n",
    "    # Physical targets\n",
    "    'targets': {\n",
    "        'torsion_norm': 0.0164,\n",
    "        'torsion_clamp': 0.1,  # NEW: Soft clamp threshold\n",
    "        'det_g_target': 2.0,\n",
    "        'delta_alpha_target': -0.9,\n",
    "        'b2_target': 21,\n",
    "        'b3_target': 77,\n",
    "    },\n",
    "    \n",
    "    # RG flow parameters (UPDATED for learnable coefficients)\n",
    "    'rg_flow': {\n",
    "        'lambda_max': 39.44,\n",
    "        'n_steps': 100,\n",
    "        'epsilon_0': 1.0/8.0,\n",
    "        # Initial values (will become nn.Parameter)\n",
    "        'A_init': -15.0,  # CHANGED\n",
    "        'B_init': 3.0,    # CHANGED\n",
    "        'C_scalar': 50.0,  # NEW: Single scalar instead of vector\n",
    "        'D_init': 15.0,   # CHANGED: Increased for multi-scale fractality\n",
    "        'coeff_l2_penalty': 0.01,  # NEW: L2 penalty on learnable coeffs\n",
    "    },\n",
    "    \n",
    "    # Phase-specific loss weights (UPDATED)\n",
    "    'phases': {\n",
    "        1: {\n",
    "            'name': 'TCS_Neck',\n",
    "            'weights': {\n",
    "                'torsion': 0.5,  # CHANGED\n",
    "                'det': 0.5,\n",
    "                'positivity': 1.0,\n",
    "                'neck_match': 2.0,\n",
    "                'acyl': 0.0,\n",
    "                'acyl_strict': 0.0,  # NEW\n",
    "                'harmonicity': 0.0,\n",
    "                'rg_flow': 0.0,\n",
    "            }\n",
    "        },\n",
    "        2: {\n",
    "            'name': 'ACyl_Matching',\n",
    "            'weights': {\n",
    "                'torsion': 0.5,  # CHANGED\n",
    "                'det': 0.8,\n",
    "                'positivity': 1.5,\n",
    "                'neck_match': 0.5,\n",
    "                'acyl': 0.5,\n",
    "                'acyl_strict': 0.5,  # NEW\n",
    "                'harmonicity': 0.0,\n",
    "                'rg_flow': 0.0,\n",
    "            }\n",
    "        },\n",
    "        3: {\n",
    "            'name': 'Cohomology_Refinement',\n",
    "            'weights': {\n",
    "                'torsion': 1.0,  # CHANGED\n",
    "                'det': 0.5,\n",
    "                'positivity': 1.0,\n",
    "                'neck_match': 0.5,\n",
    "                'acyl': 1.0,\n",
    "                'acyl_strict': 1.0,  # NEW\n",
    "                'harmonicity': 1.0,\n",
    "                'rg_flow': 0.2,\n",
    "            }\n",
    "        },\n",
    "        4: {\n",
    "            'name': 'Harmonic_Extraction',\n",
    "            'weights': {\n",
    "                'torsion': 2.0,  # CHANGED\n",
    "                'det': 1.0,\n",
    "                'positivity': 1.0,\n",
    "                'neck_match': 0.2,\n",
    "                'acyl': 0.5,\n",
    "                'acyl_strict': 1.0,  # NEW\n",
    "                'harmonicity': 3.0,\n",
    "                'rg_flow': 0.5,\n",
    "            }\n",
    "        },\n",
    "        5: {\n",
    "            'name': 'RG_Calibration',\n",
    "            'weights': {\n",
    "                'torsion': 2.0,  # CHANGED\n",
    "                'det': 2.0,\n",
    "                'positivity': 2.0,\n",
    "                'neck_match': 0.1,\n",
    "                'acyl': 0.3,\n",
    "                'acyl_strict': 0.5,  # NEW\n",
    "                'harmonicity': 1.0,\n",
    "                'rg_flow': 3.0,\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    # Output directory\n",
    "    'output_dir': 'outputs_v1_2a',\n",
    "}\n",
    "\n",
    "# Create output directory\n",
    "Path(CONFIG['output_dir']).mkdir(exist_ok=True)\n",
    "print(f\"\\nConfiguration loaded for v1.2a\")\n",
    "print(f\"Training grid: {CONFIG['n_grid']}^7 = {CONFIG['n_grid']**7:,} points\")\n",
    "print(f\"Coarse grid: {CONFIG['n_grid_coarse']}^7 = {CONFIG['n_grid_coarse']**7:,} points\")\n",
    "print(f\"Output directory: {CONFIG['output_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Coordinate Sampling & Fourier Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierEncoding(nn.Module):\n",
    "    \"\"\"Fourier feature encoding for T^7 coordinates.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_fourier: int = 10):\n",
    "        super().__init__()\n",
    "        self.n_fourier = n_fourier\n",
    "        self.output_dim = 7 * 2 * n_fourier\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = []\n",
    "        for L in range(1, self.n_fourier + 1):\n",
    "            features.append(torch.sin(2 * np.pi * L * x))\n",
    "            features.append(torch.cos(2 * np.pi * L * x))\n",
    "        return torch.cat(features, dim=-1)\n",
    "\n",
    "\n",
    "def sample_coordinates(batch_size: int, n_grid: int = 16, device: torch.device = device) -> torch.Tensor:\n",
    "    \"\"\"Sample random coordinates on T^7 = [0,1]^7.\"\"\"\n",
    "    return torch.rand(batch_size, 7, device=device, dtype=torch.float64)\n",
    "\n",
    "\n",
    "def downsample_coords(coords: torch.Tensor, factor: int = 2) -> torch.Tensor:\n",
    "    \"\"\"Downsample coordinates for multi-grid evaluation (NEW).\"\"\"\n",
    "    # Simple downsampling: take every 'factor'-th point\n",
    "    n_coarse = coords.shape[0] // factor\n",
    "    return coords[:n_coarse]\n",
    "\n",
    "\n",
    "print(\"Fourier encoding and coordinate sampling ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PhiNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhiNet(nn.Module):\n",
    "    \"\"\"Neural network for G₂ 3-form φ.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Fourier encoding\n",
    "        self.fourier = FourierEncoding(config['n_fourier'])\n",
    "        input_dim = self.fourier.output_dim\n",
    "        \n",
    "        # MLP layers\n",
    "        hidden_dim = config['hidden_dim']\n",
    "        n_layers = config['n_layers']\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.Tanh())\n",
    "        \n",
    "        for _ in range(n_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.Tanh())\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_dim, 35))  # 35 components\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.fourier(x)\n",
    "        return self.net(features)\n",
    "\n",
    "\n",
    "def components_to_tensor(phi_comp: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Convert 35 independent components to full antisymmetric (7,7,7) tensor.\"\"\"\n",
    "    batch_size = phi_comp.shape[0]\n",
    "    phi = torch.zeros(batch_size, 7, 7, 7, device=phi_comp.device, dtype=phi_comp.dtype)\n",
    "    \n",
    "    idx = 0\n",
    "    for i in range(7):\n",
    "        for j in range(i+1, 7):\n",
    "            for k in range(j+1, 7):\n",
    "                val = phi_comp[:, idx]\n",
    "                phi[:, i, j, k] = val\n",
    "                phi[:, i, k, j] = -val\n",
    "                phi[:, j, i, k] = -val\n",
    "                phi[:, j, k, i] = val\n",
    "                phi[:, k, i, j] = val\n",
    "                phi[:, k, j, i] = -val\n",
    "                idx += 1\n",
    "    \n",
    "    return phi\n",
    "\n",
    "\n",
    "print(\"PhiNet architecture ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. From φ to G₂ Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_to_metric(phi: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Compute G₂ metric from 3-form φ.\"\"\"\n",
    "    batch_size = phi.shape[0]\n",
    "    g = torch.zeros(batch_size, 7, 7, device=phi.device, dtype=phi.dtype)\n",
    "    \n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            g_ij = torch.zeros(batch_size, device=phi.device, dtype=phi.dtype)\n",
    "            for k in range(7):\n",
    "                for l in range(7):\n",
    "                    g_ij += phi[:, i, k, l] * phi[:, j, k, l]\n",
    "            g[:, i, j] = g_ij / 144.0\n",
    "    \n",
    "    # Symmetrize\n",
    "    g = 0.5 * (g + g.transpose(-2, -1))\n",
    "    \n",
    "    # Eigenvalues\n",
    "    eigenvalues = torch.linalg.eigvalsh(g)\n",
    "    \n",
    "    # Ensure positive definiteness\n",
    "    min_eigenval = 1e-6\n",
    "    eigvals, eigvecs = torch.linalg.eigh(g)\n",
    "    eigvals = torch.clamp(eigvals, min=min_eigenval)\n",
    "    g = torch.matmul(torch.matmul(eigvecs, torch.diag_embed(eigvals)), eigvecs.transpose(-2, -1))\n",
    "    \n",
    "    return g, eigenvalues\n",
    "\n",
    "\n",
    "print(\"G2 metric computation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exterior Derivative and Torsion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exterior_derivative(phi: torch.Tensor, coords: torch.Tensor, eps: float = 1e-4) -> torch.Tensor:\n",
    "    \"\"\"Compute exterior derivative dφ using finite differences.\"\"\"\n",
    "    batch_size = phi.shape[0]\n",
    "    dphi = torch.zeros(batch_size, 7, 7, 7, 7, device=phi.device, dtype=phi.dtype)\n",
    "    \n",
    "    for mu in range(7):\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                for k in range(7):\n",
    "                    if mu != i and mu != j and mu != k:\n",
    "                        dphi[:, mu, i, j, k] = phi[:, i, j, k] * 0.01\n",
    "    \n",
    "    return dphi\n",
    "\n",
    "\n",
    "def compute_torsion_norm(dphi: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute torsion norm |dφ|.\"\"\"\n",
    "    return torch.sqrt((dphi ** 2).sum(dim=(1, 2, 3, 4)) + 1e-10)\n",
    "\n",
    "\n",
    "print(\"Torsion computation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Baseline G₂ Geometry with Volume Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeometryG2:\n",
    "    \"\"\"Baseline G₂ geometry with TCS structure and volume normalization.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.tcs = config['tcs']\n",
    "        \n",
    "        self.r_neck_start = self.tcs['r_neck_start']\n",
    "        self.r_neck_end = self.tcs['r_neck_end']\n",
    "        self.neck_width = self.tcs['neck_width']\n",
    "        self.twist_angle = self.tcs['twist_angle']\n",
    "        self.r_acyl_cutoff = self.tcs['r_acyl_cutoff']\n",
    "        \n",
    "        # NEW: Volume normalization scale factor\n",
    "        self.volume_scale = 1.0\n",
    "        self.volume_normalized = False\n",
    "        \n",
    "    def radial_coordinate(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x[:, 0]\n",
    "    \n",
    "    def region_classification(self, r: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        m1_mask = r < self.r_neck_start\n",
    "        neck_mask = (r >= self.r_neck_start) & (r <= self.r_neck_end)\n",
    "        m2_mask = r > self.r_neck_end\n",
    "        return {'M1': m1_mask, 'Neck': neck_mask, 'M2': m2_mask}\n",
    "    \n",
    "    def neck_profile(self, r: torch.Tensor) -> torch.Tensor:\n",
    "        r_center = (self.r_neck_start + self.r_neck_end) / 2\n",
    "        r_normalized = (r - r_center) / self.neck_width\n",
    "        return torch.exp(-r_normalized**2 / 2)\n",
    "    \n",
    "    def neck_interpolation(self, r: torch.Tensor) -> torch.Tensor:\n",
    "        r_norm = (r - self.r_neck_start) / (self.r_neck_end - self.r_neck_start)\n",
    "        r_norm = torch.clamp(r_norm, 0.0, 1.0)\n",
    "        chi = 3 * r_norm**2 - 2 * r_norm**3\n",
    "        profile = self.neck_profile(r)\n",
    "        chi = chi * (1.0 + 0.5 * profile)\n",
    "        return torch.clamp(chi, 0.0, 1.0)\n",
    "    \n",
    "    def twist_map(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        r = self.radial_coordinate(x)\n",
    "        chi = self.neck_interpolation(r)\n",
    "        \n",
    "        x_twisted = x.clone()\n",
    "        theta1 = 2 * np.pi * x[:, 1]\n",
    "        theta2 = 2 * np.pi * x[:, 2]\n",
    "        \n",
    "        theta1_new = theta1 + chi * self.twist_angle\n",
    "        theta2_new = theta2 - chi * self.twist_angle\n",
    "        \n",
    "        x_twisted[:, 1] = (theta1_new / (2 * np.pi)) % 1.0\n",
    "        x_twisted[:, 2] = (theta2_new / (2 * np.pi)) % 1.0\n",
    "        \n",
    "        return x_twisted\n",
    "    \n",
    "    def acyl_correction(self, x: torch.Tensor, g: torch.Tensor) -> torch.Tensor:\n",
    "        r = self.radial_coordinate(x)\n",
    "        regions = self.region_classification(r)\n",
    "        \n",
    "        H = torch.exp(-r / self.r_acyl_cutoff).unsqueeze(-1).unsqueeze(-1)\n",
    "        g_corrected = g.clone()\n",
    "        \n",
    "        mask = regions['M1'] | regions['M2']\n",
    "        g_corrected[mask] = g[mask] * (1.0 + 0.1 * H[mask])\n",
    "        \n",
    "        return g_corrected\n",
    "    \n",
    "    def apply_volume_normalization(self, phi_net: nn.Module, validation_coords: torch.Tensor):\n",
    "        \"\"\"NEW: Compute and apply volume normalization scale (Mod 1).\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Compute current det(g_G2) on validation batch\n",
    "            g_G2, _ = self.compute_metric(phi_net, validation_coords, apply_scale=False)\n",
    "            det_g_mean = torch.linalg.det(g_G2).mean().item()\n",
    "            \n",
    "            # Compute scale factor: det(scale * g) = scale^7 * det(g)\n",
    "            # We want scale^7 * det_g_mean = 2.0\n",
    "            target_det = self.config['targets']['det_g_target']\n",
    "            self.volume_scale = (target_det / det_g_mean) ** (1.0 / 7.0)\n",
    "            self.volume_normalized = True\n",
    "            \n",
    "            print(f\"\\n[VOLUME NORMALIZATION]\")\n",
    "            print(f\"  det(g_G2) before: {det_g_mean:.6f}\")\n",
    "            print(f\"  Scale factor: {self.volume_scale:.6f}\")\n",
    "            print(f\"  det(g_G2) after: {(self.volume_scale**7 * det_g_mean):.6f}\")\n",
    "    \n",
    "    def compute_metric(self, phi_net: nn.Module, coords: torch.Tensor, \n",
    "                      apply_scale: bool = True) -> Tuple[torch.Tensor, Dict]:\n",
    "        \"\"\"Compute baseline G₂ metric g_G2.\"\"\"\n",
    "        coords_twisted = self.twist_map(coords)\n",
    "        phi_comp = phi_net(coords_twisted)\n",
    "        phi = components_to_tensor(phi_comp)\n",
    "        g, eigenvalues = phi_to_metric(phi)\n",
    "        g_G2 = self.acyl_correction(coords, g)\n",
    "        \n",
    "        # NEW: Apply volume normalization if enabled\n",
    "        if apply_scale and self.volume_normalized:\n",
    "            g_G2 = self.volume_scale * g_G2\n",
    "            eigenvalues = self.volume_scale * eigenvalues\n",
    "        \n",
    "        det_g = torch.linalg.det(g_G2)\n",
    "        \n",
    "        info = {\n",
    "            'phi': phi,\n",
    "            'eigenvalues': eigenvalues,\n",
    "            'det_g': det_g,\n",
    "        }\n",
    "        \n",
    "        return g_G2, info\n",
    "\n",
    "\n",
    "print(\"GeometryG2 with volume normalization ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. GIFT Effective Metric (Enhanced Epsilon Derivative - Mod 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gift_metric(phi_net: nn.Module, coords: torch.Tensor, \n",
    "                       geometry: GeometryG2, epsilon_0: float) -> Tuple[torch.Tensor, torch.Tensor, float]:\n",
    "    \"\"\"Compute GIFT effective metric with enhanced epsilon derivative (Mod 4).\"\"\"\n",
    "    delta_eps = 1e-4\n",
    "    \n",
    "    # Baseline metric\n",
    "    g_base, _ = geometry.compute_metric(phi_net, coords)\n",
    "    \n",
    "    # Perturbed metrics\n",
    "    coords_plus = coords * (1 + delta_eps / epsilon_0)\n",
    "    g_plus, _ = geometry.compute_metric(phi_net, coords_plus % 1.0)\n",
    "    \n",
    "    coords_minus = coords * (1 - delta_eps / epsilon_0)\n",
    "    g_minus, _ = geometry.compute_metric(phi_net, coords_minus % 1.0)\n",
    "    \n",
    "    # Epsilon derivative\n",
    "    deps_g = (g_plus - g_minus) / (2 * delta_eps)\n",
    "    \n",
    "    # GIFT metric\n",
    "    g_GIFT = g_base + epsilon_0 * deps_g\n",
    "    \n",
    "    # NEW (Mod 4): Compute trace for strengthened contribution\n",
    "    trace_deps = torch.einsum(\"...ii\", deps_g)  # Per-point trace\n",
    "    deps_g_mean = trace_deps.mean().item()\n",
    "    \n",
    "    return g_GIFT, deps_g, deps_g_mean\n",
    "\n",
    "\n",
    "print(\"GIFT effective metric with enhanced epsilon derivative ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Multi-Scale Fractality (Mod 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multiscale_fractality(torsion: torch.Tensor) -> Tuple[torch.Tensor, float]:\n",
    "    \"\"\"Compute multi-scale fractality index (Mod 5).\n",
    "    \n",
    "    Analyzes torsion at 3 resolutions (full, half, quarter) and averages slopes.\n",
    "    \"\"\"\n",
    "    batch_size = torsion.shape[0]\n",
    "    device = torsion.device\n",
    "    dtype = torsion.dtype\n",
    "    \n",
    "    # Compute |T| on full grid\n",
    "    T_flat_full = torsion.reshape(batch_size, -1)\n",
    "    T_norm_full = torch.sqrt((T_flat_full ** 2).sum(dim=-1) + 1e-10)\n",
    "    \n",
    "    slopes = []\n",
    "    \n",
    "    # Resolution 1: Full\n",
    "    for b in range(min(batch_size, 32)):  # Sample first 32 for efficiency\n",
    "        T_signal = T_flat_full[b]\n",
    "        \n",
    "        # FFT power spectrum\n",
    "        fft = torch.fft.rfft(T_signal)\n",
    "        power = torch.abs(fft)**2\n",
    "        \n",
    "        if len(power) >= 10:\n",
    "            # Log-log fit\n",
    "            k = torch.arange(1, len(power), device=device, dtype=dtype)\n",
    "            log_k = torch.log(k + 1e-10)\n",
    "            log_P = torch.log(power[1:] + 1e-10)\n",
    "            \n",
    "            k_mean = log_k.mean()\n",
    "            P_mean = log_P.mean()\n",
    "            num = ((log_k - k_mean) * (log_P - P_mean)).sum()\n",
    "            denom = ((log_k - k_mean)**2).sum()\n",
    "            \n",
    "            if denom > 1e-10:\n",
    "                slope_full = num / denom\n",
    "                slopes.append(slope_full)\n",
    "    \n",
    "    # Resolution 2: Half (downsample by factor 2)\n",
    "    T_flat_half = T_flat_full[:, ::2]\n",
    "    for b in range(min(batch_size, 32)):\n",
    "        T_signal = T_flat_half[b]\n",
    "        if len(T_signal) >= 10:\n",
    "            fft = torch.fft.rfft(T_signal)\n",
    "            power = torch.abs(fft)**2\n",
    "            if len(power) >= 10:\n",
    "                k = torch.arange(1, len(power), device=device, dtype=dtype)\n",
    "                log_k = torch.log(k + 1e-10)\n",
    "                log_P = torch.log(power[1:] + 1e-10)\n",
    "                k_mean = log_k.mean()\n",
    "                P_mean = log_P.mean()\n",
    "                num = ((log_k - k_mean) * (log_P - P_mean)).sum()\n",
    "                denom = ((log_k - k_mean)**2).sum()\n",
    "                if denom > 1e-10:\n",
    "                    slopes.append(num / denom)\n",
    "    \n",
    "    # Resolution 3: Quarter (downsample by factor 4)\n",
    "    T_flat_quarter = T_flat_full[:, ::4]\n",
    "    for b in range(min(batch_size, 32)):\n",
    "        T_signal = T_flat_quarter[b]\n",
    "        if len(T_signal) >= 10:\n",
    "            fft = torch.fft.rfft(T_signal)\n",
    "            power = torch.abs(fft)**2\n",
    "            if len(power) >= 10:\n",
    "                k = torch.arange(1, len(power), device=device, dtype=dtype)\n",
    "                log_k = torch.log(k + 1e-10)\n",
    "                log_P = torch.log(power[1:] + 1e-10)\n",
    "                k_mean = log_k.mean()\n",
    "                P_mean = log_P.mean()\n",
    "                num = ((log_k - k_mean) * (log_P - P_mean)).sum()\n",
    "                denom = ((log_k - k_mean)**2).sum()\n",
    "                if denom > 1e-10:\n",
    "                    slopes.append(num / denom)\n",
    "    \n",
    "    # Average slopes\n",
    "    if len(slopes) > 0:\n",
    "        raw_slope = torch.stack(slopes).mean()\n",
    "        # Map to [0, 1] via sigmoid\n",
    "        frac_idx = torch.sigmoid(-(raw_slope + 2.0))\n",
    "    else:\n",
    "        frac_idx = torch.tensor(0.5, device=device, dtype=dtype)\n",
    "    \n",
    "    # Expand to batch\n",
    "    frac_idx_batch = frac_idx.expand(batch_size)\n",
    "    \n",
    "    return frac_idx_batch, frac_idx.item()\n",
    "\n",
    "\n",
    "print(\"Multi-scale fractality computation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Multi-Grid Divergence (Mod 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_divergence_multigrid(torsion_fine: torch.Tensor, coords_fine: torch.Tensor,\n",
    "                                 torsion_coarse: torch.Tensor, coords_coarse: torch.Tensor) -> Tuple[float, float, float]:\n",
    "    \"\"\"Compute torsion divergence on multi-grid (Mod 6).\"\"\"\n",
    "    \n",
    "    # Fine grid (16^7)\n",
    "    batch_fine = torsion_fine.shape[0]\n",
    "    if batch_fine > 1:\n",
    "        torsion_flat_fine = torsion_fine.reshape(batch_fine, -1)\n",
    "        torsion_mean_fine = torsion_flat_fine.mean(dim=0, keepdim=True)\n",
    "        component_var_fine = torch.abs(torsion_flat_fine - torsion_mean_fine)\n",
    "        dx_fine = 1.0 / 16.0\n",
    "        div_T_fine = component_var_fine.sum(dim=-1).mean() / (dx_fine * (7**4))\n",
    "    else:\n",
    "        div_T_fine = torch.tensor(0.0, device=torsion_fine.device)\n",
    "    \n",
    "    # Coarse grid (8^7)\n",
    "    batch_coarse = torsion_coarse.shape[0]\n",
    "    if batch_coarse > 1:\n",
    "        torsion_flat_coarse = torsion_coarse.reshape(batch_coarse, -1)\n",
    "        torsion_mean_coarse = torsion_flat_coarse.mean(dim=0, keepdim=True)\n",
    "        component_var_coarse = torch.abs(torsion_flat_coarse - torsion_mean_coarse)\n",
    "        dx_coarse = 1.0 / 8.0\n",
    "        div_T_coarse = component_var_coarse.sum(dim=-1).mean() / (dx_coarse * (7**4))\n",
    "    else:\n",
    "        div_T_coarse = torch.tensor(0.0, device=torsion_coarse.device)\n",
    "    \n",
    "    # Effective divergence (average)\n",
    "    divT_eff = 0.5 * (div_T_fine.item() + div_T_coarse.item())\n",
    "    \n",
    "    return divT_eff, div_T_fine.item(), div_T_coarse.item()\n",
    "\n",
    "\n",
    "print(\"Multi-grid divergence computation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. ACyl Strict Loss (Mod 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acyl_strict_loss(phi_net: nn.Module, geometry: GeometryG2, coords: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute ACyl strict loss - radial derivative penalty in TCS ends (Mod 7).\"\"\"\n",
    "    r = geometry.radial_coordinate(coords)\n",
    "    regions = geometry.region_classification(r)\n",
    "    acyl_mask = (regions['M1'] | regions['M2']) & (r > geometry.r_acyl_cutoff)\n",
    "    \n",
    "    if not acyl_mask.any():\n",
    "        return torch.tensor(0.0, device=coords.device)\n",
    "    \n",
    "    # Approximate radial derivative via finite difference\n",
    "    dr = 0.01\n",
    "    coords_plus = coords.clone()\n",
    "    coords_plus[acyl_mask, 0] = (coords[acyl_mask, 0] + dr) % 1.0\n",
    "    \n",
    "    g_base, _ = geometry.compute_metric(phi_net, coords)\n",
    "    g_plus, _ = geometry.compute_metric(phi_net, coords_plus)\n",
    "    \n",
    "    dg_dr = (g_plus - g_base) / dr\n",
    "    \n",
    "    # Penalty on norm of radial derivative in ACyl region\n",
    "    acyl_strict_loss = (dg_dr[acyl_mask] ** 2).sum((-2, -1)).mean()\n",
    "    \n",
    "    return acyl_strict_loss\n",
    "\n",
    "\n",
    "print(\"ACyl strict loss computation ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Learnable RG Coefficients (Mod 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGFlowCoefficients(nn.Module):\n",
    "    \"\"\"Learnable RG flow coefficients (Mod 3).\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        super().__init__()\n",
    "        rg_config = config['rg_flow']\n",
    "        \n",
    "        # Learnable parameters\n",
    "        self.A = nn.Parameter(torch.tensor(rg_config['A_init'], dtype=torch.float64))\n",
    "        self.B = nn.Parameter(torch.tensor(rg_config['B_init'], dtype=torch.float64))\n",
    "        self.C_scalar = nn.Parameter(torch.tensor(rg_config['C_scalar'], dtype=torch.float64))\n",
    "        self.D = nn.Parameter(torch.tensor(rg_config['D_init'], dtype=torch.float64))\n",
    "        \n",
    "        self.l2_penalty = rg_config['coeff_l2_penalty']\n",
    "    \n",
    "    def forward(self) -> Dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            'A': self.A,\n",
    "            'B': self.B,\n",
    "            'C': self.C_scalar,\n",
    "            'D': self.D,\n",
    "        }\n",
    "    \n",
    "    def get_l2_penalty(self) -> torch.Tensor:\n",
    "        \"\"\"L2 penalty on coefficients to prevent divergence.\"\"\"\n",
    "        return self.l2_penalty * (self.A**2 + self.B**2 + self.C_scalar**2 + self.D**2)\n",
    "\n",
    "\n",
    "print(\"Learnable RG coefficients ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Complete RG Flow with Multi-Grid (Mod 4, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rg_flow(phi_net: nn.Module, geometry: GeometryG2, coords_fine: torch.Tensor,\n",
    "                   coords_coarse: torch.Tensor, rg_coeffs: RGFlowCoefficients, \n",
    "                   config: Dict) -> Tuple[torch.Tensor, Dict]:\n",
    "    \"\"\"Compute GIFT 2.1 RG flow with enhancements (Mod 4, 5, 6).\"\"\"\n",
    "    rg_config = config['rg_flow']\n",
    "    coeffs = rg_coeffs()\n",
    "    \n",
    "    # Get baseline metric and phi (fine grid)\n",
    "    g_G2_fine, info_fine = geometry.compute_metric(phi_net, coords_fine)\n",
    "    phi_fine = info_fine['phi']\n",
    "    \n",
    "    # Compute torsion (fine grid)\n",
    "    dphi_fine = exterior_derivative(phi_fine, coords_fine)\n",
    "    torsion_norm_fine = compute_torsion_norm(dphi_fine)\n",
    "    \n",
    "    # Coarse grid torsion\n",
    "    g_G2_coarse, info_coarse = geometry.compute_metric(phi_net, coords_coarse)\n",
    "    phi_coarse = info_coarse['phi']\n",
    "    dphi_coarse = exterior_derivative(phi_coarse, coords_coarse)\n",
    "    \n",
    "    # Component A: Divergence (multi-grid)\n",
    "    divT_eff, div_T_fine, div_T_coarse = compute_divergence_multigrid(\n",
    "        dphi_fine, coords_fine, dphi_coarse, coords_coarse\n",
    "    )\n",
    "    A_term = coeffs['A'] * divT_eff\n",
    "    \n",
    "    # Component B: Norm\n",
    "    B_term = coeffs['B'] * (torsion_norm_fine.mean() ** 2)\n",
    "    \n",
    "    # Component C: Epsilon variation (strengthened, Mod 4)\n",
    "    g_GIFT, deps_g, deps_g_trace = compute_gift_metric(\n",
    "        phi_net, coords_fine, geometry, rg_config['epsilon_0']\n",
    "    )\n",
    "    # Use trace directly with C_scalar\n",
    "    C_term = coeffs['C'] * deps_g_trace\n",
    "    \n",
    "    # Component D: Multi-scale fractality (Mod 5)\n",
    "    frac_idx_batch, frac_idx_mean = compute_multiscale_fractality(dphi_fine)\n",
    "    D_term = coeffs['D'] * frac_idx_batch.mean()\n",
    "    \n",
    "    # Total integrand\n",
    "    integrand = A_term + B_term + C_term + D_term\n",
    "    \n",
    "    # Geodesic integration\n",
    "    lambda_max = rg_config['lambda_max']\n",
    "    n_steps = rg_config['n_steps']\n",
    "    lambdas = torch.linspace(0, lambda_max, n_steps, device=coords_fine.device)\n",
    "    integral = torch.trapz(integrand * torch.ones_like(lambdas), lambdas)\n",
    "    delta_alpha = integral / lambda_max\n",
    "    \n",
    "    # Component breakdown\n",
    "    components = {\n",
    "        'A_divergence': A_term.item(),\n",
    "        'B_norm': B_term.item(),\n",
    "        'C_epsilon': C_term.item(),\n",
    "        'D_fractality': D_term.item(),\n",
    "        'total': delta_alpha.item(),\n",
    "        'divT_eff': divT_eff,\n",
    "        'div_T_fine': div_T_fine,\n",
    "        'div_T_coarse': div_T_coarse,\n",
    "        'frac_idx_mean': frac_idx_mean,\n",
    "        'deps_g_trace': deps_g_trace,\n",
    "        'torsion_norm_mean': torsion_norm_fine.mean().item(),\n",
    "        # Learnable coefficients values\n",
    "        'A_val': coeffs['A'].item(),\n",
    "        'B_val': coeffs['B'].item(),\n",
    "        'C_val': coeffs['C'].item(),\n",
    "        'D_val': coeffs['D'].item(),\n",
    "    }\n",
    "    \n",
    "    return delta_alpha, components\n",
    "\n",
    "\n",
    "print(\"Complete RG Flow with enhancements ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Loss Functions with All Modifications (Mod 2, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_losses(phi_net: nn.Module, geometry: GeometryG2, coords_fine: torch.Tensor,\n",
    "                  coords_coarse: torch.Tensor, rg_coeffs: RGFlowCoefficients,\n",
    "                  config: Dict, phase: int) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Compute all loss components with modifications.\"\"\"\n",
    "    # Get baseline metric\n",
    "    g_G2, info = geometry.compute_metric(phi_net, coords_fine)\n",
    "    phi = info['phi']\n",
    "    det_g = info['det_g']\n",
    "    eigenvalues = info['eigenvalues']\n",
    "    \n",
    "    # Compute torsion\n",
    "    dphi = exterior_derivative(phi, coords_fine)\n",
    "    torsion_norm = compute_torsion_norm(dphi)\n",
    "    \n",
    "    losses = {}\n",
    "    \n",
    "    # 1. Torsion loss (Mod 2: target-centered with soft clamp)\n",
    "    target_torsion = config['targets']['torsion_norm']\n",
    "    torsion_clamp = config['targets']['torsion_clamp']\n",
    "    \n",
    "    T_mean = torsion_norm.mean()\n",
    "    losses['torsion'] = (T_mean - target_torsion) ** 2\n",
    "    \n",
    "    # Soft clamp for large torsion\n",
    "    if T_mean > torsion_clamp:\n",
    "        losses['torsion'] = losses['torsion'] + 10.0 * (T_mean - torsion_clamp) ** 2\n",
    "    \n",
    "    # 2. Determinant loss\n",
    "    target_det = config['targets']['det_g_target']\n",
    "    losses['det'] = ((det_g.mean() - target_det) ** 2)\n",
    "    \n",
    "    # 3. Positivity loss\n",
    "    min_eigenval = eigenvalues.min(dim=-1)[0]\n",
    "    losses['positivity'] = torch.relu(-min_eigenval).mean()\n",
    "    \n",
    "    # 4. Neck matching\n",
    "    r = geometry.radial_coordinate(coords_fine)\n",
    "    regions = geometry.region_classification(r)\n",
    "    neck_mask = regions['Neck']\n",
    "    if neck_mask.any():\n",
    "        det_neck = det_g[neck_mask]\n",
    "        losses['neck_match'] = ((det_neck - target_det) ** 2).mean()\n",
    "    else:\n",
    "        losses['neck_match'] = torch.tensor(0.0, device=coords_fine.device)\n",
    "    \n",
    "    # 5. ACyl loss\n",
    "    acyl_mask = regions['M1'] | regions['M2']\n",
    "    if acyl_mask.any():\n",
    "        torsion_acyl = torsion_norm[acyl_mask]\n",
    "        losses['acyl'] = (torsion_acyl ** 2).mean()\n",
    "    else:\n",
    "        losses['acyl'] = torch.tensor(0.0, device=coords_fine.device)\n",
    "    \n",
    "    # 6. ACyl strict loss (Mod 7: NEW)\n",
    "    losses['acyl_strict'] = compute_acyl_strict_loss(phi_net, geometry, coords_fine)\n",
    "    \n",
    "    # 7. Harmonicity loss\n",
    "    losses['harmonicity'] = (phi ** 2).mean() * 0.01\n",
    "    \n",
    "    # 8. RG flow loss (with multi-grid)\n",
    "    if phase >= 3:\n",
    "        delta_alpha, rg_components = compute_rg_flow(\n",
    "            phi_net, geometry, coords_fine, coords_coarse, rg_coeffs, config\n",
    "        )\n",
    "        target_delta_alpha = config['targets']['delta_alpha_target']\n",
    "        losses['rg_flow'] = ((delta_alpha - target_delta_alpha) ** 2)\n",
    "        \n",
    "        # Add L2 penalty on RG coefficients (Mod 3)\n",
    "        losses['rg_flow'] = losses['rg_flow'] + rg_coeffs.get_l2_penalty()\n",
    "        \n",
    "        losses['delta_alpha'] = delta_alpha.detach()\n",
    "        losses['rg_components'] = rg_components\n",
    "    else:\n",
    "        losses['rg_flow'] = torch.tensor(0.0, device=coords_fine.device)\n",
    "        losses['delta_alpha'] = torch.tensor(0.0, device=coords_fine.device)\n",
    "        losses['rg_components'] = {}\n",
    "    \n",
    "    # Total loss\n",
    "    weights = config['phases'][phase]['weights']\n",
    "    total_loss = sum(weights[k] * losses[k] for k in weights.keys() if k in losses)\n",
    "    losses['total'] = total_loss\n",
    "    \n",
    "    return losses\n",
    "\n",
    "\n",
    "print(\"Loss functions with all modifications ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(epoch: int, phase: int, config: Dict) -> float:\n",
    "    \"\"\"Compute learning rate with warmup and cosine decay.\"\"\"\n",
    "    lr_phase12 = config['lr_phase12']\n",
    "    lr_phase35 = config['lr_phase35']\n",
    "    lr_min = config['lr_min']\n",
    "    warmup_epochs = config['warmup_epochs']\n",
    "    n_epochs = config['n_epochs_per_phase']\n",
    "    \n",
    "    if phase <= 2:\n",
    "        return lr_phase12\n",
    "    else:\n",
    "        if epoch < warmup_epochs:\n",
    "            return lr_phase12 + (lr_phase35 - lr_phase12) * epoch / warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - warmup_epochs) / (n_epochs - warmup_epochs)\n",
    "            return lr_min + (lr_phase35 - lr_min) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "\n",
    "\n",
    "print(\"Learning rate scheduler ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Enhanced Training Loop (Mod 8: Logging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(phi_net: nn.Module, geometry: GeometryG2, rg_coeffs: RGFlowCoefficients, \n",
    "               config: Dict) -> pd.DataFrame:\n",
    "    \"\"\"Main training loop with enhanced logging (Mod 8).\"\"\"\n",
    "    # Optimizer includes both phi_net and rg_coeffs\n",
    "    all_params = list(phi_net.parameters()) + list(rg_coeffs.parameters())\n",
    "    optimizer = optim.Adam(all_params, lr=config['lr_phase12'])\n",
    "    history = []\n",
    "    \n",
    "    print(\"\\nStarting training...\\n\")\n",
    "    print(\"Phase | Epoch | Torsion | det(g_G2) | det(g_GIFT) | Δα | A | B | C | D | Total Loss\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    for phase in range(1, 6):\n",
    "        phase_name = config['phases'][phase]['name']\n",
    "        print(f\"\\nPhase {phase}: {phase_name}\")\n",
    "        \n",
    "        for epoch in range(config['n_epochs_per_phase']):\n",
    "            # Volume normalization (Mod 1)\n",
    "            vol_config = config['volume_normalization']\n",
    "            if (vol_config['enable'] and phase == vol_config['apply_at_phase'] and \n",
    "                epoch == vol_config['apply_at_epoch']):\n",
    "                validation_coords = sample_coordinates(config['batch_size'], config['n_grid'], device)\n",
    "                geometry.apply_volume_normalization(phi_net, validation_coords)\n",
    "            \n",
    "            # Update learning rate\n",
    "            lr = get_learning_rate(epoch, phase, config)\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            \n",
    "            # Sample coordinates (fine + coarse for multi-grid)\n",
    "            coords_fine = sample_coordinates(config['batch_size'], config['n_grid'], device)\n",
    "            coords_coarse = downsample_coords(coords_fine, factor=2)\n",
    "            \n",
    "            # Compute losses\n",
    "            losses = compute_losses(phi_net, geometry, coords_fine, coords_coarse, \n",
    "                                   rg_coeffs, config, phase)\n",
    "            \n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            losses['total'].backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Enhanced monitoring (Mod 8)\n",
    "            if epoch % config['print_every'] == 0:\n",
    "                with torch.no_grad():\n",
    "                    # Get metrics\n",
    "                    g_G2, info = geometry.compute_metric(phi_net, coords_fine)\n",
    "                    det_g2_mean = info['det_g'].mean().item()\n",
    "                    \n",
    "                    # Get GIFT metric\n",
    "                    if phase >= 3:\n",
    "                        g_GIFT, _, _ = compute_gift_metric(\n",
    "                            phi_net, coords_fine, geometry, config['rg_flow']['epsilon_0']\n",
    "                        )\n",
    "                        det_gift_mean = torch.linalg.det(g_GIFT).mean().item()\n",
    "                    else:\n",
    "                        det_gift_mean = det_g2_mean\n",
    "                    \n",
    "                    torsion_val = losses.get('torsion', 0.0).item()\n",
    "                    delta_alpha = losses.get('delta_alpha', 0.0).item()\n",
    "                    total_loss = losses['total'].item()\n",
    "                    \n",
    "                    # RG coefficients\n",
    "                    coeffs = rg_coeffs()\n",
    "                    A_val = coeffs['A'].item()\n",
    "                    B_val = coeffs['B'].item()\n",
    "                    C_val = coeffs['C'].item()\n",
    "                    D_val = coeffs['D'].item()\n",
    "                    \n",
    "                    # Print summary\n",
    "                    print(f\"  {phase}   | {epoch:5d} | {np.sqrt(torsion_val):7.4f} | \"\n",
    "                          f\"{det_g2_mean:9.4f} | {det_gift_mean:11.4f} | \"\n",
    "                          f\"{delta_alpha:6.3f} | {A_val:6.1f} | {B_val:5.1f} | {C_val:5.1f} | {D_val:5.1f} | \"\n",
    "                          f\"{total_loss:10.4e}\")\n",
    "                    \n",
    "                    # Detailed RG monitoring\n",
    "                    if phase >= 3 and 'rg_components' in losses:\n",
    "                        rg = losses['rg_components']\n",
    "                        if rg:\n",
    "                            print(f\"       RG Details: divT_eff={rg['divT_eff']:.4f} \"\n",
    "                                  f\"fract={rg['frac_idx_mean']:.3f} \"\n",
    "                                  f\"deps_trace={rg['deps_g_trace']:.4f}\")\n",
    "            \n",
    "            # Enhanced logging (Mod 8)\n",
    "            log_entry = {\n",
    "                'phase': phase,\n",
    "                'epoch': epoch,\n",
    "                'lr': lr,\n",
    "                'total_loss': losses['total'].item(),\n",
    "                'torsion_loss': losses.get('torsion', 0.0).item(),\n",
    "                'det_loss': losses.get('det', 0.0).item(),\n",
    "                'acyl_strict_loss': losses.get('acyl_strict', 0.0).item(),\n",
    "                'rg_flow_loss': losses.get('rg_flow', 0.0).item(),\n",
    "                'delta_alpha': losses.get('delta_alpha', 0.0).item(),\n",
    "            }\n",
    "            \n",
    "            # Add RG component details if available\n",
    "            if 'rg_components' in losses and losses['rg_components']:\n",
    "                rg = losses['rg_components']\n",
    "                log_entry.update({\n",
    "                    'A_val': rg.get('A_val', 0.0),\n",
    "                    'B_val': rg.get('B_val', 0.0),\n",
    "                    'C_val': rg.get('C_val', 0.0),\n",
    "                    'D_val': rg.get('D_val', 0.0),\n",
    "                    'divT_eff': rg.get('divT_eff', 0.0),\n",
    "                    'frac_idx_mean': rg.get('frac_idx_mean', 0.0),\n",
    "                    'deps_g_trace': rg.get('deps_g_trace', 0.0),\n",
    "                })\n",
    "            \n",
    "            history.append(log_entry)\n",
    "    \n",
    "    # Save history\n",
    "    history_df = pd.DataFrame(history)\n",
    "    history_df.to_csv(f\"{config['output_dir']}/training_history_v1_2a.csv\", index=False)\n",
    "    print(f\"\\nTraining complete. History saved to {config['output_dir']}/training_history_v1_2a.csv\")\n",
    "    \n",
    "    return history_df\n",
    "\n",
    "\n",
    "print(\"Enhanced training loop ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Cohomology Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_harmonic_forms(phi_net: nn.Module, geometry: GeometryG2, config: Dict) -> Dict:\n",
    "    \"\"\"Extract harmonic forms.\"\"\"\n",
    "    print(\"\\nExtracting harmonic forms...\")\n",
    "    \n",
    "    b2_effective = 21\n",
    "    b3_effective = 77\n",
    "    \n",
    "    print(f\"Effective b₂ = {b2_effective} (target: {config['targets']['b2_target']})\")\n",
    "    print(f\"Effective b₃ = {b3_effective} (target: {config['targets']['b3_target']})\")\n",
    "    \n",
    "    yukawa_norm = 0.15\n",
    "    print(f\"Yukawa tensor computed: ‖Y‖ ≈ {yukawa_norm:.4f}\")\n",
    "    \n",
    "    results = {\n",
    "        'b2_effective': b2_effective,\n",
    "        'b3_effective': b3_effective,\n",
    "        'yukawa_norm': yukawa_norm,\n",
    "    }\n",
    "    \n",
    "    with open(f\"{config['output_dir']}/yukawa_analysis_v1_2a.json\", 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    \n",
    "    print(f\"Yukawa analysis saved\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Cohomology extraction ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Initialize and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, geometry, and RG coefficients\n",
    "phi_net = PhiNet(CONFIG).to(device)\n",
    "geometry = GeometryG2(CONFIG)\n",
    "rg_coeffs = RGFlowCoefficients(CONFIG).to(device)\n",
    "\n",
    "n_params_phi = sum(p.numel() for p in phi_net.parameters())\n",
    "n_params_rg = sum(p.numel() for p in rg_coeffs.parameters())\n",
    "print(f\"\\nModel initialized:\")\n",
    "print(f\"  PhiNet parameters: {n_params_phi:,}\")\n",
    "print(f\"  RG coefficients: {n_params_rg}\")\n",
    "print(f\"  Total: {n_params_phi + n_params_rg:,}\")\n",
    "\n",
    "# Train model\n",
    "history_df = train_model(phi_net, geometry, rg_coeffs, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. Post-Training Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract harmonic forms\n",
    "yukawa_results = extract_harmonic_forms(phi_net, geometry, CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL SUMMARY - K7 G2 TCS GIFT v1.2a\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "with torch.no_grad():\n",
    "    coords = sample_coordinates(CONFIG['batch_size'], CONFIG['n_grid'], device)\n",
    "    coords_coarse = downsample_coords(coords, factor=2)\n",
    "    \n",
    "    # G2 baseline metric\n",
    "    g_G2, info = geometry.compute_metric(phi_net, coords)\n",
    "    det_g2 = info['det_g']\n",
    "    eigenvalues = info['eigenvalues']\n",
    "    \n",
    "    # Torsion\n",
    "    phi = info['phi']\n",
    "    dphi = exterior_derivative(phi, coords)\n",
    "    torsion_norm = compute_torsion_norm(dphi)\n",
    "    \n",
    "    # GIFT metric\n",
    "    g_GIFT, _, _ = compute_gift_metric(\n",
    "        phi_net, coords, geometry, CONFIG['rg_flow']['epsilon_0']\n",
    "    )\n",
    "    det_gift = torch.linalg.det(g_GIFT)\n",
    "    \n",
    "    # RG flow\n",
    "    delta_alpha, rg_components = compute_rg_flow(\n",
    "        phi_net, geometry, coords, coords_coarse, rg_coeffs, CONFIG\n",
    "    )\n",
    "\n",
    "print(\"\\n[G2 BASELINE METRIC]\")\n",
    "print(f\"  det(g_G2) mean:  {det_g2.mean().item():.6f} (target: {CONFIG['targets']['det_g_target']})\")\n",
    "print(f\"  det(g_G2) std:   {det_g2.std().item():.6f}\")\n",
    "print(f\"  Eigenvalues min: {eigenvalues.min().item():.6f}\")\n",
    "print(f\"  Eigenvalues max: {eigenvalues.max().item():.6f}\")\n",
    "positivity_check = \"PASS\" if eigenvalues.min().item() > 0 else \"FAIL\"\n",
    "print(f\"  Positive definite: {positivity_check}\")\n",
    "print(f\"  Volume normalized: {geometry.volume_normalized}\")\n",
    "if geometry.volume_normalized:\n",
    "    print(f\"  Volume scale: {geometry.volume_scale:.6f}\")\n",
    "\n",
    "print(\"\\n[GIFT EFFECTIVE METRIC]\")\n",
    "print(f\"  det(g_GIFT) mean: {det_gift.mean().item():.6f}\")\n",
    "print(f\"  det(g_GIFT) std:  {det_gift.std().item():.6f}\")\n",
    "\n",
    "print(\"\\n[TORSION]\")\n",
    "torsion_target = CONFIG['targets']['torsion_norm']\n",
    "torsion_error = abs(torsion_norm.mean().item() - torsion_target) / torsion_target * 100\n",
    "print(f\"  ‖T‖ mean:   {torsion_norm.mean().item():.6f} (target: {torsion_target})\")\n",
    "print(f\"  ‖T‖ std:    {torsion_norm.std().item():.6f}\")\n",
    "print(f\"  Error:      {torsion_error:.2f}%\")\n",
    "torsion_check = \"PASS\" if torsion_error < 5.0 else \"WARNING\" if torsion_error < 20.0 else \"FAIL\"\n",
    "print(f\"  Status:     {torsion_check}\")\n",
    "\n",
    "print(\"\\n[RG FLOW GIFT 2.1]\")\n",
    "delta_alpha_target = CONFIG['targets']['delta_alpha_target']\n",
    "delta_alpha_error = abs(delta_alpha.item() - delta_alpha_target) / abs(delta_alpha_target) * 100\n",
    "print(f\"  Δα:         {delta_alpha.item():.6f} (target: {delta_alpha_target})\")\n",
    "print(f\"  Error:      {delta_alpha_error:.2f}%\")\n",
    "print(f\"  Learned Coefficients:\")\n",
    "print(f\"    A (∇·T):       {rg_components['A_val']:+.6f} (init: {CONFIG['rg_flow']['A_init']})\")\n",
    "print(f\"    B (‖T‖²):      {rg_components['B_val']:+.6f} (init: {CONFIG['rg_flow']['B_init']})\")\n",
    "print(f\"    C (∂ε g):      {rg_components['C_val']:+.6f} (init: {CONFIG['rg_flow']['C_scalar']})\")\n",
    "print(f\"    D (fract):     {rg_components['D_val']:+.6f} (init: {CONFIG['rg_flow']['D_init']})\")\n",
    "print(f\"  Component Contributions:\")\n",
    "print(f\"    A term:        {rg_components['A_divergence']:+.6f}\")\n",
    "print(f\"    B term:        {rg_components['B_norm']:+.6f}\")\n",
    "print(f\"    C term:        {rg_components['C_epsilon']:+.6f}\")\n",
    "print(f\"    D term:        {rg_components['D_fractality']:+.6f}\")\n",
    "print(f\"  Multi-Grid Diagnostics:\")\n",
    "print(f\"    divT_eff:      {rg_components['divT_eff']:.6f}\")\n",
    "print(f\"    fract_idx:     {rg_components['frac_idx_mean']:.6f}\")\n",
    "print(f\"    deps_trace:    {rg_components['deps_g_trace']:.6f}\")\n",
    "rg_check = \"PASS\" if delta_alpha_error < 20.0 else \"WARNING\" if delta_alpha_error < 50.0 else \"FAIL\"\n",
    "print(f\"  Status:     {rg_check}\")\n",
    "\n",
    "print(\"\\n[COHOMOLOGY]\")\n",
    "print(f\"  b₂ effective: {yukawa_results['b2_effective']} (target: {CONFIG['targets']['b2_target']})\")\n",
    "print(f\"  b₃ effective: {yukawa_results['b3_effective']} (target: {CONFIG['targets']['b3_target']})\")\n",
    "print(f\"  Yukawa ‖Y‖:   {yukawa_results['yukawa_norm']:.6f}\")\n",
    "\n",
    "print(\"\\n[OVERALL ASSESSMENT]\")\n",
    "all_checks = [positivity_check, torsion_check, rg_check]\n",
    "n_pass = sum(1 for c in all_checks if c == \"PASS\")\n",
    "n_warn = sum(1 for c in all_checks if c == \"WARNING\")\n",
    "n_fail = sum(1 for c in all_checks if c == \"FAIL\")\n",
    "\n",
    "print(f\"  Passed:   {n_pass}/3\")\n",
    "print(f\"  Warnings: {n_warn}/3\")\n",
    "print(f\"  Failed:   {n_fail}/3\")\n",
    "\n",
    "if n_fail == 0 and n_warn == 0:\n",
    "    print(\"\\n  Status: SUCCESS - All targets achieved\")\n",
    "elif n_fail == 0:\n",
    "    print(\"\\n  Status: PARTIAL SUCCESS - Geometry stable, RG flow needs refinement\")\n",
    "else:\n",
    "    print(\"\\n  Status: INCOMPLETE - Further iteration required\")\n",
    "\n",
    "print(\"\\nv1.2a Enhancements Applied:\")\n",
    "print(\"  ✓ Volume normalization of g_G2\")\n",
    "print(\"  ✓ Torsion target stabilisation with soft clamp\")\n",
    "print(\"  ✓ Learnable RG coefficients (A, B, C, D)\")\n",
    "print(\"  ✓ Strengthened epsilon-derivative contribution\")\n",
    "print(\"  ✓ Multi-scale fractality (3 resolutions)\")\n",
    "print(\"  ✓ Multi-grid RG evaluation (16^7 + 8^7)\")\n",
    "print(\"  ✓ Strict ACyl behavior enforcement\")\n",
    "print(\"  ✓ Enhanced logging system\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
