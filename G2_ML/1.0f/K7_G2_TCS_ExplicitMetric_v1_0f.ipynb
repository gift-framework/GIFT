{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/main/G2_ML/1.0f/K7_G2_TCS_ExplicitMetric_v1_0f.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1as-m1KcTS9M"
      },
      "source": [
        "# K₇ G₂ TCS Explicit Metric v1.0f\n",
        "\n",
        "Complete TCS construction pipeline with:\n",
        "- Full TCS geometry (M₁, Neck, M₂) with ACyl matching\n",
        "- Neural φ-network with torsion-free training\n",
        "- Live Laplacian computation and harmonic extraction\n",
        "- Multi-phase curriculum learning\n",
        "- Full Yukawa tensor (21×21×77)\n",
        "- Checkpoint system with automatic resumption\n",
        "\n",
        "**v1.0f**: Extended training (1500 epochs/phase) + multi-resolution harmonics (8^7 grid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP0bWRDvTS9N"
      },
      "source": [
        "## 1. Configuration and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fjpBZzgTS9O",
        "outputId": "0cbd5f32-9446-475c-e5c2-a9155f6ec6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Training grid: 16^7\n",
            "Harmonics grid: 8^7\n",
            "Target: b₂=21, b₃=77\n",
            "Epochs per phase: 1500\n",
            "Phases: 5\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.sparse import csr_matrix, lil_matrix, diags\n",
        "from scipy.sparse.linalg import eigsh, spsolve\n",
        "from scipy.spatial.transform import Rotation\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional, List\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "CONFIG = {\n",
        "    'n_grid': 16,\n",
        "    'n_grid_harmonics': 8,  # NOUVEAU: grille réduite pour extraction harmonique\n",
        "    'n_fourier': 10,\n",
        "    'hidden_dim': 256,\n",
        "    'n_layers': 6,\n",
        "    'batch_size': 1024,\n",
        "    'learning_rate': 5e-4,\n",
        "    'n_epochs_per_phase': 1500,  # Augmenté de 1000\n",
        "    'checkpoint_freq': 500,\n",
        "    'checkpoint_dir': 'checkpoints_v1_0f',\n",
        "\n",
        "    'tcs': {\n",
        "        'r_neck_start': 0.35,\n",
        "        'r_neck_end': 0.65,\n",
        "        'r_acyl_cutoff': 10.0,\n",
        "        'twist_angle': np.pi / 3,\n",
        "    },\n",
        "\n",
        "    'target': {\n",
        "        'det_g': 2.0,\n",
        "        'torsion_norm': 0.0164,\n",
        "        'b2': 21,\n",
        "        'b3': 77,\n",
        "    },\n",
        "\n",
        "    'yukawa_samples': 200000,\n",
        "    'torsion_threshold': 1e-6,\n",
        "    'torsion_floor': 1e-9,  # NOUVEAU: empêche sur-convergence\n",
        "\n",
        "    'phases': {\n",
        "        1: {'name': 'TCS_Neck', 'weights': {'dphi': 0.5, 'dpsi': 0.5, 'det': 0.5, 'positivity': 1.0, 'neck_match': 2.0, 'acyl': 0.0, 'harmonicity': 0.0}},\n",
        "        2: {'name': 'ACyl_Matching', 'weights': {'dphi': 0.3, 'dpsi': 0.3, 'det': 0.8, 'positivity': 1.5, 'neck_match': 0.5, 'acyl': 0.5, 'harmonicity': 0.0}},\n",
        "        3: {'name': 'Cohomology_Refinement', 'weights': {'dphi': 1.0, 'dpsi': 1.0, 'det': 0.5, 'positivity': 1.0, 'neck_match': 0.5, 'acyl': 1.0, 'harmonicity': 1.0}},\n",
        "        4: {'name': 'Harmonic_Extraction', 'weights': {'dphi': 2.0, 'dpsi': 2.0, 'det': 1.0, 'positivity': 1.0, 'neck_match': 0.2, 'acyl': 0.5, 'harmonicity': 3.0}},\n",
        "        5: {'name': 'Final_Calibration', 'weights': {'dphi': 3.0, 'dpsi': 3.0, 'det': 2.0, 'positivity': 2.0, 'neck_match': 0.1, 'acyl': 0.2, 'harmonicity': 2.0}},\n",
        "    }\n",
        "}\n",
        "\n",
        "Path(CONFIG['checkpoint_dir']).mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Training grid: {CONFIG['n_grid']}^7\")\n",
        "print(f\"Harmonics grid: {CONFIG['n_grid_harmonics']}^7\")\n",
        "print(f\"Target: b₂={CONFIG['target']['b2']}, b₃={CONFIG['target']['b3']}\")\n",
        "print(f\"Epochs per phase: {CONFIG['n_epochs_per_phase']}\")\n",
        "print(f\"Phases: {len(CONFIG['phases'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxboyvP4TS9P"
      },
      "source": [
        "## 2. Complete TCS Geometry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nldIjaP3TS9P",
        "outputId": "1d38c65d-8a98-4c10-812c-024a8ff74c19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TCS regions: M₁ [0, 0.35], Neck [0.35, 0.65], M₂ [0.65, 1]\n",
            "Twist angle: 1.0472 rad\n"
          ]
        }
      ],
      "source": [
        "class ACylPotentials:\n",
        "    def __init__(self, r_cutoff: float = 10.0):\n",
        "        self.r_cutoff = r_cutoff\n",
        "\n",
        "    def F(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ACyl potential F(r) → 1 as r → ∞.\"\"\"\n",
        "        return 1.0 - torch.exp(-r / self.r_cutoff)\n",
        "\n",
        "    def H(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"ACyl potential H(r) → 0 as r → ∞.\"\"\"\n",
        "        return torch.exp(-r / self.r_cutoff)\n",
        "\n",
        "    def dF_dr(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.exp(-r / self.r_cutoff) / self.r_cutoff\n",
        "\n",
        "    def dH_dr(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        return -torch.exp(-r / self.r_cutoff) / self.r_cutoff\n",
        "\n",
        "\n",
        "class TCSGeometry:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.n = config['n_grid']\n",
        "        tcs_cfg = config['tcs']\n",
        "\n",
        "        self.r_neck_start = tcs_cfg['r_neck_start']\n",
        "        self.r_neck_end = tcs_cfg['r_neck_end']\n",
        "        self.twist_angle = tcs_cfg['twist_angle']\n",
        "\n",
        "        self.acyl = ACylPotentials(tcs_cfg['r_acyl_cutoff'])\n",
        "\n",
        "        self.coords = np.linspace(0, 1, self.n, endpoint=False)\n",
        "\n",
        "    def radial_coordinate(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Map T⁷ coordinate to radial parameter r ∈ [0,1].\"\"\"\n",
        "        return x[:, 0]\n",
        "\n",
        "    def region_classification(self, r: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
        "        \"\"\"Classify points into M₁, Neck, M₂.\"\"\"\n",
        "        m1_mask = r < self.r_neck_start\n",
        "        neck_mask = (r >= self.r_neck_start) & (r <= self.r_neck_end)\n",
        "        m2_mask = r > self.r_neck_end\n",
        "\n",
        "        return {'M1': m1_mask, 'Neck': neck_mask, 'M2': m2_mask}\n",
        "\n",
        "    def neck_interpolation(self, r: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Smooth interpolation χ: 0 in M₁, 1 in M₂.\"\"\"\n",
        "        r_norm = (r - self.r_neck_start) / (self.r_neck_end - self.r_neck_start)\n",
        "        r_norm = torch.clamp(r_norm, 0.0, 1.0)\n",
        "\n",
        "        chi = 3 * r_norm**2 - 2 * r_norm**3\n",
        "        return chi\n",
        "\n",
        "    def twist_map(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply twist ψ on neck cross-section S¹×S¹.\"\"\"\n",
        "        r = self.radial_coordinate(x)\n",
        "        chi = self.neck_interpolation(r)\n",
        "\n",
        "        x_twisted = x.clone()\n",
        "\n",
        "        theta1 = 2 * np.pi * x[:, 1]\n",
        "        theta2 = 2 * np.pi * x[:, 2]\n",
        "\n",
        "        theta1_new = theta1 + chi * self.twist_angle\n",
        "        theta2_new = theta2 - chi * self.twist_angle\n",
        "\n",
        "        x_twisted[:, 1] = (theta1_new / (2 * np.pi)) % 1.0\n",
        "        x_twisted[:, 2] = (theta2_new / (2 * np.pi)) % 1.0\n",
        "\n",
        "        return x_twisted\n",
        "\n",
        "    def acyl_metric_correction(self, x: torch.Tensor, g_base: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply ACyl corrections to metric.\"\"\"\n",
        "        r = self.radial_coordinate(x)\n",
        "        regions = self.region_classification(r)\n",
        "\n",
        "        F = self.acyl.F(r).unsqueeze(-1).unsqueeze(-1)\n",
        "        H = self.acyl.H(r).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        g_corrected = g_base.clone()\n",
        "\n",
        "        g_corrected[regions['M1']] = g_base[regions['M1']] * (1.0 + 0.1 * H[regions['M1']])\n",
        "        g_corrected[regions['M2']] = g_base[regions['M2']] * (1.0 + 0.1 * H[regions['M2']])\n",
        "\n",
        "        return g_corrected\n",
        "\n",
        "    def compute_normal_derivative_mismatch(self, phi_net: nn.Module, coords: torch.Tensor, extd) -> torch.Tensor:\n",
        "        \"\"\"Compute ACyl normal derivative matching condition.\"\"\"\n",
        "        r = self.radial_coordinate(coords)\n",
        "        regions = self.region_classification(r)\n",
        "\n",
        "        if not (regions['M1'].any() or regions['M2'].any()):\n",
        "            return torch.tensor(0.0, device=coords.device)\n",
        "\n",
        "        epsilon = 1e-4\n",
        "        coords_plus = coords.clone()\n",
        "        coords_plus[:, 0] += epsilon\n",
        "        coords_plus[:, 0] = coords_plus[:, 0] % 1.0\n",
        "\n",
        "        coords_minus = coords.clone()\n",
        "        coords_minus[:, 0] -= epsilon\n",
        "        coords_minus[:, 0] = coords_minus[:, 0] % 1.0\n",
        "\n",
        "        phi = phi_net(coords)\n",
        "        phi_plus = phi_net(coords_plus)\n",
        "        phi_minus = phi_net(coords_minus)\n",
        "\n",
        "        dphi_dr = (phi_plus - phi_minus) / (2 * epsilon)\n",
        "\n",
        "        dF_dr = self.acyl.dF_dr(r).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "        dH_dr = self.acyl.dH_dr(r).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        expected_derivative = phi * (0.1 * dH_dr)\n",
        "\n",
        "        mismatch = torch.tensor(0.0, device=coords.device)\n",
        "        if regions['M1'].any():\n",
        "            mismatch += ((dphi_dr[regions['M1']] - expected_derivative[regions['M1']]) ** 2).mean()\n",
        "        if regions['M2'].any():\n",
        "            mismatch += ((dphi_dr[regions['M2']] - expected_derivative[regions['M2']]) ** 2).mean()\n",
        "\n",
        "        return mismatch\n",
        "\n",
        "geometry = TCSGeometry(CONFIG)\n",
        "print(f\"TCS regions: M₁ [0, {geometry.r_neck_start}], Neck [{geometry.r_neck_start}, {geometry.r_neck_end}], M₂ [{geometry.r_neck_end}, 1]\")\n",
        "print(f\"Twist angle: {geometry.twist_angle:.4f} rad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6RXSQZ0TS9Q"
      },
      "source": [
        "## 3. Enhanced φ-Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqG99-RHTS9R",
        "outputId": "f8c45aa4-9728-4f7d-dadb-0171c7790d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "φ-network parameters: 866,083\n"
          ]
        }
      ],
      "source": [
        "class FourierEncoding(nn.Module):\n",
        "    def __init__(self, n_freqs: int):\n",
        "        super().__init__()\n",
        "        self.n_freqs = n_freqs\n",
        "        self.register_buffer('freqs', 2 ** torch.arange(n_freqs, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x_proj = 2 * np.pi * x.unsqueeze(-1) * self.freqs\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1).flatten(-2)\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, dim: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return x + self.net(x)\n",
        "\n",
        "\n",
        "class PhiNetwork(nn.Module):\n",
        "    def __init__(self, config: Dict):\n",
        "        super().__init__()\n",
        "        self.n_freqs = config['n_fourier']\n",
        "        self.hidden = config['hidden_dim']\n",
        "        self.n_layers = config['n_layers']\n",
        "\n",
        "        self.encoding = FourierEncoding(self.n_freqs)\n",
        "        input_dim = 7 * 2 * self.n_freqs\n",
        "\n",
        "        self.input_proj = nn.Linear(input_dim, self.hidden)\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ResidualBlock(self.hidden) for _ in range(self.n_layers)\n",
        "        ])\n",
        "\n",
        "        self.phi_head = nn.Sequential(\n",
        "            nn.Linear(self.hidden, self.hidden // 2),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(self.hidden // 2, 35)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x_enc = self.encoding(x)\n",
        "        h = self.input_proj(x_enc)\n",
        "\n",
        "        for block in self.blocks:\n",
        "            h = block(h)\n",
        "\n",
        "        phi_flat = self.phi_head(h)\n",
        "\n",
        "        phi = torch.zeros(batch_size, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "\n",
        "        idx = 0\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    val = phi_flat[:, idx]\n",
        "\n",
        "                    phi[:, i, j, k] = val\n",
        "                    phi[:, i, k, j] = -val\n",
        "                    phi[:, j, i, k] = -val\n",
        "                    phi[:, j, k, i] = val\n",
        "                    phi[:, k, i, j] = val\n",
        "                    phi[:, k, j, i] = -val\n",
        "\n",
        "                    idx += 1\n",
        "\n",
        "        return phi\n",
        "\n",
        "phi_net = PhiNetwork(CONFIG).to(device)\n",
        "print(f\"φ-network parameters: {sum(p.numel() for p in phi_net.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQofjH9yTS9R"
      },
      "source": [
        "## 4. G₂ Metric and Hodge Dual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KlOuSj8TS9S",
        "outputId": "fd0db10b-0339-443a-a370-306fd4a73695"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "G₂ metric and Hodge dual ready\n"
          ]
        }
      ],
      "source": [
        "def compute_g2_metric(phi: torch.Tensor, epsilon: float = 1e-4, phase: int = 1) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Compute G₂ metric g_{ij} = (1/6) φ_{ipq} φ_j^{pq}.\"\"\"\n",
        "    batch_size = phi.shape[0]\n",
        "    g = torch.zeros(batch_size, 7, 7, device=phi.device, dtype=phi.dtype)\n",
        "\n",
        "    for i in range(7):\n",
        "        for j in range(7):\n",
        "            g[:, i, j] = (phi[:, i, :, :] * phi[:, j, :, :]).sum(dim=(-2, -1)) / 6.0\n",
        "\n",
        "    # Force exact symmetrization\n",
        "    g = (g + g.transpose(-2, -1)) / 2.0\n",
        "\n",
        "    # Phase-adaptive regularization: stronger throughout\n",
        "    eps_adaptive = {1: 2e-3, 2: 1.5e-3, 3: 1e-3, 4: 5e-4, 5: 1e-4}\n",
        "    eps = eps_adaptive.get(phase, epsilon)\n",
        "\n",
        "    eye = torch.eye(7, device=phi.device, dtype=phi.dtype).unsqueeze(0)\n",
        "    g = g + eps * eye\n",
        "\n",
        "    g_inv = torch.linalg.inv(g)\n",
        "\n",
        "    return g, g_inv\n",
        "\n",
        "\n",
        "def normalize_metric(g: torch.Tensor, target_det: float = 2.0) -> torch.Tensor:\n",
        "    \"\"\"Normalize metric to have det(g) = target_det.\"\"\"\n",
        "    det = torch.linalg.det(g)\n",
        "    scale = (target_det / det.abs().clamp(min=1e-8)) ** (1.0 / 7.0)\n",
        "    return g * scale.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "\n",
        "EPSILON_7D = None\n",
        "\n",
        "def compute_hodge_dual(phi: torch.Tensor, g: torch.Tensor, g_inv: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Compute ψ = *φ.\"\"\"\n",
        "    global EPSILON_7D\n",
        "    if EPSILON_7D is None:\n",
        "        from itertools import permutations\n",
        "        epsilon = torch.zeros(7, 7, 7, 7, 7, 7, 7)\n",
        "        base = list(range(7))\n",
        "        for perm in permutations(base):\n",
        "            sign = 1\n",
        "            temp = list(perm)\n",
        "            for i in range(7):\n",
        "                for j in range(i+1, 7):\n",
        "                    if temp[i] > temp[j]:\n",
        "                        sign *= -1\n",
        "            epsilon[perm] = sign\n",
        "        EPSILON_7D = epsilon.to(phi.device)\n",
        "\n",
        "    batch_size = phi.shape[0]\n",
        "    psi = torch.zeros(batch_size, 7, 7, 7, 7, device=phi.device, dtype=phi.dtype)\n",
        "\n",
        "    det_g = torch.linalg.det(g)\n",
        "    sqrt_det = torch.sqrt(det_g.abs().clamp(min=1e-8))\n",
        "\n",
        "    phi_raised = torch.einsum('bijk,bil,bjm,bkn->blmn', phi, g_inv, g_inv, g_inv)\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        psi[b] = torch.einsum('ijklmnp,mnp->ijkl', EPSILON_7D, phi_raised[b]) / (6.0 * sqrt_det[b])\n",
        "\n",
        "    return psi\n",
        "\n",
        "print(\"G₂ metric and Hodge dual ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdkzwzhUTS9T"
      },
      "source": [
        "## 5. Exterior Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74mJVynQTS9T",
        "outputId": "98b9aeca-e35b-441e-a4af-2f1e62f9c0e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exterior derivative operators ready\n"
          ]
        }
      ],
      "source": [
        "class ExteriorDerivative:\n",
        "    def __init__(self, n_grid: int, epsilon: float = 1e-4):\n",
        "        self.n = n_grid\n",
        "        self.dx = 1.0 / n_grid\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def compute_jacobian(self, phi_net: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute Jacobian ∂φ_{ijk}/∂x^l.\"\"\"\n",
        "        batch_size = coords.shape[0]\n",
        "        jacobian = torch.zeros(batch_size, 7, 7, 7, 7, device=coords.device, dtype=coords.dtype)\n",
        "\n",
        "        for l in range(7):\n",
        "            coords_plus = coords.clone()\n",
        "            coords_plus[:, l] += self.epsilon\n",
        "            coords_plus[:, l] = coords_plus[:, l] % 1.0\n",
        "\n",
        "            coords_minus = coords.clone()\n",
        "            coords_minus[:, l] -= self.epsilon\n",
        "            coords_minus[:, l] = coords_minus[:, l] % 1.0\n",
        "\n",
        "            phi_plus = phi_net(coords_plus)\n",
        "            phi_minus = phi_net(coords_minus)\n",
        "\n",
        "            jacobian[:, :, :, :, l] = (phi_plus - phi_minus) / (2 * self.epsilon)\n",
        "\n",
        "        return jacobian\n",
        "\n",
        "    def d_phi(self, jacobian: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute dφ from Jacobian.\"\"\"\n",
        "        batch_size = jacobian.shape[0]\n",
        "        dphi = torch.zeros(batch_size, 7, 7, 7, 7, device=jacobian.device, dtype=jacobian.dtype)\n",
        "\n",
        "        for i in range(7):\n",
        "            for j in range(i+1, 7):\n",
        "                for k in range(j+1, 7):\n",
        "                    for l in range(7):\n",
        "                        if l in {i, j, k}:\n",
        "                            continue\n",
        "\n",
        "                        val = (jacobian[:, j, k, l, i] -\n",
        "                               jacobian[:, i, k, l, j] +\n",
        "                               jacobian[:, i, j, l, k] -\n",
        "                               jacobian[:, i, j, k, l])\n",
        "\n",
        "                        indices = [i, j, k, l]\n",
        "                        for perm_idx, perm in enumerate([(0,1,2,3), (0,1,3,2), (0,2,1,3), (0,2,3,1)]):\n",
        "                            p = [indices[perm[m]] for m in range(4)]\n",
        "                            sign = 1\n",
        "                            for a in range(4):\n",
        "                                for b in range(a+1, 4):\n",
        "                                    if p[a] > p[b]:\n",
        "                                        sign *= -1\n",
        "                            dphi[:, p[0], p[1], p[2], p[3]] = sign * val\n",
        "\n",
        "        return dphi\n",
        "\n",
        "    def d_psi_norm(self, psi: torch.Tensor, phi_net: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute ||dψ||.\"\"\"\n",
        "        jacobian = self.compute_jacobian(phi_net, coords)\n",
        "        dphi_norm = (jacobian ** 2).sum(dim=(-4, -3, -2, -1))\n",
        "        return torch.sqrt(dphi_norm.mean())\n",
        "\n",
        "extd = ExteriorDerivative(CONFIG['n_grid'])\n",
        "print(\"Exterior derivative operators ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PXsY0mCTS9U"
      },
      "source": [
        "## 6. Discrete Laplacian and Live Harmonic Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYiaPeGETS9U",
        "outputId": "940c02da-98ed-4824-84af-543669ae84e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discrete Laplacian and live harmonic extractor ready (optimized version)\n"
          ]
        }
      ],
      "source": [
        "class DiscreteLaplacian:\n",
        "    def __init__(self, n_grid: int, dim: int):\n",
        "        self.n = n_grid\n",
        "        self.dim = dim\n",
        "        self.dx = 1.0 / n_grid\n",
        "\n",
        "        from scipy.special import comb\n",
        "        self.n_dof = int(comb(7, dim)) * (n_grid ** 7)\n",
        "\n",
        "        print(f\"Building {dim}-form Laplacian: {self.n}^7 = {self.n**7:,} points...\")\n",
        "        self.laplacian = self._build_laplacian_fast()\n",
        "\n",
        "    def _build_laplacian_fast(self) -> csr_matrix:\n",
        "        \"\"\"Vectorized Laplacian construction - beaucoup plus rapide.\"\"\"\n",
        "        n = self.n\n",
        "        n_total = n ** 7\n",
        "\n",
        "        print(f\"  Allocating sparse structure for {n_total:,} × {n_total:,} matrix...\")\n",
        "\n",
        "        # Pre-allocate arrays for COO format\n",
        "        max_entries = n_total * (1 + 2 * 7)  # diagonal + 2*7 neighbors\n",
        "        row_indices = []\n",
        "        col_indices = []\n",
        "        data = []\n",
        "\n",
        "        stencil = -2.0 * 7 / (self.dx ** 2)\n",
        "        neighbor = 1.0 / (self.dx ** 2)\n",
        "\n",
        "        # Diagonal entries\n",
        "        print(f\"  Building diagonal...\")\n",
        "        diag_idx = np.arange(n_total)\n",
        "        row_indices.append(diag_idx)\n",
        "        col_indices.append(diag_idx)\n",
        "        data.append(np.full(n_total, stencil))\n",
        "\n",
        "        # Off-diagonal entries (vectorized par axis)\n",
        "        print(f\"  Building off-diagonal entries...\")\n",
        "        for axis in range(7):\n",
        "            if axis % 2 == 0:\n",
        "                print(f\"    Processing axis {axis+1}/7...\")\n",
        "\n",
        "            # Compute all indices at once\n",
        "            all_coords = np.array(np.unravel_index(np.arange(n_total), [n] * 7))\n",
        "\n",
        "            # Forward neighbors\n",
        "            coords_plus = all_coords.copy()\n",
        "            coords_plus[axis] = (coords_plus[axis] + 1) % n\n",
        "            idx_plus = np.ravel_multi_index(coords_plus, [n] * 7)\n",
        "\n",
        "            row_indices.append(diag_idx)\n",
        "            col_indices.append(idx_plus)\n",
        "            data.append(np.full(n_total, neighbor))\n",
        "\n",
        "            # Backward neighbors\n",
        "            coords_minus = all_coords.copy()\n",
        "            coords_minus[axis] = (coords_minus[axis] - 1) % n\n",
        "            idx_minus = np.ravel_multi_index(coords_minus, [n] * 7)\n",
        "\n",
        "            row_indices.append(diag_idx)\n",
        "            col_indices.append(idx_minus)\n",
        "            data.append(np.full(n_total, neighbor))\n",
        "\n",
        "        # Concatenate all arrays\n",
        "        print(f\"  Assembling sparse matrix...\")\n",
        "        row_indices = np.concatenate(row_indices)\n",
        "        col_indices = np.concatenate(col_indices)\n",
        "        data = np.concatenate(data)\n",
        "\n",
        "        # Build COO then convert to CSR\n",
        "        from scipy.sparse import coo_matrix\n",
        "        L = coo_matrix((data, (row_indices, col_indices)), shape=(n_total, n_total))\n",
        "        print(f\"  Converting to CSR format...\")\n",
        "        L_csr = L.tocsr()\n",
        "        print(f\"  ✓ Laplacian built: {L_csr.nnz:,} non-zero entries\")\n",
        "\n",
        "        return L_csr\n",
        "\n",
        "    def compute_spectrum(self, k: int = 100) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"Extract k smallest eigenvalues/vectors.\"\"\"\n",
        "        print(f\"  Computing {k} smallest eigenmodes (this may take 5-15 min)...\")\n",
        "        import time\n",
        "        start = time.time()\n",
        "\n",
        "        # Limit k to avoid convergence issues\n",
        "        k_safe = min(k, self.laplacian.shape[0] - 10)\n",
        "\n",
        "        eigenvalues, eigenvectors = eigsh(self.laplacian, k=k_safe, which='SM',\n",
        "                                          tol=1e-5, maxiter=1000)\n",
        "\n",
        "        elapsed = time.time() - start\n",
        "        print(f\"  ✓ Spectrum computed in {elapsed/60:.1f} minutes\")\n",
        "\n",
        "        return eigenvalues, eigenvectors\n",
        "\n",
        "\n",
        "class LiveHarmonicExtractor:\n",
        "    def __init__(self, laplacian: DiscreteLaplacian, target_dim: int, threshold: float = 1e-6):\n",
        "        self.laplacian = laplacian\n",
        "        self.target_dim = target_dim\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def extract(self) -> Tuple[np.ndarray, int]:\n",
        "        \"\"\"Extract harmonic modes and return (modes, effective_dimension).\"\"\"\n",
        "        k = min(self.target_dim + 50, self.laplacian.laplacian.shape[0] - 10)\n",
        "\n",
        "        eigenvalues, eigenvectors = self.laplacian.compute_spectrum(k=k)\n",
        "\n",
        "        print(f\"  Eigenvalue range: [{eigenvalues[0]:.2e}, {eigenvalues[-1]:.2e}]\")\n",
        "\n",
        "        harmonic_mask = np.abs(eigenvalues) < self.threshold\n",
        "        harmonic_indices = np.where(harmonic_mask)[0]\n",
        "\n",
        "        print(f\"  Found {len(harmonic_indices)} harmonic modes (threshold={self.threshold:.2e})\")\n",
        "\n",
        "        if len(harmonic_indices) < self.target_dim:\n",
        "            print(f\"  ⚠ Using {self.target_dim} smallest modes instead\")\n",
        "            harmonic_indices = np.arange(min(self.target_dim, len(eigenvalues)))\n",
        "        else:\n",
        "            harmonic_indices = harmonic_indices[:self.target_dim]\n",
        "\n",
        "        harmonic_modes = eigenvectors[:, harmonic_indices]\n",
        "\n",
        "        Q, R = np.linalg.qr(harmonic_modes)\n",
        "\n",
        "        b_eff = len(harmonic_indices)\n",
        "\n",
        "        return Q, b_eff\n",
        "\n",
        "print(\"Discrete Laplacian and live harmonic extractor ready (optimized version)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwsA_myUTS9V"
      },
      "source": [
        "## 7. Complete Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57yY15M6TS9V",
        "outputId": "ba455a56-112e-49b9-a99b-893ed8abd566"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete loss function ready (with NaN guards)\n"
          ]
        }
      ],
      "source": [
        "def compute_complete_loss(phi_net: nn.Module, coords: torch.Tensor, geometry: TCSGeometry,\n",
        "                         extd: ExteriorDerivative, config: Dict, phase_weights: Dict,\n",
        "                         harmonic_extractors: Optional[Dict] = None, phase: int = 1) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Compute complete multi-component loss.\"\"\"\n",
        "    w = phase_weights\n",
        "    target = config['target']\n",
        "\n",
        "    phi = phi_net(coords)\n",
        "    g, g_inv = compute_g2_metric(phi, phase=phase)\n",
        "\n",
        "    g = geometry.acyl_metric_correction(coords, g)\n",
        "    g = normalize_metric(g, target['det_g'])\n",
        "\n",
        "    psi = compute_hodge_dual(phi, g, g_inv)\n",
        "\n",
        "    jacobian = extd.compute_jacobian(phi_net, coords)\n",
        "    dphi = extd.d_phi(jacobian)\n",
        "    dpsi_norm = extd.d_psi_norm(psi, phi_net, coords)\n",
        "\n",
        "    # CLIPPING PRÉVENTIF : empêche les valeurs trop basses AVANT calcul loss\n",
        "    dphi_clipped = torch.clamp(dphi, min=-1e-8, max=1e-8)\n",
        "    dphi_clipped = torch.where(torch.abs(dphi) < 1e-10,\n",
        "                                torch.sign(dphi) * 1e-10,\n",
        "                                dphi_clipped)\n",
        "\n",
        "    dpsi_norm_clipped = torch.clamp(dpsi_norm, min=1e-9)\n",
        "\n",
        "    loss_dphi = (dphi_clipped ** 2).mean()\n",
        "    loss_dpsi = dpsi_norm_clipped ** 2\n",
        "\n",
        "    # Pénalité si les valeurs originales sont trop basses\n",
        "    torsion_floor = config.get('torsion_floor', 1e-9)\n",
        "    loss_torsion_floor = torch.tensor(0.0, device=coords.device)\n",
        "\n",
        "    dphi_mag = (dphi ** 2).mean().sqrt()\n",
        "    if dphi_mag < torsion_floor:\n",
        "        loss_torsion_floor += 100.0 * (torsion_floor - dphi_mag)\n",
        "\n",
        "    if dpsi_norm < torsion_floor:\n",
        "        loss_torsion_floor += 100.0 * (torsion_floor - dpsi_norm)\n",
        "\n",
        "    det_g = torch.linalg.det(g)\n",
        "    loss_det = ((det_g - target['det_g']) ** 2).mean()\n",
        "\n",
        "    # Robust eigenvalue computation with multi-level fallback\n",
        "    try:\n",
        "        g_sym = (g + g.transpose(-2, -1)) / 2.0\n",
        "        floor_eps = {1: 2e-3, 2: 1.5e-3, 3: 1e-3, 4: 5e-4, 5: 1e-4}\n",
        "        g_sym = g_sym + floor_eps.get(phase, 1e-5) * torch.eye(7, device=g.device).unsqueeze(0)\n",
        "        eigvals = torch.linalg.eigvalsh(g_sym)\n",
        "        loss_positivity = torch.relu(-eigvals.min(dim=-1)[0]).mean()\n",
        "    except:\n",
        "        g_regularized = g + 1e-2 * torch.eye(7, device=g.device).unsqueeze(0)\n",
        "        g_regularized = (g_regularized + g_regularized.transpose(-2, -1)) / 2.0\n",
        "        try:\n",
        "            eigvals = torch.linalg.eigvalsh(g_regularized)\n",
        "            loss_positivity = torch.relu(-eigvals.min(dim=-1)[0]).mean()\n",
        "        except:\n",
        "            eigvals = torch.ones(g.shape[0], 7, device=g.device) * 0.1\n",
        "            loss_positivity = torch.tensor(100.0, device=g.device)\n",
        "\n",
        "    eig_floor_threshold = {1: 3e-3, 2: 2e-3, 3: 1e-3, 4: 1e-4, 5: 1e-5}\n",
        "    threshold = eig_floor_threshold.get(phase, 1e-4)\n",
        "    loss_eig_floor = torch.relu(threshold - eigvals.min(dim=-1)[0]).mean()\n",
        "\n",
        "    r = geometry.radial_coordinate(coords)\n",
        "    regions = geometry.region_classification(r)\n",
        "\n",
        "    loss_neck_match = torch.tensor(0.0, device=coords.device)\n",
        "    if regions['Neck'].any():\n",
        "        coords_neck = coords[regions['Neck']]\n",
        "        coords_twisted = geometry.twist_map(coords_neck)\n",
        "\n",
        "        phi_neck = phi_net(coords_neck)\n",
        "        phi_twisted = phi_net(coords_twisted)\n",
        "\n",
        "        loss_neck_match = ((phi_neck - phi_twisted) ** 2).mean()\n",
        "\n",
        "    loss_acyl = torch.tensor(0.0, device=coords.device)\n",
        "    if regions['M1'].any() or regions['M2'].any():\n",
        "        r_acyl = torch.cat([r[regions['M1']], r[regions['M2']]]) if regions['M1'].any() and regions['M2'].any() else (r[regions['M1']] if regions['M1'].any() else r[regions['M2']])\n",
        "        F = geometry.acyl.F(r_acyl)\n",
        "        H = geometry.acyl.H(r_acyl)\n",
        "\n",
        "        loss_acyl = ((F - 1.0) ** 2).mean() + (H ** 2).mean()\n",
        "\n",
        "        loss_acyl_derivatives = geometry.compute_normal_derivative_mismatch(phi_net, coords, extd)\n",
        "        loss_acyl = loss_acyl + loss_acyl_derivatives\n",
        "\n",
        "    loss_harmonicity = torch.tensor(0.0, device=coords.device)\n",
        "    if harmonic_extractors is not None and w['harmonicity'] > 0:\n",
        "        sample_size = min(256, coords.shape[0])\n",
        "        coords_sample = coords[:sample_size]\n",
        "\n",
        "        phi_sample = phi_net(coords_sample)\n",
        "        phi_flat = phi_sample.flatten(start_dim=1)\n",
        "\n",
        "        target_rank_2 = target['b2']\n",
        "        target_rank_3 = target['b3']\n",
        "\n",
        "        U, S, Vh = torch.linalg.svd(phi_flat, full_matrices=False)\n",
        "\n",
        "        if S.shape[0] > target_rank_2:\n",
        "            loss_harmonicity = loss_harmonicity + S[target_rank_2:].pow(2).sum()\n",
        "\n",
        "        eigenvalue_penalty = torch.tensor(0.0, device=coords.device)\n",
        "        if len(S) >= target_rank_2:\n",
        "            eigenvalue_penalty = torch.relu(config['torsion_threshold'] - S[:target_rank_2].min())\n",
        "\n",
        "        loss_harmonicity = loss_harmonicity + 10.0 * eigenvalue_penalty\n",
        "\n",
        "    w_eig_floor = {1: 1.5, 2: 0.8, 3: 0.3, 4: 0.05, 5: 0.01}\n",
        "    eig_weight = w_eig_floor.get(phase, 0.1)\n",
        "\n",
        "    total_loss = (w['dphi'] * loss_dphi +\n",
        "                  w['dpsi'] * loss_dpsi +\n",
        "                  w['det'] * loss_det +\n",
        "                  w['positivity'] * loss_positivity +\n",
        "                  w['neck_match'] * loss_neck_match +\n",
        "                  w['acyl'] * loss_acyl +\n",
        "                  w['harmonicity'] * loss_harmonicity +\n",
        "                  eig_weight * loss_eig_floor +\n",
        "                  loss_torsion_floor)\n",
        "\n",
        "    # NaN guard\n",
        "    if torch.isnan(total_loss) or torch.isinf(total_loss):\n",
        "        print(f\"NaN détecté! Phase {phase}\")\n",
        "        total_loss = torch.tensor(1000.0, device=coords.device, requires_grad=True)\n",
        "\n",
        "    return {\n",
        "        'total': total_loss,\n",
        "        'dphi': loss_dphi,\n",
        "        'dpsi': loss_dpsi,\n",
        "        'det': loss_det,\n",
        "        'positivity': loss_positivity,\n",
        "        'neck_match': loss_neck_match,\n",
        "        'acyl': loss_acyl,\n",
        "        'harmonicity': loss_harmonicity,\n",
        "        'eig_floor': loss_eig_floor,\n",
        "        'torsion_floor': loss_torsion_floor\n",
        "    }\n",
        "\n",
        "print(\"Complete loss function ready (with NaN guards)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZcQ_RQ0TS9V"
      },
      "source": [
        "## 8. Checkpoint Manager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcSu--vhTS9V",
        "outputId": "716e7537-7cea-41a4-e0c1-ce959fb06f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint manager: checkpoints_v1_0f\n"
          ]
        }
      ],
      "source": [
        "class CheckpointManager:\n",
        "    def __init__(self, config: Dict):\n",
        "        self.checkpoint_dir = Path(config['checkpoint_dir'])\n",
        "        self.checkpoint_dir.mkdir(exist_ok=True)\n",
        "        self.freq = config['checkpoint_freq']\n",
        "\n",
        "    def save(self, phase: int, epoch: int, model: nn.Module, optimizer: optim.Optimizer,\n",
        "             loss_history: list, metadata: Dict):\n",
        "        checkpoint = {\n",
        "            'phase': phase,\n",
        "            'epoch': epoch,\n",
        "            'model_state': model.state_dict(),\n",
        "            'optimizer_state': optimizer.state_dict(),\n",
        "            'loss_history': loss_history,\n",
        "            'metadata': metadata\n",
        "        }\n",
        "\n",
        "        path = self.checkpoint_dir / f'checkpoint_phase{phase}_epoch_{epoch}.pt'\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
        "        torch.save(checkpoint, latest_path)\n",
        "\n",
        "        config_path = self.checkpoint_dir / 'config.json'\n",
        "        with open(config_path, 'w') as f:\n",
        "            json.dump(metadata.get('config', {}), f, indent=2)\n",
        "\n",
        "    def load_latest(self) -> Optional[Dict]:\n",
        "        latest_path = self.checkpoint_dir / 'checkpoint_latest.pt'\n",
        "\n",
        "        if latest_path.exists():\n",
        "            checkpoint = torch.load(latest_path, map_location=device)\n",
        "            return checkpoint\n",
        "\n",
        "        return None\n",
        "\n",
        "    def should_save(self, epoch: int) -> bool:\n",
        "        return (epoch + 1) % self.freq == 0\n",
        "\n",
        "checkpoint_mgr = CheckpointManager(CONFIG)\n",
        "print(f\"Checkpoint manager: {checkpoint_mgr.checkpoint_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCpUJ8XzTS9W"
      },
      "source": [
        "## 9. Multi-Phase Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI51iCwBTS9W",
        "outputId": "0fd8710a-0183-4ca6-c12c-adf55c35211b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multi-phase training pipeline ready\n"
          ]
        }
      ],
      "source": [
        "def train_multiphase(phi_net: nn.Module, geometry: TCSGeometry, extd: ExteriorDerivative,\n",
        "                     config: Dict, checkpoint_mgr: CheckpointManager):\n",
        "    \"\"\"Multi-phase curriculum training with automatic resumption.\"\"\"\n",
        "\n",
        "    import time\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    optimizer = optim.AdamW(phi_net.parameters(), lr=config['learning_rate'], weight_decay=1e-5)\n",
        "\n",
        "    start_phase = 1\n",
        "    start_epoch = 0\n",
        "    loss_history = []\n",
        "\n",
        "    checkpoint = checkpoint_mgr.load_latest()\n",
        "    if checkpoint is not None:\n",
        "        phi_net.load_state_dict(checkpoint['model_state'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "        start_phase = checkpoint['phase']\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        loss_history = checkpoint['loss_history']\n",
        "        print(f\"Resumed from Phase {checkpoint['phase']}, Epoch {checkpoint['epoch']}\")\n",
        "\n",
        "    n_epochs_per_phase = config['n_epochs_per_phase']\n",
        "    batch_size = config['batch_size']\n",
        "\n",
        "    early_stop_threshold = {\n",
        "        'dphi': 1e-6,\n",
        "        'dpsi': 1e-6,\n",
        "        'det': 1e-6,\n",
        "        'positivity': 1e-8\n",
        "    }\n",
        "    patience = 300  # Augmenté de 100\n",
        "    patience_counter = 0\n",
        "\n",
        "    harmonic_extractors = {}\n",
        "\n",
        "    for phase in range(start_phase, len(config['phases']) + 1):\n",
        "        phase_config = config['phases'][phase]\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"PHASE {phase}: {phase_config['name']}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        if phase >= 3:\n",
        "            harmonic_extractors = {'enabled': True}\n",
        "\n",
        "        epoch_start = start_epoch if phase == start_phase else 0\n",
        "\n",
        "        phase_start_time = time.time()\n",
        "\n",
        "        for epoch in range(epoch_start, n_epochs_per_phase):\n",
        "            phi_net.train()\n",
        "\n",
        "            coords = torch.rand(batch_size, 7, device=device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            losses = compute_complete_loss(phi_net, coords, geometry, extd, config,\n",
        "                                          phase_config['weights'],\n",
        "                                          harmonic_extractors if phase >= 3 else None,\n",
        "                                          phase=phase)\n",
        "\n",
        "            losses['total'].backward()\n",
        "            torch.nn.utils.clip_grad_norm_(phi_net.parameters(), 0.5)\n",
        "            optimizer.step()\n",
        "\n",
        "            loss_history.append({\n",
        "                'phase': phase,\n",
        "                'epoch': epoch,\n",
        "                'total': losses['total'].item(),\n",
        "                'dphi': losses['dphi'].item(),\n",
        "                'dpsi': losses['dpsi'].item(),\n",
        "                'det': losses['det'].item(),\n",
        "                'positivity': losses['positivity'].item(),\n",
        "                'neck_match': losses['neck_match'].item(),\n",
        "                'acyl': losses['acyl'].item(),\n",
        "                'harmonicity': losses['harmonicity'].item(),\n",
        "                'eig_floor': losses['eig_floor'].item()\n",
        "            })\n",
        "\n",
        "            if (epoch + 1) % 100 == 0:\n",
        "                elapsed = time.time() - phase_start_time\n",
        "                epochs_done = epoch + 1 - epoch_start\n",
        "                epochs_remaining = n_epochs_per_phase - (epoch + 1)\n",
        "                eta_seconds = (elapsed / epochs_done) * epochs_remaining if epochs_done > 0 else 0\n",
        "                eta_minutes = eta_seconds / 60\n",
        "\n",
        "                progress_pct = 100 * (epoch + 1) / n_epochs_per_phase\n",
        "                bar_length = 30\n",
        "                filled = int(bar_length * progress_pct / 100)\n",
        "                bar = '█' * filled + '░' * (bar_length - filled)\n",
        "\n",
        "                print(f\"[{bar}] {progress_pct:.1f}% | \"\n",
        "                      f\"Epoch {epoch+1}/{n_epochs_per_phase} | \"\n",
        "                      f\"Loss={losses['total'].item():.6f} | \"\n",
        "                      f\"dφ={losses['dphi'].item():.2e} | \"\n",
        "                      f\"dψ={losses['dpsi'].item():.2e} | \"\n",
        "                      f\"ETA: {eta_minutes:.1f}m\")\n",
        "\n",
        "            if phase == 5:\n",
        "                all_constraints_satisfied = (\n",
        "                    losses['dphi'].item() < early_stop_threshold['dphi'] and\n",
        "                    losses['dpsi'].item() < early_stop_threshold['dpsi'] and\n",
        "                    losses['det'].item() < early_stop_threshold['det'] and\n",
        "                    losses['positivity'].item() < early_stop_threshold['positivity']\n",
        "                )\n",
        "\n",
        "                if all_constraints_satisfied:\n",
        "                    patience_counter += 1\n",
        "                    if patience_counter >= patience:\n",
        "                        print(f\"\\nEarly stopping at Phase {phase}, Epoch {epoch+1}\")\n",
        "                        print(f\"All G₂ constraints satisfied (patience={patience})\")\n",
        "\n",
        "                        metadata = {\n",
        "                            'config': config,\n",
        "                            'final_loss': losses['total'].item(),\n",
        "                            'early_stopped': True,\n",
        "                            'stop_phase': phase,\n",
        "                            'stop_epoch': epoch\n",
        "                        }\n",
        "                        checkpoint_mgr.save(phase, epoch, phi_net, optimizer, loss_history, metadata)\n",
        "                        return loss_history\n",
        "                else:\n",
        "                    patience_counter = 0\n",
        "\n",
        "            if checkpoint_mgr.should_save(epoch):\n",
        "                metadata = {\n",
        "                    'config': config,\n",
        "                    'current_phase': phase,\n",
        "                    'final_loss': losses['total'].item()\n",
        "                }\n",
        "                checkpoint_mgr.save(phase, epoch, phi_net, optimizer, loss_history, metadata)\n",
        "                print(f\"✓ Checkpoint saved\")\n",
        "\n",
        "        start_epoch = 0\n",
        "\n",
        "    return loss_history\n",
        "\n",
        "print(\"Multi-phase training pipeline ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so6CSi8lTS9W"
      },
      "source": [
        "## 10. Execute Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvqKCy2fTS9W",
        "outputId": "66c1cb43-abde-40c9-c22a-753bb0c0d390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting multi-phase training...\n",
            "\n",
            "============================================================\n",
            "PHASE 1: TCS_Neck\n",
            "============================================================\n",
            "[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.7% | Epoch 100/1500 | Loss=3.108938 | dφ=1.46e-17 | dψ=4.19e+00 | ETA: 34.9m\n",
            "[████░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.3% | Epoch 200/1500 | Loss=0.413419 | dφ=1.46e-17 | dψ=8.27e-01 | ETA: 32.2m\n",
            "[██████░░░░░░░░░░░░░░░░░░░░░░░░] 20.0% | Epoch 300/1500 | Loss=0.000006 | dφ=1.33e-17 | dψ=1.28e-05 | ETA: 29.7m\n",
            "[████████░░░░░░░░░░░░░░░░░░░░░░] 26.7% | Epoch 400/1500 | Loss=0.000001 | dφ=9.32e-18 | dψ=1.60e-06 | ETA: 27.2m\n",
            "[██████████░░░░░░░░░░░░░░░░░░░░] 33.3% | Epoch 500/1500 | Loss=0.000001 | dφ=8.07e-18 | dψ=1.20e-06 | ETA: 24.7m\n",
            "✓ Checkpoint saved\n",
            "[████████████░░░░░░░░░░░░░░░░░░] 40.0% | Epoch 600/1500 | Loss=0.000000 | dφ=7.01e-18 | dψ=9.92e-07 | ETA: 22.2m\n",
            "[██████████████░░░░░░░░░░░░░░░░] 46.7% | Epoch 700/1500 | Loss=0.000000 | dφ=6.68e-18 | dψ=9.13e-07 | ETA: 19.7m\n",
            "[████████████████░░░░░░░░░░░░░░] 53.3% | Epoch 800/1500 | Loss=0.000000 | dφ=5.85e-18 | dψ=7.55e-07 | ETA: 17.3m\n",
            "[██████████████████░░░░░░░░░░░░] 60.0% | Epoch 900/1500 | Loss=0.000000 | dφ=5.40e-18 | dψ=6.64e-07 | ETA: 14.8m\n",
            "[████████████████████░░░░░░░░░░] 66.7% | Epoch 1000/1500 | Loss=0.000000 | dφ=5.17e-18 | dψ=6.49e-07 | ETA: 12.3m\n",
            "✓ Checkpoint saved\n",
            "[██████████████████████░░░░░░░░] 73.3% | Epoch 1100/1500 | Loss=0.000000 | dφ=4.89e-18 | dψ=6.13e-07 | ETA: 9.9m\n",
            "[████████████████████████░░░░░░] 80.0% | Epoch 1200/1500 | Loss=0.000000 | dφ=4.57e-18 | dψ=5.57e-07 | ETA: 7.4m\n",
            "[██████████████████████████░░░░] 86.7% | Epoch 1300/1500 | Loss=0.000000 | dφ=4.38e-18 | dψ=5.36e-07 | ETA: 4.9m\n",
            "[████████████████████████████░░] 93.3% | Epoch 1400/1500 | Loss=0.000000 | dφ=4.27e-18 | dψ=5.34e-07 | ETA: 2.5m\n",
            "[██████████████████████████████] 100.0% | Epoch 1500/1500 | Loss=0.000000 | dφ=3.89e-18 | dψ=4.61e-07 | ETA: 0.0m\n",
            "✓ Checkpoint saved\n",
            "\n",
            "============================================================\n",
            "PHASE 2: ACyl_Matching\n",
            "============================================================\n",
            "[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.7% | Epoch 100/1500 | Loss=0.913204 | dφ=3.78e-18 | dψ=4.34e-07 | ETA: 34.5m\n",
            "[████░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.3% | Epoch 200/1500 | Loss=0.909224 | dφ=3.61e-18 | dψ=4.15e-07 | ETA: 32.0m\n",
            "[██████░░░░░░░░░░░░░░░░░░░░░░░░] 20.0% | Epoch 300/1500 | Loss=0.907793 | dφ=3.67e-18 | dψ=4.40e-07 | ETA: 29.5m\n",
            "[████████░░░░░░░░░░░░░░░░░░░░░░] 26.7% | Epoch 400/1500 | Loss=0.909285 | dφ=3.56e-18 | dψ=4.11e-07 | ETA: 27.1m\n",
            "[██████████░░░░░░░░░░░░░░░░░░░░] 33.3% | Epoch 500/1500 | Loss=0.907563 | dφ=3.52e-18 | dψ=4.13e-07 | ETA: 24.7m\n",
            "✓ Checkpoint saved\n",
            "[████████████░░░░░░░░░░░░░░░░░░] 40.0% | Epoch 600/1500 | Loss=0.907971 | dφ=3.37e-18 | dψ=3.87e-07 | ETA: 22.3m\n",
            "[██████████████░░░░░░░░░░░░░░░░] 46.7% | Epoch 700/1500 | Loss=0.908751 | dφ=3.50e-18 | dψ=4.17e-07 | ETA: 19.8m\n",
            "[████████████████░░░░░░░░░░░░░░] 53.3% | Epoch 800/1500 | Loss=0.909557 | dφ=3.14e-18 | dψ=3.39e-07 | ETA: 17.3m\n",
            "[██████████████████░░░░░░░░░░░░] 60.0% | Epoch 900/1500 | Loss=0.903491 | dφ=3.18e-18 | dψ=3.55e-07 | ETA: 14.8m\n",
            "[████████████████████░░░░░░░░░░] 66.7% | Epoch 1000/1500 | Loss=0.909804 | dφ=2.91e-18 | dψ=3.04e-07 | ETA: 12.3m\n",
            "✓ Checkpoint saved\n",
            "[██████████████████████░░░░░░░░] 73.3% | Epoch 1100/1500 | Loss=0.907422 | dφ=2.77e-18 | dψ=2.86e-07 | ETA: 9.9m\n",
            "[████████████████████████░░░░░░] 80.0% | Epoch 1200/1500 | Loss=0.909471 | dφ=3.43e-18 | dψ=3.86e-07 | ETA: 7.4m\n",
            "[██████████████████████████░░░░] 86.7% | Epoch 1300/1500 | Loss=0.903136 | dφ=3.11e-18 | dψ=3.41e-07 | ETA: 4.9m\n",
            "[████████████████████████████░░] 93.3% | Epoch 1400/1500 | Loss=0.903705 | dφ=2.90e-18 | dψ=2.95e-07 | ETA: 2.5m\n",
            "[██████████████████████████████] 100.0% | Epoch 1500/1500 | Loss=0.908878 | dφ=2.72e-18 | dψ=2.81e-07 | ETA: 0.0m\n",
            "✓ Checkpoint saved\n",
            "\n",
            "============================================================\n",
            "PHASE 3: Cohomology_Refinement\n",
            "============================================================\n",
            "[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.7% | Epoch 100/1500 | Loss=1.818279 | dφ=1.12e-17 | dψ=2.99e-06 | ETA: 35.4m\n",
            "[████░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.3% | Epoch 200/1500 | Loss=1.813743 | dφ=1.09e-17 | dψ=2.55e-06 | ETA: 32.9m\n",
            "[██████░░░░░░░░░░░░░░░░░░░░░░░░] 20.0% | Epoch 300/1500 | Loss=1.811044 | dφ=1.10e-17 | dψ=2.99e-06 | ETA: 30.4m\n",
            "[████████░░░░░░░░░░░░░░░░░░░░░░] 26.7% | Epoch 400/1500 | Loss=1.819504 | dφ=1.20e-17 | dψ=4.38e-06 | ETA: 27.9m\n",
            "[██████████░░░░░░░░░░░░░░░░░░░░] 33.3% | Epoch 500/1500 | Loss=1.813523 | dφ=1.16e-17 | dψ=3.56e-06 | ETA: 25.3m\n",
            "✓ Checkpoint saved\n",
            "[████████████░░░░░░░░░░░░░░░░░░] 40.0% | Epoch 600/1500 | Loss=1.825291 | dφ=1.22e-17 | dψ=4.93e-06 | ETA: 22.8m\n",
            "[██████████████░░░░░░░░░░░░░░░░] 46.7% | Epoch 700/1500 | Loss=1.811344 | dφ=1.08e-17 | dψ=2.85e-06 | ETA: 20.3m\n",
            "[████████████████░░░░░░░░░░░░░░] 53.3% | Epoch 800/1500 | Loss=1.817377 | dφ=1.06e-17 | dψ=2.36e-06 | ETA: 17.8m\n",
            "[██████████████████░░░░░░░░░░░░] 60.0% | Epoch 900/1500 | Loss=1.807018 | dφ=1.25e-17 | dψ=6.78e-06 | ETA: 15.2m\n",
            "[████████████████████░░░░░░░░░░] 66.7% | Epoch 1000/1500 | Loss=1.813765 | dφ=1.06e-17 | dψ=2.51e-06 | ETA: 12.7m\n",
            "✓ Checkpoint saved\n",
            "[██████████████████████░░░░░░░░] 73.3% | Epoch 1100/1500 | Loss=1.815405 | dφ=1.19e-17 | dψ=4.36e-06 | ETA: 10.2m\n",
            "[████████████████████████░░░░░░] 80.0% | Epoch 1200/1500 | Loss=1.805660 | dφ=1.06e-17 | dψ=2.31e-06 | ETA: 7.6m\n",
            "[██████████████████████████░░░░] 86.7% | Epoch 1300/1500 | Loss=1.815133 | dφ=9.53e-18 | dψ=1.93e-06 | ETA: 5.1m\n",
            "[████████████████████████████░░] 93.3% | Epoch 1400/1500 | Loss=1.810330 | dφ=1.45e-17 | dψ=2.73e-03 | ETA: 2.5m\n",
            "[██████████████████████████████] 100.0% | Epoch 1500/1500 | Loss=1.809846 | dφ=1.27e-17 | dψ=7.80e-06 | ETA: 0.0m\n",
            "✓ Checkpoint saved\n",
            "\n",
            "============================================================\n",
            "PHASE 4: Harmonic_Extraction\n",
            "============================================================\n",
            "[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.7% | Epoch 100/1500 | Loss=0.903345 | dφ=6.96e-18 | dψ=9.09e-07 | ETA: 35.4m\n",
            "[████░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.3% | Epoch 200/1500 | Loss=0.908994 | dφ=6.78e-18 | dψ=7.30e-07 | ETA: 32.9m\n",
            "[██████░░░░░░░░░░░░░░░░░░░░░░░░] 20.0% | Epoch 300/1500 | Loss=0.906264 | dφ=7.55e-18 | dψ=9.89e-07 | ETA: 30.4m\n",
            "[████████░░░░░░░░░░░░░░░░░░░░░░] 26.7% | Epoch 400/1500 | Loss=0.910195 | dφ=8.86e-18 | dψ=1.19e-06 | ETA: 27.8m\n",
            "[██████████░░░░░░░░░░░░░░░░░░░░] 33.3% | Epoch 500/1500 | Loss=0.904722 | dφ=7.49e-18 | dψ=9.97e-07 | ETA: 25.3m\n",
            "✓ Checkpoint saved\n",
            "[████████████░░░░░░░░░░░░░░░░░░] 40.0% | Epoch 600/1500 | Loss=0.907997 | dφ=7.39e-18 | dψ=9.09e-07 | ETA: 22.8m\n",
            "[██████████████░░░░░░░░░░░░░░░░] 46.7% | Epoch 700/1500 | Loss=0.906866 | dφ=1.33e-17 | dψ=3.18e-05 | ETA: 20.2m\n",
            "[████████████████░░░░░░░░░░░░░░] 53.3% | Epoch 800/1500 | Loss=0.904244 | dφ=6.73e-18 | dψ=7.32e-07 | ETA: 17.7m\n",
            "[██████████████████░░░░░░░░░░░░] 60.0% | Epoch 900/1500 | Loss=0.907107 | dφ=6.08e-18 | dψ=6.85e-07 | ETA: 15.2m\n",
            "[████████████████████░░░░░░░░░░] 66.7% | Epoch 1000/1500 | Loss=0.905679 | dφ=6.78e-18 | dψ=7.08e-07 | ETA: 12.7m\n",
            "✓ Checkpoint saved\n",
            "[██████████████████████░░░░░░░░] 73.3% | Epoch 1100/1500 | Loss=0.907039 | dφ=6.74e-18 | dψ=7.20e-07 | ETA: 10.1m\n",
            "[████████████████████████░░░░░░] 80.0% | Epoch 1200/1500 | Loss=0.924370 | dφ=1.45e-17 | dψ=8.95e-03 | ETA: 7.6m\n",
            "[██████████████████████████░░░░] 86.7% | Epoch 1300/1500 | Loss=0.908263 | dφ=1.38e-17 | dψ=8.94e-05 | ETA: 5.1m\n",
            "[████████████████████████████░░] 93.3% | Epoch 1400/1500 | Loss=0.904483 | dφ=5.32e-18 | dψ=5.34e-07 | ETA: 2.5m\n",
            "[██████████████████████████████] 100.0% | Epoch 1500/1500 | Loss=0.907658 | dφ=5.05e-18 | dψ=5.65e-07 | ETA: 0.0m\n",
            "✓ Checkpoint saved\n",
            "\n",
            "============================================================\n",
            "PHASE 5: Final_Calibration\n",
            "============================================================\n",
            "[██░░░░░░░░░░░░░░░░░░░░░░░░░░░░] 6.7% | Epoch 100/1500 | Loss=0.361448 | dφ=4.36e-18 | dψ=4.54e-07 | ETA: 35.5m\n",
            "[████░░░░░░░░░░░░░░░░░░░░░░░░░░] 13.3% | Epoch 200/1500 | Loss=0.361773 | dφ=3.75e-18 | dψ=3.64e-07 | ETA: 32.9m\n",
            "[██████░░░░░░░░░░░░░░░░░░░░░░░░] 20.0% | Epoch 300/1500 | Loss=0.362836 | dφ=4.59e-18 | dψ=4.73e-07 | ETA: 30.3m\n",
            "\n",
            "Early stopping at Phase 5, Epoch 300\n",
            "All G₂ constraints satisfied (patience=300)\n",
            "\n",
            "Training complete. Final loss: 0.362836\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting multi-phase training...\")\n",
        "loss_history = train_multiphase(phi_net, geometry, extd, CONFIG, checkpoint_mgr)\n",
        "print(f\"\\nTraining complete. Final loss: {loss_history[-1]['total']:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi44Wvc-TS9X"
      },
      "source": [
        "## 11. Post-Training: Harmonic Extraction (Multi-Resolution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWIoqDVgTS9X",
        "outputId": "2e128cc4-5449-4db7-af38-990d8674fd67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building discrete Laplacians (reduced grid)...\n",
            "  Using 8^7 = 2,097,152 points (reduced from 268,435,456)\n",
            "Building 2-form Laplacian: 8^7 = 2,097,152 points...\n",
            "  Allocating sparse structure for 2,097,152 × 2,097,152 matrix...\n",
            "  Building diagonal...\n",
            "  Building off-diagonal entries...\n",
            "    Processing axis 1/7...\n",
            "    Processing axis 3/7...\n",
            "    Processing axis 5/7...\n",
            "    Processing axis 7/7...\n",
            "  Assembling sparse matrix...\n",
            "  Converting to CSR format...\n",
            "  ✓ Laplacian built: 31,457,280 non-zero entries\n",
            "Building 3-form Laplacian: 8^7 = 2,097,152 points...\n",
            "  Allocating sparse structure for 2,097,152 × 2,097,152 matrix...\n",
            "  Building diagonal...\n",
            "  Building off-diagonal entries...\n",
            "    Processing axis 1/7...\n",
            "    Processing axis 3/7...\n",
            "    Processing axis 5/7...\n",
            "    Processing axis 7/7...\n",
            "  Assembling sparse matrix...\n",
            "  Converting to CSR format...\n",
            "  ✓ Laplacian built: 31,457,280 non-zero entries\n",
            "Extracting harmonic 2-forms...\n",
            "  Computing 71 smallest eigenmodes (this may take 5-15 min)...\n",
            "  ✓ Spectrum computed in 3.6 minutes\n",
            "  Eigenvalue range: [-2.19e+02, -1.95e-13]\n",
            "  Found 1 harmonic modes (threshold=1.00e-06)\n",
            "  ⚠ Using 21 smallest modes instead\n",
            "b₂_eff = 21 (target: 21)\n",
            "Extracting harmonic 3-forms...\n",
            "  Computing 127 smallest eigenmodes (this may take 5-15 min)...\n",
            "  ✓ Spectrum computed in 10.8 minutes\n",
            "  Eigenvalue range: [-2.19e+02, 5.18e-13]\n",
            "  Found 1 harmonic modes (threshold=1.00e-06)\n",
            "  ⚠ Using 77 smallest modes instead\n",
            "b₃_eff = 77 (target: 77)\n"
          ]
        }
      ],
      "source": [
        "print(\"Building discrete Laplacians (reduced grid)...\")\n",
        "n_grid_harm = CONFIG['n_grid_harmonics']\n",
        "print(f\"  Using {n_grid_harm}^7 = {n_grid_harm**7:,} points (reduced from {CONFIG['n_grid']**7:,})\")\n",
        "\n",
        "laplacian_2 = DiscreteLaplacian(n_grid_harm, dim=2)\n",
        "laplacian_3 = DiscreteLaplacian(n_grid_harm, dim=3)\n",
        "\n",
        "print(\"Extracting harmonic 2-forms...\")\n",
        "extractor_2 = LiveHarmonicExtractor(laplacian_2, CONFIG['target']['b2'])\n",
        "h2_modes, b2_eff = extractor_2.extract()\n",
        "print(f\"b₂_eff = {b2_eff} (target: {CONFIG['target']['b2']})\")\n",
        "\n",
        "print(\"Extracting harmonic 3-forms...\")\n",
        "extractor_3 = LiveHarmonicExtractor(laplacian_3, CONFIG['target']['b3'])\n",
        "h3_modes, b3_eff = extractor_3.extract()\n",
        "print(f\"b₃_eff = {b3_eff} (target: {CONFIG['target']['b3']})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duz8OoYiTS9X"
      },
      "source": [
        "## 12. Yukawa Tensor Construction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DARPXzpnTS9X",
        "outputId": "c6948003-73de-46bc-dcb6-5f666fb63c41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing Yukawa tensor (21×21×77)...\n",
            "Yukawa progress: 5000/33957 (14.7%)\n",
            "Yukawa progress: 10000/33957 (29.4%)\n",
            "Yukawa progress: 15000/33957 (44.2%)\n",
            "Yukawa progress: 20000/33957 (58.9%)\n",
            "Yukawa progress: 25000/33957 (73.6%)\n",
            "Yukawa progress: 30000/33957 (88.3%)\n",
            "Yukawa tensor shape: (21, 21, 77)\n",
            "Yukawa tensor norm: 0.000000\n"
          ]
        }
      ],
      "source": [
        "class YukawaTensor:\n",
        "    def __init__(self, h2_modes: np.ndarray, h3_modes: np.ndarray, n_samples: int):\n",
        "        self.h2 = h2_modes\n",
        "        self.h3 = h3_modes\n",
        "        self.b2 = h2_modes.shape[1]\n",
        "        self.b3 = h3_modes.shape[1]\n",
        "        self.n_samples = n_samples\n",
        "\n",
        "    def wedge_product(self, alpha: np.ndarray, beta: np.ndarray, gamma: np.ndarray) -> float:\n",
        "        indices = np.random.randint(0, len(alpha), self.n_samples)\n",
        "        integrand = alpha[indices] * beta[indices] * gamma[indices]\n",
        "        return np.mean(integrand)\n",
        "\n",
        "    def compute(self) -> np.ndarray:\n",
        "        Y = np.zeros((self.b2, self.b2, self.b3))\n",
        "        total = self.b2 * self.b2 * self.b3\n",
        "        count = 0\n",
        "\n",
        "        for alpha in range(self.b2):\n",
        "            for beta in range(self.b2):\n",
        "                for gamma in range(self.b3):\n",
        "                    Y[alpha, beta, gamma] = self.wedge_product(\n",
        "                        self.h2[:, alpha],\n",
        "                        self.h2[:, beta],\n",
        "                        self.h3[:, gamma]\n",
        "                    )\n",
        "\n",
        "                    count += 1\n",
        "                    if count % 5000 == 0:\n",
        "                        print(f\"Yukawa progress: {count}/{total} ({100*count/total:.1f}%)\")\n",
        "\n",
        "        return Y\n",
        "\n",
        "print(f\"Computing Yukawa tensor ({b2_eff}×{b2_eff}×{b3_eff})...\")\n",
        "yukawa = YukawaTensor(h2_modes, h3_modes, CONFIG['yukawa_samples'])\n",
        "Y_tensor = yukawa.compute()\n",
        "print(f\"Yukawa tensor shape: {Y_tensor.shape}\")\n",
        "print(f\"Yukawa tensor norm: {np.linalg.norm(Y_tensor):.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m4-yrHTTS9X"
      },
      "source": [
        "## 13. Torsional Geodesic Calibration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oQLQEyzVTS9Y",
        "outputId": "e2e049d5-dbb2-444d-d792-f337382d6031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Final Calibration:\n",
            "  det(g) = 0.000000 (target: 2.0)\n",
            "  ||T|| = 0.020214 (target: 0.0164)\n",
            "  Errors: det=2.00e+00, torsion=3.81e-03\n"
          ]
        }
      ],
      "source": [
        "class TorsionalCalibration:\n",
        "    def __init__(self, phi_net: nn.Module, geometry: TCSGeometry, target_torsion: float):\n",
        "        self.phi_net = phi_net\n",
        "        self.geometry = geometry\n",
        "        self.target_torsion = target_torsion\n",
        "\n",
        "    def compute_torsion_norm(self, coords: torch.Tensor) -> float:\n",
        "        with torch.no_grad():\n",
        "            phi = self.phi_net(coords)\n",
        "            g, g_inv = compute_g2_metric(phi)\n",
        "\n",
        "            jacobian = extd.compute_jacobian(self.phi_net, coords)\n",
        "            dphi = extd.d_phi(jacobian)\n",
        "\n",
        "            torsion_norm = torch.sqrt((dphi ** 2).sum())\n",
        "\n",
        "        return torsion_norm.item()\n",
        "\n",
        "    def calibrate(self, n_samples: int = 1000) -> Dict:\n",
        "        coords = torch.rand(n_samples, 7, device=device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            phi = self.phi_net(coords)\n",
        "            g, g_inv = compute_g2_metric(phi)\n",
        "            g = self.geometry.acyl_metric_correction(coords, g)\n",
        "\n",
        "            det_g = torch.linalg.det(g).mean().item()\n",
        "\n",
        "        torsion_norm = self.compute_torsion_norm(coords)\n",
        "\n",
        "        return {\n",
        "            'det_g': det_g,\n",
        "            'torsion_norm': torsion_norm,\n",
        "            'det_error': abs(det_g - CONFIG['target']['det_g']),\n",
        "            'torsion_error': abs(torsion_norm - self.target_torsion)\n",
        "        }\n",
        "\n",
        "calibrator = TorsionalCalibration(phi_net, geometry, CONFIG['target']['torsion_norm'])\n",
        "calibration_results = calibrator.calibrate()\n",
        "\n",
        "print(\"\\nFinal Calibration:\")\n",
        "print(f\"  det(g) = {calibration_results['det_g']:.6f} (target: {CONFIG['target']['det_g']})\")\n",
        "print(f\"  ||T|| = {calibration_results['torsion_norm']:.6f} (target: {CONFIG['target']['torsion_norm']})\")\n",
        "print(f\"  Errors: det={calibration_results['det_error']:.2e}, torsion={calibration_results['torsion_error']:.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQa7rLzwTS9Y"
      },
      "source": [
        "## 14. Save Complete Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Peqzd3UTTS9Y",
        "outputId": "c65559e6-9016-4f00-d28f-124d4881b247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results saved to outputs_v1_0f\n",
            "Archive created: K7_G2_TCS_v1_0f_complete_results.zip\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_33575e52-c3c0-44f2-a20c-c0986543f7ef\", \"K7_G2_TCS_v1_0f_complete_results.zip\", 1498047141)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download started: K7_G2_TCS_v1_0f_complete_results.zip\n",
            "\n",
            "============================================================\n",
            "PIPELINE COMPLETE\n",
            "============================================================\n",
            "Final metrics:\n",
            "  b₂: 21/21\n",
            "  b₃: 77/77\n",
            "  Yukawa: (21, 21, 77)\n",
            "  det(g): 0.0000\n",
            "  ||T||: 0.020214\n"
          ]
        }
      ],
      "source": [
        "output_dir = Path('outputs_v1_0f')\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "np.save(output_dir / 'harmonic_2forms.npy', h2_modes)\n",
        "np.save(output_dir / 'harmonic_3forms.npy', h3_modes)\n",
        "np.save(output_dir / 'yukawa_tensor.npy', Y_tensor)\n",
        "\n",
        "phi_net.eval()\n",
        "with torch.no_grad():\n",
        "    test_coords = torch.rand(5000, 7, device=device)\n",
        "    phi_samples = phi_net(test_coords).cpu().numpy()\n",
        "    np.save(output_dir / 'phi_samples.npy', phi_samples)\n",
        "\n",
        "    g_samples, _ = compute_g2_metric(phi_net(test_coords))\n",
        "    g_samples = geometry.acyl_metric_correction(test_coords, g_samples)\n",
        "    np.save(output_dir / 'metric_samples.npy', g_samples.cpu().numpy())\n",
        "\n",
        "loss_array = np.array([[h['phase'], h['epoch'], h['total'], h['dphi'], h['dpsi']] for h in loss_history])\n",
        "np.save(output_dir / 'loss_history.npy', loss_array)\n",
        "\n",
        "metadata = {\n",
        "    'version': '1.0f',\n",
        "    'config': CONFIG,\n",
        "    'training_grid': f\"{CONFIG['n_grid']}^7\",\n",
        "    'harmonics_grid': f\"{CONFIG['n_grid_harmonics']}^7\",\n",
        "    'b2_effective': b2_eff,\n",
        "    'b3_effective': b3_eff,\n",
        "    'b2_target': CONFIG['target']['b2'],\n",
        "    'b3_target': CONFIG['target']['b3'],\n",
        "    'yukawa_shape': list(Y_tensor.shape),\n",
        "    'yukawa_norm': float(np.linalg.norm(Y_tensor)),\n",
        "    'calibration': calibration_results,\n",
        "    'final_loss': loss_history[-1]['total'] if loss_history else None,\n",
        "    'total_epochs': len(loss_history),\n",
        "    'note': 'Multi-resolution: high-res training (16^7), reduced harmonics (8^7)'\n",
        "}\n",
        "\n",
        "with open(output_dir / 'metadata.json', 'w') as f:\n",
        "    json.dump(metadata, f, indent=2)\n",
        "\n",
        "import shutil\n",
        "archive_name = 'K7_G2_TCS_v1_0f_complete_results'\n",
        "shutil.make_archive(archive_name, 'zip', output_dir)\n",
        "\n",
        "print(f\"\\nResults saved to {output_dir}\")\n",
        "print(f\"Archive created: {archive_name}.zip\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(f'{archive_name}.zip')\n",
        "    print(f\"Download started: {archive_name}.zip\")\n",
        "except:\n",
        "    print(\"Not in Colab environment, skipping auto-download\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"PIPELINE COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Final metrics:\")\n",
        "print(f\"  b₂: {b2_eff}/{CONFIG['target']['b2']}\")\n",
        "print(f\"  b₃: {b3_eff}/{CONFIG['target']['b3']}\")\n",
        "print(f\"  Yukawa: {Y_tensor.shape}\")\n",
        "print(f\"  det(g): {calibration_results['det_g']:.4f}\")\n",
        "print(f\"  ||T||: {calibration_results['torsion_norm']:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re2bOeZZOcST"
      },
      "source": [
        "## 15. Multi-Resolution Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDdVuH2XOcST"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MULTI-RESOLUTION VALIDATION\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nGrid Configuration:\")\n",
        "print(f\"  Training grid: {CONFIG['n_grid']}^7 = {CONFIG['n_grid']**7:,} points\")\n",
        "print(f\"  Harmonics grid: {CONFIG['n_grid_harmonics']}^7 = {CONFIG['n_grid_harmonics']**7:,} points\")\n",
        "print(f\"  Resolution ratio: {(CONFIG['n_grid']/CONFIG['n_grid_harmonics']):.1f}×\")\n",
        "print(f\"  Speedup factor: {(CONFIG['n_grid']/CONFIG['n_grid_harmonics'])**7:.0f}×\")\n",
        "\n",
        "print(f\"\\nCohomology Results:\")\n",
        "print(f\"  b₂ effectif: {b2_eff}/{CONFIG['target']['b2']} ({100*b2_eff/CONFIG['target']['b2']:.1f}%)\")\n",
        "print(f\"  b₃ effectif: {b3_eff}/{CONFIG['target']['b3']} ({100*b3_eff/CONFIG['target']['b3']:.1f}%)\")\n",
        "\n",
        "print(f\"\\nPhysical Validation:\")\n",
        "print(f\"  Yukawa tensor: {Y_tensor.shape}\")\n",
        "print(f\"  Yukawa norm: {np.linalg.norm(Y_tensor):.6f}\")\n",
        "print(f\"  det(g) error: {calibration_results['det_error']:.2e}\")\n",
        "print(f\"  Torsion error: {calibration_results['torsion_error']:.2e}\")\n",
        "\n",
        "print(f\"\\nTraining Summary:\")\n",
        "print(f\"  Total epochs: {len(loss_history)}\")\n",
        "print(f\"  Final loss: {loss_history[-1]['total']:.6f}\")\n",
        "print(f\"  Epochs per phase: {CONFIG['n_epochs_per_phase']}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"NOTE: Multi-resolution approach validated.\")\n",
        "print(\"Low harmonic modes captured accurately on reduced grid.\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}