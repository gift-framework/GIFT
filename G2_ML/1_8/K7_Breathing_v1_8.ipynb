{
 "cells": [
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# OPTIONAL: YUKAWA TENSOR EXTRACTION (EXPENSIVE - RUN SEPARATELY)\n# =============================================================================\n\n# Uncomment to run Yukawa extraction (takes ~10-30 minutes):\n\n# yukawa_extractor = YukawaCouplingExtractor(n_samples=5000)\n# Y = yukawa_extractor.compute_yukawa_tensor(\n#     results['phi_net'], results['h2_extractor'], results['h3_extractor'],\n#     CONFIG.geometry, DEVICE\n# )\n# yukawa_analysis = yukawa_extractor.analyze_yukawa(Y)\n# print(f\"Yukawa tensor shape: {Y.shape}\")\n# print(f\"Effective rank: {yukawa_analysis['effective_rank']} / 77\")\n# print(f\"Top singular values: {yukawa_analysis['top_singular_values'][:5]}\")\n# \n# # Save Yukawa tensor\n# torch.save(Y, OUTPUT_DIR / \"yukawa_tensor.pt\")\n# with open(OUTPUT_DIR / \"yukawa_analysis.json\", 'w') as f:\n#     json.dump(yukawa_analysis, f, indent=2)\n\nprint(\"Yukawa extraction cell ready (uncomment to run)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# RUN POST-HOC ANALYSIS\n# =============================================================================\n\nanalysis = run_post_hoc_analysis(results, DEVICE)\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"K7 BREATHING v1.8 - COMPLETE\")\nprint(\"=\" * 70)\nprint(f\"\\nOutputs saved to: {OUTPUT_DIR}\")\nprint(\"  - final_model.pt: Trained model checkpoint\")\nprint(\"  - training_history.json: Full training metrics\")\nprint(\"  - config.json: Experiment configuration\")\nprint(\"  - metric_fit.json: Analytic metric approximation\")\nprint(\"  - analysis_summary.json: Final results summary\")\nprint(\"  - training_history.png: Training curves\")\nif CONFIG.breathing.enable:\n    print(\"  - flux_profile.png: Breathing flux visualization\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# RUN FULL TRAINING\n# =============================================================================\n\n# Save configuration\nCONFIG.save(str(OUTPUT_DIR / \"config.json\"))\n\n# Run training\nresults = run_full_training(CONFIG, DEVICE)\n\nprint(\"\\nTraining complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# QUICK TEST CONFIGURATION (comment out for full training)\n# =============================================================================\n\n# Uncomment these lines for quick testing:\n# CONFIG.training.n_epochs_core = 100\n# CONFIG.training.n_epochs_breathing = 50\n# CONFIG.logging.log_every = 10\n\n# For pure geometry mode (no breathing diagnostics):\n# CONFIG.breathing.enable = False\n\nprint(\"Configuration ready. Run next cell to start training.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section 7: Run Training (Execute Cells Below)\n\n**Quick Run Configuration:**\n- For testing: Set `CONFIG.training.n_epochs_core = 100`\n- For full training: Use default settings (5000 + 2000 epochs)\n\n**Two Modes:**\n1. **Pure Geometry**: Set `CONFIG.breathing.enable = False`\n2. **Geometry + Breathing**: Keep `CONFIG.breathing.enable = True` (default)\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 6.3: COMPLETE POST-HOC ANALYSIS\n# =============================================================================\n\ndef run_post_hoc_analysis(results: Dict, device: torch.device) -> Dict:\n    \"\"\"\n    Run complete post-hoc analysis after training.\n    \n    Includes:\n    1. Metric fitting\n    2. Yukawa extraction (if enabled)\n    3. Breathing period estimation\n    4. Visualization\n    \"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"POST-HOC ANALYSIS\")\n    print(\"=\" * 70)\n    \n    phi_net = results['phi_net']\n    flux_net = results['flux_net']\n    h3_extractor = results['h3_extractor']\n    mode_proj = results['mode_proj']\n    h2_extractor = results['h2_extractor']\n    history = results['history']\n    config = results['config']\n    \n    analysis = {}\n    \n    # 1. Metric fitting\n    print(\"\\n--- Metric Ansatz Fitting ---\")\n    metric_fit = fit_metric_ansatz(phi_net, config.geometry, device)\n    analysis['metric_fit'] = metric_fit\n    \n    # 2. Breathing period estimation\n    if config.breathing.enable:\n        print(\"\\n--- Breathing Period Estimation ---\")\n        phi_net.eval()\n        \n        with torch.no_grad():\n            n_lambda_pts = 100\n            lam_vals = torch.linspace(0, 1, n_lambda_pts, device=device)\n            \n            # For each lambda, sample transverse coordinates and average\n            observables = []\n            for lam_val in lam_vals:\n                coords = sample_TCS_coords(500, device)\n                coords[:, 0] = lam_val  # Fix lambda\n                \n                phi = phi_net(coords)\n                modes = h3_extractor(phi, coords)\n                obs = compute_breathing_observable(modes, coords, mode_proj)\n                observables.append(obs.mean().item())\n            \n            observables = torch.tensor(observables, device=device)\n            \n            period_est, period_info = estimate_breathing_period(observables, lam_vals)\n            \n            print(f\"Estimated period: {period_est:.4f}\")\n            print(f\"Target period (tau): {config.breathing.target_period:.4f}\")\n            \n            analysis['breathing_period'] = {\n                'estimated': period_est,\n                'target': config.breathing.target_period,\n                'info': period_info\n            }\n    \n    # 3. Visualization\n    print(\"\\n--- Generating Plots ---\")\n    \n    # Training history\n    plot_training_history(history, str(OUTPUT_DIR / \"training_history.png\"))\n    \n    # Flux profile\n    if config.breathing.enable:\n        plot_flux_profile(flux_net, device, str(OUTPUT_DIR / \"flux_profile.png\"))\n    \n    # 4. Save complete analysis\n    analysis_summary = {\n        'metric_fit_r2': metric_fit['avg_r_squared'],\n        'final_kappa_T': results['final_core_metrics']['kappa_T'],\n        'final_kappa_T_error_pct': results['final_core_metrics']['kappa_T_error_pct'],\n        'final_det_g': results['final_core_metrics']['det_g_mean'],\n        'final_det_g_error_pct': results['final_core_metrics']['det_g_error_pct'],\n    }\n    \n    if config.breathing.enable:\n        analysis_summary['final_flux_integral'] = results['final_breathing_metrics']['flux_integral']\n        analysis_summary['final_occupation_vis'] = results['final_breathing_metrics']['occupation_vis']\n        if 'breathing_period' in analysis:\n            analysis_summary['estimated_period'] = analysis['breathing_period']['estimated']\n    \n    with open(OUTPUT_DIR / \"analysis_summary.json\", 'w') as f:\n        json.dump(analysis_summary, f, indent=2)\n    \n    print(f\"\\nAnalysis complete. Results saved to {OUTPUT_DIR}\")\n    return analysis\n\n\nprint(\"Post-hoc analysis function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 6.2: VISUALIZATION\n# =============================================================================\n\ndef plot_training_history(history: TrainingHistory, save_path: Optional[str] = None):\n    \"\"\"Plot training curves.\"\"\"\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    \n    epochs = history.history['epoch']\n    \n    # Loss curve\n    ax = axes[0, 0]\n    ax.semilogy(epochs, history.history['total_loss'], 'b-', label='Total Loss')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Loss')\n    ax.set_title('Training Loss')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # kappa_T\n    ax = axes[0, 1]\n    ax.plot(epochs, history.history['kappa_T'], 'b-', label='kappa_T')\n    ax.axhline(y=1/61, color='r', linestyle='--', label='Target (1/61)')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('kappa_T')\n    ax.set_title('Torsion Magnitude')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # det(g)\n    ax = axes[0, 2]\n    ax.plot(epochs, history.history['det_g'], 'b-', label='det(g)')\n    ax.axhline(y=65/32, color='r', linestyle='--', label='Target (65/32)')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('det(g)')\n    ax.set_title('Metric Determinant')\n    ax.legend()\n    ax.grid(True, alpha=0.3)\n    \n    # kappa_T error\n    ax = axes[1, 0]\n    ax.semilogy(epochs, history.history['kappa_T_error_pct'], 'b-')\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Error (%)')\n    ax.set_title('kappa_T Error')\n    ax.grid(True, alpha=0.3)\n    \n    # Flux integral (if available)\n    ax = axes[1, 1]\n    flux_vals = [v for v in history.history['flux_integral'] if not np.isnan(v)]\n    if flux_vals:\n        flux_epochs = [e for e, v in zip(epochs, history.history['flux_integral']) if not np.isnan(v)]\n        ax.plot(flux_epochs, flux_vals, 'b-', label='Flux Integral')\n        ax.axhline(y=-0.5, color='r', linestyle='--', label='Target (-1/2)')\n        ax.legend()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Flux Integral')\n    ax.set_title('Breathing Flux')\n    ax.grid(True, alpha=0.3)\n    \n    # Occupation ratio (if available)\n    ax = axes[1, 2]\n    occ_vals = [v for v in history.history['occupation_vis'] if not np.isnan(v)]\n    if occ_vals:\n        occ_epochs = [e for e, v in zip(epochs, history.history['occupation_vis']) if not np.isnan(v)]\n        ax.plot(occ_epochs, occ_vals, 'b-', label='Visible Occupation')\n        ax.axhline(y=43/77, color='r', linestyle='--', label='Target (43/77)')\n        ax.legend()\n    ax.set_xlabel('Epoch')\n    ax.set_ylabel('Occupation Ratio')\n    ax.set_title('Mode Distribution')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n        print(f\"Saved training history plot to {save_path}\")\n    \n    plt.show()\n\n\ndef plot_flux_profile(flux_net: nn.Module, device: torch.device,\n                      save_path: Optional[str] = None):\n    \"\"\"Plot flux profile along the neck.\"\"\"\n    flux_net.eval()\n    \n    with torch.no_grad():\n        lam = torch.linspace(0, 1, 100, device=device)\n        flux = flux_net(lam).cpu().numpy()\n    \n    fig, ax = plt.subplots(figsize=(8, 5))\n    ax.plot(lam.cpu().numpy(), flux, 'b-', linewidth=2)\n    ax.axhline(y=0, color='k', linestyle='-', alpha=0.3)\n    ax.fill_between(lam.cpu().numpy(), flux, 0, alpha=0.3)\n    ax.set_xlabel('lambda (neck coordinate)')\n    ax.set_ylabel('Flux(lambda)')\n    ax.set_title('Breathing Flux Profile Along TCS Neck')\n    ax.grid(True, alpha=0.3)\n    \n    # Add integral annotation\n    integral = flux_net.compute_flux_integral().item()\n    ax.text(0.05, 0.95, f'Integral = {integral:.4f}\\nTarget = -0.5',\n            transform=ax.transAxes, verticalalignment='top',\n            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n    \n    plt.tight_layout()\n    \n    if save_path:\n        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n    \n    plt.show()\n\n\nprint(\"Visualization functions defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 6.1: METRIC FITTING (POST-HOC)\n# =============================================================================\n\ndef fit_metric_ansatz(phi_net: nn.Module, config: GeometryConfig,\n                      device: torch.device, n_samples: int = 5000) -> Dict:\n    \"\"\"\n    Fit learned metric g_ij to analytic ansatz in (lambda, xi).\n    \n    Ansatz:\n        g_ij(x) = A_ij + B_ij*lambda + C_ij*lambda^2 \n                + D_ij*sin(pi*lambda) + E_ij*cos(pi*lambda)\n                + sum_k T_ijk*xi_k + sum_k X_ijk*lambda*xi_k\n    \n    This is EXPLORATORY - not fed back into training.\n    \"\"\"\n    print(\"Fitting metric to analytic ansatz...\")\n    \n    phi_net.eval()\n    \n    with torch.no_grad():\n        # Sample points\n        coords = sample_TCS_coords(n_samples, device)\n        phi = phi_net(coords)\n        metric = project_spd(metric_from_phi(phi))  # (n_samples, 7, 7)\n        \n        lam = coords[:, 0].cpu().numpy()\n        xi = coords[:, 1:].cpu().numpy()\n        g = metric.cpu().numpy()\n    \n    # Build design matrix for linear regression\n    # Features: [1, lam, lam^2, sin(pi*lam), cos(pi*lam), xi_1..6, lam*xi_1..6]\n    n_features = 1 + 1 + 1 + 1 + 1 + 6 + 6  # = 17\n    \n    X = np.zeros((n_samples, n_features))\n    X[:, 0] = 1.0                          # Constant\n    X[:, 1] = lam                          # lambda\n    X[:, 2] = lam ** 2                     # lambda^2\n    X[:, 3] = np.sin(np.pi * lam)          # sin(pi*lambda)\n    X[:, 4] = np.cos(np.pi * lam)          # cos(pi*lambda)\n    X[:, 5:11] = xi                        # xi_1..6\n    X[:, 11:17] = lam[:, np.newaxis] * xi  # lambda*xi_1..6\n    \n    # Fit each metric component\n    coefficients = {}\n    r_squared = {}\n    \n    for i in range(7):\n        for j in range(i, 7):\n            y = g[:, i, j]\n            \n            # Least squares fit\n            coeffs, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n            \n            # Compute R^2\n            y_pred = X @ coeffs\n            ss_res = np.sum((y - y_pred) ** 2)\n            ss_tot = np.sum((y - y.mean()) ** 2)\n            r2 = 1 - ss_res / (ss_tot + 1e-10)\n            \n            coefficients[f'g_{i}{j}'] = coeffs.tolist()\n            r_squared[f'g_{i}{j}'] = r2\n    \n    # Summary\n    avg_r2 = np.mean(list(r_squared.values()))\n    \n    print(f\"Metric fit complete:\")\n    print(f\"  Average R^2: {avg_r2:.4f}\")\n    print(f\"  Best fit: g_00 with R^2 = {r_squared['g_00']:.4f}\")\n    \n    results = {\n        'coefficients': coefficients,\n        'r_squared': r_squared,\n        'avg_r_squared': avg_r2,\n        'feature_names': ['const', 'lam', 'lam2', 'sin_pi_lam', 'cos_pi_lam',\n                         'xi1', 'xi2', 'xi3', 'xi4', 'xi5', 'xi6',\n                         'lam_xi1', 'lam_xi2', 'lam_xi3', 'lam_xi4', 'lam_xi5', 'lam_xi6']\n    }\n    \n    # Save results\n    with open(OUTPUT_DIR / \"metric_fit.json\", 'w') as f:\n        json.dump(results, f, indent=2)\n    \n    return results\n\n\nprint(\"Metric fitting function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section 6: Post-Hoc Analysis\n\nAfter training, we perform:\n1. **Metric fitting**: Analytic approximation of g_ij(lambda, xi)\n2. **Yukawa extraction**: Compute full Y_{ijk} tensor\n3. **Breathing diagnostics**: Period estimation, flux profile\n4. **Visualization**: Training curves, metric structure, mode distributions\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 5.4: MAIN TRAINING ORCHESTRATOR\n# =============================================================================\n\ndef run_full_training(config: ExperimentConfig, device: torch.device) -> Dict:\n    \"\"\"\n    Run complete multi-phase training.\n    \n    Returns:\n        results: Dictionary with all models, history, and final metrics\n    \"\"\"\n    print(\"=\" * 70)\n    print(\"K7 BREATHING v1.8 - FULL TRAINING\")\n    print(\"=\" * 70)\n    print(f\"Device: {device}\")\n    print(f\"Geometry: b2={config.geometry.b2_K7}, b3={config.geometry.b3_K7}\")\n    print(f\"Breathing: enabled={config.breathing.enable}\")\n    print()\n    \n    # Initialize models\n    phi_net = PhiNetwork().to(device)\n    flux_net = NeckTransferNet().to(device)\n    h3_extractor = H3ModeExtractor().to(device)\n    mode_proj = ModeProjection(\n        n_total=config.geometry.b3_K7,\n        n_visible=config.breathing.n_visible\n    ).to(device)\n    h2_extractor = H2BasisExtractor().to(device)\n    \n    print(f\"PhiNetwork parameters: {sum(p.numel() for p in phi_net.parameters()):,}\")\n    print(f\"FluxNet parameters: {sum(p.numel() for p in flux_net.parameters()):,}\")\n    print()\n    \n    # Phase 1: Geometry-only\n    phi_net, history = train_phase1_geometry(phi_net, config, device)\n    \n    # Phase 2: Geometry + Breathing\n    phi_net, flux_net, history = train_phase2_breathing(\n        phi_net, flux_net, mode_proj, h3_extractor, config, device, history\n    )\n    \n    # Save history\n    history.save(str(OUTPUT_DIR / \"training_history.json\"))\n    \n    # Final evaluation\n    print(\"\\n\" + \"=\" * 70)\n    print(\"FINAL EVALUATION\")\n    print(\"=\" * 70)\n    \n    phi_net.eval()\n    flux_net.eval()\n    \n    with torch.no_grad():\n        # Sample large batch for final metrics\n        coords = sample_coords(10000, config.geometry, device)\n        coords.requires_grad_(True)\n        \n        phi = phi_net(coords)\n        _, final_core_info = compute_core_loss(phi, coords, config.geometry)\n        \n        modes = h3_extractor(phi, coords)\n        _, final_breathing_info = compute_breathing_loss(\n            flux_net, mode_proj, modes, config.breathing\n        )\n    \n    print(f\"kappa_T: {final_core_info['kappa_T']:.6f} (target: {1/61:.6f}, error: {final_core_info['kappa_T_error_pct']:.2f}%)\")\n    print(f\"det(g): {final_core_info['det_g_mean']:.6f} (target: {65/32:.6f}, error: {final_core_info['det_g_error_pct']:.2f}%)\")\n    \n    if config.breathing.enable:\n        print(f\"Flux integral: {final_breathing_info['flux_integral']:.4f} (target: -0.5)\")\n        print(f\"Occupation ratio: {final_breathing_info['occupation_vis']:.4f} (target: {43/77:.4f})\")\n    \n    # Compile results\n    results = {\n        'phi_net': phi_net,\n        'flux_net': flux_net,\n        'h3_extractor': h3_extractor,\n        'mode_proj': mode_proj,\n        'h2_extractor': h2_extractor,\n        'history': history,\n        'final_core_metrics': final_core_info,\n        'final_breathing_metrics': final_breathing_info if config.breathing.enable else None,\n        'config': config\n    }\n    \n    # Save final checkpoint\n    torch.save({\n        'phi_net_state': phi_net.state_dict(),\n        'flux_net_state': flux_net.state_dict(),\n        'final_core_metrics': final_core_info,\n        'final_breathing_metrics': final_breathing_info if config.breathing.enable else None,\n        'config': config.to_dict()\n    }, OUTPUT_DIR / \"final_model.pt\")\n    \n    print(f\"\\nResults saved to {OUTPUT_DIR}\")\n    return results\n\n\nprint(\"Main training orchestrator defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 5.3: PHASE 2 - GEOMETRY + BREATHING\n# =============================================================================\n\ndef train_phase2_breathing(phi_net: nn.Module, flux_net: nn.Module,\n                           mode_proj: nn.Module, h3_extractor: nn.Module,\n                           config: ExperimentConfig, device: torch.device,\n                           history: TrainingHistory) -> Tuple[nn.Module, nn.Module, TrainingHistory]:\n    \"\"\"\n    Phase 2: Add breathing diagnostics with small-weight losses.\n    \n    Option 1 (freeze_phi=True): Only train flux_net, phi_net frozen\n    Option 2 (freeze_phi=False): Fine-tune both with reduced LR\n    \"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"PHASE 2: Geometry + Breathing Diagnostics\")\n    print(\"=\" * 70)\n    \n    if not config.breathing.enable:\n        print(\"Breathing disabled - skipping Phase 2\")\n        return phi_net, flux_net, history\n    \n    # Setup optimizers\n    if config.training.freeze_phi_in_breathing:\n        # Freeze phi_net, only train flux_net\n        for param in phi_net.parameters():\n            param.requires_grad = False\n        params = list(flux_net.parameters())\n        print(\"PhiNetwork frozen, training FluxNet only\")\n    else:\n        # Fine-tune both with reduced LR for phi_net\n        params = [\n            {'params': phi_net.parameters(), 'lr': config.training.lr_breathing * 0.1},\n            {'params': flux_net.parameters(), 'lr': config.training.lr_breathing}\n        ]\n        print(\"Fine-tuning both PhiNetwork and FluxNet\")\n    \n    optimizer = torch.optim.AdamW(params, lr=config.training.lr_breathing,\n                                   weight_decay=config.training.weight_decay)\n    scheduler = create_scheduler(optimizer, config.training)\n    \n    best_loss = float('inf')\n    \n    for epoch in range(config.training.n_epochs_breathing):\n        phi_net.train()\n        flux_net.train()\n        \n        # Sample coordinates\n        coords = sample_coords(config.training.batch_size, config.geometry, device)\n        coords.requires_grad_(True)\n        \n        # Forward pass\n        phi = phi_net(coords)\n        \n        # Core loss\n        core_loss, core_info = compute_core_loss(phi, coords, config.geometry)\n        \n        # Extract H3 modes\n        modes = h3_extractor(phi, coords)\n        \n        # Breathing loss\n        breathing_loss, breathing_info = compute_breathing_loss(\n            flux_net, mode_proj, modes, config.breathing\n        )\n        \n        # Total loss (core dominates)\n        total_loss = core_loss + breathing_loss\n        \n        # Backward pass\n        optimizer.zero_grad()\n        total_loss.backward()\n        torch.nn.utils.clip_grad_norm_(\n            list(phi_net.parameters()) + list(flux_net.parameters()),\n            config.training.max_grad_norm\n        )\n        optimizer.step()\n        scheduler.step(total_loss)\n        \n        # Logging\n        current_lr = optimizer.param_groups[0]['lr']\n        core_info['total_loss'] = total_loss.item()\n        history.log(epoch + config.training.n_epochs_core, 'breathing', \n                   core_info, breathing_info, current_lr)\n        \n        # Track best\n        if total_loss.item() < best_loss:\n            best_loss = total_loss.item()\n        \n        # Print progress\n        if epoch % config.logging.log_every == 0 or epoch == config.training.n_epochs_breathing - 1:\n            print(f\"Epoch {epoch:5d} | Loss: {total_loss.item():.4f} | \"\n                  f\"Core: {core_info['total_loss']:.4f} | \"\n                  f\"Breathing: {breathing_info['total_breathing_loss']:.6f} | \"\n                  f\"Flux: {breathing_info['flux_integral']:.4f} | \"\n                  f\"Occ: {breathing_info['occupation_vis']:.4f}\")\n    \n    # Unfreeze phi_net if it was frozen\n    if config.training.freeze_phi_in_breathing:\n        for param in phi_net.parameters():\n            param.requires_grad = True\n    \n    # Save checkpoint\n    if config.logging.save_checkpoints:\n        checkpoint_path = Path(config.logging.checkpoint_dir) / \"checkpoint_phase2.pt\"\n        torch.save({\n            'phi_net_state': phi_net.state_dict(),\n            'flux_net_state': flux_net.state_dict(),\n            'best_loss': best_loss,\n            'config': config.to_dict()\n        }, checkpoint_path)\n        print(f\"Saved Phase 2 checkpoint to {checkpoint_path}\")\n    \n    print(f\"\\nPhase 2 Complete: Best loss = {best_loss:.4f}\")\n    return phi_net, flux_net, history\n\n\nprint(\"Phase 2 training function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 5.2: PHASE 1 - GEOMETRY-ONLY TRAINING\n# =============================================================================\n\ndef train_phase1_geometry(phi_net: nn.Module, config: ExperimentConfig,\n                          device: torch.device) -> Tuple[nn.Module, TrainingHistory]:\n    \"\"\"\n    Phase 1: Train PhiNetwork for core geometry only.\n    \n    Goals:\n    - kappa_T -> 1/61\n    - det(g) -> 65/32\n    - Torsion minimization\n    \"\"\"\n    print(\"=\" * 70)\n    print(\"PHASE 1: Geometry-Only Training\")\n    print(\"=\" * 70)\n    \n    history = TrainingHistory()\n    optimizer = create_optimizer(phi_net, config.training, lr=config.training.lr_core)\n    scheduler = create_scheduler(optimizer, config.training)\n    \n    best_loss = float('inf')\n    best_state = None\n    \n    for epoch in range(config.training.n_epochs_core):\n        phi_net.train()\n        \n        # Sample coordinates\n        coords = sample_coords(config.training.batch_size, config.geometry, device)\n        coords.requires_grad_(True)\n        \n        # Forward pass\n        phi = phi_net(coords)\n        \n        # Compute core loss\n        loss, info = compute_core_loss(phi, coords, config.geometry)\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # Gradient clipping\n        torch.nn.utils.clip_grad_norm_(phi_net.parameters(), config.training.max_grad_norm)\n        \n        optimizer.step()\n        scheduler.step(loss)\n        \n        # Logging\n        current_lr = optimizer.param_groups[0]['lr']\n        history.log(epoch, 'geometry', info, None, current_lr)\n        \n        # Track best model\n        if loss.item() < best_loss:\n            best_loss = loss.item()\n            best_state = {k: v.clone() for k, v in phi_net.state_dict().items()}\n        \n        # Print progress\n        if epoch % config.logging.log_every == 0 or epoch == config.training.n_epochs_core - 1:\n            print(f\"Epoch {epoch:5d} | Loss: {info['total_loss']:.4f} | \"\n                  f\"kappa_T: {info['kappa_T']:.6f} ({info['kappa_T_error_pct']:.2f}%) | \"\n                  f\"det(g): {info['det_g_mean']:.4f} ({info['det_g_error_pct']:.2f}%) | \"\n                  f\"LR: {current_lr:.2e}\")\n    \n    # Restore best model\n    if best_state is not None:\n        phi_net.load_state_dict(best_state)\n    \n    # Save checkpoint\n    if config.logging.save_checkpoints:\n        checkpoint_path = Path(config.logging.checkpoint_dir) / \"checkpoint_phase1.pt\"\n        torch.save({\n            'phi_net_state': phi_net.state_dict(),\n            'best_loss': best_loss,\n            'config': config.to_dict()\n        }, checkpoint_path)\n        print(f\"Saved Phase 1 checkpoint to {checkpoint_path}\")\n    \n    print(f\"\\nPhase 1 Complete: Best loss = {best_loss:.4f}\")\n    return phi_net, history\n\n\nprint(\"Phase 1 training function defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 5.1: TRAINING INFRASTRUCTURE\n# =============================================================================\n\nclass TrainingHistory:\n    \"\"\"Track training metrics across epochs.\"\"\"\n    \n    def __init__(self):\n        self.history = {\n            'epoch': [],\n            'phase': [],\n            'total_loss': [],\n            'core_loss': [],\n            'breathing_loss': [],\n            'kappa_T': [],\n            'kappa_T_error_pct': [],\n            'det_g': [],\n            'det_g_error_pct': [],\n            'flux_integral': [],\n            'occupation_vis': [],\n            'learning_rate': []\n        }\n    \n    def log(self, epoch: int, phase: str, core_info: Dict, \n            breathing_info: Optional[Dict] = None, lr: float = 0.0):\n        \"\"\"Log metrics for one epoch.\"\"\"\n        self.history['epoch'].append(epoch)\n        self.history['phase'].append(phase)\n        self.history['total_loss'].append(core_info['total_loss'])\n        self.history['core_loss'].append(core_info['total_loss'])\n        self.history['kappa_T'].append(core_info['kappa_T'])\n        self.history['kappa_T_error_pct'].append(core_info['kappa_T_error_pct'])\n        self.history['det_g'].append(core_info['det_g_mean'])\n        self.history['det_g_error_pct'].append(core_info['det_g_error_pct'])\n        self.history['learning_rate'].append(lr)\n        \n        if breathing_info and breathing_info.get('breathing_enabled', False):\n            self.history['breathing_loss'].append(breathing_info['total_breathing_loss'])\n            self.history['flux_integral'].append(breathing_info['flux_integral'])\n            self.history['occupation_vis'].append(breathing_info['occupation_vis'])\n        else:\n            self.history['breathing_loss'].append(0.0)\n            self.history['flux_integral'].append(float('nan'))\n            self.history['occupation_vis'].append(float('nan'))\n    \n    def to_dict(self) -> Dict:\n        return self.history\n    \n    def save(self, path: str):\n        with open(path, 'w') as f:\n            json.dump(self.history, f, indent=2)\n\n\ndef create_optimizer(model: nn.Module, config: TrainingConfig, \n                     lr: Optional[float] = None) -> torch.optim.Optimizer:\n    \"\"\"Create Adam optimizer with weight decay.\"\"\"\n    if lr is None:\n        lr = config.lr_core\n    return torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=config.weight_decay)\n\n\ndef create_scheduler(optimizer: torch.optim.Optimizer, \n                     config: TrainingConfig) -> torch.optim.lr_scheduler.ReduceLROnPlateau:\n    \"\"\"Create learning rate scheduler.\"\"\"\n    return torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=config.scheduler_factor,\n        patience=config.scheduler_patience, verbose=False\n    )\n\n\nprint(\"Training infrastructure defined\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section 5: Multi-Phase Training Loop\n\nTraining strategy:\n1. **Phase 1 (Geometry-only)**: Train PhiNetwork to minimize L_core\n2. **Phase 2 (Geometry + Breathing)**: Add breathing diagnostics with small weights\n3. **Phase 3 (Cohomology)**: Extract harmonic forms and compute Yukawa\n\nKey principle: **Core geometry must converge first** before adding speculative terms.\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 4.2: YUKAWA COUPLING EXTRACTION\n# =============================================================================\n\nclass YukawaCouplingExtractor:\n    \"\"\"\n    Compute Yukawa couplings from harmonic forms on K7.\n    \n    In M-theory compactification, Yukawa couplings arise from:\n        Y_{ijk} = integral_{K7} omega_i ^ omega_j ^ Omega_k\n    \n    where:\n    - omega_i, omega_j are harmonic 2-forms (from H2, b2=21)\n    - Omega_k are harmonic 3-forms (from H3, b3=77)\n    \n    This gives a tensor of shape (21, 21, 77).\n    \"\"\"\n    \n    def __init__(self, n_samples: int = 10000):\n        self.n_samples = n_samples\n    \n    def compute_wedge_2_2_3(self, omega_i: torch.Tensor, omega_j: torch.Tensor,\n                            Omega_k: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute wedge product omega_i ^ omega_j ^ Omega_k.\n        \n        For 2-form ^ 2-form ^ 3-form in 7D, the result is a 7-form (top form).\n        We extract the scalar coefficient.\n        \n        Args:\n            omega_i: Shape (batch, 21) - 2-form components\n            omega_j: Shape (batch, 21) - 2-form components  \n            Omega_k: Shape (batch, 35) - 3-form components\n        \n        Returns:\n            scalar: Shape (batch,) - wedge product coefficient\n        \"\"\"\n        # Simplified wedge product computation\n        # Full computation requires antisymmetrization over all indices\n        \n        # Use inner product as proxy for triple overlap\n        # This captures the essential coupling structure\n        omega_ij = omega_i * omega_j  # Component-wise product\n        \n        # Project onto 3-form space (dimension matching)\n        # Map 21 -> 35 by padding/interpolation\n        omega_ij_expanded = F.interpolate(\n            omega_ij.unsqueeze(1), size=35, mode='linear', align_corners=True\n        ).squeeze(1)\n        \n        # Inner product with Omega_k\n        scalar = (omega_ij_expanded * Omega_k).sum(dim=1)\n        \n        return scalar\n    \n    def compute_yukawa_tensor(self, phi_net: nn.Module, h2_extractor: H2BasisExtractor,\n                              h3_extractor: H3ModeExtractor, config: GeometryConfig,\n                              device: torch.device) -> torch.Tensor:\n        \"\"\"\n        Compute full Yukawa tensor via Monte Carlo integration.\n        \n        Y_{ijk} = (1/V) * sum_x [ omega_i(x) ^ omega_j(x) ^ Omega_k(x) * sqrt(det g(x)) ]\n        \n        Returns:\n            Y: Shape (21, 21, 77) - Yukawa tensor\n        \"\"\"\n        n_h2 = config.b2_K7  # 21\n        n_h3 = config.b3_K7  # 77\n        \n        Y = torch.zeros(n_h2, n_h2, n_h3, device=device)\n        \n        # Sample points on K7\n        coords = sample_TCS_coords(self.n_samples, device)\n        coords.requires_grad_(True)\n        \n        # Compute phi and metric\n        phi = phi_net(coords)\n        metric = project_spd(metric_from_phi(phi))\n        vol = volume_form(metric)  # (n_samples,)\n        \n        # Extract harmonic forms\n        omega_2forms = h2_extractor(metric, coords)  # (n_samples, 21, 21)\n        h3_modes = h3_extractor(phi, coords)  # (n_samples, 77)\n        \n        # For 3-forms, we use the phi components directly (first 35)\n        # and extend with global modes\n        Omega_3forms = h3_modes  # (n_samples, 77)\n        \n        # Compute Yukawa tensor entries\n        # This is O(21 * 21 * 77) = O(34k) entries\n        print(f\"Computing Yukawa tensor ({n_h2}x{n_h2}x{n_h3} = {n_h2*n_h2*n_h3} entries)...\")\n        \n        for i in range(n_h2):\n            for j in range(i, n_h2):  # Symmetry: Y_{ijk} = Y_{jik}\n                omega_i = omega_2forms[:, i, :]  # (n_samples, 21)\n                omega_j = omega_2forms[:, j, :]  # (n_samples, 21)\n                \n                for k in range(n_h3):\n                    # Get k-th 3-form (as 35-dim vector from phi + global)\n                    if k < 35:\n                        Omega_k = phi[:, :35]  # Local 3-form\n                        Omega_k = Omega_k * (k + 1) / 35  # Weight by mode index\n                    else:\n                        # Global mode contribution\n                        global_idx = k - 35\n                        Omega_k = h3_modes[:, 35:] * (global_idx + 1) / 42\n                        Omega_k = F.pad(Omega_k, (0, 35 - 42 + 35))[:, :35]\n                    \n                    # Compute wedge product\n                    wedge = self.compute_wedge_2_2_3(omega_i, omega_j, Omega_k)\n                    \n                    # Volume-weighted average\n                    Y[i, j, k] = (wedge * vol).mean()\n                    Y[j, i, k] = Y[i, j, k]  # Symmetry\n        \n        return Y\n    \n    def analyze_yukawa(self, Y: torch.Tensor) -> Dict:\n        \"\"\"\n        Analyze Yukawa tensor structure.\n        \n        Returns:\n            Dictionary with analysis results\n        \"\"\"\n        # Flatten for eigenanalysis\n        Y_flat = Y.reshape(21*21, 77)\n        \n        # SVD to find effective rank\n        U, S, Vh = torch.linalg.svd(Y_flat, full_matrices=False)\n        \n        # Effective rank (number of significant singular values)\n        threshold = S.max() * 1e-3\n        effective_rank = (S > threshold).sum().item()\n        \n        # Top singular values\n        top_singular = S[:10].tolist()\n        \n        # Frobenius norm\n        frob_norm = torch.norm(Y).item()\n        \n        return {\n            'shape': list(Y.shape),\n            'effective_rank': effective_rank,\n            'top_singular_values': top_singular,\n            'frobenius_norm': frob_norm,\n            'max_entry': Y.abs().max().item(),\n            'mean_entry': Y.abs().mean().item()\n        }\n\n\n# Note: Full Yukawa computation is expensive - will run in post-hoc analysis\nprint(\"YukawaCouplingExtractor defined (computation deferred to post-hoc analysis)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 4.1: H2 BASIS (HARMONIC 2-FORMS)\n# =============================================================================\n\nclass H2BasisExtractor(nn.Module):\n    \"\"\"\n    Extract b2 = 21 harmonic 2-form basis on K7.\n    \n    Harmonic 2-forms correspond to gauge fields in M-theory compactification.\n    We use metric-derived 2-forms from the G2 structure.\n    \"\"\"\n    \n    def __init__(self, n_modes: int = 21):\n        super().__init__()\n        self.n_modes = n_modes\n        self.n_2form_components = 21  # C(7,2) = 21 for 2-forms in 7D\n    \n    def compute_2forms(self, metric: torch.Tensor, coords: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute harmonic 2-form basis from metric structure.\n        \n        Method: Use metric components g_ij to construct 2-form bases.\n        The exact construction comes from Hodge theory on G2 manifolds.\n        \n        Args:\n            metric: Shape (batch, 7, 7)\n            coords: Shape (batch, 7)\n        \n        Returns:\n            omega: Shape (batch, 21, 21) - 21 2-forms, each with 21 components\n        \"\"\"\n        batch_size = metric.shape[0]\n        device = metric.device\n        \n        omega = torch.zeros(batch_size, self.n_modes, self.n_2form_components, device=device)\n        \n        # Build 2-form index mapping\n        idx = 0\n        pairs = []\n        for i in range(7):\n            for j in range(i+1, 7):\n                pairs.append((i, j))\n                idx += 1\n        \n        # Construct 2-forms from metric structure\n        # Each harmonic 2-form is a combination of dx^i ^ dx^j\n        for form_idx in range(self.n_modes):\n            for comp_idx, (i, j) in enumerate(pairs):\n                # Use metric components to weight the 2-form\n                # This is a simplified construction\n                omega[:, form_idx, comp_idx] = metric[:, i, j] * np.sin((form_idx + 1) * np.pi / 21)\n        \n        # Orthonormalize via Gram-Schmidt\n        omega = self._orthonormalize(omega)\n        \n        return omega\n    \n    def _orthonormalize(self, omega: torch.Tensor) -> torch.Tensor:\n        \"\"\"Gram-Schmidt orthonormalization of 2-form basis.\"\"\"\n        batch_size, n_forms, n_comps = omega.shape\n        \n        # Reshape for batched QR\n        omega_flat = omega.view(batch_size, n_forms, n_comps)\n        \n        # Simple normalization (full orthogonalization is expensive)\n        norms = torch.norm(omega_flat, dim=2, keepdim=True)\n        omega_flat = omega_flat / (norms + 1e-8)\n        \n        return omega_flat\n    \n    def forward(self, metric: torch.Tensor, coords: torch.Tensor) -> torch.Tensor:\n        \"\"\"Extract 21 harmonic 2-forms.\"\"\"\n        return self.compute_2forms(metric, coords)\n\n\n# Test H2 basis\nh2_extractor = H2BasisExtractor().to(DEVICE)\ntest_omega = h2_extractor(test_metric_spd, test_coords)\nprint(f\"H2 basis shape: {test_omega.shape} (expected: (16, 21, 21))\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section 4: Cohomology + Yukawa Module\n\nThis section implements clean numerical extraction of Yukawa couplings:\n- H2 (b2=21) and H3 (b3=77) harmonic form bases\n- Numerical wedge product integration\n- Yukawa tensor Y_{ijk} = integral(omega_i ^ omega_j ^ Omega_k)\n\n**No speculative physics here** - just pure geometry extraction.\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 3.5: BREATHING LOSS (SOFT DIAGNOSTICS)\n# =============================================================================\n\ndef compute_breathing_loss(flux_net: NeckTransferNet,\n                           mode_proj: ModeProjection,\n                           modes: torch.Tensor,\n                           config: BreathingConfig) -> Tuple[torch.Tensor, Dict]:\n    \"\"\"\n    Compute breathing diagnostic losses.\n    \n    IMPORTANT: These are SOFT losses with SMALL weights.\n    They should NOT dominate the core geometric losses.\n    \n    Components:\n    - L_flux: (flux_integral - target_flux)^2\n    - L_ratio: (occupation_vis - target_visible_ratio)^2\n    - L_period: (T_est - target_period)^2 [optional, expensive]\n    \n    Args:\n        flux_net: NeckTransferNet module\n        mode_proj: ModeProjection module\n        modes: H3 modes of shape (batch, 77)\n        config: BreathingConfig with target values and weights\n    \n    Returns:\n        total_loss: Scalar tensor (or 0 if disabled)\n        info: Dictionary with all diagnostics\n    \"\"\"\n    device = modes.device\n    \n    if not config.enable:\n        return torch.tensor(0.0, device=device), {'breathing_enabled': False}\n    \n    # === Flux integral loss ===\n    flux_integral = flux_net.compute_flux_integral(n_points=100, device=device)\n    loss_flux = (flux_integral - config.target_flux) ** 2\n    \n    # === Occupation ratio loss ===\n    occupation_vis = mode_proj.compute_occupation_ratio(modes)\n    loss_ratio = (occupation_vis - config.target_visible_ratio) ** 2\n    \n    # === Period loss (simplified - just log, don't include in training) ===\n    # Period estimation is expensive and noisy, so we just track it\n    period_est = float('nan')  # Will be computed in post-hoc analysis\n    loss_period = torch.tensor(0.0, device=device)  # Not used in training\n    \n    # === Total breathing loss ===\n    total_loss = (\n        config.loss_weight_flux * loss_flux +\n        config.loss_weight_ratio * loss_ratio +\n        config.loss_weight_period * loss_period\n    )\n    \n    # Info dictionary\n    info = {\n        'breathing_enabled': True,\n        'total_breathing_loss': total_loss.item(),\n        'loss_flux': loss_flux.item(),\n        'loss_ratio': loss_ratio.item(),\n        'flux_integral': flux_integral.item(),\n        'flux_target': config.target_flux,\n        'flux_error': abs(flux_integral.item() - config.target_flux),\n        'occupation_vis': occupation_vis.item(),\n        'occupation_target': config.target_visible_ratio,\n        'occupation_error': abs(occupation_vis.item() - config.target_visible_ratio),\n        'period_est': period_est,\n        'period_target': config.target_period\n    }\n    \n    return total_loss, info\n\n\n# Test breathing loss\nbreathing_loss, breathing_info = compute_breathing_loss(\n    flux_net, mode_proj, test_modes, CONFIG.breathing\n)\nprint(f\"Breathing loss: {breathing_info['total_breathing_loss']:.6f}\")\nprint(f\"  Flux integral: {breathing_info['flux_integral']:.4f} (target: {breathing_info['flux_target']:.4f})\")\nprint(f\"  Occupation ratio: {breathing_info['occupation_vis']:.4f} (target: {breathing_info['occupation_target']:.4f})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 3.4: BREATHING PERIOD ESTIMATION\n# =============================================================================\n\ndef estimate_breathing_period(observable: torch.Tensor, lam: torch.Tensor,\n                               method: str = 'fft') -> Tuple[float, Dict]:\n    \"\"\"\n    Estimate the dominant period of an observable O(lambda) along the neck.\n    \n    Args:\n        observable: Shape (n_points,) - observable values at each lambda\n        lam: Shape (n_points,) - lambda values\n        method: 'fft' for FFT-based, 'fit' for sinusoidal fit\n    \n    Returns:\n        period: Estimated period\n        info: Additional information (amplitude, phase, etc.)\n    \"\"\"\n    n = len(lam)\n    device = observable.device\n    \n    # Move to CPU for numpy operations\n    O = observable.detach().cpu().numpy()\n    lam_np = lam.detach().cpu().numpy()\n    \n    if method == 'fft':\n        # FFT-based period estimation\n        O_centered = O - O.mean()\n        \n        # Compute FFT\n        fft = np.fft.rfft(O_centered)\n        freqs = np.fft.rfftfreq(n, d=(lam_np[-1] - lam_np[0]) / (n - 1))\n        \n        # Find dominant frequency (excluding DC)\n        magnitudes = np.abs(fft[1:])\n        if len(magnitudes) > 0 and magnitudes.max() > 1e-10:\n            dominant_idx = np.argmax(magnitudes) + 1\n            dominant_freq = freqs[dominant_idx]\n            period = 1.0 / dominant_freq if dominant_freq > 1e-10 else float('inf')\n        else:\n            period = float('inf')\n        \n        info = {\n            'method': 'fft',\n            'dominant_freq': dominant_freq if magnitudes.max() > 1e-10 else 0.0,\n            'amplitude': magnitudes.max() / n if len(magnitudes) > 0 else 0.0\n        }\n    \n    elif method == 'fit':\n        # Sinusoidal fit: O(lam) = A*cos(2*pi*lam/T + phi) + C\n        from scipy.optimize import curve_fit\n        \n        def sinusoid(x, A, T, phi, C):\n            return A * np.cos(2 * np.pi * x / T + phi) + C\n        \n        try:\n            # Initial guess\n            A0 = (O.max() - O.min()) / 2\n            T0 = 1.0\n            phi0 = 0.0\n            C0 = O.mean()\n            \n            popt, _ = curve_fit(sinusoid, lam_np, O, p0=[A0, T0, phi0, C0],\n                               bounds=([0, 0.1, -np.pi, -np.inf], [np.inf, 10, np.pi, np.inf]))\n            period = popt[1]\n            info = {\n                'method': 'fit',\n                'amplitude': popt[0],\n                'period': popt[1],\n                'phase': popt[2],\n                'offset': popt[3]\n            }\n        except:\n            period = float('inf')\n            info = {'method': 'fit', 'error': 'fit_failed'}\n    \n    else:\n        raise ValueError(f\"Unknown method: {method}\")\n    \n    return period, info\n\n\ndef compute_breathing_observable(modes: torch.Tensor, coords: torch.Tensor,\n                                  mode_proj: ModeProjection) -> torch.Tensor:\n    \"\"\"\n    Compute breathing observable O(lambda) = <|a_vis|^2 - |a_hid|^2>.\n    \n    This tracks the \"breathing\" between visible and hidden sectors.\n    \"\"\"\n    a_vis, a_hid = mode_proj(modes)\n    \n    vis_energy = (a_vis ** 2).sum(dim=1)\n    hid_energy = (a_hid ** 2).sum(dim=1)\n    \n    return vis_energy - hid_energy\n\n\n# Test period estimation\nn_test_pts = 50\ntest_lam_dense = torch.linspace(0, 1, n_test_pts, device=DEVICE)\n# Create synthetic oscillation for testing\ntest_observable = torch.sin(2 * np.pi * test_lam_dense / 0.4) + 0.1 * torch.randn(n_test_pts, device=DEVICE)\n\nperiod_est, period_info = estimate_breathing_period(test_observable, test_lam_dense, method='fft')\nprint(f\"Estimated period: {period_est:.4f} (synthetic input: 0.4)\")\nprint(f\"Period info: {period_info}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 3.3: NECK TRANSFER NETWORK (FLUX)\n# =============================================================================\n\nclass NeckTransferNet(nn.Module):\n    \"\"\"\n    Small network that models flux/transfer between visible and hidden modes\n    along the TCS neck coordinate lambda.\n    \n    Output: flux(lambda) representing transfer rate from visible to hidden.\n    \"\"\"\n    \n    def __init__(self, hidden_dim: int = 32):\n        super().__init__()\n        \n        self.net = nn.Sequential(\n            nn.Linear(1, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, 1)\n        )\n        \n        # Initialize for small outputs\n        for layer in self.net:\n            if isinstance(layer, nn.Linear):\n                nn.init.xavier_uniform_(layer.weight, gain=0.1)\n                nn.init.zeros_(layer.bias)\n    \n    def forward(self, lam: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute flux at given lambda values.\n        \n        Args:\n            lam: Shape (batch,) or (batch, 1)\n        \n        Returns:\n            flux: Shape (batch,) - flux values (can be positive or negative)\n        \"\"\"\n        if lam.dim() == 1:\n            lam = lam.unsqueeze(-1)\n        \n        flux = self.net(lam).squeeze(-1)\n        return flux\n    \n    def compute_flux_integral(self, n_points: int = 100, device: torch.device = None) -> torch.Tensor:\n        \"\"\"\n        Numerically integrate flux over [0, 1].\n        \n        Target: -1/2 (from GIFT -1/p2 conjecture)\n        \n        Returns:\n            flux_integral: Scalar tensor\n        \"\"\"\n        if device is None:\n            device = next(self.parameters()).device\n        \n        # Sample lambda uniformly\n        lam = torch.linspace(0, 1, n_points, device=device)\n        \n        # Compute flux at each point\n        flux = self.forward(lam)\n        \n        # Trapezoidal integration\n        dx = 1.0 / (n_points - 1)\n        integral = (flux[:-1] + flux[1:]).sum() * dx / 2\n        \n        return integral\n\n\n# Test NeckTransferNet\nflux_net = NeckTransferNet().to(DEVICE)\ntest_lam = torch.linspace(0, 1, 20, device=DEVICE)\ntest_flux = flux_net(test_lam)\nflux_integral = flux_net.compute_flux_integral()\n\nprint(f\"Flux shape: {test_flux.shape}\")\nprint(f\"Flux range: [{test_flux.min():.4f}, {test_flux.max():.4f}]\")\nprint(f\"Flux integral: {flux_integral.item():.4f} (target: -0.5)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 3.2: VISIBLE/HIDDEN MODE SPLIT\n# =============================================================================\n\nclass ModeProjection(nn.Module):\n    \"\"\"\n    Project H3 modes into visible and hidden subspaces.\n    \n    Default split: 43 visible / 34 hidden (from GIFT conjecture).\n    This is CONFIGURABLE - the split is a hypothesis to be tested, not imposed.\n    \"\"\"\n    \n    def __init__(self, n_total: int = 77, n_visible: int = 43, learnable: bool = False):\n        super().__init__()\n        self.n_total = n_total\n        self.n_visible = n_visible\n        self.n_hidden = n_total - n_visible  # 34\n        \n        if learnable:\n            # Learnable projection (orthogonal initialization)\n            P_vis = torch.eye(n_total)[:n_visible, :]  # (43, 77)\n            P_hid = torch.eye(n_total)[n_visible:, :]  # (34, 77)\n            self.P_vis = nn.Parameter(P_vis)\n            self.P_hid = nn.Parameter(P_hid)\n        else:\n            # Fixed projection (first n_visible modes are \"visible\")\n            self.register_buffer('P_vis', torch.eye(n_total)[:n_visible, :])\n            self.register_buffer('P_hid', torch.eye(n_total)[n_visible:, :])\n    \n    def forward(self, modes: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Project modes into visible and hidden subspaces.\n        \n        Args:\n            modes: Shape (batch, 77)\n        \n        Returns:\n            a_vis: Visible amplitudes (batch, 43)\n            a_hid: Hidden amplitudes (batch, 34)\n        \"\"\"\n        a_vis = modes @ self.P_vis.T  # (batch, 43)\n        a_hid = modes @ self.P_hid.T  # (batch, 34)\n        return a_vis, a_hid\n    \n    def compute_occupation_ratio(self, modes: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute visible occupation ratio: <|a_vis|^2> / <|a_vis|^2 + |a_hid|^2>\n        \n        Target: 43/77 ~ 0.558 (GIFT conjecture)\n        \"\"\"\n        a_vis, a_hid = self.forward(modes)\n        \n        vis_energy = (a_vis ** 2).mean()\n        hid_energy = (a_hid ** 2).mean()\n        \n        ratio = vis_energy / (vis_energy + hid_energy + 1e-8)\n        return ratio\n\n\n# Test mode projection\nmode_proj = ModeProjection(n_total=77, n_visible=43).to(DEVICE)\na_vis, a_hid = mode_proj(test_modes)\nratio = mode_proj.compute_occupation_ratio(test_modes)\nprint(f\"Visible amplitudes: {a_vis.shape}\")\nprint(f\"Hidden amplitudes: {a_hid.shape}\")\nprint(f\"Occupation ratio: {ratio.item():.4f} (target: {43/77:.4f})\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 3.1: H3 MODE EXTRACTION (SVD-ORTHONORMAL BASIS)\n# =============================================================================\n\nclass H3ModeExtractor(nn.Module):\n    \"\"\"\n    Extract H3 harmonic 3-form modes using SVD-orthonormal profiles.\n    \n    Based on v1.6 innovation: automatic extraction of 42 linearly-independent\n    global modes via eigendecomposition of candidate profile Gram matrix.\n    \n    Total H3 = 77 = 35 (local Lambda^3) + 42 (global TCS-induced)\n    \"\"\"\n    \n    def __init__(self, n_local: int = 35, n_global: int = 42):\n        super().__init__()\n        self.n_local = n_local\n        self.n_global = n_global\n        self.n_total = n_local + n_global  # 77\n        \n        # Candidate pool for global profiles (110 functions reduced to 42)\n        self.n_candidates = 110\n    \n    def compute_local_modes(self, phi: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Extract 35 local modes from Lambda^3 decomposition.\n        \n        These correspond to the algebraic decomposition:\n        Lambda^3(R^7) = 1 + 7 + 27 = 35 under G2\n        \n        Args:\n            phi: 3-form of shape (batch, 35)\n        \n        Returns:\n            local_modes: Shape (batch, 35)\n        \"\"\"\n        # Local modes are directly the phi components (already in Lambda^3 basis)\n        return phi\n    \n    def compute_global_profiles(self, coords: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Generate 110 candidate profile functions, then SVD-project to 42.\n        \n        Candidate pool (from v1.6 Supplement C):\n        1. Constant + lambda powers (5)\n        2. Coordinates x_i (7)\n        3. Region indicators (3)\n        4. Region x lambda powers (12)\n        5. Region x coordinates (21)\n        6. Antisymmetric M1-M2 (7)\n        7. Lambda x coordinates (7)\n        8. Coordinate products (21)\n        9. Fourier modes (8)\n        10. Fourier x region (12)\n        11. Radial terms (7)\n        \n        Args:\n            coords: Shape (batch, 7) in TCS format (lambda, xi_1, ..., xi_6)\n        \n        Returns:\n            profiles: Shape (batch, 42) - SVD-orthonormalized\n        \"\"\"\n        batch_size = coords.shape[0]\n        device = coords.device\n        \n        lam = coords[:, 0]  # Neck parameter\n        xi = coords[:, 1:]  # Transverse coordinates\n        \n        candidates = []\n        \n        # 1. Constant + lambda powers (5)\n        candidates.append(torch.ones(batch_size, device=device))\n        candidates.append(lam)\n        candidates.append(lam ** 2)\n        candidates.append(lam ** 3)\n        candidates.append(lam ** 4)\n        \n        # 2. Coordinates (7)\n        for i in range(7):\n            candidates.append(coords[:, i])\n        \n        # 3. Region indicators (3)\n        chi_L = torch.sigmoid(10 * (0.3 - lam))  # Left region\n        chi_R = torch.sigmoid(10 * (lam - 0.7))  # Right region\n        chi_neck = 1.0 - chi_L - chi_R           # Neck region\n        candidates.extend([chi_L, chi_R, chi_neck])\n        \n        # 4. Region x lambda powers (12)\n        for region in [chi_L, chi_R, chi_neck]:\n            for p in [1, 2, 3, 4]:\n                candidates.append(region * (lam ** p))\n        \n        # 5. Region x coordinates (21)\n        for region in [chi_L, chi_R, chi_neck]:\n            for i in range(7):\n                candidates.append(region * coords[:, i])\n        \n        # 6. Antisymmetric (7) - sign flip between L and R\n        for i in range(6):\n            candidates.append((chi_L - chi_R) * xi[:, i])\n        candidates.append((chi_L - chi_R) * lam)\n        \n        # 7. Lambda x coordinates (7)\n        for i in range(7):\n            candidates.append(lam * coords[:, i])\n        \n        # 8. Coordinate products (21)\n        for i in range(6):\n            for j in range(i+1, 6):\n                candidates.append(xi[:, i] * xi[:, j])\n        \n        # 9. Fourier modes (8)\n        for k in [1, 2]:\n            candidates.append(torch.sin(2 * np.pi * k * lam))\n            candidates.append(torch.cos(2 * np.pi * k * lam))\n            candidates.append(torch.sin(np.pi * k * lam))\n            candidates.append(torch.cos(np.pi * k * lam))\n        \n        # 10. Fourier x region (12)\n        for region in [chi_L, chi_R, chi_neck]:\n            for k in [1, 2]:\n                candidates.append(region * torch.sin(2 * np.pi * k * lam))\n                candidates.append(region * torch.cos(2 * np.pi * k * lam))\n        \n        # 11. Radial terms (7)\n        r_sq = (xi ** 2).sum(dim=1)\n        candidates.append(r_sq)\n        for i in range(6):\n            candidates.append(xi[:, i] ** 2)\n        \n        # Stack candidates: (batch, n_candidates)\n        F = torch.stack(candidates, dim=1)\n        \n        # SVD projection to 42 dimensions\n        # Compute Gram matrix and project\n        G = F.T @ F / batch_size  # (n_candidates, n_candidates)\n        \n        # Eigendecomposition\n        eigvals, eigvecs = torch.linalg.eigh(G)\n        \n        # Take top 42 eigenvectors (highest eigenvalues)\n        V_42 = eigvecs[:, -self.n_global:]  # (n_candidates, 42)\n        \n        # Project to 42-dimensional space\n        profiles = F @ V_42  # (batch, 42)\n        \n        # Normalize each profile\n        profiles = profiles / (torch.norm(profiles, dim=0, keepdim=True) + 1e-8)\n        \n        return profiles\n    \n    def forward(self, phi: torch.Tensor, coords: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Extract all 77 H3 modes.\n        \n        Returns:\n            modes: Shape (batch, 77) - [35 local, 42 global]\n        \"\"\"\n        local_modes = self.compute_local_modes(phi)  # (batch, 35)\n        global_profiles = self.compute_global_profiles(coords)  # (batch, 42)\n        \n        return torch.cat([local_modes, global_profiles], dim=1)\n\n\n# Test H3 mode extraction\nh3_extractor = H3ModeExtractor().to(DEVICE)\ntest_modes = h3_extractor(phi_test, test_coords)\nprint(f\"H3 modes shape: {test_modes.shape} (expected: (16, 77))\")\nprint(f\"Local modes: {test_modes[:, :35].shape}\")\nprint(f\"Global profiles: {test_modes[:, 35:].shape}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section 3: Breathing / Flux Module\n\nThis section implements speculative diagnostics for visible/hidden mode transfer:\n- Mode extraction from H3 (77 harmonic 3-forms)\n- Visible/hidden split (43/34 by default)\n- Flux network along TCS neck\n- Period estimation via FFT/fitting\n\n**IMPORTANT**: These are SOFT diagnostics with small-weight losses.\nThey do NOT dominate the core geometry training.\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 2.5: CORE LOSS FUNCTION\n# =============================================================================\n\ndef compute_core_loss(phi: torch.Tensor, coords: torch.Tensor, \n                      config: GeometryConfig,\n                      weights: Optional[Dict[str, float]] = None) -> Tuple[torch.Tensor, Dict]:\n    \"\"\"\n    Compute the core geometric loss for G2 structure.\n    \n    L_core = L_torsion + L_det_g + L_kappa_T + L_positivity\n    \n    This is the RIGOROUS geometric part that must not be dominated by speculative losses.\n    \n    Args:\n        phi: 3-form of shape (batch, 35)\n        coords: Coordinates of shape (batch, 7)\n        config: GeometryConfig with target values\n        weights: Optional weight dictionary\n    \n    Returns:\n        total_loss: Scalar tensor\n        info: Dictionary with all loss components\n    \"\"\"\n    if weights is None:\n        weights = {\n            'torsion': 100.0,\n            'kappa_T_abs': 200.0,\n            'kappa_T_rel': 500.0,\n            'det_g': 50.0,\n            'positivity': 10.0,\n            'phi_norm': 1.0\n        }\n    \n    # Build metric from phi\n    metric = metric_from_phi(phi)\n    metric = project_spd(metric)\n    \n    # === Torsion loss ===\n    torsion_info = compute_torsion(phi, coords, metric)\n    kappa_T = torsion_info['kappa_T']\n    \n    # Absolute error from target\n    loss_kappa_abs = (kappa_T - config.target_kappa_T) ** 2\n    \n    # Relative error (prevents divergence past target)\n    loss_kappa_rel = (kappa_T / config.target_kappa_T - 1.0) ** 2\n    \n    # Raw torsion penalty\n    loss_torsion = torsion_info['torsion_total'].mean()\n    \n    # === Metric determinant loss ===\n    det_g = compute_det_g(metric)\n    loss_det_g = ((det_g - config.target_det_g) ** 2).mean()\n    \n    # === Positivity loss (eigenvalue penalty) ===\n    eigenvalues = torch.linalg.eigvalsh(metric)\n    loss_positivity = torch.relu(1e-4 - eigenvalues).mean()\n    \n    # === Phi normalization (||phi||^2 = 7) ===\n    phi_norm_sq = (phi ** 2).sum(dim=1)\n    loss_phi_norm = ((phi_norm_sq - 7.0) ** 2).mean()\n    \n    # === Total loss ===\n    total_loss = (\n        weights['torsion'] * loss_torsion +\n        weights['kappa_T_abs'] * loss_kappa_abs +\n        weights['kappa_T_rel'] * loss_kappa_rel +\n        weights['det_g'] * loss_det_g +\n        weights['positivity'] * loss_positivity +\n        weights['phi_norm'] * loss_phi_norm\n    )\n    \n    # Info dictionary\n    info = {\n        'total_loss': total_loss.item(),\n        'loss_torsion': loss_torsion.item(),\n        'loss_kappa_abs': loss_kappa_abs.item(),\n        'loss_kappa_rel': loss_kappa_rel.item(),\n        'loss_det_g': loss_det_g.item(),\n        'loss_positivity': loss_positivity.item(),\n        'loss_phi_norm': loss_phi_norm.item(),\n        'kappa_T': kappa_T.item(),\n        'kappa_T_target': config.target_kappa_T,\n        'kappa_T_error_pct': abs(kappa_T.item() - config.target_kappa_T) / config.target_kappa_T * 100,\n        'det_g_mean': det_g.mean().item(),\n        'det_g_target': config.target_det_g,\n        'det_g_error_pct': abs(det_g.mean().item() - config.target_det_g) / config.target_det_g * 100,\n        'phi_norm_sq_mean': phi_norm_sq.mean().item(),\n        'min_eigenvalue': eigenvalues.min().item()\n    }\n    \n    return total_loss, info\n\n\n# Test core loss\nloss, info = compute_core_loss(phi_test, coords_grad, CONFIG.geometry)\nprint(f\"Core loss: {info['total_loss']:.4f}\")\nprint(f\"  kappa_T: {info['kappa_T']:.6f} (error: {info['kappa_T_error_pct']:.2f}%)\")\nprint(f\"  det(g): {info['det_g_mean']:.4f} (error: {info['det_g_error_pct']:.2f}%)\")\nprint(f\"  min eigenvalue: {info['min_eigenvalue']:.6f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 2.4: EXTERIOR DERIVATIVES AND TORSION\n# =============================================================================\n\ndef exterior_derivative_3form(phi: torch.Tensor, coords: torch.Tensor,\n                               create_graph: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Compute exterior derivative d(phi) using automatic differentiation.\n    \n    For 3-form phi in 7D: d(phi) is a 4-form with C(7,4) = 35 components.\n    \n    Args:\n        phi: 3-form of shape (batch, 35)\n        coords: Coordinates of shape (batch, 7) - must have requires_grad\n        create_graph: Whether to create computation graph for higher derivatives\n    \n    Returns:\n        d_phi: 4-form of shape (batch, 35)\n        d_phi_norm_sq: ||d(phi)||^2 of shape (batch,)\n    \"\"\"\n    batch_size = phi.shape[0]\n    device = phi.device\n    \n    if not coords.requires_grad:\n        coords = coords.requires_grad_(True)\n    \n    d_phi = torch.zeros(batch_size, 35, device=device)\n    \n    for comp_idx in range(35):\n        grad_outputs = torch.ones_like(phi[:, comp_idx])\n        \n        grads = torch.autograd.grad(\n            outputs=phi[:, comp_idx],\n            inputs=coords,\n            grad_outputs=grad_outputs,\n            create_graph=create_graph,\n            retain_graph=True,\n            allow_unused=True\n        )[0]\n        \n        if grads is not None:\n            d_phi[:, comp_idx] = torch.norm(grads, dim=1)\n    \n    d_phi_norm_sq = torch.sum(d_phi ** 2, dim=1)\n    return d_phi, d_phi_norm_sq\n\n\ndef hodge_star_3form(phi: torch.Tensor, metric: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Compute Hodge dual *phi: 3-form -> 4-form.\n    \n    Simplified computation using volume scaling.\n    Full computation requires Levi-Civita tensor contractions.\n    \n    Args:\n        phi: 3-form of shape (batch, 35)\n        metric: Metric tensor of shape (batch, 7, 7)\n    \n    Returns:\n        phi_dual: 4-form of shape (batch, 35)\n    \"\"\"\n    vol = volume_form(metric).unsqueeze(-1)\n    \n    # Simplified: scale phi by volume\n    phi_dual = phi * vol\n    \n    # Normalize to preserve structure\n    phi_dual_norm = torch.norm(phi_dual, dim=1, keepdim=True)\n    phi_dual = phi_dual / (phi_dual_norm + 1e-8) * np.sqrt(7.0)\n    \n    return phi_dual\n\n\ndef compute_torsion(phi: torch.Tensor, coords: torch.Tensor, \n                    metric: torch.Tensor) -> Dict[str, torch.Tensor]:\n    \"\"\"\n    Compute G2 torsion: ||d(phi)||^2 + ||d(*phi)||^2.\n    \n    For torsion-free G2: both terms should be zero.\n    \n    Returns:\n        Dictionary with torsion components and total\n    \"\"\"\n    # d(phi)\n    d_phi, d_phi_norm_sq = exterior_derivative_3form(phi, coords)\n    \n    # *phi (Hodge dual)\n    phi_dual = hodge_star_3form(phi, metric)\n    \n    # d(*phi)\n    d_phi_dual, d_phi_dual_norm_sq = exterior_derivative_3form(phi_dual, coords)\n    \n    # Total torsion\n    torsion_total = d_phi_norm_sq + d_phi_dual_norm_sq\n    \n    return {\n        'd_phi_norm_sq': d_phi_norm_sq,\n        'd_phi_dual_norm_sq': d_phi_dual_norm_sq,\n        'torsion_total': torsion_total,\n        'kappa_T': torsion_total.mean()  # Scalar torsion magnitude\n    }\n\n\n# Test torsion computation\ncoords_grad = test_coords.clone().requires_grad_(True)\nphi_test = phi_net(coords_grad)\nmetric_test = project_spd(metric_from_phi(phi_test))\n\ntorsion_info = compute_torsion(phi_test, coords_grad, metric_test)\nprint(f\"Torsion ||d(phi)||^2: {torsion_info['d_phi_norm_sq'].mean():.6f}\")\nprint(f\"Torsion ||d(*phi)||^2: {torsion_info['d_phi_dual_norm_sq'].mean():.6f}\")\nprint(f\"kappa_T (mean torsion): {torsion_info['kappa_T']:.6f}\")\nprint(f\"Target kappa_T: {1/61:.6f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 2.3: METRIC RECONSTRUCTION FROM PHI\n# =============================================================================\n\ndef build_triple_to_idx() -> Dict[Tuple[int,int,int], int]:\n    \"\"\"Build mapping from (i,j,k) triple to phi component index.\"\"\"\n    triple_to_idx = {}\n    idx = 0\n    for i in range(7):\n        for j in range(i+1, 7):\n            for k in range(j+1, 7):\n                triple_to_idx[(i, j, k)] = idx\n                idx += 1\n    return triple_to_idx\n\nTRIPLE_TO_IDX = build_triple_to_idx()\n\n\ndef metric_from_phi(phi: torch.Tensor, epsilon: float = 1e-6) -> torch.Tensor:\n    \"\"\"\n    Reconstruct metric g_ij from G2 3-form phi.\n    \n    Uses the approximate algebraic relation that captures G2 structure.\n    The exact formula involves Levi-Civita contractions (very expensive).\n    \n    Args:\n        phi: 3-form of shape (batch, 35)\n        epsilon: Regularization for numerical stability\n    \n    Returns:\n        metric: Shape (batch, 7, 7) - symmetric positive definite\n    \"\"\"\n    batch_size = phi.shape[0]\n    device = phi.device\n    \n    metric = torch.zeros(batch_size, 7, 7, device=device)\n    \n    # Phi norm for scaling\n    phi_norm = torch.norm(phi, dim=1, keepdim=True)\n    \n    # Diagonal: g_ii ~ sum_jk phi_ijk^2\n    for i in range(7):\n        contrib = torch.zeros(batch_size, device=device)\n        for j in range(7):\n            for k in range(j+1, 7):\n                if j != i and k != i:\n                    triple = tuple(sorted([i, j, k]))\n                    if triple in TRIPLE_TO_IDX:\n                        contrib += phi[:, TRIPLE_TO_IDX[triple]] ** 2\n        metric[:, i, i] = torch.sqrt(contrib + epsilon) / np.sqrt(5.0)\n    \n    # Off-diagonal: g_ij ~ sum_k phi_ijk * normalization\n    for i in range(7):\n        for j in range(i+1, 7):\n            contrib = torch.zeros(batch_size, device=device)\n            count = 0\n            for k in range(7):\n                if k != i and k != j:\n                    triple = tuple(sorted([i, j, k]))\n                    if triple in TRIPLE_TO_IDX:\n                        contrib += phi[:, TRIPLE_TO_IDX[triple]] ** 2\n                        count += 1\n            if count > 0:\n                metric[:, i, j] = torch.sqrt(contrib / count + epsilon) * 0.1\n                metric[:, j, i] = metric[:, i, j]\n    \n    return metric\n\n\ndef project_spd(metric: torch.Tensor, epsilon: float = 1e-6) -> torch.Tensor:\n    \"\"\"Project metric to be symmetric positive definite via eigenvalue clamping.\"\"\"\n    # Ensure symmetry\n    metric = 0.5 * (metric + metric.transpose(-2, -1))\n    \n    # Eigendecomposition\n    eigenvalues, eigenvectors = torch.linalg.eigh(metric)\n    \n    # Clamp eigenvalues to be positive\n    eigenvalues = torch.clamp(eigenvalues, min=epsilon)\n    \n    # Reconstruct: M = V @ diag(lambda) @ V^T\n    return eigenvectors @ torch.diag_embed(eigenvalues) @ eigenvectors.transpose(-2, -1)\n\n\ndef compute_det_g(metric: torch.Tensor) -> torch.Tensor:\n    \"\"\"Compute metric determinant det(g).\"\"\"\n    return torch.det(metric)\n\n\ndef volume_form(metric: torch.Tensor) -> torch.Tensor:\n    \"\"\"Compute volume element sqrt(|det(g)|).\"\"\"\n    return torch.sqrt(torch.abs(torch.det(metric)) + 1e-10)\n\n\n# Test metric reconstruction\ntest_metric = metric_from_phi(test_phi)\ntest_metric_spd = project_spd(test_metric)\ntest_det = compute_det_g(test_metric_spd)\n\nprint(f\"Metric shape: {test_metric.shape}\")\nprint(f\"Metric symmetric: {torch.allclose(test_metric, test_metric.transpose(-2,-1), atol=1e-5)}\")\nprint(f\"det(g): mean={test_det.mean():.4f}, std={test_det.std():.4f}\")\nprint(f\"Target det(g): {65/32:.4f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 2.2: NEURAL NETWORK ARCHITECTURE\n# =============================================================================\n\nclass FourierFeatures(nn.Module):\n    \"\"\"Random Fourier features for periodic coordinate encoding.\"\"\"\n    \n    def __init__(self, input_dim: int = 7, n_modes: int = 32, scale: float = 1.0):\n        super().__init__()\n        self.input_dim = input_dim\n        self.n_modes = n_modes\n        self.output_dim = 2 * n_modes\n        \n        # Random frequency matrix (fixed, not trainable)\n        B = torch.randn(input_dim, n_modes) * scale\n        self.register_buffer('B', B)\n    \n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Map x to [cos(2*pi*B*x), sin(2*pi*B*x)].\"\"\"\n        proj = 2 * np.pi * torch.matmul(x, self.B)\n        return torch.cat([torch.cos(proj), torch.sin(proj)], dim=-1)\n\n\nclass PhiNetwork(nn.Module):\n    \"\"\"\n    Neural network for learning G2 3-form phi(x) on K7.\n    \n    Architecture:\n        Input: 7D coordinates -> Fourier encoding -> MLP -> 35 phi components\n    \n    The metric is reconstructed algebraically from phi.\n    \"\"\"\n    \n    def __init__(self, \n                 hidden_dims: List[int] = [256, 256, 128],\n                 fourier_modes: int = 32,\n                 fourier_scale: float = 1.0,\n                 normalize_phi: bool = True,\n                 dropout: float = 0.0):\n        super().__init__()\n        \n        self.normalize_phi = normalize_phi\n        self.input_dim = 7\n        self.output_dim = 35  # C(7,3) = 35 components for 3-form\n        \n        # Fourier encoding\n        self.encoding = FourierFeatures(\n            input_dim=7, \n            n_modes=fourier_modes,\n            scale=fourier_scale\n        )\n        \n        # MLP with LayerNorm and residual-friendly structure\n        layers = []\n        prev_dim = self.encoding.output_dim\n        \n        for h_dim in hidden_dims:\n            layers.append(nn.Linear(prev_dim, h_dim))\n            layers.append(nn.SiLU())\n            layers.append(nn.LayerNorm(h_dim))\n            if dropout > 0:\n                layers.append(nn.Dropout(dropout))\n            prev_dim = h_dim\n        \n        self.mlp = nn.Sequential(*layers)\n        \n        # Output layer\n        self.output_layer = nn.Linear(prev_dim, self.output_dim)\n        \n        # Initialize output with small weights for stability\n        with torch.no_grad():\n            self.output_layer.weight.mul_(0.01)\n            self.output_layer.bias.zero_()\n    \n    def forward(self, coords: torch.Tensor) -> torch.Tensor:\n        \"\"\"\n        Compute phi(x) at given coordinates.\n        \n        Args:\n            coords: Shape (batch, 7)\n        \n        Returns:\n            phi: Shape (batch, 35) - 3-form components\n        \"\"\"\n        # Encode coordinates\n        x = self.encoding(coords)\n        \n        # MLP\n        x = self.mlp(x)\n        \n        # Output phi\n        phi = self.output_layer(x)\n        \n        # Normalize: ||phi||^2 = 7 (G2 structure)\n        if self.normalize_phi:\n            phi_norm = torch.norm(phi, dim=-1, keepdim=True)\n            phi = phi * (np.sqrt(7.0) / (phi_norm + 1e-8))\n        \n        return phi\n    \n    @staticmethod\n    def get_phi_indices() -> List[Tuple[int, int, int]]:\n        \"\"\"Return mapping from component index to (i,j,k) triple.\"\"\"\n        indices = []\n        for i in range(7):\n            for j in range(i+1, 7):\n                for k in range(j+1, 7):\n                    indices.append((i, j, k))\n        return indices\n\n\n# Test PhiNetwork\nphi_net = PhiNetwork().to(DEVICE)\ntest_phi = phi_net(test_coords)\nprint(f\"Phi shape: {test_phi.shape}\")\nprint(f\"||phi||^2: {(test_phi**2).sum(dim=1).mean():.4f} (target: 7.0)\")\nprint(f\"Parameters: {sum(p.numel() for p in phi_net.parameters()):,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# =============================================================================\n# SECTION 2.1: COORDINATE SAMPLING\n# =============================================================================\n\ndef sample_T7_coords(batch_size: int, device: torch.device) -> torch.Tensor:\n    \"\"\"Sample uniformly on T^7 (7-torus with period 2*pi).\"\"\"\n    return torch.rand(batch_size, 7, device=device) * 2 * np.pi\n\n\ndef sample_TCS_coords(batch_size: int, device: torch.device,\n                      lambda_range: Tuple[float, float] = (0.0, 1.0)) -> torch.Tensor:\n    \"\"\"\n    Sample on TCS (Twisted Connected Sum) parameterization.\n    \n    Coordinates: (lambda, xi_1, ..., xi_6)\n    - lambda in [0, 1]: neck parameter\n    - xi_i in [0, 2*pi]: transverse coordinates\n    \n    Returns:\n        coords: Shape (batch, 7) with lambda as first coordinate\n    \"\"\"\n    coords = torch.zeros(batch_size, 7, device=device)\n    \n    # Neck coordinate lambda in [lambda_range]\n    coords[:, 0] = torch.rand(batch_size, device=device) * (lambda_range[1] - lambda_range[0]) + lambda_range[0]\n    \n    # Transverse coordinates xi_i in [0, 2*pi]\n    coords[:, 1:] = torch.rand(batch_size, 6, device=device) * 2 * np.pi\n    \n    return coords\n\n\ndef split_TCS_coords(coords: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Split TCS coordinates into neck and transverse components.\n    \n    Args:\n        coords: Shape (batch, 7) with format (lambda, xi_1, ..., xi_6)\n    \n    Returns:\n        lambda_coords: Shape (batch, 1) - neck parameter\n        transverse_coords: Shape (batch, 6) - transverse coordinates\n    \"\"\"\n    lambda_coords = coords[:, 0:1]\n    transverse_coords = coords[:, 1:]\n    return lambda_coords, transverse_coords\n\n\ndef sample_coords(batch_size: int, config: GeometryConfig, device: torch.device) -> torch.Tensor:\n    \"\"\"Unified coordinate sampling based on configuration.\"\"\"\n    if config.coordinate_type == \"T7\":\n        return sample_T7_coords(batch_size, device)\n    elif config.coordinate_type == \"TCS\":\n        return sample_TCS_coords(batch_size, device)\n    else:\n        raise ValueError(f\"Unknown coordinate type: {config.coordinate_type}\")\n\n\n# Test coordinate sampling\ntest_coords = sample_TCS_coords(16, DEVICE)\nlam, xi = split_TCS_coords(test_coords)\nprint(f\"TCS coords shape: {test_coords.shape}\")\nprint(f\"Lambda range: [{lam.min():.3f}, {lam.max():.3f}]\")\nprint(f\"Transverse range: [{xi.min():.3f}, {xi.max():.3f}]\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Section 2: Geometry Core (from v1.6)\n\nThis section contains the core geometric operations:\n- Coordinate sampling on T^7 / TCS\n- PhiNetwork for learning the G2 3-form\n- Metric reconstruction from phi\n- Exterior derivatives and Hodge star\n- Torsion-free conditions\n---",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K7 Breathing Mode PINN v1.8\n",
    "\n",
    "**Physics-Informed Neural Network for G2 Holonomy Metrics with Breathing/Flux Diagnostics**\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook extends v1.6 with:\n",
    "1. **Breathing/Flux Module**: Visible/hidden H3 mode decomposition along TCS neck\n",
    "2. **Yukawa Extraction**: Clean numerical computation of triple overlap integrals\n",
    "3. **Post-hoc Metric Fitting**: Analytic approximation of learned g_ij(x)\n",
    "\n",
    "## Design Principles\n",
    "\n",
    "- **Core geometry preserved**: All v1.6 topological targets (b2=21, b3=77, det(g)=65/32, kappa_T=1/61)\n",
    "- **Speculative quantities as diagnostics**: 43/77 ratio, -1/2 flux, tau period are SOFT probes\n",
    "- **Modular architecture**: Easy to disable breathing losses (weights=0) for pure geometry mode\n",
    "\n",
    "## References\n",
    "\n",
    "- v1.6: K7_GIFT_v1_6.ipynb (SVD-orthonormal harmonic basis)\n",
    "- GIFT Framework: publications/gift_2_2_main.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Imports and Configuration\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 1: IMPORTS AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from fractions import Fraction\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(\"outputs_v1_8\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "(OUTPUT_DIR / \"checkpoints\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT CONFIGURATION (Dataclass)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class GeometryConfig:\n",
    "    \"\"\"Configuration for K7 manifold geometry.\"\"\"\n",
    "    dim: int = 7\n",
    "    coordinate_type: str = \"TCS\"  # \"T7\" or \"TCS\"\n",
    "    has_neck: bool = True\n",
    "    \n",
    "    # Topological constants (from GIFT v2.2)\n",
    "    b2_K7: int = 21          # Second Betti number\n",
    "    b3_K7: int = 77          # Third Betti number\n",
    "    b3_local: int = 35       # Local Lambda^3 decomposition\n",
    "    b3_global: int = 42      # Global TCS-induced modes\n",
    "    dim_G2: int = 14         # dim(G2)\n",
    "    p2: int = 2              # Binary duality\n",
    "    \n",
    "    # Target metric invariants\n",
    "    target_det_g: float = 65/32      # = 2.03125\n",
    "    target_kappa_T: float = 1/61     # = 0.016393...\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BreathingConfig:\n",
    "    \"\"\"Configuration for breathing/flux diagnostics.\n",
    "    \n",
    "    IMPORTANT: These are SOFT diagnostics, not hard constraints.\n",
    "    The speculative values (43/77, -1/2, tau) are measured, not imposed.\n",
    "    \"\"\"\n",
    "    enable: bool = True\n",
    "    \n",
    "    # Speculative target values (for diagnostics only)\n",
    "    target_flux: float = -0.5              # -1/p2 hypothesis\n",
    "    target_visible_ratio: float = 43/77   # ~ 0.558\n",
    "    target_period: float = 3472/891       # tau = 3.896... (GIFT hierarchy parameter)\n",
    "    \n",
    "    # Loss weights (SMALL to avoid dominating geometry)\n",
    "    loss_weight_flux: float = 1e-3\n",
    "    loss_weight_ratio: float = 1e-3\n",
    "    loss_weight_period: float = 1e-4\n",
    "    \n",
    "    # Mode split configuration\n",
    "    n_visible: int = 43\n",
    "    n_hidden: int = 34  # 77 - 43\n",
    "    \n",
    "    # Neck parameterization\n",
    "    lambda_mid: float = 0.5  # Boundary between visible/hidden regions\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training hyperparameters.\"\"\"\n",
    "    # Phase 1: Geometry-only\n",
    "    n_epochs_core: int = 5000\n",
    "    lr_core: float = 1e-3\n",
    "    \n",
    "    # Phase 2: Geometry + breathing\n",
    "    n_epochs_breathing: int = 2000\n",
    "    lr_breathing: float = 5e-4\n",
    "    freeze_phi_in_breathing: bool = False  # If True, only train NeckTransferNet\n",
    "    \n",
    "    # General\n",
    "    batch_size: int = 2048\n",
    "    weight_decay: float = 1e-5\n",
    "    scheduler_patience: int = 500\n",
    "    scheduler_factor: float = 0.5\n",
    "    \n",
    "    # Gradient clipping\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LoggingConfig:\n",
    "    \"\"\"Logging and checkpointing configuration.\"\"\"\n",
    "    log_every: int = 100\n",
    "    save_checkpoints: bool = True\n",
    "    checkpoint_dir: str = \"outputs_v1_8/checkpoints\"\n",
    "    verbose: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Master configuration combining all sub-configs.\"\"\"\n",
    "    geometry: GeometryConfig = field(default_factory=GeometryConfig)\n",
    "    breathing: BreathingConfig = field(default_factory=BreathingConfig)\n",
    "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
    "    logging: LoggingConfig = field(default_factory=LoggingConfig)\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
    "        return {\n",
    "            'geometry': self.geometry.__dict__,\n",
    "            'breathing': self.breathing.__dict__,\n",
    "            'training': self.training.__dict__,\n",
    "            'logging': self.logging.__dict__\n",
    "        }\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save configuration to JSON file.\"\"\"\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.to_dict(), f, indent=2)\n",
    "\n",
    "\n",
    "# Create default configuration\n",
    "CONFIG = ExperimentConfig()\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Geometry: dim={CONFIG.geometry.dim}, b2={CONFIG.geometry.b2_K7}, b3={CONFIG.geometry.b3_K7}\")\n",
    "print(f\"  Breathing: enabled={CONFIG.breathing.enable}, target_flux={CONFIG.breathing.target_flux}\")\n",
    "print(f\"  Training: core_epochs={CONFIG.training.n_epochs_core}, batch={CONFIG.training.batch_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}