{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# K7 Breathing Mode PINN v1.8\n\n**Physics-Informed Neural Network for G2 Holonomy Metrics with Breathing/Flux Diagnostics**\n\n## Overview\n\nThis notebook extends v1.6 with:\n1. **Breathing/Flux Module**: Visible/hidden H3 mode decomposition along TCS neck\n2. **Yukawa Extraction**: Clean numerical computation of triple overlap integrals\n3. **Post-hoc Metric Fitting**: Analytic approximation of learned g_ij(x)\n\n## Design Principles\n\n- **Core geometry preserved**: All v1.6 topological targets (b2=21, b3=77, det(g)=65/32, kappa_T=1/61)\n- **Speculative quantities as diagnostics**: 43/77 ratio, -1/2 flux, tau period are SOFT probes\n- **Modular architecture**: Easy to disable breathing losses (weights=0) for pure geometry mode\n\n## References\n\n- v1.6: K7_GIFT_v1_6.ipynb (SVD-orthonormal harmonic basis)\n- GIFT Framework: publications/gift_2_2_main.md"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 1: Imports and Configuration",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 1: IMPORTS AND CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from fractions import Fraction\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = Path(\"outputs_v1_8\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "(OUTPUT_DIR / \"checkpoints\").mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPERIMENT CONFIGURATION (Dataclass)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class GeometryConfig:\n",
    "    \"\"\"Configuration for K7 manifold geometry.\"\"\"\n",
    "    dim: int = 7\n",
    "    coordinate_type: str = \"TCS\"  # \"T7\" or \"TCS\"\n",
    "    has_neck: bool = True\n",
    "    \n",
    "    # Topological constants (from GIFT v2.2)\n",
    "    b2_K7: int = 21          # Second Betti number\n",
    "    b3_K7: int = 77          # Third Betti number\n",
    "    b3_local: int = 35       # Local Lambda^3 decomposition\n",
    "    b3_global: int = 42      # Global TCS-induced modes\n",
    "    dim_G2: int = 14         # dim(G2)\n",
    "    p2: int = 2              # Binary duality\n",
    "    \n",
    "    # Target metric invariants\n",
    "    target_det_g: float = 65/32      # = 2.03125\n",
    "    target_kappa_T: float = 1/61     # = 0.016393...\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class BreathingConfig:\n",
    "    \"\"\"Configuration for breathing/flux diagnostics.\n",
    "    \n",
    "    IMPORTANT: These are SOFT diagnostics, not hard constraints.\n",
    "    The speculative values (43/77, -1/2, tau) are measured, not imposed.\n",
    "    \"\"\"\n",
    "    enable: bool = True\n",
    "    \n",
    "    # Speculative target values (for diagnostics only)\n",
    "    target_flux: float = -0.5              # -1/p2 hypothesis\n",
    "    target_visible_ratio: float = 43/77   # ~ 0.558\n",
    "    target_period: float = 3472/891       # tau = 3.896... (GIFT hierarchy parameter)\n",
    "    \n",
    "    # Loss weights (SMALL to avoid dominating geometry)\n",
    "    loss_weight_flux: float = 1e-3\n",
    "    loss_weight_ratio: float = 1e-3\n",
    "    loss_weight_period: float = 1e-4\n",
    "    \n",
    "    # Mode split configuration\n",
    "    n_visible: int = 43\n",
    "    n_hidden: int = 34  # 77 - 43\n",
    "    \n",
    "    # Neck parameterization\n",
    "    lambda_mid: float = 0.5  # Boundary between visible/hidden regions\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training hyperparameters.\"\"\"\n",
    "    # Phase 1: Geometry-only\n",
    "    n_epochs_core: int = 5000\n",
    "    lr_core: float = 1e-3\n",
    "    \n",
    "    # Phase 2: Geometry + breathing\n",
    "    n_epochs_breathing: int = 2000\n",
    "    lr_breathing: float = 5e-4\n",
    "    freeze_phi_in_breathing: bool = False\n",
    "    \n",
    "    # General\n",
    "    batch_size: int = 2048\n",
    "    weight_decay: float = 1e-5\n",
    "    scheduler_patience: int = 500\n",
    "    scheduler_factor: float = 0.5\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LoggingConfig:\n",
    "    \"\"\"Logging and checkpointing configuration.\"\"\"\n",
    "    log_every: int = 100\n",
    "    save_checkpoints: bool = True\n",
    "    checkpoint_dir: str = \"outputs_v1_8/checkpoints\"\n",
    "    verbose: bool = True\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ExperimentConfig:\n",
    "    \"\"\"Master configuration combining all sub-configs.\"\"\"\n",
    "    geometry: GeometryConfig = field(default_factory=GeometryConfig)\n",
    "    breathing: BreathingConfig = field(default_factory=BreathingConfig)\n",
    "    training: TrainingConfig = field(default_factory=TrainingConfig)\n",
    "    logging: LoggingConfig = field(default_factory=LoggingConfig)\n",
    "    \n",
    "    def to_dict(self) -> Dict:\n",
    "        return {\n",
    "            'geometry': self.geometry.__dict__,\n",
    "            'breathing': self.breathing.__dict__,\n",
    "            'training': self.training.__dict__,\n",
    "            'logging': self.logging.__dict__\n",
    "        }\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(self.to_dict(), f, indent=2)\n",
    "\n",
    "\n",
    "# Create default configuration\n",
    "CONFIG = ExperimentConfig()\n",
    "print(\"Configuration loaded:\")\n",
    "print(f\"  Geometry: dim={CONFIG.geometry.dim}, b2={CONFIG.geometry.b2_K7}, b3={CONFIG.geometry.b3_K7}\")\n",
    "print(f\"  Breathing: enabled={CONFIG.breathing.enable}, target_flux={CONFIG.breathing.target_flux}\")\n",
    "print(f\"  Training: core_epochs={CONFIG.training.n_epochs_core}, batch={CONFIG.training.batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 2: Geometry Core (from v1.6)",
    "",
    "This section contains the core geometric operations:",
    "- Coordinate sampling on T^7 / TCS",
    "- PhiNetwork for learning the G2 3-form",
    "- Metric reconstruction from phi",
    "- Exterior derivatives and Hodge star",
    "- Torsion-free conditions",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2.1: COORDINATE SAMPLING\n",
    "# =============================================================================\n",
    "\n",
    "def sample_T7_coords(batch_size: int, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Sample uniformly on T^7 (7-torus with period 2*pi).\"\"\"\n",
    "    return torch.rand(batch_size, 7, device=device) * 2 * np.pi\n",
    "\n",
    "\n",
    "def sample_TCS_coords(batch_size: int, device: torch.device,\n",
    "                      lambda_range: Tuple[float, float] = (0.0, 1.0)) -> torch.Tensor:\n",
    "    \"\"\"Sample on TCS (Twisted Connected Sum) parameterization.\"\"\"\n",
    "    coords = torch.zeros(batch_size, 7, device=device)\n",
    "    coords[:, 0] = torch.rand(batch_size, device=device) * (lambda_range[1] - lambda_range[0]) + lambda_range[0]\n",
    "    coords[:, 1:] = torch.rand(batch_size, 6, device=device) * 2 * np.pi\n",
    "    return coords\n",
    "\n",
    "\n",
    "def split_TCS_coords(coords: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Split TCS coordinates into neck (lambda) and transverse (xi) components.\"\"\"\n",
    "    return coords[:, 0:1], coords[:, 1:]\n",
    "\n",
    "\n",
    "def sample_coords(batch_size: int, config: GeometryConfig, device: torch.device) -> torch.Tensor:\n",
    "    \"\"\"Unified coordinate sampling based on configuration.\"\"\"\n",
    "    if config.coordinate_type == \"T7\":\n",
    "        return sample_T7_coords(batch_size, device)\n",
    "    elif config.coordinate_type == \"TCS\":\n",
    "        return sample_TCS_coords(batch_size, device)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown coordinate type: {config.coordinate_type}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "test_coords = sample_TCS_coords(16, DEVICE)\n",
    "lam, xi = split_TCS_coords(test_coords)\n",
    "print(f\"TCS coords shape: {test_coords.shape}, lambda: [{lam.min():.3f}, {lam.max():.3f}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2.2: NEURAL NETWORK ARCHITECTURE\n",
    "# =============================================================================\n",
    "\n",
    "class FourierFeatures(nn.Module):\n",
    "    \"\"\"Random Fourier features for periodic coordinate encoding.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim: int = 7, n_modes: int = 32, scale: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.n_modes = n_modes\n",
    "        self.output_dim = 2 * n_modes\n",
    "        B = torch.randn(input_dim, n_modes) * scale\n",
    "        self.register_buffer('B', B)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        proj = 2 * np.pi * torch.matmul(x, self.B)\n",
    "        return torch.cat([torch.cos(proj), torch.sin(proj)], dim=-1)\n",
    "\n",
    "\n",
    "class PhiNetwork(nn.Module):\n",
    "    \"\"\"Neural network for learning G2 3-form phi(x) on K7.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dims: List[int] = [256, 256, 128],\n",
    "                 fourier_modes: int = 32, normalize_phi: bool = True):\n",
    "        super().__init__()\n",
    "        self.normalize_phi = normalize_phi\n",
    "        self.output_dim = 35  # C(7,3) components\n",
    "        \n",
    "        self.encoding = FourierFeatures(input_dim=7, n_modes=fourier_modes)\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = self.encoding.output_dim\n",
    "        for h_dim in hidden_dims:\n",
    "            layers.extend([nn.Linear(prev_dim, h_dim), nn.SiLU(), nn.LayerNorm(h_dim)])\n",
    "            prev_dim = h_dim\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "        \n",
    "        self.output_layer = nn.Linear(prev_dim, self.output_dim)\n",
    "        with torch.no_grad():\n",
    "            self.output_layer.weight.mul_(0.01)\n",
    "            self.output_layer.bias.zero_()\n",
    "    \n",
    "    def forward(self, coords: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.encoding(coords)\n",
    "        x = self.mlp(x)\n",
    "        phi = self.output_layer(x)\n",
    "        if self.normalize_phi:\n",
    "            phi = phi * (np.sqrt(7.0) / (torch.norm(phi, dim=-1, keepdim=True) + 1e-8))\n",
    "        return phi\n",
    "\n",
    "\n",
    "# Test\n",
    "phi_net = PhiNetwork().to(DEVICE)\n",
    "test_phi = phi_net(test_coords)\n",
    "print(f\"Phi shape: {test_phi.shape}, ||phi||^2: {(test_phi**2).sum(dim=1).mean():.4f} (target: 7.0)\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in phi_net.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SECTION 2.3: METRIC RECONSTRUCTION FROM PHI\n# =============================================================================\n\ndef build_triple_to_idx() -> Dict[Tuple[int,int,int], int]:\n    \"\"\"Build mapping from (i,j,k) triple to phi component index.\"\"\"\n    triple_to_idx = {}\n    idx = 0\n    for i in range(7):\n        for j in range(i+1, 7):\n            for k in range(j+1, 7):\n                triple_to_idx[(i, j, k)] = idx\n                idx += 1\n    return triple_to_idx\n\nTRIPLE_TO_IDX = build_triple_to_idx()\n\n# Target determinant from GIFT v2.2 (topological constant)\nTARGET_DET_G = 65/32  # = 2.03125\n\n\ndef metric_from_phi(phi: torch.Tensor, epsilon: float = 1e-6) -> torch.Tensor:\n    \"\"\"Reconstruct metric g_ij from G2 3-form phi (approximate).\n    \n    Includes scaling to achieve target det(g) = 65/32.\n    \"\"\"\n    batch_size, device = phi.shape[0], phi.device\n    metric = torch.zeros(batch_size, 7, 7, device=device)\n    \n    # Diagonal components\n    for i in range(7):\n        contrib = sum(phi[:, TRIPLE_TO_IDX[tuple(sorted([i,j,k]))]]**2 \n                     for j in range(7) for k in range(j+1,7) \n                     if j!=i and k!=i and tuple(sorted([i,j,k])) in TRIPLE_TO_IDX)\n        metric[:, i, i] = torch.sqrt(contrib + epsilon) / np.sqrt(5.0)\n    \n    # Off-diagonal components\n    for i in range(7):\n        for j in range(i+1, 7):\n            contrib = sum(phi[:, TRIPLE_TO_IDX[tuple(sorted([i,j,k]))]]**2 \n                         for k in range(7) if k!=i and k!=j and tuple(sorted([i,j,k])) in TRIPLE_TO_IDX)\n            metric[:, i, j] = metric[:, j, i] = torch.sqrt(contrib/5 + epsilon) * 0.1\n    \n    # Scale metric to achieve target det(g) = 65/32\n    # For 7x7 matrix: det(s*M) = s^7 * det(M), so s = (target/det)^(1/7)\n    det_g = torch.det(metric)\n    scale = (TARGET_DET_G / (det_g.abs() + 1e-8)) ** (1.0/7.0)\n    metric = metric * scale.unsqueeze(-1).unsqueeze(-1)\n    \n    return metric\n\n\ndef project_spd(metric: torch.Tensor, epsilon: float = 1e-6) -> torch.Tensor:\n    \"\"\"Project metric to symmetric positive definite.\"\"\"\n    metric = 0.5 * (metric + metric.transpose(-2, -1))\n    eigvals, eigvecs = torch.linalg.eigh(metric)\n    eigvals = torch.clamp(eigvals, min=epsilon)\n    return eigvecs @ torch.diag_embed(eigvals) @ eigvecs.transpose(-2, -1)\n\n\ndef compute_det_g(metric: torch.Tensor) -> torch.Tensor:\n    return torch.det(metric)\n\n\ndef volume_form(metric: torch.Tensor) -> torch.Tensor:\n    return torch.sqrt(torch.abs(torch.det(metric)) + 1e-10)\n\n\n# Test\ntest_metric = project_spd(metric_from_phi(test_phi))\nprint(f\"Metric shape: {test_metric.shape}, det(g): {compute_det_g(test_metric).mean():.4f} (target: {65/32:.4f})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2.4: EXTERIOR DERIVATIVES AND TORSION\n",
    "# =============================================================================\n",
    "\n",
    "def exterior_derivative_3form(phi: torch.Tensor, coords: torch.Tensor,\n",
    "                               create_graph: bool = True) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Compute d(phi) using autograd.\"\"\"\n",
    "    batch_size, device = phi.shape[0], phi.device\n",
    "    if not coords.requires_grad:\n",
    "        coords = coords.requires_grad_(True)\n",
    "    \n",
    "    d_phi = torch.zeros(batch_size, 35, device=device)\n",
    "    for comp_idx in range(35):\n",
    "        grads = torch.autograd.grad(phi[:, comp_idx], coords, torch.ones_like(phi[:, comp_idx]),\n",
    "                                    create_graph=create_graph, retain_graph=True, allow_unused=True)[0]\n",
    "        if grads is not None:\n",
    "            d_phi[:, comp_idx] = torch.norm(grads, dim=1)\n",
    "    return d_phi, (d_phi ** 2).sum(dim=1)\n",
    "\n",
    "\n",
    "def hodge_star_3form(phi: torch.Tensor, metric: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute Hodge dual *phi (simplified).\"\"\"\n",
    "    vol = volume_form(metric).unsqueeze(-1)\n",
    "    phi_dual = phi * vol\n",
    "    return phi_dual / (torch.norm(phi_dual, dim=1, keepdim=True) + 1e-8) * np.sqrt(7.0)\n",
    "\n",
    "\n",
    "def compute_torsion(phi: torch.Tensor, coords: torch.Tensor, \n",
    "                    metric: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"Compute G2 torsion: ||d(phi)||^2 + ||d(*phi)||^2.\"\"\"\n",
    "    _, d_phi_norm_sq = exterior_derivative_3form(phi, coords)\n",
    "    phi_dual = hodge_star_3form(phi, metric)\n",
    "    _, d_phi_dual_norm_sq = exterior_derivative_3form(phi_dual, coords)\n",
    "    torsion_total = d_phi_norm_sq + d_phi_dual_norm_sq\n",
    "    return {'d_phi_norm_sq': d_phi_norm_sq, 'd_phi_dual_norm_sq': d_phi_dual_norm_sq,\n",
    "            'torsion_total': torsion_total, 'kappa_T': torsion_total.mean()}\n",
    "\n",
    "\n",
    "# Test\n",
    "coords_grad = test_coords.clone().requires_grad_(True)\n",
    "phi_test = phi_net(coords_grad)\n",
    "torsion_info = compute_torsion(phi_test, coords_grad, project_spd(metric_from_phi(phi_test)))\n",
    "print(f\"kappa_T: {torsion_info['kappa_T']:.6f} (target: {1/61:.6f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 2.5: CORE LOSS FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def compute_core_loss(phi: torch.Tensor, coords: torch.Tensor, \n",
    "                      config: GeometryConfig,\n",
    "                      weights: Optional[Dict[str, float]] = None) -> Tuple[torch.Tensor, Dict]:\n",
    "    \"\"\"Compute core geometric loss for G2 structure.\"\"\"\n",
    "    if weights is None:\n",
    "        weights = {'torsion': 100.0, 'kappa_T_abs': 200.0, 'kappa_T_rel': 500.0,\n",
    "                   'det_g': 50.0, 'positivity': 10.0, 'phi_norm': 1.0}\n",
    "    \n",
    "    metric = project_spd(metric_from_phi(phi))\n",
    "    torsion_info = compute_torsion(phi, coords, metric)\n",
    "    kappa_T = torsion_info['kappa_T']\n",
    "    \n",
    "    loss_kappa_abs = (kappa_T - config.target_kappa_T) ** 2\n",
    "    loss_kappa_rel = (kappa_T / config.target_kappa_T - 1.0) ** 2\n",
    "    loss_torsion = torsion_info['torsion_total'].mean()\n",
    "    \n",
    "    det_g = compute_det_g(metric)\n",
    "    loss_det_g = ((det_g - config.target_det_g) ** 2).mean()\n",
    "    \n",
    "    eigenvalues = torch.linalg.eigvalsh(metric)\n",
    "    loss_positivity = torch.relu(1e-4 - eigenvalues).mean()\n",
    "    \n",
    "    phi_norm_sq = (phi ** 2).sum(dim=1)\n",
    "    loss_phi_norm = ((phi_norm_sq - 7.0) ** 2).mean()\n",
    "    \n",
    "    total_loss = (weights['torsion'] * loss_torsion + weights['kappa_T_abs'] * loss_kappa_abs +\n",
    "                  weights['kappa_T_rel'] * loss_kappa_rel + weights['det_g'] * loss_det_g +\n",
    "                  weights['positivity'] * loss_positivity + weights['phi_norm'] * loss_phi_norm)\n",
    "    \n",
    "    info = {'total_loss': total_loss.item(), 'kappa_T': kappa_T.item(),\n",
    "            'kappa_T_error_pct': abs(kappa_T.item() - config.target_kappa_T) / config.target_kappa_T * 100,\n",
    "            'det_g_mean': det_g.mean().item(),\n",
    "            'det_g_error_pct': abs(det_g.mean().item() - config.target_det_g) / config.target_det_g * 100,\n",
    "            'phi_norm_sq_mean': phi_norm_sq.mean().item(), 'min_eigenvalue': eigenvalues.min().item()}\n",
    "    return total_loss, info\n",
    "\n",
    "\n",
    "# Test\n",
    "loss, info = compute_core_loss(phi_test, coords_grad, CONFIG.geometry)\n",
    "print(f\"Core loss: {info['total_loss']:.4f}, kappa_T error: {info['kappa_T_error_pct']:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 3: Breathing / Flux Module",
    "",
    "Speculative diagnostics for visible/hidden mode transfer:",
    "- Mode extraction from H3 (77 harmonic 3-forms)",
    "- Visible/hidden split (43/34 by default)",
    "- Flux network along TCS neck",
    "",
    "**IMPORTANT**: These are SOFT diagnostics with small-weight losses.",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3.1: H3 MODE EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "class H3ModeExtractor(nn.Module):\n",
    "    \"\"\"Extract H3 modes using SVD-orthonormal profiles (77 = 35 local + 42 global).\"\"\"\n",
    "    \n",
    "    def __init__(self, n_local: int = 35, n_global: int = 42):\n",
    "        super().__init__()\n",
    "        self.n_local, self.n_global = n_local, n_global\n",
    "    \n",
    "    def compute_global_profiles(self, coords: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Generate 42 SVD-orthonormalized global profiles.\"\"\"\n",
    "        batch_size, device = coords.shape[0], coords.device\n",
    "        lam, xi = coords[:, 0], coords[:, 1:]\n",
    "        \n",
    "        # Build candidate pool\n",
    "        candidates = [torch.ones(batch_size, device=device), lam, lam**2, lam**3, lam**4]\n",
    "        candidates.extend([coords[:, i] for i in range(7)])\n",
    "        \n",
    "        chi_L = torch.sigmoid(10 * (0.3 - lam))\n",
    "        chi_R = torch.sigmoid(10 * (lam - 0.7))\n",
    "        chi_neck = 1.0 - chi_L - chi_R\n",
    "        candidates.extend([chi_L, chi_R, chi_neck])\n",
    "        \n",
    "        for region in [chi_L, chi_R, chi_neck]:\n",
    "            candidates.extend([region * lam**p for p in [1,2,3,4]])\n",
    "            candidates.extend([region * coords[:, i] for i in range(7)])\n",
    "        \n",
    "        candidates.extend([(chi_L - chi_R) * xi[:, i] for i in range(6)])\n",
    "        candidates.append((chi_L - chi_R) * lam)\n",
    "        candidates.extend([lam * coords[:, i] for i in range(7)])\n",
    "        candidates.extend([xi[:, i] * xi[:, j] for i in range(6) for j in range(i+1, 6)])\n",
    "        \n",
    "        for k in [1, 2]:\n",
    "            candidates.extend([torch.sin(2*np.pi*k*lam), torch.cos(2*np.pi*k*lam),\n",
    "                              torch.sin(np.pi*k*lam), torch.cos(np.pi*k*lam)])\n",
    "        \n",
    "        F = torch.stack(candidates, dim=1)\n",
    "        G = F.T @ F / batch_size\n",
    "        _, eigvecs = torch.linalg.eigh(G)\n",
    "        V_42 = eigvecs[:, -self.n_global:]\n",
    "        profiles = F @ V_42\n",
    "        return profiles / (torch.norm(profiles, dim=0, keepdim=True) + 1e-8)\n",
    "    \n",
    "    def forward(self, phi: torch.Tensor, coords: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Extract all 77 H3 modes.\"\"\"\n",
    "        local = phi  # 35 local modes\n",
    "        global_prof = self.compute_global_profiles(coords)  # 42 global\n",
    "        return torch.cat([local, global_prof], dim=1)\n",
    "\n",
    "\n",
    "h3_extractor = H3ModeExtractor().to(DEVICE)\n",
    "test_modes = h3_extractor(phi_test, test_coords)\n",
    "print(f\"H3 modes: {test_modes.shape} (35 local + 42 global = 77)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3.2: VISIBLE/HIDDEN MODE SPLIT\n",
    "# =============================================================================\n",
    "\n",
    "class ModeProjection(nn.Module):\n",
    "    \"\"\"Project H3 modes into visible (43) and hidden (34) subspaces.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_total: int = 77, n_visible: int = 43):\n",
    "        super().__init__()\n",
    "        self.n_visible = n_visible\n",
    "        self.register_buffer('P_vis', torch.eye(n_total)[:n_visible, :])\n",
    "        self.register_buffer('P_hid', torch.eye(n_total)[n_visible:, :])\n",
    "    \n",
    "    def forward(self, modes: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return modes @ self.P_vis.T, modes @ self.P_hid.T\n",
    "    \n",
    "    def compute_occupation_ratio(self, modes: torch.Tensor) -> torch.Tensor:\n",
    "        a_vis, a_hid = self.forward(modes)\n",
    "        vis_e, hid_e = (a_vis**2).mean(), (a_hid**2).mean()\n",
    "        return vis_e / (vis_e + hid_e + 1e-8)\n",
    "\n",
    "\n",
    "mode_proj = ModeProjection().to(DEVICE)\n",
    "print(f\"Occupation ratio: {mode_proj.compute_occupation_ratio(test_modes):.4f} (target: {43/77:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3.3: NECK TRANSFER NETWORK (FLUX)\n",
    "# =============================================================================\n",
    "\n",
    "class NeckTransferNet(nn.Module):\n",
    "    \"\"\"Network for flux/transfer along TCS neck.\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim: int = 32):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(1, hidden_dim), nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        for layer in self.net:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.xavier_uniform_(layer.weight, gain=0.1)\n",
    "                nn.init.zeros_(layer.bias)\n",
    "    \n",
    "    def forward(self, lam: torch.Tensor) -> torch.Tensor:\n",
    "        if lam.dim() == 1: lam = lam.unsqueeze(-1)\n",
    "        return self.net(lam).squeeze(-1)\n",
    "    \n",
    "    def compute_flux_integral(self, n_points: int = 100, device=None) -> torch.Tensor:\n",
    "        if device is None: device = next(self.parameters()).device\n",
    "        lam = torch.linspace(0, 1, n_points, device=device)\n",
    "        flux = self.forward(lam)\n",
    "        return (flux[:-1] + flux[1:]).sum() / (2 * (n_points - 1))\n",
    "\n",
    "\n",
    "flux_net = NeckTransferNet().to(DEVICE)\n",
    "print(f\"Flux integral: {flux_net.compute_flux_integral():.4f} (target: -0.5)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 3.4: BREATHING LOSS (SOFT DIAGNOSTICS)\n",
    "# =============================================================================\n",
    "\n",
    "def compute_breathing_observable(modes: torch.Tensor, mode_proj: ModeProjection) -> torch.Tensor:\n",
    "    a_vis, a_hid = mode_proj(modes)\n",
    "    return (a_vis**2).sum(dim=1) - (a_hid**2).sum(dim=1)\n",
    "\n",
    "\n",
    "def estimate_breathing_period(observable: torch.Tensor, lam: torch.Tensor) -> Tuple[float, Dict]:\n",
    "    \"\"\"Estimate dominant period via FFT.\"\"\"\n",
    "    O = observable.detach().cpu().numpy()\n",
    "    lam_np = lam.detach().cpu().numpy()\n",
    "    n = len(lam)\n",
    "    O_centered = O - O.mean()\n",
    "    fft = np.fft.rfft(O_centered)\n",
    "    freqs = np.fft.rfftfreq(n, d=(lam_np[-1] - lam_np[0]) / (n - 1))\n",
    "    mags = np.abs(fft[1:])\n",
    "    if len(mags) > 0 and mags.max() > 1e-10:\n",
    "        dominant_freq = freqs[np.argmax(mags) + 1]\n",
    "        period = 1.0 / dominant_freq if dominant_freq > 1e-10 else float('inf')\n",
    "    else:\n",
    "        period = float('inf')\n",
    "    return period, {'method': 'fft'}\n",
    "\n",
    "\n",
    "def compute_breathing_loss(flux_net: NeckTransferNet, mode_proj: ModeProjection,\n",
    "                           modes: torch.Tensor, config: BreathingConfig) -> Tuple[torch.Tensor, Dict]:\n",
    "    \"\"\"Compute soft breathing diagnostic losses.\"\"\"\n",
    "    device = modes.device\n",
    "    if not config.enable:\n",
    "        return torch.tensor(0.0, device=device), {'breathing_enabled': False}\n",
    "    \n",
    "    flux_integral = flux_net.compute_flux_integral(device=device)\n",
    "    loss_flux = (flux_integral - config.target_flux) ** 2\n",
    "    \n",
    "    occupation_vis = mode_proj.compute_occupation_ratio(modes)\n",
    "    loss_ratio = (occupation_vis - config.target_visible_ratio) ** 2\n",
    "    \n",
    "    total_loss = config.loss_weight_flux * loss_flux + config.loss_weight_ratio * loss_ratio\n",
    "    \n",
    "    return total_loss, {'breathing_enabled': True, 'total_breathing_loss': total_loss.item(),\n",
    "                        'flux_integral': flux_integral.item(), 'flux_target': config.target_flux,\n",
    "                        'occupation_vis': occupation_vis.item(), 'occupation_target': config.target_visible_ratio}\n",
    "\n",
    "\n",
    "breathing_loss, breathing_info = compute_breathing_loss(flux_net, mode_proj, test_modes, CONFIG.breathing)\n",
    "print(f\"Breathing loss: {breathing_info['total_breathing_loss']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 4: Cohomology + Yukawa Module",
    "",
    "Clean numerical extraction of Yukawa couplings:",
    "- H2 (b2=21) and H3 (b3=77) harmonic form bases",
    "- Y_ijk = integral(omega_i ^ omega_j ^ Omega_k)",
    "",
    "**No speculative physics here** - just pure geometry extraction.",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 4.1: H2 BASIS AND YUKAWA EXTRACTION\n",
    "# =============================================================================\n",
    "\n",
    "class H2BasisExtractor(nn.Module):\n",
    "    \"\"\"Extract b2=21 harmonic 2-form basis.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_modes: int = 21):\n",
    "        super().__init__()\n",
    "        self.n_modes = n_modes\n",
    "    \n",
    "    def forward(self, metric: torch.Tensor, coords: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, device = metric.shape[0], metric.device\n",
    "        omega = torch.zeros(batch_size, self.n_modes, 21, device=device)\n",
    "        pairs = [(i,j) for i in range(7) for j in range(i+1,7)]\n",
    "        for form_idx in range(self.n_modes):\n",
    "            for comp_idx, (i,j) in enumerate(pairs):\n",
    "                omega[:, form_idx, comp_idx] = metric[:, i, j] * np.sin((form_idx+1) * np.pi / 21)\n",
    "        norms = torch.norm(omega, dim=2, keepdim=True)\n",
    "        return omega / (norms + 1e-8)\n",
    "\n",
    "\n",
    "class YukawaCouplingExtractor:\n",
    "    \"\"\"Compute Yukawa couplings Y_ijk = integral(omega_i ^ omega_j ^ Omega_k).\"\"\"\n",
    "    \n",
    "    def __init__(self, n_samples: int = 10000):\n",
    "        self.n_samples = n_samples\n",
    "    \n",
    "    def compute_yukawa_tensor(self, phi_net, h2_ext, h3_ext, config, device) -> torch.Tensor:\n",
    "        \"\"\"Compute full Yukawa tensor (21x21x77) via Monte Carlo.\"\"\"\n",
    "        Y = torch.zeros(config.b2_K7, config.b2_K7, config.b3_K7, device=device)\n",
    "        coords = sample_TCS_coords(self.n_samples, device).requires_grad_(True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            phi = phi_net(coords)\n",
    "            metric = project_spd(metric_from_phi(phi))\n",
    "            omega = h2_ext(metric, coords)\n",
    "            modes = h3_ext(phi, coords)\n",
    "            vol = volume_form(metric)\n",
    "        \n",
    "        print(f\"Computing Yukawa tensor ({config.b2_K7}x{config.b2_K7}x{config.b3_K7})...\")\n",
    "        for i in range(config.b2_K7):\n",
    "            for j in range(i, config.b2_K7):\n",
    "                for k in range(config.b3_K7):\n",
    "                    omega_ij = (omega[:, i, :] * omega[:, j, :]).sum(dim=1)\n",
    "                    mode_k = modes[:, k]\n",
    "                    Y[i, j, k] = Y[j, i, k] = (omega_ij * mode_k * vol).mean()\n",
    "        return Y\n",
    "    \n",
    "    def analyze_yukawa(self, Y: torch.Tensor) -> Dict:\n",
    "        Y_flat = Y.reshape(-1, Y.shape[-1])\n",
    "        _, S, _ = torch.linalg.svd(Y_flat, full_matrices=False)\n",
    "        eff_rank = (S > S.max() * 1e-3).sum().item()\n",
    "        return {'effective_rank': eff_rank, 'top_singular': S[:5].tolist()}\n",
    "\n",
    "\n",
    "h2_extractor = H2BasisExtractor().to(DEVICE)\n",
    "print(\"H2 extractor and YukawaCouplingExtractor defined (run in post-hoc analysis)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 5: Multi-Phase Training Loop",
    "",
    "1. **Phase 1 (Geometry-only)**: Train PhiNetwork to minimize L_core",
    "2. **Phase 2 (Geometry + Breathing)**: Add breathing diagnostics with small weights",
    "",
    "**Key principle**: Core geometry must converge first.",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.1: TRAINING INFRASTRUCTURE\n",
    "# =============================================================================\n",
    "\n",
    "class TrainingHistory:\n",
    "    def __init__(self):\n",
    "        self.history = {k: [] for k in ['epoch', 'phase', 'total_loss', 'core_loss', 'breathing_loss',\n",
    "                                         'kappa_T', 'kappa_T_error_pct', 'det_g', 'det_g_error_pct',\n",
    "                                         'flux_integral', 'occupation_vis', 'learning_rate']}\n",
    "    \n",
    "    def log(self, epoch, phase, core_info, breathing_info=None, lr=0.0):\n",
    "        self.history['epoch'].append(epoch)\n",
    "        self.history['phase'].append(phase)\n",
    "        self.history['total_loss'].append(core_info['total_loss'])\n",
    "        self.history['core_loss'].append(core_info['total_loss'])\n",
    "        self.history['kappa_T'].append(core_info['kappa_T'])\n",
    "        self.history['kappa_T_error_pct'].append(core_info['kappa_T_error_pct'])\n",
    "        self.history['det_g'].append(core_info['det_g_mean'])\n",
    "        self.history['det_g_error_pct'].append(core_info['det_g_error_pct'])\n",
    "        self.history['learning_rate'].append(lr)\n",
    "        if breathing_info and breathing_info.get('breathing_enabled'):\n",
    "            self.history['breathing_loss'].append(breathing_info['total_breathing_loss'])\n",
    "            self.history['flux_integral'].append(breathing_info['flux_integral'])\n",
    "            self.history['occupation_vis'].append(breathing_info['occupation_vis'])\n",
    "        else:\n",
    "            self.history['breathing_loss'].append(0.0)\n",
    "            self.history['flux_integral'].append(float('nan'))\n",
    "            self.history['occupation_vis'].append(float('nan'))\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'w') as f: json.dump(self.history, f, indent=2)\n",
    "\n",
    "\n",
    "print(\"Training infrastructure defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# SECTION 5.2: PHASE 1 - GEOMETRY-ONLY\n# =============================================================================\n\ndef train_phase1_geometry(phi_net, config, device):\n    \"\"\"Phase 1: Train for core geometry.\"\"\"\n    print(\"=\" * 70 + \"\\nPHASE 1: Geometry-Only Training\\n\" + \"=\" * 70)\n    \n    history = TrainingHistory()\n    optimizer = torch.optim.AdamW(phi_net.parameters(), lr=config.training.lr_core,\n                                   weight_decay=config.training.weight_decay)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=config.training.scheduler_patience)\n    best_loss, best_state = float('inf'), None\n    \n    for epoch in range(config.training.n_epochs_core):\n        phi_net.train()\n        coords = sample_coords(config.training.batch_size, config.geometry, device).requires_grad_(True)\n        phi = phi_net(coords)\n        loss, info = compute_core_loss(phi, coords, config.geometry)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(phi_net.parameters(), config.training.max_grad_norm)\n        optimizer.step()\n        scheduler.step(loss.item())  # Use .item() to avoid tensor with requires_grad\n        \n        lr = optimizer.param_groups[0]['lr']\n        history.log(epoch, 'geometry', info, None, lr)\n        \n        if loss.item() < best_loss:\n            best_loss = loss.item()\n            best_state = {k: v.clone() for k, v in phi_net.state_dict().items()}\n        \n        if epoch % config.logging.log_every == 0 or epoch == config.training.n_epochs_core - 1:\n            print(f\"Epoch {epoch:5d} | Loss: {info['total_loss']:.4f} | \"\n                  f\"kappa_T: {info['kappa_T']:.6f} ({info['kappa_T_error_pct']:.2f}%) | \"\n                  f\"det(g): {info['det_g_mean']:.4f} ({info['det_g_error_pct']:.2f}%)\")\n    \n    if best_state: phi_net.load_state_dict(best_state)\n    if config.logging.save_checkpoints:\n        torch.save({'phi_net_state': phi_net.state_dict()}, \n                   Path(config.logging.checkpoint_dir) / \"checkpoint_phase1.pt\")\n    print(f\"\\nPhase 1 Complete: Best loss = {best_loss:.4f}\")\n    return phi_net, history\n\n\nprint(\"Phase 1 training function defined\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.3: PHASE 2 - GEOMETRY + BREATHING\n",
    "# =============================================================================\n",
    "\n",
    "def train_phase2_breathing(phi_net, flux_net, mode_proj, h3_extractor, config, device, history):\n",
    "    \"\"\"Phase 2: Add breathing diagnostics.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70 + \"\\nPHASE 2: Geometry + Breathing\\n\" + \"=\" * 70)\n",
    "    \n",
    "    if not config.breathing.enable:\n",
    "        print(\"Breathing disabled - skipping Phase 2\")\n",
    "        return phi_net, flux_net, history\n",
    "    \n",
    "    params = [{'params': phi_net.parameters(), 'lr': config.training.lr_breathing * 0.1},\n",
    "              {'params': flux_net.parameters(), 'lr': config.training.lr_breathing}]\n",
    "    optimizer = torch.optim.AdamW(params, weight_decay=config.training.weight_decay)\n",
    "    \n",
    "    for epoch in range(config.training.n_epochs_breathing):\n",
    "        phi_net.train(); flux_net.train()\n",
    "        coords = sample_coords(config.training.batch_size, config.geometry, device).requires_grad_(True)\n",
    "        phi = phi_net(coords)\n",
    "        \n",
    "        core_loss, core_info = compute_core_loss(phi, coords, config.geometry)\n",
    "        modes = h3_extractor(phi, coords)\n",
    "        breathing_loss, breathing_info = compute_breathing_loss(flux_net, mode_proj, modes, config.breathing)\n",
    "        \n",
    "        total_loss = core_loss + breathing_loss\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(list(phi_net.parameters()) + list(flux_net.parameters()),\n",
    "                                        config.training.max_grad_norm)\n",
    "        optimizer.step()\n",
    "        \n",
    "        core_info['total_loss'] = total_loss.item()\n",
    "        history.log(epoch + config.training.n_epochs_core, 'breathing', core_info, breathing_info)\n",
    "        \n",
    "        if epoch % config.logging.log_every == 0 or epoch == config.training.n_epochs_breathing - 1:\n",
    "            print(f\"Epoch {epoch:5d} | Loss: {total_loss.item():.4f} | \"\n",
    "                  f\"Flux: {breathing_info['flux_integral']:.4f} | Occ: {breathing_info['occupation_vis']:.4f}\")\n",
    "    \n",
    "    if config.logging.save_checkpoints:\n",
    "        torch.save({'phi_net_state': phi_net.state_dict(), 'flux_net_state': flux_net.state_dict()},\n",
    "                   Path(config.logging.checkpoint_dir) / \"checkpoint_phase2.pt\")\n",
    "    print(\"\\nPhase 2 Complete\")\n",
    "    return phi_net, flux_net, history\n",
    "\n",
    "\n",
    "print(\"Phase 2 training function defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 5.4: MAIN TRAINING ORCHESTRATOR\n",
    "# =============================================================================\n",
    "\n",
    "def run_full_training(config, device):\n",
    "    \"\"\"Run complete multi-phase training.\"\"\"\n",
    "    print(\"=\" * 70 + \"\\nK7 BREATHING v1.8 - FULL TRAINING\\n\" + \"=\" * 70)\n",
    "    \n",
    "    phi_net = PhiNetwork().to(device)\n",
    "    flux_net = NeckTransferNet().to(device)\n",
    "    h3_extractor = H3ModeExtractor().to(device)\n",
    "    mode_proj = ModeProjection(n_visible=config.breathing.n_visible).to(device)\n",
    "    h2_extractor = H2BasisExtractor().to(device)\n",
    "    \n",
    "    print(f\"PhiNetwork params: {sum(p.numel() for p in phi_net.parameters()):,}\")\n",
    "    \n",
    "    phi_net, history = train_phase1_geometry(phi_net, config, device)\n",
    "    phi_net, flux_net, history = train_phase2_breathing(\n",
    "        phi_net, flux_net, mode_proj, h3_extractor, config, device, history)\n",
    "    \n",
    "    history.save(str(OUTPUT_DIR / \"training_history.json\"))\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\" * 70 + \"\\nFINAL EVALUATION\\n\" + \"=\" * 70)\n",
    "    phi_net.eval(); flux_net.eval()\n",
    "    with torch.no_grad():\n",
    "        coords = sample_coords(10000, config.geometry, device).requires_grad_(True)\n",
    "        phi = phi_net(coords)\n",
    "        _, final_core = compute_core_loss(phi, coords, config.geometry)\n",
    "        modes = h3_extractor(phi, coords)\n",
    "        _, final_breath = compute_breathing_loss(flux_net, mode_proj, modes, config.breathing)\n",
    "    \n",
    "    print(f\"kappa_T: {final_core['kappa_T']:.6f} (error: {final_core['kappa_T_error_pct']:.2f}%)\")\n",
    "    print(f\"det(g): {final_core['det_g_mean']:.6f} (error: {final_core['det_g_error_pct']:.2f}%)\")\n",
    "    if config.breathing.enable:\n",
    "        print(f\"Flux: {final_breath['flux_integral']:.4f}, Occupation: {final_breath['occupation_vis']:.4f}\")\n",
    "    \n",
    "    torch.save({'phi_net_state': phi_net.state_dict(), 'flux_net_state': flux_net.state_dict(),\n",
    "                'final_core': final_core, 'final_breathing': final_breath}, OUTPUT_DIR / \"final_model.pt\")\n",
    "    \n",
    "    return {'phi_net': phi_net, 'flux_net': flux_net, 'h3_extractor': h3_extractor,\n",
    "            'mode_proj': mode_proj, 'h2_extractor': h2_extractor, 'history': history,\n",
    "            'final_core_metrics': final_core, 'final_breathing_metrics': final_breath, 'config': config}\n",
    "\n",
    "\n",
    "print(\"Main training orchestrator defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 6: Post-Hoc Analysis",
    "",
    "1. Metric fitting to analytic ansatz",
    "2. Breathing period estimation",
    "3. Visualization",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 6.1: METRIC FITTING\n",
    "# =============================================================================\n",
    "\n",
    "def fit_metric_ansatz(phi_net, config, device, n_samples=5000):\n",
    "    \"\"\"Fit learned metric to analytic ansatz.\"\"\"\n",
    "    print(\"Fitting metric to analytic ansatz...\")\n",
    "    phi_net.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        coords = sample_TCS_coords(n_samples, device)\n",
    "        phi = phi_net(coords)\n",
    "        metric = project_spd(metric_from_phi(phi))\n",
    "        lam, xi = coords[:, 0].cpu().numpy(), coords[:, 1:].cpu().numpy()\n",
    "        g = metric.cpu().numpy()\n",
    "    \n",
    "    # Design matrix: [1, lam, lam^2, sin, cos, xi_1..6, lam*xi_1..6]\n",
    "    X = np.column_stack([np.ones(n_samples), lam, lam**2, np.sin(np.pi*lam), np.cos(np.pi*lam),\n",
    "                         xi, lam[:, np.newaxis] * xi])\n",
    "    \n",
    "    r_squared = {}\n",
    "    for i in range(7):\n",
    "        for j in range(i, 7):\n",
    "            y = g[:, i, j]\n",
    "            coeffs, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "            y_pred = X @ coeffs\n",
    "            r2 = 1 - np.sum((y - y_pred)**2) / (np.sum((y - y.mean())**2) + 1e-10)\n",
    "            r_squared[f'g_{i}{j}'] = r2\n",
    "    \n",
    "    avg_r2 = np.mean(list(r_squared.values()))\n",
    "    print(f\"Metric fit: Average R^2 = {avg_r2:.4f}\")\n",
    "    return {'avg_r_squared': avg_r2, 'r_squared': r_squared}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SECTION 6.2: VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def plot_training_history(history, save_path=None):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    epochs = history.history['epoch']\n",
    "    \n",
    "    axes[0,0].semilogy(epochs, history.history['total_loss']); axes[0,0].set_title('Loss')\n",
    "    axes[0,1].plot(epochs, history.history['kappa_T']); axes[0,1].axhline(1/61, c='r', ls='--'); axes[0,1].set_title('kappa_T')\n",
    "    axes[0,2].plot(epochs, history.history['det_g']); axes[0,2].axhline(65/32, c='r', ls='--'); axes[0,2].set_title('det(g)')\n",
    "    axes[1,0].semilogy(epochs, history.history['kappa_T_error_pct']); axes[1,0].set_title('kappa_T Error %')\n",
    "    \n",
    "    flux = [v for v in history.history['flux_integral'] if not np.isnan(v)]\n",
    "    if flux:\n",
    "        axes[1,1].plot(range(len(flux)), flux); axes[1,1].axhline(-0.5, c='r', ls='--')\n",
    "    axes[1,1].set_title('Flux Integral')\n",
    "    \n",
    "    occ = [v for v in history.history['occupation_vis'] if not np.isnan(v)]\n",
    "    if occ:\n",
    "        axes[1,2].plot(range(len(occ)), occ); axes[1,2].axhline(43/77, c='r', ls='--')\n",
    "    axes[1,2].set_title('Occupation Ratio')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if save_path: plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_flux_profile(flux_net, device, save_path=None):\n",
    "    flux_net.eval()\n",
    "    with torch.no_grad():\n",
    "        lam = torch.linspace(0, 1, 100, device=device)\n",
    "        flux = flux_net(lam).cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(lam.cpu().numpy(), flux, 'b-', lw=2)\n",
    "    plt.axhline(0, c='k', alpha=0.3)\n",
    "    plt.fill_between(lam.cpu().numpy(), flux, 0, alpha=0.3)\n",
    "    plt.xlabel('lambda'); plt.ylabel('Flux'); plt.title('Breathing Flux Profile')\n",
    "    plt.text(0.05, 0.95, f'Integral = {flux_net.compute_flux_integral().item():.4f}\\nTarget = -0.5',\n",
    "             transform=plt.gca().transAxes, va='top', bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "    if save_path: plt.savefig(save_path, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_post_hoc_analysis(results, device):\n",
    "    print(\"\\n\" + \"=\" * 70 + \"\\nPOST-HOC ANALYSIS\\n\" + \"=\" * 70)\n",
    "    fit_metric_ansatz(results['phi_net'], results['config'].geometry, device)\n",
    "    plot_training_history(results['history'], str(OUTPUT_DIR / \"training_history.png\"))\n",
    "    if results['config'].breathing.enable:\n",
    "        plot_flux_profile(results['flux_net'], device, str(OUTPUT_DIR / \"flux_profile.png\"))\n",
    "    print(f\"Analysis saved to {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "print(\"Post-hoc analysis functions defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---",
    "## Section 7: Run Training",
    "",
    "**Quick test**: Uncomment the config lines below to reduce epochs.",
    "**Pure geometry mode**: Set `CONFIG.breathing.enable = False`",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test configuration (uncomment for testing):\n",
    "# CONFIG.training.n_epochs_core = 100\n",
    "# CONFIG.training.n_epochs_breathing = 50\n",
    "# CONFIG.logging.log_every = 10\n",
    "\n",
    "# Pure geometry mode (no breathing):\n",
    "# CONFIG.breathing.enable = False\n",
    "\n",
    "print(\"Configuration ready. Run next cell to start training.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TRAINING\n",
    "CONFIG.save(str(OUTPUT_DIR / \"config.json\"))\n",
    "results = run_full_training(CONFIG, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN POST-HOC ANALYSIS\n",
    "run_post_hoc_analysis(results, DEVICE)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"K7 BREATHING v1.8 - COMPLETE\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: YUKAWA EXTRACTION (uncomment to run - takes 10-30 min)\n",
    "# yukawa_ext = YukawaCouplingExtractor(n_samples=5000)\n",
    "# Y = yukawa_ext.compute_yukawa_tensor(results['phi_net'], results['h2_extractor'],\n",
    "#                                       results['h3_extractor'], CONFIG.geometry, DEVICE)\n",
    "# print(f\"Yukawa shape: {Y.shape}, Effective rank: {yukawa_ext.analyze_yukawa(Y)['effective_rank']}/77\")\n",
    "# torch.save(Y, OUTPUT_DIR / \"yukawa_tensor.pt\")\n",
    "\n",
    "print(\"Yukawa extraction cell ready (uncomment to run)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}