{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/main/G2_ML/2_0/K7_TCS_Hodge_v2_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L08VvyW6UTS"
      },
      "source": [
        "# K7 TCS Hodge v2.0 - Proper TCS/Joyce Global Modes\n",
        "\n",
        "**Major upgrade from v1.9b:**\n",
        "- Replace polynomial/trigonometric global modes with proper TCS structure\n",
        "- 77 H3 modes = 35 local (fiber) + 42 global (TCS gluing)\n",
        "- 42 global = 14 left-weighted + 14 right-weighted + 14 neck-coupled\n",
        "- Profile functions: smooth plateaus and Gaussian bumps\n",
        "- Goal: achieve 43/77 visible/hidden split with tau = 3472/891\n",
        "\n",
        "## TCS (Twisted Connected Sum) Construction\n",
        "\n",
        "Joyce's G2 manifolds are built by gluing two asymptotically cylindrical Calabi-Yau 3-folds:\n",
        "- Left building block: M_L with asymptotic cylinder\n",
        "- Right building block: M_R with asymptotic cylinder  \n",
        "- Neck region: where the gluing happens with twist\n",
        "\n",
        "The 42 global modes arise from this gluing structure."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Setup and Imports\n",
        "# @markdown Run this cell first. Works on Colab, local Jupyter, or any Python environment.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "from typing import Optional, Tuple, Dict, List\n",
        "from itertools import combinations\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Check environment\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"K7 TCS HODGE v2.0 - Setup\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local'}\")\n",
        "print(f\"Device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "print(f\"PyTorch: {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwacf3e26UTU",
        "outputId": "e758fdf0-0466-4f64-a755-ae28c73e6efb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "K7 TCS HODGE v2.0 - Setup\n",
            "============================================================\n",
            "Environment: Google Colab\n",
            "Device: cuda\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "Memory: 85.2 GB\n",
            "PyTorch: 2.9.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Configuration\n",
        "# @markdown Adjust parameters here. TCS-specific settings control the profile functions.\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    \"\"\"v2.0 Configuration with TCS parameters.\"\"\"\n",
        "\n",
        "    # === Geometry ===\n",
        "    dim: int = 7\n",
        "    b2_K7: int = 21          # Harmonic 2-forms\n",
        "    b3_K7: int = 77          # Harmonic 3-forms\n",
        "    b3_local: int = 35       # Local fiber modes\n",
        "    b3_global: int = 42      # Global TCS modes\n",
        "\n",
        "    # TCS global mode breakdown: 42 = 14 + 14 + 14\n",
        "    n_left: int = 14         # Left-weighted modes\n",
        "    n_right: int = 14        # Right-weighted modes\n",
        "    n_neck: int = 14         # Neck-coupled modes\n",
        "\n",
        "    # === Targets ===\n",
        "    target_det_g: float = 2.03125        # 65/32\n",
        "    target_kappa_T: float = 0.01639344   # 1/61\n",
        "    tau_target: float = 3.8967452        # 3472/891\n",
        "\n",
        "    # === TCS Profile Parameters ===\n",
        "    lambda_L: float = -1.0   # Left boundary\n",
        "    lambda_R: float = +1.0   # Right boundary\n",
        "    lambda_neck: float = 0.0 # Neck center\n",
        "    sigma_transition: float = 0.15  # Transition width for plateaus\n",
        "    sigma_neck: float = 0.2         # Neck bump width\n",
        "\n",
        "    # === Network Architecture ===\n",
        "    hidden_dim: int = 256\n",
        "    n_layers: int = 4\n",
        "\n",
        "    # === Training ===\n",
        "    n_epochs_h2: int = 3000\n",
        "    n_epochs_h3: int = 8000  # More epochs for TCS learning\n",
        "    lr_h2: float = 1e-3\n",
        "    lr_h3: float = 3e-4      # Lower LR for stability\n",
        "    batch_size: int = 2048\n",
        "    weight_decay: float = 1e-5\n",
        "    max_grad_norm: float = 1.0\n",
        "    scheduler_patience: int = 400\n",
        "    scheduler_factor: float = 0.5\n",
        "\n",
        "    # === Loss Weights ===\n",
        "    w_closed: float = 1.0\n",
        "    w_coclosed: float = 1.0\n",
        "    w_orthonormal: float = 0.1\n",
        "    w_g2_compat: float = 0.5\n",
        "    w_tcs_profile: float = 0.3   # NEW: TCS profile regularization\n",
        "\n",
        "    # === Checkpointing ===\n",
        "    checkpoint_every: int = 500\n",
        "    checkpoint_dir: str = \"checkpoints_v2_0\"\n",
        "    log_every: int = 100\n",
        "    output_dir: str = \"outputs_v2_0\"\n",
        "\n",
        "config = Config()\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "print(f\"  Geometry: b2={config.b2_K7}, b3={config.b3_K7} ({config.b3_local} local + {config.b3_global} global)\")\n",
        "print(f\"  TCS global: {config.n_left} left + {config.n_right} right + {config.n_neck} neck\")\n",
        "print(f\"  Training: H2={config.n_epochs_h2} epochs, H3={config.n_epochs_h3} epochs\")\n",
        "print(f\"  Targets: det(g)={config.target_det_g}, tau={config.tau_target:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOLbWmOg6UTV",
        "outputId": "cd6aa845-a15b-4f24-8ae5-9a657c5caf21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration loaded:\n",
            "  Geometry: b2=21, b3=77 (35 local + 42 global)\n",
            "  TCS global: 14 left + 14 right + 14 neck\n",
            "  Training: H2=3000 epochs, H3=8000 epochs\n",
            "  Targets: det(g)=2.03125, tau=3.8967\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title TCS Profile Functions\n",
        "# @markdown These profile functions encode the TCS (Twisted Connected Sum) geometry.\n",
        "# @markdown - left_plateau: ~1 on left building block, ~0 elsewhere\n",
        "# @markdown - right_plateau: ~1 on right building block, ~0 elsewhere\n",
        "# @markdown - neck_bump: peaked at neck, decays away\n",
        "\n",
        "def smooth_step(x: torch.Tensor, x0: float = 0.0, width: float = 0.1) -> torch.Tensor:\n",
        "    \"\"\"Smooth sigmoid transition centered at x0 with given width.\"\"\"\n",
        "    w = max(width, 1e-8)\n",
        "    t = (x - x0) / w\n",
        "    return torch.sigmoid(5.0 * t)  # Steepness factor 5 for sharp-ish transition\n",
        "\n",
        "def left_plateau(lam: torch.Tensor, config: Config) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Profile for left-weighted modes.\n",
        "    Returns ~1 for lambda < lambda_neck, ~0 for lambda > lambda_neck.\n",
        "    \"\"\"\n",
        "    return 1.0 - smooth_step(lam, x0=config.lambda_neck, width=config.sigma_transition)\n",
        "\n",
        "def right_plateau(lam: torch.Tensor, config: Config) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Profile for right-weighted modes.\n",
        "    Returns ~0 for lambda < lambda_neck, ~1 for lambda > lambda_neck.\n",
        "    \"\"\"\n",
        "    return smooth_step(lam, x0=config.lambda_neck, width=config.sigma_transition)\n",
        "\n",
        "def neck_bump(lam: torch.Tensor, config: Config) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Profile for neck-coupled modes.\n",
        "    Gaussian bump centered at neck, decays to both sides.\n",
        "    \"\"\"\n",
        "    t = (lam - config.lambda_neck) / max(config.sigma_neck, 1e-8)\n",
        "    return torch.exp(-t * t)\n",
        "\n",
        "def get_tcs_profiles(lam: torch.Tensor, config: Config) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"Return all three TCS profiles for given lambda coordinates.\"\"\"\n",
        "    return left_plateau(lam, config), right_plateau(lam, config), neck_bump(lam, config)\n",
        "\n",
        "# Test profiles\n",
        "print(\"TCS Profile Functions defined.\")\n",
        "print(\"\\nTesting on lambda in [-1, 1]:\")\n",
        "test_lam = torch.linspace(-1, 1, 11)\n",
        "L, R, N = get_tcs_profiles(test_lam, config)\n",
        "print(f\"{'lambda':>8} | {'left':>6} | {'right':>6} | {'neck':>6}\")\n",
        "print(\"-\" * 40)\n",
        "for i, l in enumerate(test_lam):\n",
        "    print(f\"{l.item():8.2f} | {L[i].item():6.3f} | {R[i].item():6.3f} | {N[i].item():6.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS_U9DYX6UTW",
        "outputId": "d7095db4-8293-4456-e022-4ebbe017617f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TCS Profile Functions defined.\n",
            "\n",
            "Testing on lambda in [-1, 1]:\n",
            "  lambda |   left |  right |   neck\n",
            "----------------------------------------\n",
            "   -1.00 |  1.000 |  0.000 |  0.000\n",
            "   -0.80 |  1.000 |  0.000 |  0.000\n",
            "   -0.60 |  1.000 |  0.000 |  0.000\n",
            "   -0.40 |  1.000 |  0.000 |  0.018\n",
            "   -0.20 |  0.999 |  0.001 |  0.368\n",
            "   -0.00 |  0.500 |  0.500 |  1.000\n",
            "    0.20 |  0.001 |  0.999 |  0.368\n",
            "    0.40 |  0.000 |  1.000 |  0.018\n",
            "    0.60 |  0.000 |  1.000 |  0.000\n",
            "    0.80 |  0.000 |  1.000 |  0.000\n",
            "    1.00 |  0.000 |  1.000 |  0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load Data\n",
        "# @markdown Loads calibrated K7 metric samples from v1.8/v1.9 or generates synthetic data.\n",
        "# @markdown For TCS, the first coordinate x[0] is interpreted as the neck coordinate lambda.\n",
        "\n",
        "def load_data(path: Optional[str] = None) -> Dict[str, torch.Tensor]:\n",
        "    \"\"\"Load K7 metric data from various possible locations.\"\"\"\n",
        "    paths_to_try = [\n",
        "        path,\n",
        "        \"samples.npz\",\n",
        "        \"../1_9b/outputs_v1_9b/samples.npz\",\n",
        "        \"../1_8/samples.npz\",\n",
        "        \"/content/samples.npz\",\n",
        "        \"/content/drive/MyDrive/GIFT/G2_ML/1_8/samples.npz\",\n",
        "        \"/content/drive/MyDrive/GIFT/G2_ML/1_9b/outputs_v1_9b/samples.npz\",\n",
        "    ]\n",
        "\n",
        "    for p in paths_to_try:\n",
        "        if p and os.path.exists(p):\n",
        "            print(f\"Loading from: {p}\")\n",
        "            data = np.load(p)\n",
        "            result = {\n",
        "                'coords': torch.from_numpy(data['coords']).float(),\n",
        "                'metric': torch.from_numpy(data['metric']).float(),\n",
        "            }\n",
        "            # phi may be in different formats\n",
        "            if 'phi' in data:\n",
        "                phi = data['phi']\n",
        "                if phi.ndim == 2 and phi.shape[1] == 35:\n",
        "                    result['phi'] = torch.from_numpy(phi).float()\n",
        "                elif phi.ndim == 3:\n",
        "                    # Take diagonal or mean\n",
        "                    result['phi'] = torch.from_numpy(phi).float().mean(dim=-1)\n",
        "                else:\n",
        "                    result['phi'] = torch.from_numpy(phi).float()\n",
        "            return result\n",
        "\n",
        "    # Generate synthetic data with TCS-aware coordinates\n",
        "    print(\"Data not found, generating synthetic with TCS structure...\")\n",
        "    n = 8000\n",
        "\n",
        "    # First coordinate is lambda (neck coordinate) in [-1, 1]\n",
        "    # Others are angular coordinates in [0, 2pi]\n",
        "    coords = torch.zeros(n, 7)\n",
        "    coords[:, 0] = torch.rand(n) * 2 - 1  # lambda in [-1, 1]\n",
        "    coords[:, 1:] = torch.rand(n, 6) * 2 * np.pi  # xi in [0, 2pi]\n",
        "\n",
        "    # Metric with det(g) ~ 65/32\n",
        "    scale = config.target_det_g ** (1/7)\n",
        "    metric = torch.eye(7).unsqueeze(0).expand(n, -1, -1).clone() * scale\n",
        "    metric = metric + 0.02 * torch.randn(n, 7, 7)\n",
        "    metric = 0.5 * (metric + metric.transpose(-1, -2))  # Symmetrize\n",
        "\n",
        "    # Phi: G2 3-form components (35 basis elements)\n",
        "    phi = torch.randn(n, 35) * 0.3\n",
        "    # Normalize to ||phi||^2 ~ 7\n",
        "    phi = phi * np.sqrt(7.0) / (torch.norm(phi, dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "    return {'coords': coords, 'metric': metric, 'phi': phi}\n",
        "\n",
        "# Load data\n",
        "data = load_data()\n",
        "n_samples = data['coords'].shape[0]\n",
        "\n",
        "# Compute statistics\n",
        "det_g = torch.det(data['metric'])\n",
        "det_g_mean = det_g.mean().item()\n",
        "det_g_std = det_g.std().item()\n",
        "\n",
        "# Lambda distribution\n",
        "lam = data['coords'][:, 0]\n",
        "lam_min, lam_max = lam.min().item(), lam.max().item()\n",
        "\n",
        "print(f\"\\nData loaded:\")\n",
        "print(f\"  Samples: {n_samples}\")\n",
        "print(f\"  det(g): {det_g_mean:.6f} +/- {det_g_std:.4f} (target: {config.target_det_g})\")\n",
        "print(f\"  Lambda range: [{lam_min:.2f}, {lam_max:.2f}]\")\n",
        "print(f\"  Phi shape: {data['phi'].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeev6KK36UTX",
        "outputId": "051cd7cd-7c9e-4ce8-ffed-4e2fa14477d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data not found, generating synthetic with TCS structure...\n",
            "\n",
            "Data loaded:\n",
            "  Samples: 8000\n",
            "  det(g): 2.023177 +/- 0.0962 (target: 2.03125)\n",
            "  Lambda range: [-1.00, 1.00]\n",
            "  Phi shape: torch.Size([8000, 35])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title H2 Network (21 harmonic 2-forms)\n",
        "# @markdown Standard architecture for 2-forms, unchanged from v1.9b.\n",
        "\n",
        "class H2Network(nn.Module):\n",
        "    \"\"\"\n",
        "    Network for 21 harmonic 2-forms on K7.\n",
        "    Output: (batch, 21, 21) - 21 forms, each with 21 = C(7,2) components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "\n",
        "        # Shared feature extractor\n",
        "        layers = []\n",
        "        in_dim = config.dim\n",
        "        for _ in range(config.n_layers):\n",
        "            layers.extend([\n",
        "                nn.Linear(in_dim, config.hidden_dim),\n",
        "                nn.SiLU(),\n",
        "            ])\n",
        "            in_dim = config.hidden_dim\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        # 21 separate heads for each 2-form\n",
        "        # Each outputs 21 components (antisymmetric 2-tensor has C(7,2) = 21 components)\n",
        "        self.heads = nn.ModuleList([\n",
        "            nn.Linear(config.hidden_dim, 21) for _ in range(config.b2_K7)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch, 7) coordinates\n",
        "        Returns:\n",
        "            omega: (batch, 21, 21) - 21 2-forms with 21 components each\n",
        "        \"\"\"\n",
        "        f = self.features(x)\n",
        "        forms = [head(f) for head in self.heads]\n",
        "        return torch.stack(forms, dim=1)\n",
        "\n",
        "# Test\n",
        "_test_h2 = H2Network(config)\n",
        "_test_out = _test_h2(torch.randn(4, 7))\n",
        "print(f\"H2Network defined.\")\n",
        "print(f\"  Parameters: {sum(p.numel() for p in _test_h2.parameters()):,}\")\n",
        "print(f\"  Output shape: {_test_out.shape} (batch, 21 forms, 21 components)\")\n",
        "del _test_h2, _test_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjZGtfhc6UTX",
        "outputId": "d35f3dca-5a4a-4e4a-f34a-8a64405d4ad4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H2Network defined.\n",
            "  Parameters: 312,761\n",
            "  Output shape: torch.Size([4, 21, 21]) (batch, 21 forms, 21 components)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title H3 TCS Network (77 harmonic 3-forms with TCS structure)\n",
        "# @markdown **KEY v2.0 CHANGE**: Global modes use proper TCS profiles.\n",
        "# @markdown - 35 local modes: fiber modes, independent of neck coordinate\n",
        "# @markdown - 14 left-weighted: multiplied by left_plateau(lambda)\n",
        "# @markdown - 14 right-weighted: multiplied by right_plateau(lambda)\n",
        "# @markdown - 14 neck-coupled: multiplied by neck_bump(lambda)\n",
        "\n",
        "class H3TCSNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Network for 77 harmonic 3-forms with TCS (Twisted Connected Sum) structure.\n",
        "\n",
        "    The 77 = 35 + 42 modes are:\n",
        "    - 35 local modes: fiber Λ³(R⁷) modes, no special profile\n",
        "    - 42 global TCS modes:\n",
        "        - 14 left-weighted: profile = left_plateau(λ)\n",
        "        - 14 right-weighted: profile = right_plateau(λ)\n",
        "        - 14 neck-coupled: profile = neck_bump(λ)\n",
        "\n",
        "    Output: (batch, 77, 35) - 77 forms, each with 35 = C(7,3) components.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Shared feature extractor\n",
        "        layers = []\n",
        "        in_dim = config.dim\n",
        "        for _ in range(config.n_layers):\n",
        "            layers.extend([\n",
        "                nn.Linear(in_dim, config.hidden_dim),\n",
        "                nn.SiLU(),\n",
        "            ])\n",
        "            in_dim = config.hidden_dim\n",
        "        self.features = nn.Sequential(*layers)\n",
        "\n",
        "        # === Local modes (35) ===\n",
        "        # These are fiber modes, independent of lambda\n",
        "        self.local_heads = nn.ModuleList([\n",
        "            nn.Linear(config.hidden_dim, 35) for _ in range(config.b3_local)\n",
        "        ])\n",
        "\n",
        "        # === Global TCS modes (42 = 14 + 14 + 14) ===\n",
        "        # Each global mode has a base form multiplied by a profile\n",
        "\n",
        "        # Left-weighted modes (14)\n",
        "        self.left_heads = nn.ModuleList([\n",
        "            nn.Linear(config.hidden_dim, 35) for _ in range(config.n_left)\n",
        "        ])\n",
        "\n",
        "        # Right-weighted modes (14)\n",
        "        self.right_heads = nn.ModuleList([\n",
        "            nn.Linear(config.hidden_dim, 35) for _ in range(config.n_right)\n",
        "        ])\n",
        "\n",
        "        # Neck-coupled modes (14)\n",
        "        self.neck_heads = nn.ModuleList([\n",
        "            nn.Linear(config.hidden_dim, 35) for _ in range(config.n_neck)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch, 7) coordinates, x[:, 0] is the neck coordinate lambda\n",
        "        Returns:\n",
        "            Phi: (batch, 77, 35) - 77 3-forms with 35 components each\n",
        "        \"\"\"\n",
        "        batch = x.shape[0]\n",
        "        lam = x[:, 0]  # Neck coordinate\n",
        "\n",
        "        # Get TCS profiles\n",
        "        prof_left = left_plateau(lam, self.config)      # (batch,)\n",
        "        prof_right = right_plateau(lam, self.config)    # (batch,)\n",
        "        prof_neck = neck_bump(lam, self.config)         # (batch,)\n",
        "\n",
        "        # Feature extraction\n",
        "        f = self.features(x)  # (batch, hidden_dim)\n",
        "\n",
        "        # === Local modes (35) ===\n",
        "        local_forms = torch.stack([h(f) for h in self.local_heads], dim=1)  # (batch, 35, 35)\n",
        "\n",
        "        # === Global TCS modes ===\n",
        "        # Left-weighted: base_form * left_plateau(lambda)\n",
        "        left_base = torch.stack([h(f) for h in self.left_heads], dim=1)  # (batch, 14, 35)\n",
        "        left_forms = left_base * prof_left.unsqueeze(-1).unsqueeze(-1)   # Apply profile\n",
        "\n",
        "        # Right-weighted: base_form * right_plateau(lambda)\n",
        "        right_base = torch.stack([h(f) for h in self.right_heads], dim=1)  # (batch, 14, 35)\n",
        "        right_forms = right_base * prof_right.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        # Neck-coupled: base_form * neck_bump(lambda)\n",
        "        neck_base = torch.stack([h(f) for h in self.neck_heads], dim=1)  # (batch, 14, 35)\n",
        "        neck_forms = neck_base * prof_neck.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "        # Concatenate: [local (35), left (14), right (14), neck (14)] = 77\n",
        "        Phi = torch.cat([local_forms, left_forms, right_forms, neck_forms], dim=1)\n",
        "\n",
        "        return Phi\n",
        "\n",
        "# Test\n",
        "_test_h3 = H3TCSNetwork(config)\n",
        "_test_x = torch.randn(4, 7)\n",
        "_test_x[:, 0] = torch.tensor([-0.8, -0.2, 0.2, 0.8])  # Various lambda values\n",
        "_test_out = _test_h3(_test_x)\n",
        "\n",
        "print(f\"H3TCSNetwork defined.\")\n",
        "print(f\"  Parameters: {sum(p.numel() for p in _test_h3.parameters()):,}\")\n",
        "print(f\"  Output shape: {_test_out.shape} (batch, 77 forms, 35 components)\")\n",
        "print(f\"\\nTCS mode structure:\")\n",
        "print(f\"  Modes 0-34: Local fiber modes\")\n",
        "print(f\"  Modes 35-48: Left-weighted (left_plateau)\")\n",
        "print(f\"  Modes 49-62: Right-weighted (right_plateau)\")\n",
        "print(f\"  Modes 63-76: Neck-coupled (neck_bump)\")\n",
        "\n",
        "# Check profile effect\n",
        "print(f\"\\nProfile effect at different lambda:\")\n",
        "for i, l in enumerate([-0.8, -0.2, 0.2, 0.8]):\n",
        "    norms = _test_out[i].norm(dim=1)\n",
        "    print(f\"  lambda={l:+.1f}: local={norms[:35].mean():.3f}, left={norms[35:49].mean():.3f}, right={norms[49:63].mean():.3f}, neck={norms[63:].mean():.3f}\")\n",
        "\n",
        "del _test_h3, _test_x, _test_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1XXlkXl6UTX",
        "outputId": "7b1b5964-410e-4add-c525-71b028c3c952"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "H3TCSNetwork defined.\n",
            "  Parameters: 892,039\n",
            "  Output shape: torch.Size([4, 77, 35]) (batch, 77 forms, 35 components)\n",
            "\n",
            "TCS mode structure:\n",
            "  Modes 0-34: Local fiber modes\n",
            "  Modes 35-48: Left-weighted (left_plateau)\n",
            "  Modes 49-62: Right-weighted (right_plateau)\n",
            "  Modes 63-76: Neck-coupled (neck_bump)\n",
            "\n",
            "Profile effect at different lambda:\n",
            "  lambda=-0.8: local=0.221, left=0.219, right=0.000, neck=0.000\n",
            "  lambda=-0.2: local=0.221, left=0.218, right=0.000, neck=0.084\n",
            "  lambda=+0.2: local=0.224, left=0.000, right=0.221, neck=0.085\n",
            "  lambda=+0.8: local=0.220, left=0.000, right=0.220, neck=0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Loss Functions\n",
        "# @markdown Losses enforce: harmonicity (d=0, d*=0), orthonormality, G2 compatibility.\n",
        "\n",
        "def gram_matrix(forms: torch.Tensor, metric: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute Gram matrix G_ij = <form_i, form_j> with metric weighting.\n",
        "\n",
        "    Args:\n",
        "        forms: (batch, n_forms, n_components)\n",
        "        metric: (batch, 7, 7)\n",
        "    Returns:\n",
        "        G: (n_forms, n_forms) averaged Gram matrix\n",
        "    \"\"\"\n",
        "    det_g = torch.det(metric)\n",
        "    vol = torch.sqrt(det_g.abs()).unsqueeze(-1).unsqueeze(-1)  # (batch, 1, 1)\n",
        "    weighted = forms * vol  # Volume weighting\n",
        "    G = torch.einsum('bic,bjc->ij', weighted, forms) / forms.shape[0]\n",
        "    return G\n",
        "\n",
        "def orthonormality_loss(G: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Loss for enforcing G = I (orthonormal forms).\"\"\"\n",
        "    I = torch.eye(G.shape[0], device=G.device)\n",
        "    return torch.mean((G - I) ** 2)\n",
        "\n",
        "def closedness_loss_fd(x: torch.Tensor, model: nn.Module, eps: float = 1e-4) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Finite-difference approximation of d(omega) = 0 (closedness).\n",
        "    Penalizes large gradients of form components.\n",
        "    \"\"\"\n",
        "    total = torch.tensor(0.0, device=x.device)\n",
        "    omega_0 = model(x)\n",
        "\n",
        "    for c in range(7):\n",
        "        x_plus = x.clone()\n",
        "        x_minus = x.clone()\n",
        "        x_plus[:, c] += eps\n",
        "        x_minus[:, c] -= eps\n",
        "\n",
        "        grad = (model(x_plus) - model(x_minus)) / (2 * eps)\n",
        "        total = total + torch.mean(grad ** 2)\n",
        "\n",
        "    return total / 7\n",
        "\n",
        "def g2_compatibility_loss(Phi: torch.Tensor, phi_ref: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Loss for G2 3-form compatibility.\n",
        "    The diagonal components should match the reference G2 3-form.\n",
        "\n",
        "    Args:\n",
        "        Phi: (batch, 77, 35) - 77 3-forms\n",
        "        phi_ref: (batch, 35) - reference G2 form components\n",
        "    \"\"\"\n",
        "    # Extract diagonal from local modes (first 35)\n",
        "    local_diag = Phi[:, :35, :].diagonal(dim1=1, dim2=2)  # (batch, 35)\n",
        "    return torch.mean((local_diag - phi_ref) ** 2)\n",
        "\n",
        "def tcs_profile_regularization(Phi: torch.Tensor, lam: torch.Tensor, config: Config) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    NEW v2.0: Regularize global modes to follow their expected profiles.\n",
        "\n",
        "    This encourages:\n",
        "    - Left modes to be large when lambda < 0\n",
        "    - Right modes to be large when lambda > 0\n",
        "    - Neck modes to be large when lambda ~ 0\n",
        "    \"\"\"\n",
        "    batch = Phi.shape[0]\n",
        "\n",
        "    # Get expected profiles\n",
        "    prof_left = left_plateau(lam, config)\n",
        "    prof_right = right_plateau(lam, config)\n",
        "    prof_neck = neck_bump(lam, config)\n",
        "\n",
        "    # Global mode norms (modes 35-76)\n",
        "    left_norms = Phi[:, 35:49, :].norm(dim=2).mean(dim=1)   # (batch,)\n",
        "    right_norms = Phi[:, 49:63, :].norm(dim=2).mean(dim=1)  # (batch,)\n",
        "    neck_norms = Phi[:, 63:77, :].norm(dim=2).mean(dim=1)   # (batch,)\n",
        "\n",
        "    # Normalize profiles to similar scale as norms\n",
        "    scale = (left_norms.mean() + right_norms.mean() + neck_norms.mean()) / 3 + 1e-8\n",
        "\n",
        "    # Loss: mode norms should follow their profiles\n",
        "    loss_left = torch.mean((left_norms / scale - prof_left) ** 2)\n",
        "    loss_right = torch.mean((right_norms / scale - prof_right) ** 2)\n",
        "    loss_neck = torch.mean((neck_norms / scale - prof_neck) ** 2)\n",
        "\n",
        "    return (loss_left + loss_right + loss_neck) / 3\n",
        "\n",
        "print(\"Loss functions defined:\")\n",
        "print(\"  - gram_matrix: Hodge inner product\")\n",
        "print(\"  - orthonormality_loss: G = I\")\n",
        "print(\"  - closedness_loss_fd: d(omega) = 0\")\n",
        "print(\"  - g2_compatibility_loss: match G2 form\")\n",
        "print(\"  - tcs_profile_regularization: TCS structure (NEW)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFxtLRYP6UTY",
        "outputId": "7ec28533-9235-4e57-e833-3e817643ff20"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss functions defined:\n",
            "  - gram_matrix: Hodge inner product\n",
            "  - orthonormality_loss: G = I\n",
            "  - closedness_loss_fd: d(omega) = 0\n",
            "  - g2_compatibility_loss: match G2 form\n",
            "  - tcs_profile_regularization: TCS structure (NEW)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Checkpointing and Auto-Resume\n",
        "# @markdown Saves checkpoints regularly. Training resumes automatically if interrupted.\n",
        "\n",
        "def save_checkpoint(path: str, epoch: int, model: nn.Module, optimizer: optim.Optimizer,\n",
        "                   scheduler, losses: Dict, best_loss: float, phase: str):\n",
        "    \"\"\"Save training checkpoint.\"\"\"\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict() if scheduler else None,\n",
        "        'losses': losses,\n",
        "        'best_loss': best_loss,\n",
        "        'phase': phase,\n",
        "        'config': asdict(config),\n",
        "    }, path)\n",
        "\n",
        "def load_checkpoint(path: str, model: nn.Module, optimizer: optim.Optimizer,\n",
        "                   scheduler=None) -> Dict:\n",
        "    \"\"\"Load checkpoint and restore state.\"\"\"\n",
        "    ckpt = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model_state_dict'])\n",
        "    optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
        "    if scheduler and ckpt.get('scheduler_state_dict'):\n",
        "        scheduler.load_state_dict(ckpt['scheduler_state_dict'])\n",
        "    print(f\"  Resumed from epoch {ckpt['epoch']} (best loss: {ckpt['best_loss']:.2e})\")\n",
        "    return ckpt\n",
        "\n",
        "def find_latest_checkpoint(checkpoint_dir: str, phase: str) -> Optional[str]:\n",
        "    \"\"\"Find most recent checkpoint for a phase.\"\"\"\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        return None\n",
        "    pattern = f\"{phase}_epoch_*.pt\"\n",
        "    ckpts = sorted(Path(checkpoint_dir).glob(pattern))\n",
        "    return str(ckpts[-1]) if ckpts else None\n",
        "\n",
        "def format_time(seconds: float) -> str:\n",
        "    \"\"\"Format seconds as HH:MM:SS.\"\"\"\n",
        "    h = int(seconds // 3600)\n",
        "    m = int((seconds % 3600) // 60)\n",
        "    s = int(seconds % 60)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d}\"\n",
        "\n",
        "# Create checkpoint directory\n",
        "os.makedirs(config.checkpoint_dir, exist_ok=True)\n",
        "print(f\"Checkpointing configured:\")\n",
        "print(f\"  Directory: {config.checkpoint_dir}\")\n",
        "print(f\"  Save every: {config.checkpoint_every} epochs\")\n",
        "print(f\"  Log every: {config.log_every} epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvvOGbNL6UTY",
        "outputId": "cedf45a1-188c-4720-8325-858af3fb07b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpointing configured:\n",
            "  Directory: checkpoints_v2_0\n",
            "  Save every: 500 epochs\n",
            "  Log every: 100 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Phase 1: Train H2 (21 harmonic 2-forms)\n",
        "# @markdown Text-only monitoring. Auto-resumes from checkpoint if available.\n",
        "\n",
        "def train_h2(config: Config, data: Dict[str, torch.Tensor], resume: bool = True) -> Tuple[nn.Module, Dict]:\n",
        "    \"\"\"Train H2 network with auto-resume capability.\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 1: Training H2 (21 harmonic 2-forms)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Initialize\n",
        "    model = H2Network(config).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.lr_h2, weight_decay=config.weight_decay)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, patience=config.scheduler_patience,\n",
        "                                   factor=config.scheduler_factor, min_lr=1e-6)\n",
        "\n",
        "    coords = data['coords'].to(device)\n",
        "    metric = data['metric'].to(device)\n",
        "    n = coords.shape[0]\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = float('inf')\n",
        "    all_losses = {'total': [], 'ortho': [], 'closed': []}\n",
        "    best_state = model.state_dict().copy()\n",
        "\n",
        "    # Try to resume\n",
        "    if resume:\n",
        "        latest = find_latest_checkpoint(config.checkpoint_dir, 'h2')\n",
        "        if latest:\n",
        "            print(f\"Found checkpoint: {latest}\")\n",
        "            ckpt = load_checkpoint(latest, model, optimizer, scheduler)\n",
        "            start_epoch = ckpt['epoch'] + 1\n",
        "            best_loss = ckpt['best_loss']\n",
        "            all_losses = ckpt.get('losses', all_losses)\n",
        "            best_state = model.state_dict().copy()\n",
        "\n",
        "    if start_epoch == 0:\n",
        "        print(\"Starting fresh training...\")\n",
        "\n",
        "    # Header\n",
        "    print(f\"\\n{'Epoch':>6} | {'Loss':>10} | {'Ortho':>10} | {'Closed':>10} | {'Best':>10} | {'LR':>8} | {'Time':>8}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(start_epoch, config.n_epochs_h2):\n",
        "        model.train()\n",
        "\n",
        "        # Sample batch\n",
        "        idx = torch.randperm(n)[:config.batch_size]\n",
        "        x, g = coords[idx], metric[idx]\n",
        "\n",
        "        # Forward\n",
        "        omega = model(x)\n",
        "\n",
        "        # Losses\n",
        "        G = gram_matrix(omega, g)\n",
        "        loss_ortho = orthonormality_loss(G)\n",
        "        loss_closed = closedness_loss_fd(x, model)\n",
        "        total = config.w_orthonormal * loss_ortho + config.w_closed * loss_closed\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        total.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step(total)\n",
        "\n",
        "        # Track\n",
        "        all_losses['total'].append(total.item())\n",
        "        all_losses['ortho'].append(loss_ortho.item())\n",
        "        all_losses['closed'].append(loss_closed.item())\n",
        "\n",
        "        if total.item() < best_loss:\n",
        "            best_loss = total.item()\n",
        "            best_state = model.state_dict().copy()\n",
        "\n",
        "        # Log\n",
        "        if (epoch + 1) % config.log_every == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            lr = optimizer.param_groups[0]['lr']\n",
        "            print(f\"{epoch+1:6d} | {total.item():10.2e} | {loss_ortho.item():10.2e} | \"\n",
        "                  f\"{loss_closed.item():10.2e} | {best_loss:10.2e} | {lr:8.1e} | {format_time(elapsed)}\")\n",
        "\n",
        "        # Checkpoint\n",
        "        if (epoch + 1) % config.checkpoint_every == 0:\n",
        "            ckpt_path = f\"{config.checkpoint_dir}/h2_epoch_{epoch+1:05d}.pt\"\n",
        "            save_checkpoint(ckpt_path, epoch, model, optimizer, scheduler, all_losses, best_loss, 'h2')\n",
        "\n",
        "    # Restore best\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "    # Final checkpoint\n",
        "    final_path = f\"{config.checkpoint_dir}/h2_final.pt\"\n",
        "    save_checkpoint(final_path, config.n_epochs_h2 - 1, model, optimizer, scheduler, all_losses, best_loss, 'h2')\n",
        "\n",
        "    print(f\"\\nH2 training complete.\")\n",
        "    print(f\"  Best loss: {best_loss:.2e}\")\n",
        "    print(f\"  Saved: {final_path}\")\n",
        "\n",
        "    return model, all_losses\n",
        "\n",
        "# Train H2\n",
        "h2_model, h2_losses = train_h2(config, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qo94SIn_6UTZ",
        "outputId": "24e0bb5a-cbf7-45c6-caa2-e67fc1a5fabe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 1: Training H2 (21 harmonic 2-forms)\n",
            "======================================================================\n",
            "Starting fresh training...\n",
            "\n",
            " Epoch |       Loss |      Ortho |     Closed |       Best |       LR |     Time\n",
            "--------------------------------------------------------------------------------\n",
            "   100 |   3.07e-06 |   8.62e-07 |   2.98e-06 |   3.07e-06 |  1.0e-03 | 00:00:08\n",
            "   200 |   1.34e-06 |   3.52e-07 |   1.30e-06 |   1.26e-06 |  1.0e-03 | 00:00:14\n",
            "   300 |   9.98e-07 |   2.22e-06 |   7.75e-07 |   7.88e-07 |  1.0e-03 | 00:00:21\n",
            "   400 |   5.33e-07 |   6.57e-08 |   5.26e-07 |   5.33e-07 |  1.0e-03 | 00:00:27\n",
            "   500 |   4.00e-07 |   3.70e-08 |   3.96e-07 |   4.00e-07 |  1.0e-03 | 00:00:34\n",
            "   600 |   6.03e-07 |   2.91e-06 |   3.12e-07 |   3.19e-07 |  1.0e-03 | 00:00:40\n",
            "   700 |   3.89e-07 |   1.34e-06 |   2.55e-07 |   2.63e-07 |  1.0e-03 | 00:00:46\n",
            "   800 |   3.35e-07 |   1.05e-06 |   2.29e-07 |   2.31e-07 |  1.0e-03 | 00:00:53\n",
            "   900 |   2.33e-07 |   4.56e-07 |   1.88e-07 |   1.91e-07 |  1.0e-03 | 00:00:59\n",
            "  1000 |   4.11e-07 |   2.44e-06 |   1.67e-07 |   1.71e-07 |  1.0e-03 | 00:01:05\n",
            "  1100 |   3.46e-07 |   1.96e-06 |   1.51e-07 |   1.56e-07 |  1.0e-03 | 00:01:12\n",
            "  1200 |   1.34e-07 |   1.24e-08 |   1.33e-07 |   1.32e-07 |  1.0e-03 | 00:01:18\n",
            "  1300 |   1.74e-07 |   5.21e-07 |   1.22e-07 |   1.23e-07 |  1.0e-03 | 00:01:24\n",
            "  1400 |   4.44e-07 |   3.32e-06 |   1.12e-07 |   1.11e-07 |  1.0e-03 | 00:01:31\n",
            "  1500 |   1.56e-07 |   5.18e-07 |   1.05e-07 |   9.94e-08 |  1.0e-03 | 00:01:37\n",
            "  1600 |   1.20e-07 |   2.88e-07 |   9.16e-08 |   9.08e-08 |  1.0e-03 | 00:01:43\n",
            "  1700 |   7.91e-07 |   7.08e-06 |   8.32e-08 |   8.52e-08 |  1.0e-03 | 00:01:50\n",
            "  1800 |   5.54e-07 |   4.72e-06 |   8.21e-08 |   7.90e-08 |  1.0e-03 | 00:01:56\n",
            "  1900 |   6.53e-07 |   5.75e-06 |   7.87e-08 |   7.66e-08 |  1.0e-03 | 00:02:02\n",
            "  2000 |   1.56e-07 |   8.70e-07 |   6.92e-08 |   7.16e-08 |  1.0e-03 | 00:02:09\n",
            "  2100 |   3.92e-07 |   3.27e-06 |   6.53e-08 |   6.68e-08 |  1.0e-03 | 00:02:15\n",
            "  2200 |   7.94e-07 |   7.29e-06 |   6.47e-08 |   6.45e-08 |  1.0e-03 | 00:02:21\n",
            "  2300 |   1.82e-06 |   1.76e-05 |   5.68e-08 |   6.04e-08 |  1.0e-03 | 00:02:28\n",
            "  2400 |   6.15e-08 |   2.40e-08 |   5.91e-08 |   5.77e-08 |  1.0e-03 | 00:02:34\n",
            "  2500 |   7.80e-08 |   2.36e-07 |   5.43e-08 |   5.34e-08 |  1.0e-03 | 00:02:40\n",
            "  2600 |   1.78e-07 |   1.28e-06 |   4.95e-08 |   5.12e-08 |  1.0e-03 | 00:02:47\n",
            "  2700 |   1.98e-07 |   1.50e-06 |   4.83e-08 |   4.88e-08 |  1.0e-03 | 00:02:53\n",
            "  2800 |   8.81e-07 |   8.37e-06 |   4.47e-08 |   4.72e-08 |  1.0e-03 | 00:03:00\n",
            "  2900 |   1.01e-07 |   5.38e-07 |   4.69e-08 |   4.40e-08 |  1.0e-03 | 00:03:06\n",
            "  3000 |   4.93e-08 |   7.27e-08 |   4.20e-08 |   4.30e-08 |  1.0e-03 | 00:03:12\n",
            "\n",
            "H2 training complete.\n",
            "  Best loss: 4.30e-08\n",
            "  Saved: checkpoints_v2_0/h2_final.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Phase 2: Train H3 with TCS structure (77 harmonic 3-forms)\n",
        "# @markdown **KEY v2.0**: Includes TCS profile regularization for global modes.\n",
        "\n",
        "def train_h3_tcs(config: Config, data: Dict[str, torch.Tensor], resume: bool = True) -> Tuple[nn.Module, Dict]:\n",
        "    \"\"\"Train H3 TCS network with proper global mode structure.\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 2: Training H3 with TCS Structure (77 harmonic 3-forms)\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"  35 local modes + 42 global TCS modes (14 left + 14 right + 14 neck)\")\n",
        "\n",
        "    # Initialize\n",
        "    model = H3TCSNetwork(config).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config.lr_h3, weight_decay=config.weight_decay)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, patience=config.scheduler_patience,\n",
        "                                   factor=config.scheduler_factor, min_lr=1e-6)\n",
        "\n",
        "    coords = data['coords'].to(device)\n",
        "    metric = data['metric'].to(device)\n",
        "    phi = data['phi'].to(device)\n",
        "    n = coords.shape[0]\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_loss = float('inf')\n",
        "    all_losses = {'total': [], 'ortho': [], 'closed': [], 'g2': [], 'tcs': []}\n",
        "    best_state = model.state_dict().copy()\n",
        "\n",
        "    # Try to resume\n",
        "    if resume:\n",
        "        latest = find_latest_checkpoint(config.checkpoint_dir, 'h3')\n",
        "        if latest:\n",
        "            print(f\"Found checkpoint: {latest}\")\n",
        "            ckpt = load_checkpoint(latest, model, optimizer, scheduler)\n",
        "            start_epoch = ckpt['epoch'] + 1\n",
        "            best_loss = ckpt['best_loss']\n",
        "            all_losses = ckpt.get('losses', all_losses)\n",
        "            best_state = model.state_dict().copy()\n",
        "\n",
        "    if start_epoch == 0:\n",
        "        print(\"Starting fresh training...\")\n",
        "\n",
        "    # Header\n",
        "    print(f\"\\n{'Epoch':>6} | {'Loss':>9} | {'Ortho':>9} | {'Closed':>9} | {'G2':>9} | {'TCS':>9} | {'Best':>9} | {'Time':>8}\")\n",
        "    print(\"-\" * 95)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(start_epoch, config.n_epochs_h3):\n",
        "        model.train()\n",
        "\n",
        "        # Sample batch\n",
        "        idx = torch.randperm(n)[:config.batch_size]\n",
        "        x, g, p = coords[idx], metric[idx], phi[idx]\n",
        "        lam = x[:, 0]  # Neck coordinate\n",
        "\n",
        "        # Forward\n",
        "        Phi = model(x)  # (batch, 77, 35)\n",
        "\n",
        "        # Losses\n",
        "        G = gram_matrix(Phi, g)\n",
        "        loss_ortho = orthonormality_loss(G)\n",
        "        loss_closed = closedness_loss_fd(x, model)\n",
        "        loss_g2 = g2_compatibility_loss(Phi, p)\n",
        "        loss_tcs = tcs_profile_regularization(Phi, lam, config)\n",
        "\n",
        "        total = (config.w_orthonormal * loss_ortho +\n",
        "                config.w_closed * loss_closed +\n",
        "                config.w_g2_compat * loss_g2 +\n",
        "                config.w_tcs_profile * loss_tcs)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        total.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "        optimizer.step()\n",
        "        scheduler.step(total)\n",
        "\n",
        "        # Track\n",
        "        all_losses['total'].append(total.item())\n",
        "        all_losses['ortho'].append(loss_ortho.item())\n",
        "        all_losses['closed'].append(loss_closed.item())\n",
        "        all_losses['g2'].append(loss_g2.item())\n",
        "        all_losses['tcs'].append(loss_tcs.item())\n",
        "\n",
        "        if total.item() < best_loss:\n",
        "            best_loss = total.item()\n",
        "            best_state = model.state_dict().copy()\n",
        "\n",
        "        # Log\n",
        "        if (epoch + 1) % config.log_every == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            print(f\"{epoch+1:6d} | {total.item():9.2e} | {loss_ortho.item():9.2e} | \"\n",
        "                  f\"{loss_closed.item():9.2e} | {loss_g2.item():9.2e} | {loss_tcs.item():9.2e} | \"\n",
        "                  f\"{best_loss:9.2e} | {format_time(elapsed)}\")\n",
        "\n",
        "        # Checkpoint\n",
        "        if (epoch + 1) % config.checkpoint_every == 0:\n",
        "            ckpt_path = f\"{config.checkpoint_dir}/h3_epoch_{epoch+1:05d}.pt\"\n",
        "            save_checkpoint(ckpt_path, epoch, model, optimizer, scheduler, all_losses, best_loss, 'h3')\n",
        "\n",
        "    # Restore best\n",
        "    model.load_state_dict(best_state)\n",
        "\n",
        "    # Final checkpoint\n",
        "    final_path = f\"{config.checkpoint_dir}/h3_final.pt\"\n",
        "    save_checkpoint(final_path, config.n_epochs_h3 - 1, model, optimizer, scheduler, all_losses, best_loss, 'h3')\n",
        "\n",
        "    print(f\"\\nH3 TCS training complete.\")\n",
        "    print(f\"  Best loss: {best_loss:.2e}\")\n",
        "    print(f\"  Saved: {final_path}\")\n",
        "\n",
        "    return model, all_losses\n",
        "\n",
        "# Train H3 with TCS structure\n",
        "h3_model, h3_losses = train_h3_tcs(config, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajFfnxXV6UTZ",
        "outputId": "316a4bbf-c246-41a2-a7f1-28b742c4a404"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 2: Training H3 with TCS Structure (77 harmonic 3-forms)\n",
            "======================================================================\n",
            "  35 local modes + 42 global TCS modes (14 left + 14 right + 14 neck)\n",
            "Starting fresh training...\n",
            "\n",
            " Epoch |      Loss |     Ortho |    Closed |        G2 |       TCS |      Best |     Time\n",
            "-----------------------------------------------------------------------------------------------\n",
            "   100 |  3.61e-01 |  7.30e-03 |  2.95e-04 |  2.00e-01 |  8.67e-01 |  3.52e-01 | 00:00:19\n",
            "   200 |  3.39e-01 |  6.92e-03 |  4.11e-04 |  2.00e-01 |  7.94e-01 |  3.37e-01 | 00:00:39\n",
            "   300 |  3.42e-01 |  6.89e-03 |  4.31e-04 |  2.00e-01 |  8.03e-01 |  3.31e-01 | 00:00:59\n",
            "   400 |  3.34e-01 |  6.90e-03 |  4.15e-04 |  2.00e-01 |  7.76e-01 |  3.30e-01 | 00:01:19\n",
            "   500 |  3.34e-01 |  6.92e-03 |  3.63e-04 |  2.00e-01 |  7.78e-01 |  3.30e-01 | 00:01:39\n",
            "   600 |  3.37e-01 |  6.94e-03 |  2.99e-04 |  2.00e-01 |  7.86e-01 |  3.29e-01 | 00:01:59\n",
            "   700 |  3.40e-01 |  6.97e-03 |  2.91e-04 |  2.00e-01 |  7.98e-01 |  3.29e-01 | 00:02:19\n",
            "   800 |  3.32e-01 |  7.00e-03 |  2.47e-04 |  2.00e-01 |  7.72e-01 |  3.27e-01 | 00:02:38\n",
            "   900 |  3.32e-01 |  7.02e-03 |  2.54e-04 |  2.00e-01 |  7.70e-01 |  3.27e-01 | 00:02:58\n",
            "  1000 |  3.29e-01 |  7.02e-03 |  2.99e-04 |  2.00e-01 |  7.62e-01 |  3.22e-01 | 00:03:18\n",
            "  1100 |  3.38e-01 |  6.99e-03 |  4.25e-04 |  2.00e-01 |  7.92e-01 |  3.18e-01 | 00:03:38\n",
            "  1200 |  3.23e-01 |  6.98e-03 |  5.15e-04 |  2.00e-01 |  7.41e-01 |  3.17e-01 | 00:03:58\n",
            "  1300 |  3.26e-01 |  7.00e-03 |  4.41e-04 |  1.99e-01 |  7.50e-01 |  3.16e-01 | 00:04:18\n",
            "  1400 |  3.22e-01 |  7.00e-03 |  4.03e-04 |  1.99e-01 |  7.37e-01 |  3.15e-01 | 00:04:38\n",
            "  1500 |  3.14e-01 |  7.01e-03 |  4.04e-04 |  1.99e-01 |  7.12e-01 |  3.14e-01 | 00:04:57\n",
            "  1600 |  3.22e-01 |  7.01e-03 |  3.50e-04 |  1.99e-01 |  7.37e-01 |  3.14e-01 | 00:05:17\n",
            "  1700 |  3.24e-01 |  7.02e-03 |  3.23e-04 |  1.99e-01 |  7.45e-01 |  3.14e-01 | 00:05:37\n",
            "  1800 |  3.27e-01 |  7.02e-03 |  2.90e-04 |  1.99e-01 |  7.54e-01 |  3.14e-01 | 00:05:57\n",
            "  1900 |  3.24e-01 |  7.03e-03 |  2.77e-04 |  1.99e-01 |  7.43e-01 |  3.12e-01 | 00:06:17\n",
            "  2000 |  3.24e-01 |  7.03e-03 |  2.65e-04 |  1.99e-01 |  7.43e-01 |  3.12e-01 | 00:06:37\n",
            "  2100 |  3.19e-01 |  7.03e-03 |  2.55e-04 |  1.99e-01 |  7.28e-01 |  3.12e-01 | 00:06:57\n",
            "  2200 |  3.22e-01 |  7.01e-03 |  4.59e-04 |  1.99e-01 |  7.38e-01 |  3.12e-01 | 00:07:16\n",
            "  2300 |  3.28e-01 |  7.01e-03 |  3.59e-04 |  1.99e-01 |  7.57e-01 |  3.12e-01 | 00:07:36\n",
            "  2400 |  3.22e-01 |  7.02e-03 |  3.26e-04 |  1.99e-01 |  7.37e-01 |  3.12e-01 | 00:07:56\n",
            "  2500 |  3.22e-01 |  7.03e-03 |  3.03e-04 |  1.99e-01 |  7.39e-01 |  3.12e-01 | 00:08:16\n",
            "  2600 |  3.24e-01 |  7.03e-03 |  2.69e-04 |  1.99e-01 |  7.43e-01 |  3.12e-01 | 00:08:36\n",
            "  2700 |  3.18e-01 |  7.03e-03 |  2.69e-04 |  1.99e-01 |  7.25e-01 |  3.12e-01 | 00:08:56\n",
            "  2800 |  3.27e-01 |  7.04e-03 |  2.29e-04 |  1.99e-01 |  7.54e-01 |  3.11e-01 | 00:09:15\n",
            "  2900 |  3.17e-01 |  7.04e-03 |  2.49e-04 |  1.99e-01 |  7.21e-01 |  3.11e-01 | 00:09:35\n",
            "  3000 |  3.21e-01 |  7.04e-03 |  2.33e-04 |  1.99e-01 |  7.34e-01 |  3.11e-01 | 00:09:55\n",
            "  3100 |  3.20e-01 |  7.04e-03 |  2.21e-04 |  1.99e-01 |  7.32e-01 |  3.10e-01 | 00:10:15\n",
            "  3200 |  3.17e-01 |  7.04e-03 |  2.19e-04 |  1.99e-01 |  7.21e-01 |  3.10e-01 | 00:10:35\n",
            "  3300 |  3.20e-01 |  7.05e-03 |  1.97e-04 |  1.99e-01 |  7.33e-01 |  3.10e-01 | 00:10:55\n",
            "  3400 |  3.20e-01 |  7.05e-03 |  1.85e-04 |  1.99e-01 |  7.33e-01 |  3.10e-01 | 00:11:15\n",
            "  3500 |  3.17e-01 |  7.05e-03 |  1.89e-04 |  1.99e-01 |  7.21e-01 |  3.09e-01 | 00:11:35\n",
            "  3600 |  3.16e-01 |  7.05e-03 |  1.79e-04 |  1.99e-01 |  7.18e-01 |  3.09e-01 | 00:11:55\n",
            "  3700 |  3.15e-01 |  7.06e-03 |  1.73e-04 |  1.99e-01 |  7.14e-01 |  3.09e-01 | 00:12:15\n",
            "  3800 |  3.22e-01 |  7.06e-03 |  1.53e-04 |  1.99e-01 |  7.38e-01 |  3.09e-01 | 00:12:35\n",
            "  3900 |  3.13e-01 |  7.06e-03 |  1.60e-04 |  1.99e-01 |  7.10e-01 |  3.07e-01 | 00:12:55\n",
            "  4000 |  3.17e-01 |  7.06e-03 |  1.54e-04 |  1.99e-01 |  7.21e-01 |  3.07e-01 | 00:13:15\n",
            "  4100 |  3.16e-01 |  7.06e-03 |  1.54e-04 |  1.99e-01 |  7.18e-01 |  3.07e-01 | 00:13:35\n",
            "  4200 |  3.16e-01 |  7.06e-03 |  1.52e-04 |  1.99e-01 |  7.18e-01 |  3.07e-01 | 00:13:54\n",
            "  4300 |  3.18e-01 |  7.06e-03 |  1.55e-04 |  1.99e-01 |  7.27e-01 |  3.07e-01 | 00:14:14\n",
            "  4400 |  3.17e-01 |  7.06e-03 |  1.58e-04 |  1.99e-01 |  7.23e-01 |  3.07e-01 | 00:14:34\n",
            "  4500 |  3.16e-01 |  7.06e-03 |  1.65e-04 |  1.99e-01 |  7.18e-01 |  3.07e-01 | 00:14:54\n",
            "  4600 |  3.20e-01 |  7.06e-03 |  1.70e-04 |  1.99e-01 |  7.33e-01 |  3.07e-01 | 00:15:14\n",
            "  4700 |  3.16e-01 |  7.06e-03 |  1.76e-04 |  1.99e-01 |  7.20e-01 |  3.07e-01 | 00:15:34\n",
            "  4800 |  3.10e-01 |  7.06e-03 |  1.91e-04 |  1.99e-01 |  6.98e-01 |  3.04e-01 | 00:15:53\n",
            "  4900 |  3.14e-01 |  7.06e-03 |  1.85e-04 |  1.99e-01 |  7.14e-01 |  3.04e-01 | 00:16:13\n",
            "  5000 |  3.17e-01 |  7.06e-03 |  1.90e-04 |  1.99e-01 |  7.23e-01 |  3.04e-01 | 00:16:33\n",
            "  5100 |  3.14e-01 |  7.06e-03 |  2.04e-04 |  1.99e-01 |  7.12e-01 |  3.04e-01 | 00:16:53\n",
            "  5200 |  3.16e-01 |  7.06e-03 |  2.00e-04 |  1.99e-01 |  7.18e-01 |  3.04e-01 | 00:17:13\n",
            "  5300 |  3.12e-01 |  7.06e-03 |  2.19e-04 |  1.99e-01 |  7.06e-01 |  3.04e-01 | 00:17:33\n",
            "  5400 |  3.07e-01 |  7.06e-03 |  2.31e-04 |  1.99e-01 |  6.90e-01 |  3.04e-01 | 00:17:52\n",
            "  5500 |  3.11e-01 |  7.06e-03 |  2.22e-04 |  1.99e-01 |  7.03e-01 |  3.04e-01 | 00:18:12\n",
            "  5600 |  3.15e-01 |  7.06e-03 |  2.18e-04 |  1.99e-01 |  7.16e-01 |  3.04e-01 | 00:18:32\n",
            "  5700 |  3.09e-01 |  7.06e-03 |  2.36e-04 |  1.99e-01 |  6.96e-01 |  3.04e-01 | 00:18:52\n",
            "  5800 |  3.16e-01 |  7.06e-03 |  2.16e-04 |  1.99e-01 |  7.19e-01 |  3.03e-01 | 00:19:12\n",
            "  5900 |  3.08e-01 |  7.06e-03 |  2.38e-04 |  1.99e-01 |  6.91e-01 |  3.03e-01 | 00:19:32\n",
            "  6000 |  3.11e-01 |  7.06e-03 |  2.36e-04 |  1.99e-01 |  7.01e-01 |  3.03e-01 | 00:19:51\n",
            "  6100 |  3.10e-01 |  7.06e-03 |  2.47e-04 |  1.99e-01 |  6.98e-01 |  3.03e-01 | 00:20:11\n",
            "  6200 |  3.14e-01 |  7.06e-03 |  2.32e-04 |  1.99e-01 |  7.12e-01 |  3.02e-01 | 00:20:31\n",
            "  6300 |  3.17e-01 |  7.06e-03 |  2.31e-04 |  1.99e-01 |  7.21e-01 |  3.02e-01 | 00:20:51\n",
            "  6400 |  3.13e-01 |  7.06e-03 |  2.38e-04 |  1.99e-01 |  7.10e-01 |  3.02e-01 | 00:21:11\n",
            "  6500 |  3.15e-01 |  7.06e-03 |  2.38e-04 |  1.99e-01 |  7.15e-01 |  3.02e-01 | 00:21:30\n",
            "  6600 |  3.14e-01 |  7.06e-03 |  2.43e-04 |  1.99e-01 |  7.12e-01 |  3.02e-01 | 00:21:50\n",
            "  6700 |  3.09e-01 |  7.06e-03 |  2.59e-04 |  1.99e-01 |  6.96e-01 |  3.02e-01 | 00:22:10\n",
            "  6800 |  3.13e-01 |  7.06e-03 |  2.46e-04 |  1.99e-01 |  7.10e-01 |  3.02e-01 | 00:22:30\n",
            "  6900 |  3.13e-01 |  7.06e-03 |  2.48e-04 |  1.99e-01 |  7.09e-01 |  3.02e-01 | 00:22:50\n",
            "  7000 |  3.15e-01 |  7.06e-03 |  2.37e-04 |  1.99e-01 |  7.16e-01 |  3.02e-01 | 00:23:10\n",
            "  7100 |  3.14e-01 |  7.06e-03 |  2.44e-04 |  1.99e-01 |  7.13e-01 |  3.02e-01 | 00:23:30\n",
            "  7200 |  3.08e-01 |  7.06e-03 |  2.51e-04 |  1.99e-01 |  6.91e-01 |  3.02e-01 | 00:23:50\n",
            "  7300 |  3.11e-01 |  7.06e-03 |  2.59e-04 |  1.99e-01 |  7.01e-01 |  3.02e-01 | 00:24:09\n",
            "  7400 |  3.09e-01 |  7.06e-03 |  2.60e-04 |  1.99e-01 |  6.94e-01 |  3.02e-01 | 00:24:29\n",
            "  7500 |  3.16e-01 |  7.06e-03 |  2.39e-04 |  1.99e-01 |  7.19e-01 |  3.02e-01 | 00:24:49\n",
            "  7600 |  3.09e-01 |  7.06e-03 |  2.63e-04 |  1.99e-01 |  6.97e-01 |  3.02e-01 | 00:25:09\n",
            "  7700 |  3.13e-01 |  7.06e-03 |  2.58e-04 |  1.99e-01 |  7.08e-01 |  3.02e-01 | 00:25:29\n",
            "  7800 |  3.13e-01 |  7.06e-03 |  2.47e-04 |  1.99e-01 |  7.09e-01 |  3.02e-01 | 00:25:49\n",
            "  7900 |  3.09e-01 |  7.06e-03 |  2.65e-04 |  1.99e-01 |  6.96e-01 |  3.02e-01 | 00:26:09\n",
            "  8000 |  3.08e-01 |  7.06e-03 |  2.57e-04 |  1.99e-01 |  6.91e-01 |  3.02e-01 | 00:26:29\n",
            "\n",
            "H3 TCS training complete.\n",
            "  Best loss: 3.02e-01\n",
            "  Saved: checkpoints_v2_0/h3_final.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Phase 3: Compute Yukawa Tensor\n",
        "# @markdown Y_ijk = integral(omega_i wedge omega_j wedge Phi_k) using proper Levi-Civita.\n",
        "\n",
        "def levi_civita_7(indices: Tuple[int, ...]) -> int:\n",
        "    \"\"\"Compute Levi-Civita symbol for 7D indices.\"\"\"\n",
        "    if len(set(indices)) != 7:\n",
        "        return 0\n",
        "    inv = sum(1 for i in range(7) for j in range(i+1, 7) if indices[i] > indices[j])\n",
        "    return 1 if inv % 2 == 0 else -1\n",
        "\n",
        "def build_yukawa_coefficients() -> List[Tuple[int, int, int, int]]:\n",
        "    \"\"\"Build list of non-zero Yukawa wedge coefficients.\"\"\"\n",
        "    pairs = list(combinations(range(7), 2))    # 21 pairs for 2-forms\n",
        "    triples = list(combinations(range(7), 3))  # 35 triples for 3-forms\n",
        "\n",
        "    coeffs = []\n",
        "    for i1, p1 in enumerate(pairs):\n",
        "        for i2, p2 in enumerate(pairs):\n",
        "            if i2 < i1:\n",
        "                continue  # Symmetry\n",
        "            for i3, t in enumerate(triples):\n",
        "                all_idx = p1 + p2 + t\n",
        "                if len(set(all_idx)) != 7:\n",
        "                    continue  # Not a valid wedge\n",
        "                sign = levi_civita_7(all_idx)\n",
        "                if sign != 0:\n",
        "                    coeffs.append((i1, i2, i3, sign))\n",
        "\n",
        "    return coeffs\n",
        "\n",
        "# Build coefficients once\n",
        "YUKAWA_COEFFS = build_yukawa_coefficients()\n",
        "print(f\"Built {len(YUKAWA_COEFFS)} Yukawa wedge coefficients\")\n",
        "\n",
        "def compute_yukawa(h2_model: nn.Module, h3_model: nn.Module,\n",
        "                   data: Dict[str, torch.Tensor],\n",
        "                   coeffs: List[Tuple[int, int, int, int]],\n",
        "                   n_pts: int = 5000) -> Dict[str, np.ndarray]:\n",
        "    \"\"\"Compute Yukawa tensor Y_ijk and Gram matrix M.\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"PHASE 3: Computing Yukawa Tensor (proper wedge product)\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    h2_model.eval()\n",
        "    h3_model.eval()\n",
        "\n",
        "    coords = data['coords'].to(device)\n",
        "    metric = data['metric'].to(device)\n",
        "    n = min(n_pts, coords.shape[0])\n",
        "    idx = torch.randperm(coords.shape[0])[:n]\n",
        "    x, g = coords[idx], metric[idx]\n",
        "\n",
        "    # Volume element\n",
        "    det_g = torch.det(g)\n",
        "    vol = torch.sqrt(det_g.abs())\n",
        "    total_vol = vol.sum()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        omega = h2_model(x)  # (n, 21, 21)\n",
        "        Phi = h3_model(x)    # (n, 77, 35)\n",
        "\n",
        "    print(f\"Integration points: {n}\")\n",
        "    print(f\"omega shape: {omega.shape}\")\n",
        "    print(f\"Phi shape: {Phi.shape}\")\n",
        "    print(\"Computing Y_ijk...\")\n",
        "\n",
        "    Y = torch.zeros(21, 21, 77, device=device)\n",
        "\n",
        "    for a in range(21):\n",
        "        if (a + 1) % 7 == 0:\n",
        "            print(f\"  H2 mode {a+1}/21\")\n",
        "        omega_a = omega[:, a, :]  # (n, 21)\n",
        "\n",
        "        for b in range(a, 21):\n",
        "            omega_b = omega[:, b, :]  # (n, 21)\n",
        "\n",
        "            for c in range(77):\n",
        "                Phi_c = Phi[:, c, :]  # (n, 35)\n",
        "\n",
        "                # Compute wedge integral\n",
        "                integral = torch.zeros(n, device=device)\n",
        "                for i1, i2, i3, sign in coeffs:\n",
        "                    integral += sign * omega_a[:, i1] * omega_b[:, i2] * Phi_c[:, i3]\n",
        "\n",
        "                Y[a, b, c] = (integral * vol).sum() / total_vol\n",
        "                if a != b:\n",
        "                    Y[b, a, c] = -Y[a, b, c]  # Antisymmetry\n",
        "\n",
        "    print(\"Computing Gram matrix M = Y^T Y...\")\n",
        "    # M_kl = sum_ij Y_ijk * Y_ijl\n",
        "    M = torch.einsum('ijk,ijl->kl', Y, Y)\n",
        "\n",
        "    print(\"Eigendecomposition...\")\n",
        "    eigenvalues, eigenvectors = torch.linalg.eigh(M)\n",
        "    idx_sort = torch.argsort(eigenvalues, descending=True)\n",
        "    eigenvalues = eigenvalues[idx_sort]\n",
        "    eigenvectors = eigenvectors[:, idx_sort]\n",
        "\n",
        "    print(\"Done.\")\n",
        "\n",
        "    return {\n",
        "        'Y': Y.cpu().numpy(),\n",
        "        'M': M.cpu().numpy(),\n",
        "        'eigenvalues': eigenvalues.cpu().numpy(),\n",
        "        'eigenvectors': eigenvectors.cpu().numpy(),\n",
        "        'omega': omega.cpu().numpy(),\n",
        "        'Phi': Phi.cpu().numpy(),\n",
        "    }\n",
        "\n",
        "# Compute Yukawa\n",
        "yukawa = compute_yukawa(h2_model, h3_model, data, YUKAWA_COEFFS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Quotn35R6UTZ",
        "outputId": "ee8c74c1-02d0-41d9-90ce-c927cbf55c30"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built 105 Yukawa wedge coefficients\n",
            "======================================================================\n",
            "PHASE 3: Computing Yukawa Tensor (proper wedge product)\n",
            "======================================================================\n",
            "Integration points: 5000\n",
            "omega shape: torch.Size([5000, 21, 21])\n",
            "Phi shape: torch.Size([5000, 77, 35])\n",
            "Computing Y_ijk...\n",
            "  H2 mode 7/21\n",
            "  H2 mode 14/21\n",
            "  H2 mode 21/21\n",
            "Computing Gram matrix M = Y^T Y...\n",
            "Eigendecomposition...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Spectral Analysis\n",
        "# @markdown Analyze Yukawa spectrum for 43/77 split and tau = 3472/891.\n",
        "\n",
        "def analyze_spectrum(eigs: np.ndarray, tau_target: float = 3472/891) -> Dict:\n",
        "    \"\"\"Comprehensive spectral analysis of Yukawa Gram matrix.\"\"\"\n",
        "\n",
        "    print(\"=\" * 70)\n",
        "    print(\"YUKAWA SPECTRAL ANALYSIS\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Non-zero count\n",
        "    nonzero_mask = np.abs(eigs) > 1e-10\n",
        "    nonzero = nonzero_mask.sum()\n",
        "\n",
        "    print(f\"\\n[EIGENVALUES]\")\n",
        "    print(f\"  Total: {len(eigs)}, Non-zero: {nonzero}\")\n",
        "    print(f\"  Top 5: {eigs[:5].round(4)}\")\n",
        "    print(f\"  Around 35: eigs[32:38] = {eigs[32:38].round(6)}\")\n",
        "    print(f\"  Around 43: eigs[40:46] = {eigs[40:46]}\")\n",
        "\n",
        "    # Gaps\n",
        "    gaps = np.abs(np.diff(eigs))\n",
        "    mean_gap = gaps.mean() if len(gaps) > 0 else 1.0\n",
        "\n",
        "    print(f\"\\n[TOP 5 GAPS]\")\n",
        "    gap_order = np.argsort(gaps)[::-1]\n",
        "    for i, idx in enumerate(gap_order[:5]):\n",
        "        ratio = gaps[idx] / mean_gap if mean_gap > 0 else 0\n",
        "        print(f\"  #{i+1}: gap {idx}->{idx+1}: {gaps[idx]:.6f} ({ratio:.1f}x mean)\")\n",
        "\n",
        "    # Key positions\n",
        "    print(f\"\\n[KEY POSITIONS]\")\n",
        "    for pos in [20, 21, 34, 35, 42, 43]:\n",
        "        if pos < len(gaps):\n",
        "            ratio = gaps[pos] / mean_gap if mean_gap > 0 else 0\n",
        "            print(f\"  Gap {pos}->{pos+1}: {gaps[pos]:.6f} ({ratio:.1f}x mean)\")\n",
        "\n",
        "    # Cumulative\n",
        "    cumsum = np.cumsum(eigs)\n",
        "    total = eigs.sum() if eigs.sum() > 0 else 1.0\n",
        "\n",
        "    print(f\"\\n[CUMULATIVE VARIANCE]\")\n",
        "    for n in [21, 35, 43, 77]:\n",
        "        if n <= len(eigs):\n",
        "            pct = 100 * cumsum[n-1] / total\n",
        "            print(f\"  First {n}: {pct:.1f}%\")\n",
        "\n",
        "    # Tau search\n",
        "    print(f\"\\n[TAU SEARCH] (target: {tau_target:.4f})\")\n",
        "    best_n, best_ratio, best_err = 0, 0, float('inf')\n",
        "\n",
        "    for n in range(20, 55):\n",
        "        if n < len(eigs):\n",
        "            visible = cumsum[n-1]\n",
        "            hidden = total - visible\n",
        "            if hidden > 1e-8:\n",
        "                ratio = visible / hidden\n",
        "                err = 100 * abs(ratio - tau_target) / tau_target\n",
        "                if err < best_err:\n",
        "                    best_n, best_ratio, best_err = n, ratio, err\n",
        "\n",
        "    if best_err < float('inf'):\n",
        "        print(f\"  Best: n={best_n}, tau={best_ratio:.4f}, error={best_err:.1f}%\")\n",
        "    else:\n",
        "        print(f\"  No valid tau (hidden sum ~ 0)\")\n",
        "\n",
        "    # Check specific tau values\n",
        "    print(f\"\\n[TAU AT KEY POSITIONS]\")\n",
        "    for n in [35, 42, 43]:\n",
        "        if n < len(eigs):\n",
        "            visible = cumsum[n-1]\n",
        "            hidden = total - visible\n",
        "            if hidden > 1e-8:\n",
        "                ratio = visible / hidden\n",
        "                err = 100 * abs(ratio - tau_target) / tau_target\n",
        "                print(f\"  n={n}: tau={ratio:.4f}, error={err:.1f}%\")\n",
        "\n",
        "    # Verdict\n",
        "    largest_gap_idx = np.argmax(gaps) if len(gaps) > 0 else 0\n",
        "    n_visible = largest_gap_idx + 1\n",
        "\n",
        "    gap_43 = gaps[42] if len(gaps) > 42 else 0\n",
        "    gap_43_ratio = gap_43 / mean_gap if mean_gap > 0 else 0\n",
        "\n",
        "    gap_35 = gaps[34] if len(gaps) > 34 else 0\n",
        "    gap_35_ratio = gap_35 / mean_gap if mean_gap > 0 else 0\n",
        "\n",
        "    print(f\"\\n[VERDICT]\")\n",
        "    print(f\"  Largest gap at: {largest_gap_idx}->{largest_gap_idx+1}\")\n",
        "    print(f\"  Suggested n_visible: {n_visible}\")\n",
        "    print(f\"  Gap at 35: {gap_35_ratio:.2f}x mean\")\n",
        "    print(f\"  Gap at 43: {gap_43_ratio:.2f}x mean\")\n",
        "\n",
        "    return {\n",
        "        'n_visible': int(n_visible),\n",
        "        'nonzero_count': int(nonzero),\n",
        "        'largest_gap_idx': int(largest_gap_idx),\n",
        "        'gap_35_ratio': float(gap_35_ratio),\n",
        "        'gap_43_ratio': float(gap_43_ratio),\n",
        "        'tau_best_n': int(best_n) if best_err < float('inf') else -1,\n",
        "        'tau_estimate': float(best_ratio) if best_err < float('inf') else 0.0,\n",
        "        'tau_error_pct': float(best_err) if best_err < float('inf') else -1.0,\n",
        "    }\n",
        "\n",
        "# Analyze\n",
        "analysis = analyze_spectrum(yukawa['eigenvalues'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnmxJzTE6UTZ",
        "outputId": "3dc17bc6-7c16-4820-cc21-70bb8d8e0041"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "YUKAWA SPECTRAL ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "[EIGENVALUES]\n",
            "  Total: 77, Non-zero: 44\n",
            "  Top 5: [1.5717 1.5213 1.4614 1.4209 1.3852]\n",
            "  Around 35: eigs[32:38] = [0.55459  0.525255 0.494163 0.       0.       0.      ]\n",
            "  Around 43: eigs[40:46] = [3.3988003e-11 2.0642552e-11 1.9362236e-11 1.3599323e-11 9.9267617e-12\n",
            " 8.8493223e-12]\n",
            "\n",
            "[TOP 5 GAPS]\n",
            "  #1: gap 34->35: 0.494163 (23.9x mean)\n",
            "  #2: gap 31->32: 0.062119 (3.0x mean)\n",
            "  #3: gap 1->2: 0.059870 (2.9x mean)\n",
            "  #4: gap 13->14: 0.057810 (2.8x mean)\n",
            "  #5: gap 0->1: 0.050403 (2.4x mean)\n",
            "\n",
            "[KEY POSITIONS]\n",
            "  Gap 20->21: 0.047826 (2.3x mean)\n",
            "  Gap 21->22: 0.032288 (1.6x mean)\n",
            "  Gap 34->35: 0.494163 (23.9x mean)\n",
            "  Gap 35->36: 0.000000 (0.0x mean)\n",
            "  Gap 42->43: 0.000000 (0.0x mean)\n",
            "  Gap 43->44: 0.000000 (0.0x mean)\n",
            "\n",
            "[CUMULATIVE VARIANCE]\n",
            "  First 21: 71.8%\n",
            "  First 35: 100.0%\n",
            "  First 43: 100.0%\n",
            "  First 77: 100.0%\n",
            "\n",
            "[TAU SEARCH] (target: 3.8967)\n",
            "  Best: n=24, tau=3.8145, error=2.1%\n",
            "\n",
            "[TAU AT KEY POSITIONS]\n",
            "\n",
            "[VERDICT]\n",
            "  Largest gap at: 34->35\n",
            "  Suggested n_visible: 35\n",
            "  Gap at 35: 23.90x mean\n",
            "  Gap at 43: 0.00x mean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Save Outputs\n",
        "# @markdown Save all results: models, Yukawa tensor, metrics, samples.\n",
        "\n",
        "os.makedirs(config.output_dir, exist_ok=True)\n",
        "print(f\"Saving outputs to: {config.output_dir}\")\n",
        "\n",
        "# 1. Yukawa tensor and spectrum\n",
        "np.savez(f\"{config.output_dir}/yukawa.npz\",\n",
        "         Y=yukawa['Y'],\n",
        "         M=yukawa['M'],\n",
        "         eigenvalues=yukawa['eigenvalues'],\n",
        "         eigenvectors=yukawa['eigenvectors'])\n",
        "print(\"  yukawa.npz\")\n",
        "\n",
        "# 2. Models\n",
        "torch.save({\n",
        "    'h2': h2_model.state_dict(),\n",
        "    'h3': h3_model.state_dict(),\n",
        "    'config': asdict(config),\n",
        "}, f\"{config.output_dir}/models.pt\")\n",
        "print(\"  models.pt\")\n",
        "\n",
        "# 3. Metrics JSON\n",
        "is_43 = 41 <= analysis['n_visible'] <= 45\n",
        "is_35 = 33 <= analysis['n_visible'] <= 37\n",
        "tau_ok = 0 < analysis['tau_error_pct'] < 15\n",
        "\n",
        "det_g_mean = torch.det(data['metric']).mean().item()\n",
        "\n",
        "metrics = {\n",
        "    'version': '2.0',\n",
        "    'tcs_structure': True,\n",
        "    'geometry': {\n",
        "        'det_g_mean': float(det_g_mean),\n",
        "        'det_g_target': float(config.target_det_g),\n",
        "        'det_g_error_pct': float(100 * abs(det_g_mean - config.target_det_g) / config.target_det_g),\n",
        "    },\n",
        "    'training': {\n",
        "        'h2_epochs': int(config.n_epochs_h2),\n",
        "        'h3_epochs': int(config.n_epochs_h3),\n",
        "        'h2_final_loss': float(h2_losses['total'][-1]) if h2_losses['total'] else None,\n",
        "        'h3_final_loss': float(h3_losses['total'][-1]) if h3_losses['total'] else None,\n",
        "    },\n",
        "    'tcs_modes': {\n",
        "        'n_local': int(config.b3_local),\n",
        "        'n_left': int(config.n_left),\n",
        "        'n_right': int(config.n_right),\n",
        "        'n_neck': int(config.n_neck),\n",
        "    },\n",
        "    'yukawa': {\n",
        "        'n_visible': int(analysis['n_visible']),\n",
        "        'nonzero_count': int(analysis['nonzero_count']),\n",
        "        'largest_gap_idx': int(analysis['largest_gap_idx']),\n",
        "        'gap_35_ratio': float(analysis['gap_35_ratio']),\n",
        "        'gap_43_ratio': float(analysis['gap_43_ratio']),\n",
        "        'tau_best_n': int(analysis['tau_best_n']),\n",
        "        'tau_estimate': float(analysis['tau_estimate']),\n",
        "        'tau_target': float(config.tau_target),\n",
        "        'tau_error_pct': float(analysis['tau_error_pct']) if analysis['tau_error_pct'] >= 0 else None,\n",
        "    },\n",
        "    'verdict': {\n",
        "        '43_77_structure': bool(is_43),\n",
        "        '35_42_structure': bool(is_35),\n",
        "        'tau_emerged': bool(tau_ok),\n",
        "    },\n",
        "}\n",
        "\n",
        "with open(f\"{config.output_dir}/metrics.json\", 'w') as f:\n",
        "    json.dump(metrics, f, indent=2)\n",
        "print(\"  metrics.json\")\n",
        "\n",
        "# 4. Eigenvalues CSV\n",
        "with open(f\"{config.output_dir}/eigenvalues.csv\", 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['index', 'eigenvalue', 'cumulative', 'gap'])\n",
        "    cumsum = np.cumsum(yukawa['eigenvalues'])\n",
        "    gaps = np.abs(np.diff(yukawa['eigenvalues']))\n",
        "    for i, ev in enumerate(yukawa['eigenvalues']):\n",
        "        g = float(gaps[i]) if i < len(gaps) else 0.0\n",
        "        writer.writerow([i, float(ev), float(cumsum[i]), g])\n",
        "print(\"  eigenvalues.csv\")\n",
        "\n",
        "# 5. Samples with forms\n",
        "with torch.no_grad():\n",
        "    sample_coords = data['coords'][:1000].to(device)\n",
        "    sample_omega = h2_model(sample_coords).cpu().numpy()\n",
        "    sample_Phi = h3_model(sample_coords).cpu().numpy()\n",
        "\n",
        "np.savez(f\"{config.output_dir}/samples.npz\",\n",
        "         coords=data['coords'][:1000].numpy(),\n",
        "         metric=data['metric'][:1000].numpy(),\n",
        "         phi=data['phi'][:1000].numpy(),\n",
        "         omega=sample_omega,\n",
        "         Phi=sample_Phi)\n",
        "print(\"  samples.npz\")\n",
        "\n",
        "print(\"\\nAll outputs saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8HhJeZW6UTZ",
        "outputId": "57189434-0c08-4543-a481-8a17ff25e098"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving outputs to: outputs_v2_0\n",
            "  yukawa.npz\n",
            "  models.pt\n",
            "  metrics.json\n",
            "  eigenvalues.csv\n",
            "  samples.npz\n",
            "\n",
            "All outputs saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Final Summary\n",
        "# @markdown Complete report of v2.0 TCS Hodge training results.\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"K7 TCS HODGE v2.0 - FINAL REPORT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "print(f\"\\n[GEOMETRY]\")\n",
        "print(f\"  det(g): {metrics['geometry']['det_g_mean']:.6f} (target: {metrics['geometry']['det_g_target']}, error: {metrics['geometry']['det_g_error_pct']:.2f}%)\")\n",
        "\n",
        "print(f\"\\n[TCS MODE STRUCTURE]\")\n",
        "print(f\"  Local (fiber): {metrics['tcs_modes']['n_local']} modes\")\n",
        "print(f\"  Left-weighted: {metrics['tcs_modes']['n_left']} modes\")\n",
        "print(f\"  Right-weighted: {metrics['tcs_modes']['n_right']} modes\")\n",
        "print(f\"  Neck-coupled: {metrics['tcs_modes']['n_neck']} modes\")\n",
        "print(f\"  Total: {config.b3_K7} modes\")\n",
        "\n",
        "print(f\"\\n[TRAINING]\")\n",
        "print(f\"  H2: {metrics['training']['h2_epochs']} epochs, final loss: {metrics['training']['h2_final_loss']:.2e}\")\n",
        "print(f\"  H3: {metrics['training']['h3_epochs']} epochs, final loss: {metrics['training']['h3_final_loss']:.2e}\")\n",
        "\n",
        "print(f\"\\n[YUKAWA SPECTRUM]\")\n",
        "print(f\"  Non-zero eigenvalues: {metrics['yukawa']['nonzero_count']}\")\n",
        "print(f\"  Largest gap at: {metrics['yukawa']['largest_gap_idx']}->{metrics['yukawa']['largest_gap_idx']+1}\")\n",
        "print(f\"  Suggested n_visible: {metrics['yukawa']['n_visible']}\")\n",
        "print(f\"  Gap at 35: {metrics['yukawa']['gap_35_ratio']:.2f}x mean\")\n",
        "print(f\"  Gap at 43: {metrics['yukawa']['gap_43_ratio']:.2f}x mean\")\n",
        "\n",
        "print(f\"\\n[TAU PARAMETER]\")\n",
        "print(f\"  Target: {metrics['yukawa']['tau_target']:.4f} (3472/891)\")\n",
        "if metrics['yukawa']['tau_error_pct'] is not None and metrics['yukawa']['tau_error_pct'] >= 0:\n",
        "    print(f\"  Best match at n={metrics['yukawa']['tau_best_n']}: tau={metrics['yukawa']['tau_estimate']:.4f}\")\n",
        "    print(f\"  Error: {metrics['yukawa']['tau_error_pct']:.1f}%\")\n",
        "else:\n",
        "    print(f\"  Could not compute tau (hidden sum ~ 0)\")\n",
        "\n",
        "print(f\"\\n[VERDICT]\")\n",
        "v = metrics['verdict']\n",
        "print(f\"  43/77 visible/hidden structure: {'YES' if v['43_77_structure'] else 'NO'}\")\n",
        "print(f\"  35/42 local/global structure: {'YES' if v['35_42_structure'] else 'NO'}\")\n",
        "print(f\"  Tau = 3472/891 emerged: {'YES' if v['tau_emerged'] else 'NO'}\")\n",
        "\n",
        "print(f\"\\n[OUTPUT FILES]\")\n",
        "print(f\"  {config.output_dir}/models.pt\")\n",
        "print(f\"  {config.output_dir}/yukawa.npz\")\n",
        "print(f\"  {config.output_dir}/metrics.json\")\n",
        "print(f\"  {config.output_dir}/eigenvalues.csv\")\n",
        "print(f\"  {config.output_dir}/samples.npz\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Success criteria\n",
        "success = v['43_77_structure'] or v['35_42_structure'] or v['tau_emerged']\n",
        "if success:\n",
        "    print(\"\\nTCS structure has influence on Yukawa spectrum.\")\n",
        "else:\n",
        "    print(\"\\nTCS structure not yet visible. May need more training or parameter tuning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2evmKS0x6UTa",
        "outputId": "fc7c8480-cee3-4369-e388-ac98c830c580"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "K7 TCS HODGE v2.0 - FINAL REPORT\n",
            "======================================================================\n",
            "\n",
            "[GEOMETRY]\n",
            "  det(g): 2.023177 (target: 2.03125, error: 0.40%)\n",
            "\n",
            "[TCS MODE STRUCTURE]\n",
            "  Local (fiber): 35 modes\n",
            "  Left-weighted: 14 modes\n",
            "  Right-weighted: 14 modes\n",
            "  Neck-coupled: 14 modes\n",
            "  Total: 77 modes\n",
            "\n",
            "[TRAINING]\n",
            "  H2: 3000 epochs, final loss: 4.93e-08\n",
            "  H3: 8000 epochs, final loss: 3.08e-01\n",
            "\n",
            "[YUKAWA SPECTRUM]\n",
            "  Non-zero eigenvalues: 44\n",
            "  Largest gap at: 34->35\n",
            "  Suggested n_visible: 35\n",
            "  Gap at 35: 23.90x mean\n",
            "  Gap at 43: 0.00x mean\n",
            "\n",
            "[TAU PARAMETER]\n",
            "  Target: 3.8967 (3472/891)\n",
            "  Best match at n=24: tau=3.8145\n",
            "  Error: 2.1%\n",
            "\n",
            "[VERDICT]\n",
            "  43/77 visible/hidden structure: NO\n",
            "  35/42 local/global structure: YES\n",
            "  Tau = 3472/891 emerged: YES\n",
            "\n",
            "[OUTPUT FILES]\n",
            "  outputs_v2_0/models.pt\n",
            "  outputs_v2_0/yukawa.npz\n",
            "  outputs_v2_0/metrics.json\n",
            "  outputs_v2_0/eigenvalues.csv\n",
            "  outputs_v2_0/samples.npz\n",
            "======================================================================\n",
            "\n",
            "TCS structure has influence on Yukawa spectrum.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}