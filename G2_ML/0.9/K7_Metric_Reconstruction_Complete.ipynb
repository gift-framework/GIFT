{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# K₇ Metric Reconstruction via Neural Networks\n",
    "\n",
    "This notebook implements a complete pipeline for reconstructing the Riemannian metric on the compact G₂ manifold K₇ using deep learning techniques. The architecture employs curriculum learning across three phases to learn a smooth, Ricci-flat metric consistent with G₂ holonomy.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- Three-phase curriculum training (region-specific → global blending → curvature refinement)\n",
    "- Automatic checkpoint management with Google Drive integration\n",
    "- Auto-resume functionality for interrupted training sessions\n",
    "- Multi-format output (.pt, .npy, .json)\n",
    "- H³ harmonic forms extraction\n",
    "- Comprehensive loss composition (6 geometric constraints)\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "**Phase 1 (Epochs 0-2000)**: Train region-specific networks (M1, Neck, M2)\n",
    "\n",
    "**Phase 2 (Epochs 2000-5000)**: Global network with smooth blending and H² constraint\n",
    "\n",
    "**Phase 3 (Epochs 5000-8000)**: Ricci curvature refinement\n",
    "\n",
    "## References\n",
    "\n",
    "Based on the GIFT framework for G₂ manifold construction using hierarchical gluing techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup and Google Drive Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoint persistence\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Drive\n",
    "PROJECT_DIR = '/content/drive/MyDrive/K7_Reconstruction'\n",
    "CHECKPOINT_DIR = f'{PROJECT_DIR}/checkpoints'\n",
    "OUTPUT_DIR = f'{PROJECT_DIR}/outputs'\n",
    "DATA_DIR = f'{PROJECT_DIR}/data'\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Project directory: {PROJECT_DIR}\")\n",
    "print(f\"Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"Outputs: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install scipy numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import scipy\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## 2. Configuration and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config_cell"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "CONFIG = {\n",
    "    # Training parameters\n",
    "    'epochs': 8000,\n",
    "    'batch_size': 1024,\n",
    "    'lr': 2e-4,\n",
    "    'weight_decay': 1e-4,\n",
    "    'grad_clip': 1.0,\n",
    "    \n",
    "    # Phase boundaries\n",
    "    'phase_boundaries': [(0, 2000), (2000, 5000), (5000, 8000)],\n",
    "    \n",
    "    # Network architecture\n",
    "    'n_fourier': 32,\n",
    "    'hidden_dims': [256, 256, 128],\n",
    "    'phi_hidden_dims': [384, 384, 256],\n",
    "    'h2_n_forms': 21,\n",
    "    'h2_n_fourier': 24,\n",
    "    'h2_hidden_dim': 128,\n",
    "    \n",
    "    # GIFT parameters (from v0.7)\n",
    "    'gift_params': {\n",
    "        'tau': 3.8967,\n",
    "        'xi': 2.5,\n",
    "        'transition_radius': 2.0\n",
    "    },\n",
    "    \n",
    "    # Checkpoint and logging\n",
    "    'checkpoint_frequency': 500,  # Save every N epochs\n",
    "    'log_frequency': 100,          # Print every N epochs\n",
    "    'auto_resume': True,           # Automatically resume from latest checkpoint\n",
    "    \n",
    "    # H³ extraction\n",
    "    'extract_h3': True,\n",
    "    'h3_n_forms': 77,\n",
    "    'h3_n_sample_points': 8192,\n",
    "    \n",
    "    # Device\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    \n",
    "    # Random seed\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(CONFIG['seed'])\n",
    "np.random.seed(CONFIG['seed'])\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(CONFIG['seed'])\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "device = torch.device(CONFIG['device'])\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Configuration loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## 3. Data Loading and Snapshot Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upload_data"
   },
   "outputs": [],
   "source": [
    "# Upload metric snapshot data from v0.7\n",
    "# Users should upload: metric_data.json, metric_m1.npy, metric_neck.npy, metric_m2.npy\n",
    "\n",
    "from google.colab import files\n",
    "import shutil\n",
    "\n",
    "print(\"Please upload the following files from G2_ML/0.7:\")\n",
    "print(\"  - metric_data.json\")\n",
    "print(\"  - metric_m1.npy\")\n",
    "print(\"  - metric_neck.npy\")\n",
    "print(\"  - metric_m2.npy\")\n",
    "print(\"  - config.json (optional)\")\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Move uploaded files to data directory\n",
    "for filename in uploaded.keys():\n",
    "    shutil.move(filename, f\"{DATA_DIR}/{filename}\")\n",
    "    print(f\"Moved {filename} to {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_snapshots"
   },
   "outputs": [],
   "source": [
    "def load_snapshots_from_data(\n",
    "    data_dir: str = DATA_DIR,\n",
    "    device: torch.device = device\n",
    ") -> Dict[str, Dict[str, torch.Tensor]]:\n",
    "    \"\"\"Load metric snapshots from uploaded data.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing snapshot data for M1, Neck, and M2 regions\n",
    "    \"\"\"\n",
    "    # Load metric data JSON\n",
    "    metric_data_path = Path(data_dir) / 'metric_data.json'\n",
    "    with open(metric_data_path, 'r') as f:\n",
    "        metric_data = json.load(f)\n",
    "    \n",
    "    # Extract mean metrics from JSON\n",
    "    g_m1 = torch.tensor(metric_data['M1']['metric_mean'], dtype=torch.float32, device=device)\n",
    "    g_neck = torch.tensor(metric_data['Neck']['metric_mean'], dtype=torch.float32, device=device)\n",
    "    g_m2 = torch.tensor(metric_data['M2']['metric_mean'], dtype=torch.float32, device=device)\n",
    "    \n",
    "    # Define representative coordinates for each region\n",
    "    # TCS structure: (t, θ, x₁, x₂, x₃, x₄, x₅)\n",
    "    \n",
    "    coords_m1 = torch.tensor([\n",
    "        -5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    ], dtype=torch.float32, device=device)\n",
    "    \n",
    "    coords_neck = torch.tensor([\n",
    "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    ], dtype=torch.float32, device=device)\n",
    "    \n",
    "    coords_m2 = torch.tensor([\n",
    "        5.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    ], dtype=torch.float32, device=device)\n",
    "    \n",
    "    snapshots = {\n",
    "        'm1': {'coords': coords_m1, 'metric': g_m1},\n",
    "        'neck': {'coords': coords_neck, 'metric': g_neck},\n",
    "        'm2': {'coords': coords_m2, 'metric': g_m2}\n",
    "    }\n",
    "    \n",
    "    print(\"Metric snapshots loaded successfully:\")\n",
    "    print(f\"  M1 metric shape: {g_m1.shape}\")\n",
    "    print(f\"  Neck metric shape: {g_neck.shape}\")\n",
    "    print(f\"  M2 metric shape: {g_m2.shape}\")\n",
    "    \n",
    "    return snapshots\n",
    "\n",
    "# Load snapshots\n",
    "snapshots = load_snapshots_from_data()\n",
    "print(f\"\\nGIFT parameters: τ={CONFIG['gift_params']['tau']:.4f}, ξ={CONFIG['gift_params']['xi']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utils"
   },
   "source": [
    "## 4. Utility Functions and Geometric Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fourier_features"
   },
   "outputs": [],
   "source": [
    "class FourierFeatures(nn.Module):\n",
    "    \"\"\"Random Fourier Features for coordinate encoding.\n",
    "    \n",
    "    Maps x ∈ ℝⁿ to [sin(2πBx), cos(2πBx)] for better neural network expressiveness.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_dim: int = 7, n_fourier: int = 32, scale: float = 1.0):\n",
    "        super().__init__()\n",
    "        self.n_dim = n_dim\n",
    "        self.n_fourier = n_fourier\n",
    "        self.scale = scale\n",
    "        \n",
    "        # Random projection matrix B ~ N(0, scale²)\n",
    "        B = torch.randn(n_fourier, n_dim) * scale\n",
    "        self.register_buffer('B', B)\n",
    "        self.output_dim = 2 * n_fourier * n_dim\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.shape[0]\n",
    "        x_expanded = x.unsqueeze(1)\n",
    "        Bx = x_expanded * self.B.unsqueeze(0)\n",
    "        Bx_flat = Bx.reshape(batch_size, -1)\n",
    "        \n",
    "        features_sin = torch.sin(2 * np.pi * Bx_flat)\n",
    "        features_cos = torch.cos(2 * np.pi * Bx_flat)\n",
    "        features = torch.cat([features_sin, features_cos], dim=1)\n",
    "        \n",
    "        return features\n",
    "\n",
    "print(\"Fourier feature encoding module defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geometric_utils"
   },
   "outputs": [],
   "source": [
    "def ensure_positive_definite(g: torch.Tensor, min_eig: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"Ensure metric is positive definite via eigenvalue clipping.\"\"\"\n",
    "    eigvals, eigvecs = torch.linalg.eigh(g)\n",
    "    eigvals = torch.clamp(eigvals, min=min_eig)\n",
    "    g_positive = eigvecs @ torch.diag_embed(eigvals) @ eigvecs.transpose(-2, -1)\n",
    "    return g_positive\n",
    "\n",
    "def compute_metric_determinant(g: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute det(g) for batch of metrics.\"\"\"\n",
    "    return torch.det(g)\n",
    "\n",
    "def compute_volume_form(g: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Compute volume form √det(g).\"\"\"\n",
    "    det_g = compute_metric_determinant(g)\n",
    "    return torch.sqrt(torch.abs(det_g))\n",
    "\n",
    "def compute_metric_derivatives(\n",
    "    g: torch.Tensor,\n",
    "    coords: torch.Tensor,\n",
    "    create_graph: bool = True\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute ∂_k g_ij via automatic differentiation.\"\"\"\n",
    "    batch_size = coords.shape[0]\n",
    "    n_dim = 7\n",
    "    g_derivs = torch.zeros(batch_size, n_dim, n_dim, n_dim, device=coords.device)\n",
    "    \n",
    "    for i in range(n_dim):\n",
    "        for j in range(n_dim):\n",
    "            g_ij = g[:, i, j]\n",
    "            if coords.grad is not None:\n",
    "                coords.grad.zero_()\n",
    "            \n",
    "            grad_outputs = torch.ones_like(g_ij)\n",
    "            grads = torch.autograd.grad(\n",
    "                outputs=g_ij,\n",
    "                inputs=coords,\n",
    "                grad_outputs=grad_outputs,\n",
    "                create_graph=create_graph,\n",
    "                retain_graph=True,\n",
    "                allow_unused=True\n",
    "            )[0]\n",
    "            \n",
    "            if grads is not None:\n",
    "                g_derivs[:, i, j, :] = grads\n",
    "    \n",
    "    return g_derivs\n",
    "\n",
    "def compute_christoffel(\n",
    "    g: torch.Tensor,\n",
    "    g_inv: torch.Tensor,\n",
    "    g_derivs: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute Christoffel symbols Γ^k_ij.\"\"\"\n",
    "    batch_size = g.shape[0]\n",
    "    n_dim = 7\n",
    "    gamma = torch.zeros(batch_size, n_dim, n_dim, n_dim, device=g.device)\n",
    "    \n",
    "    for k in range(n_dim):\n",
    "        for i in range(n_dim):\n",
    "            for j in range(n_dim):\n",
    "                term = torch.zeros(batch_size, device=g.device)\n",
    "                for l in range(n_dim):\n",
    "                    d_i_gjl = g_derivs[:, j, l, i]\n",
    "                    d_j_gil = g_derivs[:, i, l, j]\n",
    "                    d_l_gij = g_derivs[:, i, j, l]\n",
    "                    g_kl = g_inv[:, k, l]\n",
    "                    term += 0.5 * g_kl * (d_i_gjl + d_j_gil - d_l_gij)\n",
    "                gamma[:, k, i, j] = term\n",
    "    \n",
    "    return gamma\n",
    "\n",
    "def compute_ricci_tensor(\n",
    "    gamma: torch.Tensor,\n",
    "    coords: torch.Tensor,\n",
    "    create_graph: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute Ricci tensor (simplified approximation).\"\"\"\n",
    "    batch_size = coords.shape[0]\n",
    "    n_dim = 7\n",
    "    ricci = torch.zeros(batch_size, n_dim, n_dim, device=coords.device)\n",
    "    \n",
    "    for i in range(n_dim):\n",
    "        for j in range(n_dim):\n",
    "            term_algebraic = torch.zeros(batch_size, device=coords.device)\n",
    "            for k in range(n_dim):\n",
    "                for l in range(n_dim):\n",
    "                    gamma_klk = gamma[:, k, l, k]\n",
    "                    gamma_lij = gamma[:, l, i, j]\n",
    "                    gamma_klj = gamma[:, k, l, j]\n",
    "                    gamma_lik = gamma[:, l, i, k]\n",
    "                    term_algebraic += gamma_klk * gamma_lij - gamma_klj * gamma_lik\n",
    "            ricci[:, i, j] = term_algebraic\n",
    "    \n",
    "    return ricci\n",
    "\n",
    "def exterior_derivative_3form(\n",
    "    phi: torch.Tensor,\n",
    "    coords: torch.Tensor,\n",
    "    create_graph: bool = True\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute exterior derivative dφ for 3-form φ.\"\"\"\n",
    "    batch_size = coords.shape[0]\n",
    "    d_phi = torch.zeros(batch_size, 35, device=coords.device)\n",
    "    \n",
    "    for i in range(35):\n",
    "        phi_i = phi[:, i]\n",
    "        if coords.grad is not None:\n",
    "            coords.grad.zero_()\n",
    "        \n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=phi_i,\n",
    "            inputs=coords,\n",
    "            grad_outputs=torch.ones_like(phi_i),\n",
    "            create_graph=create_graph,\n",
    "            retain_graph=True,\n",
    "            allow_unused=True\n",
    "        )[0]\n",
    "        \n",
    "        if grads is not None:\n",
    "            d_phi[:, i] = grads.norm(dim=1)\n",
    "    \n",
    "    return d_phi\n",
    "\n",
    "print(\"Geometric utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "networks"
   },
   "source": [
    "## 5. Neural Network Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "region_network"
   },
   "outputs": [],
   "source": [
    "class RegionMetricNetwork(nn.Module):\n",
    "    \"\"\"Region-specific metric network for Phase 1.\n",
    "    \n",
    "    Maps coordinates x ∈ ℝ⁷ to metric tensor g ∈ S⁺(7).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fourier: int = 32,\n",
    "        hidden_dims: list = [256, 256, 128],\n",
    "        use_layer_norm: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_fourier = n_fourier\n",
    "        self.hidden_dims = hidden_dims\n",
    "        \n",
    "        # Fourier feature encoding\n",
    "        self.fourier = FourierFeatures(n_dim=7, n_fourier=n_fourier, scale=1.0)\n",
    "        fourier_dim = self.fourier.output_dim\n",
    "        \n",
    "        # MLP backbone\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(fourier_dim, hidden_dims[0]))\n",
    "        if use_layer_norm:\n",
    "            layers.append(nn.LayerNorm(hidden_dims[0]))\n",
    "        layers.append(nn.SiLU())\n",
    "        \n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i + 1]))\n",
    "            if use_layer_norm:\n",
    "                layers.append(nn.LayerNorm(hidden_dims[i + 1]))\n",
    "            layers.append(nn.SiLU())\n",
    "        \n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        \n",
    "        # Output layer: 28 values for upper triangular 7×7 matrix\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 28)\n",
    "        nn.init.normal_(self.output_layer.weight, std=0.01)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        # Fourier features\n",
    "        features = self.fourier(x)\n",
    "        hidden = self.backbone(features)\n",
    "        g_upper = self.output_layer(hidden)\n",
    "        \n",
    "        # Reconstruct symmetric 7×7 matrix\n",
    "        g = torch.zeros(batch_size, 7, 7, device=x.device)\n",
    "        idx = torch.triu_indices(7, 7, device=x.device)\n",
    "        g[:, idx[0], idx[1]] = g_upper\n",
    "        \n",
    "        # Symmetrize\n",
    "        g = g + g.transpose(-2, -1)\n",
    "        diag_idx = torch.arange(7, device=x.device)\n",
    "        g[:, diag_idx, diag_idx] = g[:, diag_idx, diag_idx] / 2.0\n",
    "        \n",
    "        # Add identity for positive definiteness\n",
    "        eye = torch.eye(7, device=x.device).unsqueeze(0)\n",
    "        g = g + 0.5 * eye\n",
    "        \n",
    "        # Ensure positive definite\n",
    "        g = ensure_positive_definite(g, min_eig=0.1)\n",
    "        \n",
    "        return g\n",
    "\n",
    "print(\"RegionMetricNetwork defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "global_network"
   },
   "outputs": [],
   "source": [
    "class GlobalMetricNetwork(nn.Module):\n",
    "    \"\"\"Global metric network with region blending for Phase 2.\n",
    "    \n",
    "    Combines three region networks with smooth transition functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        region_networks: Dict[str, RegionMetricNetwork],\n",
    "        tau: float = 3.8967,\n",
    "        transition_radius: float = 2.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "        self.R = transition_radius\n",
    "        \n",
    "        self.net_m1 = region_networks['m1']\n",
    "        self.net_neck = region_networks['neck']\n",
    "        self.net_m2 = region_networks['m2']\n",
    "    \n",
    "    def region_weights(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute smooth blending weights for three regions.\"\"\"\n",
    "        w_m1 = torch.sigmoid(-self.tau * (t + self.R))\n",
    "        w_m2 = torch.sigmoid(self.tau * (t - self.R))\n",
    "        w_neck = 1.0 - w_m1 - w_m2\n",
    "        w_neck = torch.clamp(w_neck, min=0.0)\n",
    "        \n",
    "        weights = torch.stack([w_m1, w_neck, w_m2], dim=-1)\n",
    "        weights = weights / (weights.sum(dim=-1, keepdim=True) + 1e-8)\n",
    "        return weights\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        g_m1 = self.net_m1(x)\n",
    "        g_neck = self.net_neck(x)\n",
    "        g_m2 = self.net_m2(x)\n",
    "        \n",
    "        t = x[:, 0]\n",
    "        weights = self.region_weights(t)\n",
    "        \n",
    "        g = (\n",
    "            weights[:, 0, None, None] * g_m1 +\n",
    "            weights[:, 1, None, None] * g_neck +\n",
    "            weights[:, 2, None, None] * g_m2\n",
    "        )\n",
    "        \n",
    "        g = ensure_positive_definite(g, min_eig=0.1)\n",
    "        return g\n",
    "\n",
    "print(\"GlobalMetricNetwork defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "phi_network"
   },
   "outputs": [],
   "source": [
    "class PhiNetwork(nn.Module):\n",
    "    \"\"\"Network for G₂ 3-form φ (associative form).\n",
    "    \n",
    "    A 3-form on ℝ⁷ has C(7,3) = 35 independent components.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fourier: int = 32,\n",
    "        hidden_dims: list = [384, 384, 256]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fourier = FourierFeatures(n_dim=7, n_fourier=n_fourier, scale=1.0)\n",
    "        fourier_dim = self.fourier.output_dim\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(fourier_dim, hidden_dims[0]))\n",
    "        layers.append(nn.LayerNorm(hidden_dims[0]))\n",
    "        layers.append(nn.SiLU())\n",
    "        \n",
    "        for i in range(len(hidden_dims) - 1):\n",
    "            layers.append(nn.Linear(hidden_dims[i], hidden_dims[i + 1]))\n",
    "            layers.append(nn.LayerNorm(hidden_dims[i + 1]))\n",
    "            layers.append(nn.SiLU())\n",
    "        \n",
    "        self.backbone = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 35)\n",
    "        \n",
    "        nn.init.normal_(self.output_layer.weight, std=0.01)\n",
    "        nn.init.zeros_(self.output_layer.bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.fourier(x)\n",
    "        hidden = self.backbone(features)\n",
    "        phi = self.output_layer(hidden)\n",
    "        return phi\n",
    "\n",
    "print(\"PhiNetwork defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2_network"
   },
   "outputs": [],
   "source": [
    "class HarmonicFormsNetwork(nn.Module):\n",
    "    \"\"\"Network for harmonic 2-forms (H² basis).\n",
    "    \n",
    "    Outputs 21 harmonic 2-forms that should be L²-orthonormal.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_forms: int = 21,\n",
    "        n_fourier: int = 24,\n",
    "        hidden_dim: int = 128\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.n_forms = n_forms\n",
    "        \n",
    "        self.fourier = FourierFeatures(n_dim=7, n_fourier=n_fourier, scale=1.0)\n",
    "        fourier_dim = self.fourier.output_dim\n",
    "        \n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Linear(fourier_dim, hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        # Separate heads for each harmonic form (each has 21 components)\n",
    "        self.form_heads = nn.ModuleList([\n",
    "            nn.Linear(hidden_dim, 21) for _ in range(n_forms)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        features = self.fourier(x)\n",
    "        hidden = self.backbone(features)\n",
    "        forms = torch.stack([head(hidden) for head in self.form_heads], dim=1)\n",
    "        return forms\n",
    "\n",
    "print(\"HarmonicFormsNetwork defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "losses"
   },
   "source": [
    "## 6. Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loss_functions"
   },
   "outputs": [],
   "source": [
    "class SnapshotAnchoringLoss(nn.Module):\n",
    "    \"\"\"Loss 1: Anchor network predictions to known metric snapshots.\"\"\"\n",
    "    \n",
    "    def __init__(self, snapshots: Dict[str, Dict[str, torch.Tensor]]):\n",
    "        super().__init__()\n",
    "        for region in ['m1', 'neck', 'm2']:\n",
    "            self.register_buffer(\n",
    "                f'coords_{region}',\n",
    "                snapshots[region]['coords'].unsqueeze(0)\n",
    "            )\n",
    "            self.register_buffer(\n",
    "                f'metric_{region}',\n",
    "                snapshots[region]['metric']\n",
    "            )\n",
    "    \n",
    "    def forward(self, network: nn.Module) -> torch.Tensor:\n",
    "        loss = 0.0\n",
    "        for region in ['m1', 'neck', 'm2']:\n",
    "            coords = getattr(self, f'coords_{region}')\n",
    "            g_target = getattr(self, f'metric_{region}')\n",
    "            g_pred = network(coords).squeeze(0)\n",
    "            loss += torch.norm(g_pred - g_target, p='fro') ** 2\n",
    "        return loss / 3.0\n",
    "\n",
    "\n",
    "class VolumeNormalizationLoss(nn.Module):\n",
    "    \"\"\"Loss 3: Enforce unit volume form √det(g) ≈ 1.\"\"\"\n",
    "    \n",
    "    def forward(self, g: torch.Tensor) -> torch.Tensor:\n",
    "        det_g = compute_metric_determinant(g)\n",
    "        sqrt_det = torch.sqrt(torch.abs(det_g))\n",
    "        loss = torch.mean((sqrt_det - 1.0) ** 2)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class TCSAsymptoticLoss(nn.Module):\n",
    "    \"\"\"Loss 4: Enforce TCS asymptotic behavior.\"\"\"\n",
    "    \n",
    "    def __init__(self, tau: float = 3.8967, t_min: float = -8.0, t_max: float = 8.0, n_samples: int = 100):\n",
    "        super().__init__()\n",
    "        self.tau = tau\n",
    "        self.t_min = t_min\n",
    "        self.t_max = t_max\n",
    "        self.n_samples = n_samples\n",
    "        self.register_buffer('identity_2', torch.eye(2))\n",
    "    \n",
    "    def sample_far_regions(self, device: torch.device) -> tuple:\n",
    "        t_m1 = torch.linspace(self.t_min, self.t_min + 2, self.n_samples, device=device)\n",
    "        t_m2 = torch.linspace(self.t_max - 2, self.t_max, self.n_samples, device=device)\n",
    "        \n",
    "        theta_m1 = torch.rand(self.n_samples, device=device) * 2 * np.pi\n",
    "        theta_m2 = torch.rand(self.n_samples, device=device) * 2 * np.pi\n",
    "        \n",
    "        base_m1 = torch.randn(self.n_samples, 5, device=device) * 0.5\n",
    "        base_m2 = torch.randn(self.n_samples, 5, device=device) * 0.5\n",
    "        \n",
    "        coords_m1 = torch.cat([t_m1.unsqueeze(1), theta_m1.unsqueeze(1), base_m1], dim=1)\n",
    "        coords_m2 = torch.cat([t_m2.unsqueeze(1), theta_m2.unsqueeze(1), base_m2], dim=1)\n",
    "        \n",
    "        return coords_m1, coords_m2\n",
    "    \n",
    "    def forward(self, network: nn.Module) -> torch.Tensor:\n",
    "        device = next(network.parameters()).device\n",
    "        coords_m1, coords_m2 = self.sample_far_regions(device)\n",
    "        \n",
    "        g_m1 = network(coords_m1)\n",
    "        g_m2 = network(coords_m2)\n",
    "        \n",
    "        g_fiber_m1 = g_m1[:, :2, :2]\n",
    "        g_fiber_m2 = g_m2[:, :2, :2]\n",
    "        \n",
    "        loss_m1 = torch.mean(torch.norm(g_fiber_m1 - self.identity_2, dim=(1, 2)) ** 2)\n",
    "        loss_m2 = torch.mean(torch.norm(g_fiber_m2 - self.identity_2, dim=(1, 2)) ** 2)\n",
    "        \n",
    "        return loss_m1 + loss_m2\n",
    "\n",
    "\n",
    "class RicciFlatnessLoss(nn.Module):\n",
    "    \"\"\"Loss 5: Enforce Ricci-flatness Ric(g) = 0.\"\"\"\n",
    "    \n",
    "    def __init__(self, use_approximate: bool = True):\n",
    "        super().__init__()\n",
    "        self.use_approximate = use_approximate\n",
    "    \n",
    "    def forward(self, network: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
    "        coords = coords.detach()\n",
    "        coords.requires_grad_(True)\n",
    "        \n",
    "        g = network(coords)\n",
    "        g_derivs = compute_metric_derivatives(g, coords, create_graph=True)\n",
    "        g_inv = torch.inverse(g)\n",
    "        gamma = compute_christoffel(g, g_inv, g_derivs)\n",
    "        ricci = compute_ricci_tensor(gamma, coords, create_graph=False)\n",
    "        \n",
    "        loss = torch.mean(torch.norm(ricci, dim=(1, 2)) ** 2)\n",
    "        return loss\n",
    "\n",
    "\n",
    "class G2TorsionLoss(nn.Module):\n",
    "    \"\"\"Loss 6: Enforce G₂ torsion-free condition.\"\"\"\n",
    "    \n",
    "    def __init__(self, phi_network: Optional[nn.Module] = None, use_simplified: bool = True):\n",
    "        super().__init__()\n",
    "        self.phi_network = phi_network\n",
    "        self.use_simplified = use_simplified\n",
    "    \n",
    "    def forward(self, metric_network: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
    "        if self.phi_network is None:\n",
    "            return torch.tensor(0.0, device=coords.device)\n",
    "        \n",
    "        coords = coords.detach()\n",
    "        coords.requires_grad_(True)\n",
    "        \n",
    "        phi = self.phi_network(coords)\n",
    "        d_phi = exterior_derivative_3form(phi, coords, create_graph=False)\n",
    "        torsion = torch.mean(torch.norm(d_phi, dim=1) ** 2)\n",
    "        \n",
    "        return torsion\n",
    "\n",
    "\n",
    "class H2OrthonormalityLoss(nn.Module):\n",
    "    \"\"\"Loss 2: Enforce orthonormality of H² forms.\"\"\"\n",
    "    \n",
    "    def __init__(self, h2_network: Optional[nn.Module] = None):\n",
    "        super().__init__()\n",
    "        self.h2_network = h2_network\n",
    "        self.register_buffer('identity_21', torch.eye(21))\n",
    "    \n",
    "    def forward(self, metric_network: nn.Module, coords: torch.Tensor) -> torch.Tensor:\n",
    "        if self.h2_network is None:\n",
    "            return torch.tensor(0.0, device=coords.device)\n",
    "        \n",
    "        g = metric_network(coords)\n",
    "        h2_forms = self.h2_network(coords)\n",
    "        \n",
    "        batch_size = coords.shape[0]\n",
    "        gram = torch.zeros(21, 21, device=coords.device)\n",
    "        \n",
    "        for b in range(min(batch_size, 32)):\n",
    "            forms_b = h2_forms[b]\n",
    "            gram += forms_b @ forms_b.T\n",
    "        \n",
    "        gram = gram / min(batch_size, 32)\n",
    "        loss = torch.norm(gram - self.identity_21, p='fro') ** 2\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "class CompositeLoss(nn.Module):\n",
    "    \"\"\"Composite loss combining all 6 components.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        snapshots: Dict[str, Dict[str, torch.Tensor]],\n",
    "        phi_network: Optional[nn.Module] = None,\n",
    "        h2_network: Optional[nn.Module] = None,\n",
    "        weights: Optional[Dict[str, float]] = None,\n",
    "        phase: int = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.phase = phase\n",
    "        \n",
    "        self.snapshot_loss = SnapshotAnchoringLoss(snapshots)\n",
    "        self.volume_loss = VolumeNormalizationLoss()\n",
    "        self.asymptotic_loss = TCSAsymptoticLoss()\n",
    "        self.ricci_loss = RicciFlatnessLoss(use_approximate=True)\n",
    "        self.torsion_loss = G2TorsionLoss(phi_network, use_simplified=True)\n",
    "        self.h2_loss = H2OrthonormalityLoss(h2_network)\n",
    "        \n",
    "        if weights is None:\n",
    "            if phase == 1:\n",
    "                weights = {\n",
    "                    'snapshot': 10.0, 'volume': 2.0, 'asymptotic': 3.0,\n",
    "                    'ricci': 0.0, 'torsion': 2.0, 'h2': 0.0\n",
    "                }\n",
    "            elif phase == 2:\n",
    "                weights = {\n",
    "                    'snapshot': 10.0, 'volume': 2.0, 'asymptotic': 3.0,\n",
    "                    'ricci': 0.0, 'torsion': 2.0, 'h2': 5.0\n",
    "                }\n",
    "            else:\n",
    "                weights = {\n",
    "                    'snapshot': 10.0, 'volume': 1.0, 'asymptotic': 2.0,\n",
    "                    'ricci': 1.0, 'torsion': 3.0, 'h2': 5.0\n",
    "                }\n",
    "        \n",
    "        self.weights = weights\n",
    "    \n",
    "    def forward(self, metric_network: nn.Module, coords: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        losses = {}\n",
    "        \n",
    "        losses['snapshot'] = self.snapshot_loss(metric_network)\n",
    "        g = metric_network(coords)\n",
    "        \n",
    "        if self.weights['h2'] > 0:\n",
    "            losses['h2'] = self.h2_loss(metric_network, coords)\n",
    "        else:\n",
    "            losses['h2'] = torch.tensor(0.0, device=coords.device)\n",
    "        \n",
    "        losses['volume'] = self.volume_loss(g)\n",
    "        losses['asymptotic'] = self.asymptotic_loss(metric_network)\n",
    "        \n",
    "        if self.weights['ricci'] > 0 and self.phase >= 3:\n",
    "            coords_ricci = coords[:min(64, coords.shape[0])]\n",
    "            losses['ricci'] = self.ricci_loss(metric_network, coords_ricci)\n",
    "        else:\n",
    "            losses['ricci'] = torch.tensor(0.0, device=coords.device)\n",
    "        \n",
    "        if self.weights['torsion'] > 0:\n",
    "            losses['torsion'] = self.torsion_loss(metric_network, coords)\n",
    "        else:\n",
    "            losses['torsion'] = torch.tensor(0.0, device=coords.device)\n",
    "        \n",
    "        total = sum(self.weights[key] * losses[key] for key in self.weights.keys())\n",
    "        losses['total'] = total\n",
    "        \n",
    "        return losses\n",
    "\n",
    "print(\"Loss functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "trainer"
   },
   "source": [
    "## 7. Curriculum Trainer with Checkpoint Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sampling"
   },
   "outputs": [],
   "source": [
    "def sample_training_coordinates(\n",
    "    batch_size: int,\n",
    "    phase: int,\n",
    "    device: torch.device\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Sample coordinates for training based on phase.\"\"\"\n",
    "    \n",
    "    if phase == 1:\n",
    "        # Dense sampling near snapshots\n",
    "        n_per_region = batch_size // 3\n",
    "        t_m1 = torch.randn(n_per_region, device=device) * 0.5 - 5.0\n",
    "        t_neck = torch.randn(n_per_region, device=device) * 0.5\n",
    "        t_m2 = torch.randn(n_per_region, device=device) * 0.5 + 5.0\n",
    "        t_samples = torch.cat([t_m1, t_neck, t_m2])\n",
    "    \n",
    "    elif phase == 2:\n",
    "        # Uniform sampling across manifold\n",
    "        t_samples = torch.rand(batch_size, device=device) * 12 - 6\n",
    "    \n",
    "    else:\n",
    "        # Focus on transition regions\n",
    "        n_half = batch_size // 2\n",
    "        t_trans1 = torch.rand(n_half, device=device) * 4 - 4\n",
    "        t_trans2 = torch.rand(n_half, device=device) * 4\n",
    "        t_samples = torch.cat([t_trans1, t_trans2])\n",
    "    \n",
    "    theta = torch.rand(batch_size, device=device) * 2 * np.pi\n",
    "    base_coords = torch.randn(batch_size, 5, device=device)\n",
    "    coords = torch.stack([t_samples, theta, *base_coords.T], dim=1)\n",
    "    \n",
    "    return coords\n",
    "\n",
    "print(\"Coordinate sampling function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "curriculum_trainer"
   },
   "outputs": [],
   "source": [
    "class CurriculumTrainer:\n",
    "    \"\"\"Trainer with 3-phase curriculum learning and checkpoint management.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Dict,\n",
    "        snapshots: Dict[str, Dict[str, torch.Tensor]],\n",
    "        device: torch.device,\n",
    "        checkpoint_dir: str,\n",
    "        output_dir: str\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.snapshots = snapshots\n",
    "        self.device = device\n",
    "        self.checkpoint_dir = Path(checkpoint_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        \n",
    "        self.epochs_total = config['epochs']\n",
    "        self.batch_size = config['batch_size']\n",
    "        self.lr = config['lr']\n",
    "        self.weight_decay = config['weight_decay']\n",
    "        self.grad_clip = config['grad_clip']\n",
    "        self.phase_boundaries = config['phase_boundaries']\n",
    "        \n",
    "        self.networks = {}\n",
    "        self.current_phase = 1\n",
    "        self.start_epoch = 0\n",
    "        \n",
    "        self.history = {\n",
    "            'epoch': [], 'phase': [], 'total_loss': [],\n",
    "            'snapshot_loss': [], 'volume_loss': [], 'asymptotic_loss': [],\n",
    "            'ricci_loss': [], 'torsion_loss': [], 'h2_loss': []\n",
    "        }\n",
    "        \n",
    "        self._initialize_networks()\n",
    "    \n",
    "    def _initialize_networks(self):\n",
    "        \"\"\"Initialize networks for all phases.\"\"\"\n",
    "        print(\"Initializing networks...\")\n",
    "        \n",
    "        self.networks['m1'] = RegionMetricNetwork(\n",
    "            n_fourier=self.config['n_fourier'],\n",
    "            hidden_dims=self.config['hidden_dims']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.networks['neck'] = RegionMetricNetwork(\n",
    "            n_fourier=self.config['n_fourier'],\n",
    "            hidden_dims=self.config['hidden_dims']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.networks['m2'] = RegionMetricNetwork(\n",
    "            n_fourier=self.config['n_fourier'],\n",
    "            hidden_dims=self.config['hidden_dims']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.networks['global'] = None\n",
    "        \n",
    "        self.networks['phi'] = PhiNetwork(\n",
    "            n_fourier=self.config['n_fourier'],\n",
    "            hidden_dims=self.config['phi_hidden_dims']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        self.networks['h2'] = HarmonicFormsNetwork(\n",
    "            n_forms=self.config['h2_n_forms'],\n",
    "            n_fourier=self.config['h2_n_fourier'],\n",
    "            hidden_dim=self.config['h2_hidden_dim']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        print(f\"  Region networks: {sum(p.numel() for p in self.networks['m1'].parameters()):,} params each\")\n",
    "        print(f\"  Phi network: {sum(p.numel() for p in self.networks['phi'].parameters()):,} params\")\n",
    "        print(f\"  H² network: {sum(p.numel() for p in self.networks['h2'].parameters()):,} params\")\n",
    "    \n",
    "    def _initialize_phase(self, phase: int):\n",
    "        \"\"\"Initialize optimizers and loss for given phase.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting Phase {phase}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        self.current_phase = phase\n",
    "        \n",
    "        if phase == 1:\n",
    "            params = (\n",
    "                list(self.networks['m1'].parameters()) +\n",
    "                list(self.networks['neck'].parameters()) +\n",
    "                list(self.networks['m2'].parameters()) +\n",
    "                list(self.networks['phi'].parameters())\n",
    "            )\n",
    "            lr = self.lr\n",
    "            self.active_network = None\n",
    "        \n",
    "        elif phase == 2:\n",
    "            if self.networks['global'] is None:\n",
    "                self.networks['global'] = GlobalMetricNetwork(\n",
    "                    region_networks={\n",
    "                        'm1': self.networks['m1'],\n",
    "                        'neck': self.networks['neck'],\n",
    "                        'm2': self.networks['m2']\n",
    "                    },\n",
    "                    tau=self.config['gift_params']['tau']\n",
    "                ).to(self.device)\n",
    "            \n",
    "            params = (\n",
    "                list(self.networks['global'].parameters()) +\n",
    "                list(self.networks['phi'].parameters()) +\n",
    "                list(self.networks['h2'].parameters())\n",
    "            )\n",
    "            lr = self.lr * 0.5\n",
    "            self.active_network = self.networks['global']\n",
    "        \n",
    "        else:\n",
    "            params = (\n",
    "                list(self.networks['global'].parameters()) +\n",
    "                list(self.networks['phi'].parameters()) +\n",
    "                list(self.networks['h2'].parameters())\n",
    "            )\n",
    "            lr = self.lr * 0.1\n",
    "            self.active_network = self.networks['global']\n",
    "        \n",
    "        self.optimizer = optim.AdamW(\n",
    "            params, lr=lr, weight_decay=self.weight_decay, betas=(0.9, 0.999)\n",
    "        )\n",
    "        \n",
    "        phase_start, phase_end = self.phase_boundaries[phase - 1]\n",
    "        phase_epochs = phase_end - phase_start\n",
    "        \n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=phase_epochs, eta_min=lr * 0.1\n",
    "        )\n",
    "        \n",
    "        self.criterion = CompositeLoss(\n",
    "            snapshots=self.snapshots,\n",
    "            phi_network=self.networks['phi'],\n",
    "            h2_network=self.networks['h2'] if phase >= 2 else None,\n",
    "            phase=phase\n",
    "        ).to(self.device)\n",
    "        \n",
    "        print(f\"Learning rate: {lr:.2e}\")\n",
    "        print(f\"Phase duration: {phase_epochs} epochs\")\n",
    "    \n",
    "    def train_epoch(self, epoch: int) -> Dict[str, float]:\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        phase = 1\n",
    "        for p, (start, end) in enumerate(self.phase_boundaries, 1):\n",
    "            if start <= epoch < end:\n",
    "                phase = p\n",
    "                break\n",
    "        \n",
    "        if phase != self.current_phase:\n",
    "            self._initialize_phase(phase)\n",
    "        \n",
    "        coords = sample_training_coordinates(self.batch_size, phase, self.device)\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        if phase == 1:\n",
    "            losses_total = None\n",
    "            for region, network in [\n",
    "                ('m1', self.networks['m1']),\n",
    "                ('neck', self.networks['neck']),\n",
    "                ('m2', self.networks['m2'])\n",
    "            ]:\n",
    "                losses = self.criterion(network, coords)\n",
    "                if losses_total is None:\n",
    "                    losses_total = {k: v / 3.0 for k, v in losses.items()}\n",
    "                else:\n",
    "                    for k in losses.keys():\n",
    "                        losses_total[k] += losses[k] / 3.0\n",
    "            loss = losses_total['total']\n",
    "        else:\n",
    "            losses = self.criterion(self.active_network, coords)\n",
    "            losses_total = losses\n",
    "            loss = losses['total']\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        if self.grad_clip > 0:\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                self.optimizer.param_groups[0]['params'], self.grad_clip\n",
    "            )\n",
    "        \n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        loss_dict = {k: v.item() for k, v in losses_total.items()}\n",
    "        loss_dict['lr'] = self.optimizer.param_groups[0]['lr']\n",
    "        loss_dict['phase'] = phase\n",
    "        \n",
    "        return loss_dict\n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Run full training loop.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"Starting Curriculum Training\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total epochs: {self.epochs_total}\")\n",
    "        print(f\"Starting from epoch: {self.start_epoch}\")\n",
    "        print(f\"Batch size: {self.batch_size}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        \n",
    "        self._initialize_phase(1)\n",
    "        \n",
    "        for epoch in tqdm(range(self.start_epoch, self.epochs_total), desc=\"Training\"):\n",
    "            loss_dict = self.train_epoch(epoch)\n",
    "            \n",
    "            self.history['epoch'].append(epoch)\n",
    "            self.history['phase'].append(loss_dict['phase'])\n",
    "            self.history['total_loss'].append(loss_dict['total'])\n",
    "            self.history['snapshot_loss'].append(loss_dict.get('snapshot', 0))\n",
    "            self.history['volume_loss'].append(loss_dict.get('volume', 0))\n",
    "            self.history['asymptotic_loss'].append(loss_dict.get('asymptotic', 0))\n",
    "            self.history['ricci_loss'].append(loss_dict.get('ricci', 0))\n",
    "            self.history['torsion_loss'].append(loss_dict.get('torsion', 0))\n",
    "            self.history['h2_loss'].append(loss_dict.get('h2', 0))\n",
    "            \n",
    "            if epoch % self.config['log_frequency'] == 0 or epoch == self.epochs_total - 1:\n",
    "                print(f\"\\nEpoch {epoch:5d} | Phase {loss_dict['phase']} | \"\n",
    "                      f\"Loss: {loss_dict['total']:.6f} | \"\n",
    "                      f\"Snap: {loss_dict.get('snapshot', 0):.4f} | \"\n",
    "                      f\"Vol: {loss_dict.get('volume', 0):.4f} | \"\n",
    "                      f\"Tor: {loss_dict.get('torsion', 0):.2e} | \"\n",
    "                      f\"LR: {loss_dict['lr']:.2e}\")\n",
    "            \n",
    "            if (epoch + 1) % self.config['checkpoint_frequency'] == 0:\n",
    "                self.save_checkpoint(epoch)\n",
    "        \n",
    "        print(\"\\nTraining complete!\")\n",
    "        self.save_checkpoint(self.epochs_total - 1, final=True)\n",
    "    \n",
    "    def save_checkpoint(self, epoch: int, final: bool = False):\n",
    "        \"\"\"Save checkpoint to Google Drive.\"\"\"\n",
    "        suffix = 'final' if final else f'epoch_{epoch}'\n",
    "        \n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'phase': self.current_phase,\n",
    "            'config': self.config,\n",
    "            'history': self.history\n",
    "        }\n",
    "        \n",
    "        for name, network in self.networks.items():\n",
    "            if network is not None:\n",
    "                checkpoint[f'{name}_state'] = network.state_dict()\n",
    "        \n",
    "        checkpoint_path = self.checkpoint_dir / f'checkpoint_{suffix}.pt'\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "        history_path = self.checkpoint_dir / f'history_{suffix}.json'\n",
    "        with open(history_path, 'w') as f:\n",
    "            json.dump(self.history, f, indent=2)\n",
    "        \n",
    "        print(f\"  Checkpoint saved: {checkpoint_path}\")\n",
    "    \n",
    "    def load_checkpoint(self, checkpoint_path: Path):\n",
    "        \"\"\"Load checkpoint from file.\"\"\"\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=self.device)\n",
    "        \n",
    "        for name, network in self.networks.items():\n",
    "            if network is not None and f'{name}_state' in checkpoint:\n",
    "                network.load_state_dict(checkpoint[f'{name}_state'])\n",
    "        \n",
    "        self.history = checkpoint['history']\n",
    "        self.start_epoch = checkpoint['epoch'] + 1\n",
    "        self.current_phase = checkpoint['phase']\n",
    "        \n",
    "        print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "        print(f\"Resuming from epoch {self.start_epoch}\")\n",
    "    \n",
    "    def find_latest_checkpoint(self):\n",
    "        \"\"\"Find latest checkpoint in directory.\"\"\"\n",
    "        checkpoints = list(self.checkpoint_dir.glob('checkpoint_epoch_*.pt'))\n",
    "        if not checkpoints:\n",
    "            return None\n",
    "        \n",
    "        latest = max(checkpoints, key=lambda p: int(p.stem.split('_')[-1]))\n",
    "        return latest\n",
    "\n",
    "print(\"CurriculumTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3_extraction"
   },
   "source": [
    "## 8. H³ Harmonic Forms Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3_functions"
   },
   "outputs": [],
   "source": [
    "def sample_uniform_grid(\n",
    "    n_points: int = 8192,\n",
    "    t_range: Tuple[float, float] = (-6.0, 6.0),\n",
    "    device: torch.device = device\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Sample uniform grid of points on K₇.\"\"\"\n",
    "    t = torch.linspace(t_range[0], t_range[1], n_points, device=device)\n",
    "    t = t[torch.randperm(n_points)]\n",
    "    theta = torch.rand(n_points, device=device) * 2 * np.pi\n",
    "    base_coords = torch.randn(n_points, 5, device=device)\n",
    "    coords = torch.stack([t, theta, *base_coords.T], dim=1)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def compute_laplacian_3forms_approximate(\n",
    "    metric_network: nn.Module,\n",
    "    coords: torch.Tensor,\n",
    "    eps: float = 1e-6\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute approximate Laplacian on 3-forms.\"\"\"\n",
    "    n_points = coords.shape[0]\n",
    "    device = coords.device\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        g = metric_network(coords)\n",
    "    \n",
    "    g_inv = torch.inverse(g)\n",
    "    vol = compute_volume_form(g)\n",
    "    laplacian = torch.zeros(n_points, 35, 35, device=device)\n",
    "    trace_g_inv = torch.diagonal(g_inv, dim1=1, dim2=2).sum(dim=1)\n",
    "    \n",
    "    for i in range(35):\n",
    "        laplacian[:, i, i] = trace_g_inv / vol + eps\n",
    "    \n",
    "    return laplacian\n",
    "\n",
    "\n",
    "def extract_harmonic_forms_local(\n",
    "    metric_network: nn.Module,\n",
    "    coords: torch.Tensor,\n",
    "    n_forms: int = 77\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Extract harmonic 3-forms using local eigenvalue decomposition.\"\"\"\n",
    "    print(f\"Extracting {n_forms} harmonic 3-forms...\")\n",
    "    print(f\"  Sample points: {coords.shape[0]}\")\n",
    "    \n",
    "    n_points = coords.shape[0]\n",
    "    device = coords.device\n",
    "    \n",
    "    print(\"  Computing local Laplacians...\")\n",
    "    laplacian_local = compute_laplacian_3forms_approximate(metric_network, coords)\n",
    "    \n",
    "    print(\"  Averaging to global Laplacian...\")\n",
    "    laplacian_global = laplacian_local.mean(dim=0)\n",
    "    laplacian_global = 0.5 * (laplacian_global + laplacian_global.T)\n",
    "    \n",
    "    laplacian_np = laplacian_global.cpu().numpy()\n",
    "    \n",
    "    print(\"  Computing eigendecomposition...\")\n",
    "    if n_forms < 35:\n",
    "        try:\n",
    "            eigvals, eigvecs = eigsh(laplacian_np, k=min(n_forms, 34), which='SM')\n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: eigsh failed, using full decomposition\")\n",
    "            eigvals, eigvecs = np.linalg.eigh(laplacian_np)\n",
    "            eigvals = eigvals[:n_forms]\n",
    "            eigvecs = eigvecs[:, :n_forms]\n",
    "    else:\n",
    "        eigvals, eigvecs = np.linalg.eigh(laplacian_np)\n",
    "        eigvals = eigvals[:n_forms]\n",
    "        eigvecs = eigvecs[:, :n_forms]\n",
    "    \n",
    "    eigvals = torch.from_numpy(eigvals).float().to(device)\n",
    "    eigvecs_global = torch.from_numpy(eigvecs).float().to(device)\n",
    "    \n",
    "    eigvecs_expanded = eigvecs_global.unsqueeze(0).expand(n_points, -1, -1)\n",
    "    eigvecs_expanded = eigvecs_expanded.transpose(1, 2)\n",
    "    \n",
    "    print(f\"  Found {n_forms} forms with eigenvalues in [{eigvals.min():.2e}, {eigvals.max():.2e}]\")\n",
    "    print(f\"  Number below 1e-6: {(eigvals < 1e-6).sum().item()}\")\n",
    "    \n",
    "    return eigvals, eigvecs_expanded\n",
    "\n",
    "\n",
    "def extract_h3_forms_complete(\n",
    "    metric_network: nn.Module,\n",
    "    n_forms: int = 77,\n",
    "    n_sample_points: int = 8192,\n",
    "    device: torch.device = device\n",
    ") -> Dict:\n",
    "    \"\"\"Complete H³ extraction pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"H³ Harmonic Forms Extraction\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    metric_network = metric_network.to(device)\n",
    "    metric_network.eval()\n",
    "    \n",
    "    print(\"\\nSampling manifold...\")\n",
    "    coords = sample_uniform_grid(n_sample_points, device=device)\n",
    "    \n",
    "    eigvals, forms = extract_harmonic_forms_local(metric_network, coords, n_forms=n_forms)\n",
    "    \n",
    "    print(\"\\nFinal statistics:\")\n",
    "    print(f\"  Number of forms: {n_forms}\")\n",
    "    print(f\"  Eigenvalue range: [{eigvals.min():.2e}, {eigvals.max():.2e}]\")\n",
    "    print(f\"  Harmonic forms (λ < 1e-6): {(eigvals < 1e-6).sum().item()}\")\n",
    "    print(f\"  Forms shape: {forms.shape}\")\n",
    "    \n",
    "    return {\n",
    "        'eigenvalues': eigvals.cpu().numpy(),\n",
    "        'forms': forms.cpu().numpy(),\n",
    "        'coords': coords.cpu().numpy(),\n",
    "        'n_harmonic': (eigvals < 1e-6).sum().item()\n",
    "    }\n",
    "\n",
    "print(\"H³ extraction functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 9. Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init_trainer"
   },
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = CurriculumTrainer(\n",
    "    config=CONFIG,\n",
    "    snapshots=snapshots,\n",
    "    device=device,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")\n",
    "\n",
    "# Auto-resume from latest checkpoint if available\n",
    "if CONFIG['auto_resume']:\n",
    "    latest_checkpoint = trainer.find_latest_checkpoint()\n",
    "    if latest_checkpoint is not None:\n",
    "        print(f\"\\nFound checkpoint: {latest_checkpoint}\")\n",
    "        response = input(\"Resume from this checkpoint? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            trainer.load_checkpoint(latest_checkpoint)\n",
    "        else:\n",
    "            print(\"Starting fresh training\")\n",
    "    else:\n",
    "        print(\"No checkpoint found, starting fresh training\")\n",
    "\n",
    "print(\"\\nTrainer initialized and ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "try:\n",
    "    trainer.train()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nTraining interrupted by user\")\n",
    "    trainer.save_checkpoint(trainer.current_phase * 1000, final=False)\n",
    "except Exception as e:\n",
    "    print(f\"\\n\\nTraining failed with error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    trainer.save_checkpoint(trainer.current_phase * 1000, final=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export"
   },
   "source": [
    "## 10. Export Results in Multiple Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export_results"
   },
   "outputs": [],
   "source": [
    "# Export trained networks and results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Exporting Results\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 1. Export as PyTorch (.pt)\n",
    "print(\"\\n1. Exporting PyTorch models (.pt)...\")\n",
    "for name, network in trainer.networks.items():\n",
    "    if network is not None:\n",
    "        pt_path = Path(OUTPUT_DIR) / f'{name}_network_{timestamp}.pt'\n",
    "        torch.save(network.state_dict(), pt_path)\n",
    "        print(f\"   Saved: {pt_path}\")\n",
    "\n",
    "# 2. Export training history as JSON\n",
    "print(\"\\n2. Exporting training history (.json)...\")\n",
    "history_path = Path(OUTPUT_DIR) / f'training_history_{timestamp}.json'\n",
    "with open(history_path, 'w') as f:\n",
    "    json.dump(trainer.history, f, indent=2)\n",
    "print(f\"   Saved: {history_path}\")\n",
    "\n",
    "# 3. Export configuration as JSON\n",
    "print(\"\\n3. Exporting configuration (.json)...\")\n",
    "config_path = Path(OUTPUT_DIR) / f'config_{timestamp}.json'\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print(f\"   Saved: {config_path}\")\n",
    "\n",
    "# 4. Export sample metric evaluations as NumPy (.npy)\n",
    "print(\"\\n4. Exporting sample metric evaluations (.npy)...\")\n",
    "sample_coords = sample_uniform_grid(1000, device=device)\n",
    "with torch.no_grad():\n",
    "    if trainer.networks['global'] is not None:\n",
    "        sample_metrics = trainer.networks['global'](sample_coords).cpu().numpy()\n",
    "    else:\n",
    "        sample_metrics = trainer.networks['m2'](sample_coords).cpu().numpy()\n",
    "\n",
    "metrics_path = Path(OUTPUT_DIR) / f'sample_metrics_{timestamp}.npy'\n",
    "np.save(metrics_path, sample_metrics)\n",
    "print(f\"   Saved: {metrics_path}\")\n",
    "\n",
    "coords_path = Path(OUTPUT_DIR) / f'sample_coords_{timestamp}.npy'\n",
    "np.save(coords_path, sample_coords.cpu().numpy())\n",
    "print(f\"   Saved: {coords_path}\")\n",
    "\n",
    "print(\"\\nExport complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3_extract"
   },
   "source": [
    "## 11. H³ Harmonic Forms Extraction and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_h3_extraction"
   },
   "outputs": [],
   "source": [
    "if CONFIG['extract_h3']:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"H³ Harmonic Forms Extraction\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Get appropriate network\n",
    "    if trainer.networks['global'] is not None:\n",
    "        metric_network = trainer.networks['global']\n",
    "    else:\n",
    "        print(\"Warning: Global network not available, using M2 network\")\n",
    "        metric_network = trainer.networks['m2']\n",
    "    \n",
    "    # Extract H³ forms\n",
    "    h3_results = extract_h3_forms_complete(\n",
    "        metric_network=metric_network,\n",
    "        n_forms=CONFIG['h3_n_forms'],\n",
    "        n_sample_points=CONFIG['h3_n_sample_points'],\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    # Export results\n",
    "    print(\"\\nExporting H³ results...\")\n",
    "    \n",
    "    # Export as NumPy (.npz)\n",
    "    h3_npz_path = Path(OUTPUT_DIR) / f'h3_forms_{timestamp}.npz'\n",
    "    np.savez(\n",
    "        h3_npz_path,\n",
    "        eigenvalues=h3_results['eigenvalues'],\n",
    "        forms=h3_results['forms'],\n",
    "        coords=h3_results['coords']\n",
    "    )\n",
    "    print(f\"  Saved NPZ: {h3_npz_path}\")\n",
    "    \n",
    "    # Export as separate NumPy files\n",
    "    np.save(Path(OUTPUT_DIR) / f'h3_eigenvalues_{timestamp}.npy', h3_results['eigenvalues'])\n",
    "    np.save(Path(OUTPUT_DIR) / f'h3_forms_{timestamp}.npy', h3_results['forms'])\n",
    "    np.save(Path(OUTPUT_DIR) / f'h3_coords_{timestamp}.npy', h3_results['coords'])\n",
    "    \n",
    "    # Export summary as JSON\n",
    "    h3_summary = {\n",
    "        'n_forms': CONFIG['h3_n_forms'],\n",
    "        'n_harmonic': int(h3_results['n_harmonic']),\n",
    "        'eigenvalue_min': float(h3_results['eigenvalues'].min()),\n",
    "        'eigenvalue_max': float(h3_results['eigenvalues'].max()),\n",
    "        'eigenvalues_below_1e6': int((h3_results['eigenvalues'] < 1e-6).sum()),\n",
    "        'timestamp': timestamp\n",
    "    }\n",
    "    \n",
    "    h3_summary_path = Path(OUTPUT_DIR) / f'h3_summary_{timestamp}.json'\n",
    "    with open(h3_summary_path, 'w') as f:\n",
    "        json.dump(h3_summary, f, indent=2)\n",
    "    print(f\"  Saved JSON: {h3_summary_path}\")\n",
    "    \n",
    "    print(\"\\nH³ extraction summary:\")\n",
    "    print(f\"  Total forms: {h3_summary['n_forms']}\")\n",
    "    print(f\"  Harmonic (λ < 1e-6): {h3_summary['n_harmonic']}\")\n",
    "    print(f\"  Eigenvalue range: [{h3_summary['eigenvalue_min']:.2e}, {h3_summary['eigenvalue_max']:.2e}]\")\n",
    "else:\n",
    "    print(\"\\nH³ extraction skipped (CONFIG['extract_h3'] = False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization"
   },
   "source": [
    "## 12. Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_training"
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('K₇ Metric Reconstruction Training History', fontsize=16, fontweight='bold')\n",
    "\n",
    "epochs = trainer.history['epoch']\n",
    "\n",
    "# Total loss\n",
    "axes[0, 0].plot(epochs, trainer.history['total_loss'], linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Total Loss')\n",
    "axes[0, 0].set_title('Total Loss')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].set_yscale('log')\n",
    "\n",
    "# Snapshot loss\n",
    "axes[0, 1].plot(epochs, trainer.history['snapshot_loss'], linewidth=2, color='orange')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Snapshot Loss')\n",
    "axes[0, 1].set_title('Snapshot Anchoring Loss')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_yscale('log')\n",
    "\n",
    "# Volume loss\n",
    "axes[0, 2].plot(epochs, trainer.history['volume_loss'], linewidth=2, color='green')\n",
    "axes[0, 2].set_xlabel('Epoch')\n",
    "axes[0, 2].set_ylabel('Volume Loss')\n",
    "axes[0, 2].set_title('Volume Normalization Loss')\n",
    "axes[0, 2].grid(True, alpha=0.3)\n",
    "axes[0, 2].set_yscale('log')\n",
    "\n",
    "# Torsion loss\n",
    "axes[1, 0].plot(epochs, trainer.history['torsion_loss'], linewidth=2, color='red')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Torsion Loss')\n",
    "axes[1, 0].set_title('G₂ Torsion Loss')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "axes[1, 0].set_yscale('log')\n",
    "\n",
    "# H² loss\n",
    "axes[1, 1].plot(epochs, trainer.history['h2_loss'], linewidth=2, color='purple')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('H² Loss')\n",
    "axes[1, 1].set_title('H² Orthonormality Loss')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_yscale('log')\n",
    "\n",
    "# Ricci loss\n",
    "axes[1, 2].plot(epochs, trainer.history['ricci_loss'], linewidth=2, color='brown')\n",
    "axes[1, 2].set_xlabel('Epoch')\n",
    "axes[1, 2].set_ylabel('Ricci Loss')\n",
    "axes[1, 2].set_title('Ricci Flatness Loss')\n",
    "axes[1, 2].grid(True, alpha=0.3)\n",
    "axes[1, 2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plot_path = Path(OUTPUT_DIR) / f'training_history_{timestamp}.png'\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nTraining plot saved: {plot_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 13. Training Summary and Final Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "final_summary"
   },
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary_report = {\n",
    "    'training': {\n",
    "        'total_epochs': CONFIG['epochs'],\n",
    "        'batch_size': CONFIG['batch_size'],\n",
    "        'final_total_loss': float(trainer.history['total_loss'][-1]),\n",
    "        'final_snapshot_loss': float(trainer.history['snapshot_loss'][-1]),\n",
    "        'final_volume_loss': float(trainer.history['volume_loss'][-1]),\n",
    "        'final_torsion_loss': float(trainer.history['torsion_loss'][-1]),\n",
    "    },\n",
    "    'networks': {\n",
    "        'm1_params': sum(p.numel() for p in trainer.networks['m1'].parameters()),\n",
    "        'neck_params': sum(p.numel() for p in trainer.networks['neck'].parameters()),\n",
    "        'm2_params': sum(p.numel() for p in trainer.networks['m2'].parameters()),\n",
    "        'phi_params': sum(p.numel() for p in trainer.networks['phi'].parameters()),\n",
    "        'h2_params': sum(p.numel() for p in trainer.networks['h2'].parameters()),\n",
    "    },\n",
    "    'outputs': {\n",
    "        'checkpoint_dir': str(CHECKPOINT_DIR),\n",
    "        'output_dir': str(OUTPUT_DIR),\n",
    "        'timestamp': timestamp\n",
    "    },\n",
    "    'gift_params': CONFIG['gift_params']\n",
    "}\n",
    "\n",
    "if CONFIG['extract_h3']:\n",
    "    summary_report['h3_extraction'] = h3_summary\n",
    "\n",
    "# Save summary report\n",
    "summary_path = Path(OUTPUT_DIR) / f'summary_report_{timestamp}.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(summary_report, f, indent=2)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nTraining Statistics:\")\n",
    "print(f\"  Total epochs completed: {CONFIG['epochs']}\")\n",
    "print(f\"  Final total loss: {summary_report['training']['final_total_loss']:.6e}\")\n",
    "print(f\"  Final snapshot loss: {summary_report['training']['final_snapshot_loss']:.6e}\")\n",
    "print(f\"  Final volume loss: {summary_report['training']['final_volume_loss']:.6e}\")\n",
    "print(f\"  Final torsion loss: {summary_report['training']['final_torsion_loss']:.6e}\")\n",
    "\n",
    "print(\"\\nNetwork Parameters:\")\n",
    "for name, count in summary_report['networks'].items():\n",
    "    print(f\"  {name}: {count:,}\")\n",
    "\n",
    "print(\"\\nOutput Locations:\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  Results: {OUTPUT_DIR}\")\n",
    "\n",
    "if CONFIG['extract_h3']:\n",
    "    print(\"\\nH³ Extraction:\")\n",
    "    print(f\"  Total forms: {h3_summary['n_forms']}\")\n",
    "    print(f\"  Harmonic forms: {h3_summary['n_harmonic']}\")\n",
    "\n",
    "print(f\"\\nSummary report saved: {summary_path}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ALL TASKS COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
