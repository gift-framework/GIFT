{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# G₂ Universality v9 — High-N Convergence Test\n",
        "\n",
        "## Goal: Determine the true limit of λ₁ × H* as N → ∞\n",
        "\n",
        "### Key insight from literature:\n",
        "Graph Laplacian convergence rate for dimension m=7:\n",
        "```\n",
        "O(N^(-1/(m+4))) = O(N^(-1/11)) ≈ O(N^(-0.091))\n",
        "```\n",
        "\n",
        "This is **very slow**! We need large N to see the true limit.\n",
        "\n",
        "### Hypothesis to test:\n",
        "- **H₀**: λ₁ × H* → 14 = dim(G₂)\n",
        "- **H₁**: λ₁ × H* → 13 = dim(G₂) - 1\n",
        "\n",
        "### Test plan:\n",
        "N ∈ [1000, 2000, 5000, 10000, 20000, 35000, 50000]\n",
        "\n",
        "---\n",
        "*GIFT Framework — v9 Convergence*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Imports\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg import eigsh\n",
        "from scipy.optimize import curve_fit\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"  G₂ Universality v9 — High-N Convergence\")\n",
        "print(\"  Testing: λ₁ × H* → 13 or 14 ?\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Date: {datetime.now()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Configuration\n",
        "# K7 manifold\n",
        "H_STAR = 99\n",
        "RATIO = 99 / 84  # = 1.1786\n",
        "DET_G = 65 / 32\n",
        "\n",
        "# Test points - up to 50k\n",
        "N_VALUES = [1000, 2000, 5000, 10000, 20000, 35000, 50000]\n",
        "\n",
        "# Graph Laplacian params\n",
        "K_NEIGHBORS = 30  # Slightly higher for large N\n",
        "\n",
        "# Seeds for averaging\n",
        "SEEDS = [42, 123, 456]\n",
        "\n",
        "# Theoretical convergence rate for m=7\n",
        "CONV_RATE = 1/11  # O(N^(-1/11))\n",
        "\n",
        "print(f\"K7: H* = {H_STAR}, ratio = {RATIO:.4f}\")\n",
        "print(f\"N values: {N_VALUES}\")\n",
        "print(f\"Theoretical rate: O(N^(-{CONV_RATE:.4f}))\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Optimized Quaternion S³ sampling\n",
        "def sample_S3(n, seed):\n",
        "    \"\"\"Sample n points uniformly on S³.\"\"\"\n",
        "    np.random.seed(seed)\n",
        "    q = np.random.randn(n, 4)\n",
        "    return q / np.linalg.norm(q, axis=1, keepdims=True)\n",
        "\n",
        "def geodesic_S3(Q):\n",
        "    \"\"\"Pairwise geodesic distances on S³.\"\"\"\n",
        "    dot = np.abs(Q @ Q.T)\n",
        "    np.clip(dot, 0, 1, out=dot)\n",
        "    return 2 * np.arccos(dot)\n",
        "\n",
        "print(\"S³ functions ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: TCS distance matrix (optimized)\n",
        "def tcs_distance_matrix(n, ratio, seed):\n",
        "    \"\"\"\n",
        "    Compute TCS distance matrix for S¹ × S³ × S³.\n",
        "    Optimized for memory with large N.\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # S¹\n",
        "    theta = np.random.uniform(0, 2*np.pi, n)\n",
        "    theta_diff = np.abs(theta[:, None] - theta[None, :])\n",
        "    d_S1_sq = np.minimum(theta_diff, 2*np.pi - theta_diff)**2\n",
        "    \n",
        "    # S³ factors\n",
        "    q1 = sample_S3(n, seed + 1000)\n",
        "    q2 = sample_S3(n, seed + 2000)\n",
        "    d1 = geodesic_S3(q1)\n",
        "    d2 = geodesic_S3(q2)\n",
        "    \n",
        "    # Metric: α dθ² + d₁² + r² d₂²\n",
        "    alpha = DET_G / (ratio**3)\n",
        "    D_sq = alpha * d_S1_sq + d1**2 + (ratio**2) * d2**2\n",
        "    \n",
        "    return np.sqrt(D_sq)\n",
        "\n",
        "print(\"TCS distance function ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Graph Laplacian λ₁ (optimized)\n",
        "def compute_lambda1(D, k=30):\n",
        "    \"\"\"\n",
        "    Compute first non-zero eigenvalue of normalized graph Laplacian.\n",
        "    Optimized for large matrices.\n",
        "    \"\"\"\n",
        "    n = D.shape[0]\n",
        "    k = min(k, n - 1)\n",
        "    \n",
        "    # Adaptive bandwidth\n",
        "    knn_dists = np.partition(D, k, axis=1)[:, :k]\n",
        "    sigma = np.median(knn_dists)\n",
        "    sigma = max(sigma, 1e-10)\n",
        "    \n",
        "    # Gaussian kernel with k-NN sparsification\n",
        "    W = np.exp(-D**2 / (2 * sigma**2))\n",
        "    np.fill_diagonal(W, 0)\n",
        "    \n",
        "    # Keep only k nearest neighbors (symmetric)\n",
        "    for i in range(n):\n",
        "        idx = np.argpartition(W[i], -k)[-k:]\n",
        "        mask = np.ones(n, dtype=bool)\n",
        "        mask[idx] = False\n",
        "        W[i, mask] = 0\n",
        "    W = (W + W.T) / 2\n",
        "    \n",
        "    # Normalized Laplacian\n",
        "    d = W.sum(axis=1)\n",
        "    d_inv_sqrt = np.where(d > 1e-10, 1/np.sqrt(d), 0)\n",
        "    D_inv = sp.diags(d_inv_sqrt)\n",
        "    L = sp.eye(n) - D_inv @ sp.csr_matrix(W) @ D_inv\n",
        "    \n",
        "    # Get smallest eigenvalues\n",
        "    eigenvalues, _ = eigsh(L, k=5, which='SM')\n",
        "    eigenvalues = np.sort(eigenvalues)\n",
        "    \n",
        "    return eigenvalues[1]  # First non-zero\n",
        "\n",
        "print(\"Eigenvalue solver ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Run convergence study\n",
        "print(\"=\"*60)\n",
        "print(\"CONVERGENCE STUDY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nRunning N = {N_VALUES}\")\n",
        "print(f\"This may take 10-20 minutes for large N...\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for N in N_VALUES:\n",
        "    print(f\"N = {N:6d} ... \", end='', flush=True)\n",
        "    \n",
        "    lambda1_vals = []\n",
        "    for seed in SEEDS:\n",
        "        D = tcs_distance_matrix(N, RATIO, seed)\n",
        "        l1 = compute_lambda1(D, k=K_NEIGHBORS)\n",
        "        lambda1_vals.append(l1)\n",
        "    \n",
        "    mean_l1 = np.mean(lambda1_vals)\n",
        "    std_l1 = np.std(lambda1_vals)\n",
        "    product = mean_l1 * H_STAR\n",
        "    product_std = std_l1 * H_STAR\n",
        "    \n",
        "    results.append({\n",
        "        'N': N,\n",
        "        'lambda1': mean_l1,\n",
        "        'lambda1_std': std_l1,\n",
        "        'product': product,\n",
        "        'product_std': product_std\n",
        "    })\n",
        "    \n",
        "    print(f\"λ₁×H* = {product:7.4f} ± {product_std:.4f}\")\n",
        "\n",
        "print(\"\\nDone!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Fit multiple convergence models\n",
        "print(\"=\"*60)\n",
        "print(\"CONVERGENCE FITS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "N_arr = np.array([r['N'] for r in results])\n",
        "P_arr = np.array([r['product'] for r in results])\n",
        "P_std = np.array([r['product_std'] for r in results])\n",
        "\n",
        "# Fit 1: λ₁H* = A + B/N (naive)\n",
        "inv_N = 1 / N_arr\n",
        "c1 = np.polyfit(inv_N, P_arr, 1)\n",
        "extrap_1 = c1[1]\n",
        "print(f\"\\n1. Fit A + B/N:\")\n",
        "print(f\"   Limit = {extrap_1:.4f}\")\n",
        "\n",
        "# Fit 2: λ₁H* = A + B/√N\n",
        "inv_sqrtN = 1 / np.sqrt(N_arr)\n",
        "c2 = np.polyfit(inv_sqrtN, P_arr, 1)\n",
        "extrap_2 = c2[1]\n",
        "print(f\"\\n2. Fit A + B/√N:\")\n",
        "print(f\"   Limit = {extrap_2:.4f}\")\n",
        "\n",
        "# Fit 3: λ₁H* = A + B × N^(-1/11) (theoretical rate)\n",
        "N_rate = N_arr ** (-CONV_RATE)\n",
        "c3 = np.polyfit(N_rate, P_arr, 1)\n",
        "extrap_3 = c3[1]\n",
        "print(f\"\\n3. Fit A + B × N^(-1/11) [THEORETICAL]:\")\n",
        "print(f\"   Limit = {extrap_3:.4f}\")\n",
        "\n",
        "# Fit 4: Power law λ₁H* = A + B × N^(-α)\n",
        "def power_law(N, A, B, alpha):\n",
        "    return A + B * N ** (-alpha)\n",
        "\n",
        "try:\n",
        "    popt, pcov = curve_fit(power_law, N_arr, P_arr, \n",
        "                           p0=[13, 100, 0.1], \n",
        "                           bounds=([0, 0, 0.01], [20, 1000, 1]),\n",
        "                           maxfev=10000)\n",
        "    extrap_4 = popt[0]\n",
        "    alpha_fit = popt[2]\n",
        "    perr = np.sqrt(np.diag(pcov))\n",
        "    print(f\"\\n4. Fit A + B × N^(-α) [BEST FIT]:\")\n",
        "    print(f\"   A (limit) = {extrap_4:.4f} ± {perr[0]:.4f}\")\n",
        "    print(f\"   α = {alpha_fit:.4f} ± {perr[2]:.4f}\")\n",
        "    print(f\"   (Theory: α = 1/11 ≈ 0.0909)\")\n",
        "except Exception as e:\n",
        "    print(f\"\\n4. Power law fit failed: {e}\")\n",
        "    extrap_4 = np.nan\n",
        "    alpha_fit = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Hypothesis test\n",
        "print(\"=\"*60)\n",
        "print(\"HYPOTHESIS TEST\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "candidates = [\n",
        "    ('dim(G₂) = 14', 14),\n",
        "    ('dim(G₂) - 1 = 13', 13),\n",
        "    ('99/7 ≈ 14.14', 99/7),\n",
        "    ('98/7 = 14', 98/7),\n",
        "    ('91/7 = 13', 91/7),\n",
        "]\n",
        "\n",
        "print(\"\\nComparing extrapolations to GIFT constants:\\n\")\n",
        "print(f\"{'Fit':<25} {'Limit':>10} | \", end='')\n",
        "for name, _ in candidates:\n",
        "    print(f\"{name:>15}\", end=' ')\n",
        "print()\n",
        "print(\"-\" * 100)\n",
        "\n",
        "for fit_name, extrap in [('1/N', extrap_1), ('1/√N', extrap_2), \n",
        "                          ('N^(-1/11) [theory]', extrap_3), \n",
        "                          ('N^(-α) [best fit]', extrap_4)]:\n",
        "    if np.isnan(extrap):\n",
        "        continue\n",
        "    print(f\"{fit_name:<25} {extrap:>10.4f} | \", end='')\n",
        "    for name, val in candidates:\n",
        "        dev = abs(extrap - val) / val * 100\n",
        "        marker = '✓' if dev < 10 else ' '\n",
        "        print(f\"{dev:>13.1f}%{marker}\", end=' ')\n",
        "    print()\n",
        "\n",
        "# Best estimate\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if not np.isnan(extrap_4):\n",
        "    best = extrap_4\n",
        "    best_name = \"power law\"\n",
        "else:\n",
        "    best = extrap_3\n",
        "    best_name = \"N^(-1/11)\"\n",
        "\n",
        "print(f\"Best estimate (from {best_name}): λ₁×H* → {best:.4f}\")\n",
        "print(f\"\\nClosest GIFT constant:\")\n",
        "closest = min(candidates, key=lambda x: abs(best - x[1]))\n",
        "print(f\"  {closest[0]} with {abs(best - closest[1])/closest[1]*100:.2f}% deviation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Visualization\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: λ₁×H* vs N\n",
        "ax1 = axes[0]\n",
        "ax1.errorbar(N_arr, P_arr, yerr=P_std, fmt='o-', markersize=8, \n",
        "             capsize=4, color='blue', linewidth=2, label='Data')\n",
        "ax1.axhline(y=14, color='green', linestyle='--', linewidth=2, label='14 = dim(G₂)')\n",
        "ax1.axhline(y=13, color='red', linestyle='--', linewidth=2, label='13 = dim(G₂)-1')\n",
        "ax1.set_xlabel('N (sample size)', fontsize=12)\n",
        "ax1.set_ylabel('λ₁ × H*', fontsize=12)\n",
        "ax1.set_title('Convergence: λ₁×H* vs N', fontsize=14)\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_ylim([8, 25])\n",
        "\n",
        "# Plot 2: λ₁×H* vs N^(-1/11)\n",
        "ax2 = axes[1]\n",
        "ax2.errorbar(N_rate, P_arr, yerr=P_std, fmt='o', markersize=10, \n",
        "             capsize=4, color='blue')\n",
        "# Fit line\n",
        "x_fit = np.linspace(0, max(N_rate)*1.1, 100)\n",
        "ax2.plot(x_fit, c3[0]*x_fit + c3[1], 'g-', linewidth=2, \n",
        "         label=f'Fit: limit = {extrap_3:.2f}')\n",
        "ax2.axhline(y=14, color='green', linestyle='--', alpha=0.5)\n",
        "ax2.axhline(y=13, color='red', linestyle='--', alpha=0.5)\n",
        "ax2.set_xlabel('N^(-1/11)', fontsize=12)\n",
        "ax2.set_ylabel('λ₁ × H*', fontsize=12)\n",
        "ax2.set_title('Theoretical Rate Fit', fontsize=14)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Log-log for power law\n",
        "ax3 = axes[2]\n",
        "# Shift to see decay: plot λ₁×H* - limit vs N\n",
        "if not np.isnan(extrap_4):\n",
        "    shifted = P_arr - extrap_4\n",
        "    ax3.loglog(N_arr, np.abs(shifted), 'o-', markersize=10, color='blue')\n",
        "    # Reference slopes\n",
        "    N_ref = np.array([1000, 50000])\n",
        "    for alpha, name, color in [(1/11, '1/11 (theory)', 'green'), \n",
        "                                (alpha_fit, f'{alpha_fit:.3f} (fit)', 'red')]:\n",
        "        y_ref = np.abs(shifted[0]) * (N_ref / N_arr[0]) ** (-alpha)\n",
        "        ax3.loglog(N_ref, y_ref, '--', color=color, linewidth=2, label=f'α = {name}')\n",
        "    ax3.set_xlabel('N', fontsize=12)\n",
        "    ax3.set_ylabel(f'|λ₁×H* - {extrap_4:.2f}|', fontsize=12)\n",
        "    ax3.set_title('Power Law Decay', fontsize=14)\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3, which='both')\n",
        "else:\n",
        "    ax3.text(0.5, 0.5, 'Power fit failed', ha='center', va='center', transform=ax3.transAxes)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs_v9/convergence_high_N.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Saved: outputs_v9/convergence_high_N.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Save results\n",
        "import os\n",
        "os.makedirs('outputs_v9', exist_ok=True)\n",
        "\n",
        "output = {\n",
        "    'metadata': {\n",
        "        'notebook': 'G2_Universality_v9_HighN',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'H_star': H_STAR,\n",
        "        'ratio': RATIO,\n",
        "        'seeds': SEEDS,\n",
        "        'k_neighbors': K_NEIGHBORS\n",
        "    },\n",
        "    'convergence_data': results,\n",
        "    'fits': {\n",
        "        '1_over_N': {'limit': extrap_1},\n",
        "        '1_over_sqrtN': {'limit': extrap_2},\n",
        "        'N_minus_1_11': {'limit': extrap_3, 'note': 'theoretical rate'},\n",
        "        'power_law': {\n",
        "            'limit': extrap_4 if not np.isnan(extrap_4) else None,\n",
        "            'alpha': alpha_fit if not np.isnan(alpha_fit) else None\n",
        "        }\n",
        "    },\n",
        "    'conclusion': {\n",
        "        'best_estimate': best,\n",
        "        'closest_constant': closest[0],\n",
        "        'deviation_pct': abs(best - closest[1])/closest[1]*100\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('outputs_v9/convergence_results.json', 'w') as f:\n",
        "    json.dump(output, f, indent=2, default=str)\n",
        "\n",
        "print(\"Saved: outputs_v9/convergence_results.json\")\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EXPERIMENT COMPLETE\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### Convergence Rate\n",
        "For graph Laplacian on m-dimensional manifold:\n",
        "```\n",
        "Rate = O(N^(-1/(m+4)))\n",
        "For m=7: O(N^(-1/11)) ≈ O(N^(-0.091))\n",
        "```\n",
        "\n",
        "### Key Question\n",
        "Does λ₁ × H* converge to **14** (dim G₂) or **13** (dim G₂ - 1)?\n",
        "\n",
        "### Interpretation\n",
        "- If limit = 14: Graph Laplacian correctly approximates continuous\n",
        "- If limit = 13: There's a systematic offset (perhaps normalization)\n",
        "\n",
        "---\n",
        "*GIFT Framework — v9 High-N Convergence*"
      ]
    }
  ]
}
