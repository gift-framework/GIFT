{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üî¨ High-N Topological Investigation (N=20k)\n",
        "\n",
        "**Objective**: Investigate spectral topology at high resolution\n",
        "\n",
        "**NOT formalizing** ‚Äî just exploring:\n",
        "1. Convergence behavior at N=20k\n",
        "2. Zero-mode structure in 1-form spectrum\n",
        "3. Mode localization patterns\n",
        "4. Graph topology vs TCS ratio\n",
        "\n",
        "**Memory management**: Chunked computation where needed"
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SETUP WITH MEMORY MONITORING\n",
        "# =============================================================================\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import csr_matrix, lil_matrix, diags, eye\n",
        "from scipy.sparse.linalg import eigsh\n",
        "from scipy.spatial.distance import cdist\n",
        "import gc\n",
        "import time\n",
        "from datetime import datetime\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def get_memory_mb():\n",
        "    \"\"\"Get current memory usage in MB.\"\"\"\n",
        "    import psutil\n",
        "    return psutil.Process().memory_info().rss / 1024**2\n",
        "\n",
        "def log_memory(msg=\"\"):\n",
        "    print(f\"  [MEM] {get_memory_mb():.0f} MB {msg}\")\n",
        "\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(f\"‚úì Setup complete - {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
        "log_memory(\"at start\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MEMORY-EFFICIENT SAMPLING\n",
        "# =============================================================================\n",
        "\n",
        "def sample_S3(n, rng):\n",
        "    \"\"\"Sample uniformly from S¬≥ (float32 for memory).\"\"\"\n",
        "    q = rng.standard_normal((n, 4)).astype(np.float32)\n",
        "    return q / np.linalg.norm(q, axis=1, keepdims=True)\n",
        "\n",
        "def sample_TCS(n, rng):\n",
        "    \"\"\"Sample from TCS = S¬π √ó S¬≥ √ó S¬≥.\"\"\"\n",
        "    theta = rng.uniform(0, 2*np.pi, n).astype(np.float32)\n",
        "    q1 = sample_S3(n, rng)\n",
        "    q2 = sample_S3(n, rng)\n",
        "    return theta, q1, q2\n",
        "\n",
        "print(\"‚úì Sampling functions loaded\")"
      ],
      "metadata": {
        "id": "sampling"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CHUNKED DISTANCE COMPUTATION (Memory-efficient)\n",
        "# =============================================================================\n",
        "\n",
        "def geodesic_S1_chunk(theta1, theta2):\n",
        "    \"\"\"Geodesic distance on S¬π between two sets.\"\"\"\n",
        "    diff = np.abs(theta1[:, None] - theta2[None, :])\n",
        "    return np.minimum(diff, 2*np.pi - diff).astype(np.float32)\n",
        "\n",
        "def geodesic_S3_chunk(Q1, Q2):\n",
        "    \"\"\"Geodesic distance on S¬≥ between two sets.\"\"\"\n",
        "    dot = np.clip(np.abs(Q1 @ Q2.T), 0, 1)\n",
        "    return (2 * np.arccos(dot)).astype(np.float32)\n",
        "\n",
        "def compute_tcs_distance_chunked(\n",
        "    theta, q1, q2,\n",
        "    ratio=1.0,\n",
        "    det_g=65/32,\n",
        "    chunk_size=2000\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute TCS distance matrix in chunks to manage memory.\n",
        "    Returns SPARSE k-NN graph directly (not full distance matrix).\n",
        "    \"\"\"\n",
        "    n = len(theta)\n",
        "    alpha = det_g / (ratio**3)\n",
        "\n",
        "    print(f\"  Computing chunked distances (n={n}, chunk={chunk_size})...\")\n",
        "\n",
        "    # We'll build a sparse k-NN graph directly\n",
        "    # First pass: compute all distances in chunks and find k-NN\n",
        "    k = 50  # k for k-NN\n",
        "    \n",
        "    # Store k nearest neighbors for each point\n",
        "    knn_indices = np.zeros((n, k), dtype=np.int32)\n",
        "    knn_distances = np.zeros((n, k), dtype=np.float32)\n",
        "\n",
        "    n_chunks = (n + chunk_size - 1) // chunk_size\n",
        "\n",
        "    for i in range(n_chunks):\n",
        "        i_start = i * chunk_size\n",
        "        i_end = min((i + 1) * chunk_size, n)\n",
        "\n",
        "        # Get chunk data\n",
        "        theta_i = theta[i_start:i_end]\n",
        "        q1_i = q1[i_start:i_end]\n",
        "        q2_i = q2[i_start:i_end]\n",
        "\n",
        "        # Compute distances to ALL other points\n",
        "        d_s1 = geodesic_S1_chunk(theta_i, theta)\n",
        "        d_s3_1 = geodesic_S3_chunk(q1_i, q1)\n",
        "        d_s3_2 = geodesic_S3_chunk(q2_i, q2)\n",
        "\n",
        "        # TCS metric\n",
        "        D_chunk = np.sqrt(alpha * d_s1**2 + d_s3_1**2 + (ratio**2) * d_s3_2**2)\n",
        "\n",
        "        # Set self-distance to inf\n",
        "        for j in range(i_end - i_start):\n",
        "            D_chunk[j, i_start + j] = np.inf\n",
        "\n",
        "        # Find k nearest neighbors for this chunk\n",
        "        for j in range(i_end - i_start):\n",
        "            idx = np.argpartition(D_chunk[j], k)[:k]\n",
        "            knn_indices[i_start + j] = idx\n",
        "            knn_distances[i_start + j] = D_chunk[j, idx]\n",
        "\n",
        "        # Clear memory\n",
        "        del d_s1, d_s3_1, d_s3_2, D_chunk\n",
        "        gc.collect()\n",
        "\n",
        "        if (i + 1) % 5 == 0:\n",
        "            print(f\"    Chunk {i+1}/{n_chunks} done\")\n",
        "\n",
        "    return knn_indices, knn_distances\n",
        "\n",
        "print(\"‚úì Chunked distance computation loaded\")"
      ],
      "metadata": {
        "id": "chunked_distance"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SPARSE GRAPH LAPLACIAN FROM k-NN\n",
        "# =============================================================================\n",
        "\n",
        "def build_sparse_laplacian(knn_indices, knn_distances, sigma=None):\n",
        "    \"\"\"\n",
        "    Build sparse normalized Laplacian from k-NN data.\n",
        "    \"\"\"\n",
        "    n = knn_indices.shape[0]\n",
        "    k = knn_indices.shape[1]\n",
        "\n",
        "    # Compute sigma from median k-NN distance\n",
        "    if sigma is None:\n",
        "        sigma = float(np.median(knn_distances))\n",
        "    print(f\"  Using œÉ = {sigma:.6f}\")\n",
        "\n",
        "    # Build sparse weight matrix\n",
        "    W = lil_matrix((n, n), dtype=np.float32)\n",
        "\n",
        "    for i in range(n):\n",
        "        for j_idx in range(k):\n",
        "            j = knn_indices[i, j_idx]\n",
        "            d = knn_distances[i, j_idx]\n",
        "            w = np.exp(-d**2 / (2 * sigma**2))\n",
        "            W[i, j] = w\n",
        "            W[j, i] = w  # Symmetrize\n",
        "\n",
        "    W = W.tocsr()\n",
        "\n",
        "    # Degree\n",
        "    d = np.array(W.sum(axis=1)).flatten()\n",
        "    d = np.maximum(d, 1e-10)\n",
        "    d_inv_sqrt = 1.0 / np.sqrt(d)\n",
        "\n",
        "    # Normalized Laplacian: L = I - D^{-1/2} W D^{-1/2}\n",
        "    D_inv_sqrt = diags(d_inv_sqrt)\n",
        "    L = eye(n) - D_inv_sqrt @ W @ D_inv_sqrt\n",
        "\n",
        "    return L.tocsr(), W, sigma, d\n",
        "\n",
        "print(\"‚úì Sparse Laplacian builder loaded\")"
      ],
      "metadata": {
        "id": "sparse_laplacian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# TOPOLOGICAL ANALYSIS FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def count_connected_components(W):\n",
        "    \"\"\"Count connected components using BFS.\"\"\"\n",
        "    from scipy.sparse.csgraph import connected_components\n",
        "    n_components, labels = connected_components(W, directed=False)\n",
        "    return n_components, labels\n",
        "\n",
        "def estimate_betti_1(W, n_vertices):\n",
        "    \"\"\"\n",
        "    Estimate first Betti number (number of independent cycles).\n",
        "    Œ≤‚ÇÅ = m - n + c  (Euler formula for graphs)\n",
        "    where m = edges, n = vertices, c = components\n",
        "    \"\"\"\n",
        "    n_edges = W.nnz // 2  # Symmetric, so divide by 2\n",
        "    n_components, _ = count_connected_components(W)\n",
        "    beta_1 = n_edges - n_vertices + n_components\n",
        "    return beta_1, n_edges, n_components\n",
        "\n",
        "def count_triangles_sparse(W, sample_size=5000):\n",
        "    \"\"\"\n",
        "    Estimate number of triangles by sampling.\n",
        "    (Full count is O(n¬≥) which is too expensive)\n",
        "    \"\"\"\n",
        "    n = W.shape[0]\n",
        "    W_binary = (W > 0).astype(np.float32)\n",
        "\n",
        "    # Sample random triplets\n",
        "    rng = np.random.default_rng(42)\n",
        "    triangles_found = 0\n",
        "\n",
        "    indices = rng.choice(n, size=min(sample_size, n), replace=False)\n",
        "\n",
        "    for i in indices:\n",
        "        neighbors_i = W_binary[i].nonzero()[1]\n",
        "        if len(neighbors_i) < 2:\n",
        "            continue\n",
        "        # Check pairs of neighbors\n",
        "        for j_idx in range(min(20, len(neighbors_i))):\n",
        "            j = neighbors_i[j_idx]\n",
        "            neighbors_j = set(W_binary[j].nonzero()[1])\n",
        "            # Count common neighbors\n",
        "            common = len(set(neighbors_i) & neighbors_j)\n",
        "            triangles_found += common\n",
        "\n",
        "    # Scale estimate\n",
        "    scale_factor = n / len(indices)\n",
        "    estimated_triangles = int(triangles_found * scale_factor / 6)  # Each triangle counted 6 times\n",
        "\n",
        "    return estimated_triangles\n",
        "\n",
        "print(\"‚úì Topological analysis functions loaded\")"
      ],
      "metadata": {
        "id": "topology_funcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 1-FORM HODGE LAPLACIAN (Sparse version)\n",
        "# =============================================================================\n",
        "\n",
        "def build_hodge_1_sparse(W, max_edges=50000):\n",
        "    \"\"\"\n",
        "    Build sparse Hodge 1-form Laplacian.\n",
        "    Limited to max_edges for memory.\n",
        "    \"\"\"\n",
        "    n = W.shape[0]\n",
        "\n",
        "    # Extract edges\n",
        "    W_coo = W.tocoo()\n",
        "    edges = []\n",
        "    for i, j, w in zip(W_coo.row, W_coo.col, W_coo.data):\n",
        "        if i < j and w > 0:  # Upper triangular only\n",
        "            edges.append((i, j, w))\n",
        "\n",
        "    m = len(edges)\n",
        "    print(f\"  Graph has {m} edges\")\n",
        "\n",
        "    if m > max_edges:\n",
        "        print(f\"  WARNING: Limiting to {max_edges} strongest edges\")\n",
        "        edges = sorted(edges, key=lambda x: -x[2])[:max_edges]\n",
        "        m = max_edges\n",
        "\n",
        "    # Build incidence matrix d‚ÇÄ: vertices ‚Üí edges\n",
        "    d0 = lil_matrix((m, n), dtype=np.float32)\n",
        "    edge_weights = np.zeros(m, dtype=np.float32)\n",
        "\n",
        "    for e_idx, (i, j, w) in enumerate(edges):\n",
        "        d0[e_idx, i] = -1.0\n",
        "        d0[e_idx, j] = +1.0\n",
        "        edge_weights[e_idx] = w\n",
        "\n",
        "    d0 = d0.tocsr()\n",
        "\n",
        "    # Hodge 1-Laplacian: Œî‚ÇÅ = d‚ÇÄ·µÄ d‚ÇÄ\n",
        "    L1 = d0 @ d0.T\n",
        "\n",
        "    # Normalize by edge degree\n",
        "    d_edge = np.array(np.abs(L1).sum(axis=1)).flatten()\n",
        "    d_edge = np.maximum(d_edge, 1e-10)\n",
        "    d_inv_sqrt = 1.0 / np.sqrt(d_edge)\n",
        "    D_inv = diags(d_inv_sqrt)\n",
        "    L1_norm = D_inv @ L1 @ D_inv\n",
        "\n",
        "    return L1_norm.tocsr(), m, edges\n",
        "\n",
        "print(\"‚úì Sparse Hodge 1-form Laplacian loaded\")"
      ],
      "metadata": {
        "id": "hodge_sparse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# MODE ANALYSIS FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def participation_ratio(v):\n",
        "    \"\"\"PR = 1/(N √ó Œ£|v·µ¢|‚Å¥).\"\"\"\n",
        "    v = v.flatten()\n",
        "    v_norm = v / np.linalg.norm(v)\n",
        "    return float(1.0 / (len(v) * np.sum(v_norm**4)))\n",
        "\n",
        "def mode_projection_stats(v, theta, q1, q2):\n",
        "    \"\"\"\n",
        "    Compute statistics of mode projection onto each factor.\n",
        "    \"\"\"\n",
        "    v = v.flatten()\n",
        "    p = np.abs(v)**2\n",
        "    p = p / np.sum(p)\n",
        "\n",
        "    # S¬π statistics\n",
        "    cos_theta = np.cos(theta)\n",
        "    sin_theta = np.sin(theta)\n",
        "    s1_cos_moment = np.sum(p * cos_theta)\n",
        "    s1_sin_moment = np.sum(p * sin_theta)\n",
        "    s1_order_param = np.sqrt(s1_cos_moment**2 + s1_sin_moment**2)\n",
        "\n",
        "    # S¬≥ statistics (use first coordinate as proxy)\n",
        "    s3_1_mean = np.sum(p[:, None] * q1, axis=0)\n",
        "    s3_1_order = np.linalg.norm(s3_1_mean)\n",
        "\n",
        "    s3_2_mean = np.sum(p[:, None] * q2, axis=0)\n",
        "    s3_2_order = np.linalg.norm(s3_2_mean)\n",
        "\n",
        "    # Fourier-like analysis on S¬π\n",
        "    # Mode 1: cos(Œ∏), sin(Œ∏)\n",
        "    fourier_1 = np.sqrt((np.sum(p * np.cos(theta)))**2 + (np.sum(p * np.sin(theta)))**2)\n",
        "    # Mode 2: cos(2Œ∏), sin(2Œ∏)\n",
        "    fourier_2 = np.sqrt((np.sum(p * np.cos(2*theta)))**2 + (np.sum(p * np.sin(2*theta)))**2)\n",
        "\n",
        "    return {\n",
        "        \"s1_order\": float(s1_order_param),\n",
        "        \"s3_1_order\": float(s3_1_order),\n",
        "        \"s3_2_order\": float(s3_2_order),\n",
        "        \"s1_fourier_1\": float(fourier_1),\n",
        "        \"s1_fourier_2\": float(fourier_2)\n",
        "    }\n",
        "\n",
        "print(\"‚úì Mode analysis functions loaded\")"
      ],
      "metadata": {
        "id": "mode_analysis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üî¨ Main Investigation"
      ],
      "metadata": {
        "id": "investigation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# FULL ANALYSIS PIPELINE\n",
        "# =============================================================================\n",
        "\n",
        "def full_analysis(N, ratio, seed=42, H_star=99):\n",
        "    \"\"\"\n",
        "    Complete analysis pipeline for a single (N, ratio) configuration.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  N={N}, ratio={ratio:.2f}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    log_memory(\"start\")\n",
        "\n",
        "    # 1. Sample TCS\n",
        "    print(\"\\n[1] Sampling TCS...\")\n",
        "    rng = np.random.default_rng(seed)\n",
        "    theta, q1, q2 = sample_TCS(N, rng)\n",
        "    log_memory(\"after sampling\")\n",
        "\n",
        "    # 2. Compute k-NN distances (chunked)\n",
        "    print(\"\\n[2] Computing k-NN distances...\")\n",
        "    chunk_size = 2000 if N > 10000 else N\n",
        "    knn_idx, knn_dist = compute_tcs_distance_chunked(\n",
        "        theta, q1, q2, ratio=ratio, chunk_size=chunk_size\n",
        "    )\n",
        "    log_memory(\"after k-NN\")\n",
        "\n",
        "    # 3. Build sparse Laplacian\n",
        "    print(\"\\n[3] Building sparse Laplacian...\")\n",
        "    L, W, sigma, degrees = build_sparse_laplacian(knn_idx, knn_dist)\n",
        "    del knn_idx, knn_dist\n",
        "    gc.collect()\n",
        "    log_memory(\"after Laplacian\")\n",
        "\n",
        "    # 4. Compute eigenvalues (0-form)\n",
        "    print(\"\\n[4] Computing 0-form spectrum...\")\n",
        "    n_eig = 20\n",
        "    eigenvalues, eigenvectors = eigsh(L, k=n_eig, which='SM', tol=1e-8)\n",
        "    idx = np.argsort(eigenvalues)\n",
        "    eigenvalues = eigenvalues[idx]\n",
        "    eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "    # First non-zero\n",
        "    mu1 = 0.0\n",
        "    v1_idx = 1\n",
        "    for i, ev in enumerate(eigenvalues):\n",
        "        if ev > 1e-8:\n",
        "            mu1 = float(ev)\n",
        "            v1_idx = i\n",
        "            break\n",
        "\n",
        "    v1 = eigenvectors[:, v1_idx]\n",
        "    lambda1_hat = mu1 / (sigma**2)\n",
        "\n",
        "    print(f\"  Œº‚ÇÅ = {mu1:.6f}\")\n",
        "    print(f\"  œÉ = {sigma:.6f}\")\n",
        "    print(f\"  ŒªÃÇ‚ÇÅ = Œº‚ÇÅ/œÉ¬≤ = {lambda1_hat:.6f}\")\n",
        "    print(f\"  ŒªÃÇ‚ÇÅ √ó H* = {lambda1_hat * H_star:.4f}\")\n",
        "\n",
        "    # 5. Mode analysis\n",
        "    print(\"\\n[5] Analyzing mode structure...\")\n",
        "    pr = participation_ratio(v1)\n",
        "    mode_stats = mode_projection_stats(v1, theta, q1, q2)\n",
        "    print(f\"  PR = {pr:.4f}\")\n",
        "    print(f\"  S¬π order = {mode_stats['s1_order']:.4f}\")\n",
        "    print(f\"  S¬π Fourier(1) = {mode_stats['s1_fourier_1']:.4f}\")\n",
        "    print(f\"  S¬π Fourier(2) = {mode_stats['s1_fourier_2']:.4f}\")\n",
        "\n",
        "    # 6. Topological analysis\n",
        "    print(\"\\n[6] Analyzing graph topology...\")\n",
        "    beta_1, n_edges, n_components = estimate_betti_1(W, N)\n",
        "    print(f\"  Vertices: {N}\")\n",
        "    print(f\"  Edges: {n_edges}\")\n",
        "    print(f\"  Components: {n_components}\")\n",
        "    print(f\"  Œ≤‚ÇÅ (cycles): {beta_1}\")\n",
        "    print(f\"  Avg degree: {2*n_edges/N:.1f}\")\n",
        "\n",
        "    n_triangles = count_triangles_sparse(W)\n",
        "    print(f\"  Est. triangles: ~{n_triangles}\")\n",
        "\n",
        "    # 7. 1-form spectrum\n",
        "    print(\"\\n[7] Computing 1-form spectrum...\")\n",
        "    L1, m_edges, edges = build_hodge_1_sparse(W, max_edges=40000)\n",
        "\n",
        "    try:\n",
        "        n_eig_1 = min(50, m_edges - 1)\n",
        "        eig1, _ = eigsh(L1, k=n_eig_1, which='SM', tol=1e-6)\n",
        "        eig1 = np.sort(eig1)\n",
        "\n",
        "        # Count zero modes\n",
        "        zero_threshold = 1e-5\n",
        "        n_zero_modes = np.sum(eig1 < zero_threshold)\n",
        "        first_nonzero_1 = 0.0\n",
        "        for ev in eig1:\n",
        "            if ev > zero_threshold:\n",
        "                first_nonzero_1 = float(ev)\n",
        "                break\n",
        "\n",
        "        print(f\"  Zero modes (< {zero_threshold}): {n_zero_modes}/{n_eig_1}\")\n",
        "        print(f\"  First non-zero Œª‚ÇÅ(Œî‚ÇÅ): {first_nonzero_1:.6f}\")\n",
        "        print(f\"  Œª‚ÇÅ(Œî‚ÇÅ)/œÉ¬≤ = {first_nonzero_1/(sigma**2):.6f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  1-form computation failed: {e}\")\n",
        "        eig1 = np.array([])\n",
        "        n_zero_modes = -1\n",
        "        first_nonzero_1 = np.nan\n",
        "\n",
        "    elapsed = time.time() - t0\n",
        "    print(f\"\\n  Total time: {elapsed:.1f}s\")\n",
        "    log_memory(\"end\")\n",
        "\n",
        "    # Cleanup\n",
        "    del L, W, L1, eigenvectors\n",
        "    gc.collect()\n",
        "\n",
        "    return {\n",
        "        \"N\": N,\n",
        "        \"ratio\": ratio,\n",
        "        \"sigma\": sigma,\n",
        "        \"mu1\": mu1,\n",
        "        \"lambda1_hat\": lambda1_hat,\n",
        "        \"product\": lambda1_hat * H_star,\n",
        "        \"PR\": pr,\n",
        "        \"mode_stats\": mode_stats,\n",
        "        \"n_edges\": n_edges,\n",
        "        \"n_components\": n_components,\n",
        "        \"beta_1\": beta_1,\n",
        "        \"n_triangles\": n_triangles,\n",
        "        \"eigenvalues_0\": eigenvalues[:10].tolist(),\n",
        "        \"eigenvalues_1\": eig1[:20].tolist() if len(eig1) > 0 else [],\n",
        "        \"n_zero_modes_1form\": n_zero_modes,\n",
        "        \"lambda1_1form\": first_nonzero_1,\n",
        "        \"elapsed\": elapsed\n",
        "    }\n",
        "\n",
        "print(\"‚úì Analysis pipeline ready\")"
      ],
      "metadata": {
        "id": "pipeline"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# RUN INVESTIGATION AT N=20000\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"#  HIGH-N TOPOLOGICAL INVESTIGATION (N=20,000)\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "N = 20000\n",
        "ratios_to_test = [1.0, 1.18, 1.3, 1.4, 1.6]\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for ratio in ratios_to_test:\n",
        "    result = full_analysis(N=N, ratio=ratio, seed=42)\n",
        "    all_results.append(result)\n",
        "    gc.collect()  # Clean up between runs"
      ],
      "metadata": {
        "id": "run_investigation"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONVERGENCE TEST: COMPARE N=5k, 10k, 20k at ratio=1.18\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"#  CONVERGENCE TEST: N = 5k, 10k, 20k at ratio=1.18\")\n",
        "print(\"#\"*70)\n",
        "\n",
        "convergence_results = []\n",
        "\n",
        "for N_test in [5000, 10000, 20000]:\n",
        "    result = full_analysis(N=N_test, ratio=1.18, seed=42)\n",
        "    convergence_results.append(result)\n",
        "    gc.collect()"
      ],
      "metadata": {
        "id": "convergence_test"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# SUMMARY TABLE\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"  RATIO SWEEP SUMMARY (N=20,000)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'Ratio':>6} | {'ŒªÃÇ‚ÇÅ√óH*':>8} | {'PR':>6} | {'Œ≤‚ÇÅ':>7} | {'#Edges':>7} | {'Zero(Œî‚ÇÅ)':>9} | {'S¬π F(1)':>8}\")\n",
        "print(\"-\"*75)\n",
        "\n",
        "for r in all_results:\n",
        "    print(f\"{r['ratio']:6.2f} | {r['product']:8.4f} | {r['PR']:6.3f} | \"\n",
        "          f\"{r['beta_1']:7d} | {r['n_edges']:7d} | {r['n_zero_modes_1form']:9d} | \"\n",
        "          f\"{r['mode_stats']['s1_fourier_1']:8.4f}\")"
      ],
      "metadata": {
        "id": "summary_table"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CONVERGENCE SUMMARY\n",
        "# =============================================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"  CONVERGENCE SUMMARY (ratio=1.18)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\n{'N':>7} | {'ŒªÃÇ‚ÇÅ√óH*':>10} | {'œÉ':>10} | {'Œº‚ÇÅ':>10} | {'Œ≤‚ÇÅ':>8} | {'PR':>6}\")\n",
        "print(\"-\"*65)\n",
        "\n",
        "for r in convergence_results:\n",
        "    print(f\"{r['N']:7d} | {r['product']:10.4f} | {r['sigma']:10.6f} | \"\n",
        "          f\"{r['mu1']:10.6f} | {r['beta_1']:8d} | {r['PR']:6.3f}\")\n",
        "\n",
        "# Extrapolation\n",
        "if len(convergence_results) >= 3:\n",
        "    Ns = np.array([r['N'] for r in convergence_results])\n",
        "    prods = np.array([r['product'] for r in convergence_results])\n",
        "\n",
        "    # Fit: product = a + b/sqrt(N)\n",
        "    X = 1.0 / np.sqrt(Ns)\n",
        "    coeffs = np.polyfit(X, prods, 1)\n",
        "    product_inf = coeffs[1]  # Intercept = limit as N‚Üí‚àû\n",
        "\n",
        "    print(f\"\\n  Linear fit: ŒªÃÇ‚ÇÅ√óH* = {coeffs[1]:.4f} + {coeffs[0]:.4f}/‚àöN\")\n",
        "    print(f\"  Extrapolated limit (N‚Üí‚àû): ŒªÃÇ‚ÇÅ√óH* ‚Üí {product_inf:.4f}\")"
      ],
      "metadata": {
        "id": "convergence_summary"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# VISUALIZATION: TOPOLOGY VS RATIO\n",
        "# =============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "ratios_plot = [r['ratio'] for r in all_results]\n",
        "products = [r['product'] for r in all_results]\n",
        "prs = [r['PR'] for r in all_results]\n",
        "beta1s = [r['beta_1'] for r in all_results]\n",
        "zero_modes = [r['n_zero_modes_1form'] for r in all_results]\n",
        "s1_fourier = [r['mode_stats']['s1_fourier_1'] for r in all_results]\n",
        "n_edges = [r['n_edges'] for r in all_results]\n",
        "\n",
        "# 1. Spectral product\n",
        "ax = axes[0, 0]\n",
        "ax.plot(ratios_plot, products, 'o-', markersize=10, linewidth=2)\n",
        "ax.axhline(y=13, color='red', linestyle='--', alpha=0.7, label='13')\n",
        "ax.axhline(y=21, color='blue', linestyle='--', alpha=0.7, label='21')\n",
        "ax.set_xlabel('Ratio', fontsize=12)\n",
        "ax.set_ylabel('ŒªÃÇ‚ÇÅ √ó H*', fontsize=12)\n",
        "ax.set_title('Spectral Product (N=20k)', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Participation ratio\n",
        "ax = axes[0, 1]\n",
        "ax.plot(ratios_plot, prs, 's-', markersize=10, linewidth=2, color='purple')\n",
        "ax.set_xlabel('Ratio', fontsize=12)\n",
        "ax.set_ylabel('Participation Ratio', fontsize=12)\n",
        "ax.set_title('Mode Delocalization', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Œ≤‚ÇÅ (cycles)\n",
        "ax = axes[0, 2]\n",
        "ax.plot(ratios_plot, beta1s, 'D-', markersize=10, linewidth=2, color='green')\n",
        "ax.set_xlabel('Ratio', fontsize=12)\n",
        "ax.set_ylabel('Œ≤‚ÇÅ (graph cycles)', fontsize=12)\n",
        "ax.set_title('First Betti Number of Graph', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Zero modes (1-form)\n",
        "ax = axes[1, 0]\n",
        "ax.plot(ratios_plot, zero_modes, '^-', markersize=10, linewidth=2, color='orange')\n",
        "ax.set_xlabel('Ratio', fontsize=12)\n",
        "ax.set_ylabel('Zero modes in Œî‚ÇÅ', fontsize=12)\n",
        "ax.set_title('1-Form Harmonic Modes', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. S¬π Fourier(1) component\n",
        "ax = axes[1, 1]\n",
        "ax.plot(ratios_plot, s1_fourier, 'v-', markersize=10, linewidth=2, color='brown')\n",
        "ax.set_xlabel('Ratio', fontsize=12)\n",
        "ax.set_ylabel('S¬π Fourier(1) amplitude', fontsize=12)\n",
        "ax.set_title('Mode S¬π Structure (cos Œ∏)', fontsize=14, fontweight='bold')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Convergence\n",
        "ax = axes[1, 2]\n",
        "Ns_conv = [r['N'] for r in convergence_results]\n",
        "prods_conv = [r['product'] for r in convergence_results]\n",
        "ax.plot(Ns_conv, prods_conv, 'o-', markersize=12, linewidth=2, color='darkblue')\n",
        "ax.axhline(y=13, color='red', linestyle='--', alpha=0.7)\n",
        "if 'product_inf' in dir():\n",
        "    ax.axhline(y=product_inf, color='green', linestyle=':', label=f'Extrap: {product_inf:.2f}')\n",
        "ax.set_xlabel('N (sample size)', fontsize=12)\n",
        "ax.set_ylabel('ŒªÃÇ‚ÇÅ √ó H*', fontsize=12)\n",
        "ax.set_title('Convergence (ratio=1.18)', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('high_n_topology_investigation.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Saved: high_n_topology_investigation.png\")"
      ],
      "metadata": {
        "id": "visualization"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# DETAILED MODE STRUCTURE VISUALIZATION\n",
        "# =============================================================================\n",
        "\n",
        "# Re-run at ratio=1.18 to get eigenvector for plotting\n",
        "print(\"Re-computing at ratio=1.18 for mode visualization...\")\n",
        "\n",
        "N_viz = 10000  # Smaller for visualization\n",
        "rng = np.random.default_rng(42)\n",
        "theta, q1, q2 = sample_TCS(N_viz, rng)\n",
        "\n",
        "knn_idx, knn_dist = compute_tcs_distance_chunked(theta, q1, q2, ratio=1.18, chunk_size=2000)\n",
        "L, W, sigma, _ = build_sparse_laplacian(knn_idx, knn_dist)\n",
        "eigenvalues, eigenvectors = eigsh(L, k=10, which='SM', tol=1e-8)\n",
        "idx = np.argsort(eigenvalues)\n",
        "v1 = eigenvectors[:, idx[1]]  # First non-constant mode\n",
        "\n",
        "# Normalize for plotting\n",
        "v1_plot = np.abs(v1)\n",
        "v1_plot = v1_plot / np.max(v1_plot)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# S¬π projection\n",
        "ax = axes[0]\n",
        "ax.scatter(theta, v1_plot, c=v1_plot, cmap='viridis', s=1, alpha=0.5)\n",
        "ax.set_xlabel('Œ∏ (S¬π angle)', fontsize=12)\n",
        "ax.set_ylabel('|v‚ÇÅ|', fontsize=12)\n",
        "ax.set_title('Mode on S¬π (ratio=1.18)', fontsize=14, fontweight='bold')\n",
        "\n",
        "# S¬≥‚ÇÅ projection (first coordinate)\n",
        "ax = axes[1]\n",
        "ax.scatter(q1[:, 0], v1_plot, c=v1_plot, cmap='viridis', s=1, alpha=0.5)\n",
        "ax.set_xlabel('q‚ÇÅ[0] (S¬≥‚ÇÅ coord)', fontsize=12)\n",
        "ax.set_ylabel('|v‚ÇÅ|', fontsize=12)\n",
        "ax.set_title('Mode on S¬≥‚ÇÅ', fontsize=14, fontweight='bold')\n",
        "\n",
        "# S¬≥‚ÇÇ projection\n",
        "ax = axes[2]\n",
        "ax.scatter(q2[:, 0], v1_plot, c=v1_plot, cmap='viridis', s=1, alpha=0.5)\n",
        "ax.set_xlabel('q‚ÇÇ[0] (S¬≥‚ÇÇ coord)', fontsize=12)\n",
        "ax.set_ylabel('|v‚ÇÅ|', fontsize=12)\n",
        "ax.set_title('Mode on S¬≥‚ÇÇ', fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('mode_structure_ratio118.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Saved: mode_structure_ratio118.png\")"
      ],
      "metadata": {
        "id": "mode_viz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# EXPORT ALL RESULTS\n",
        "# =============================================================================\n",
        "\n",
        "export_data = {\n",
        "    \"timestamp\": datetime.now().isoformat(),\n",
        "    \"investigation\": \"high_n_topology\",\n",
        "    \"ratio_sweep\": all_results,\n",
        "    \"convergence_test\": convergence_results,\n",
        "    \"extrapolated_limit\": float(product_inf) if 'product_inf' in dir() else None\n",
        "}\n",
        "\n",
        "with open('high_n_topology_results.json', 'w') as f:\n",
        "    json.dump(export_data, f, indent=2, default=str)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"  INVESTIGATION COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nExported files:\")\n",
        "print(\"  - high_n_topology_results.json\")\n",
        "print(\"  - high_n_topology_investigation.png\")\n",
        "print(\"  - mode_structure_ratio118.png\")"
      ],
      "metadata": {
        "id": "export"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# üîç Key Questions to Answer\n",
        "\n",
        "After running this notebook, look for:\n",
        "\n",
        "1. **Convergence**: Does ŒªÃÇ‚ÇÅ√óH* increase toward 13 as N increases?\n",
        "2. **Œ≤‚ÇÅ pattern**: How does the graph Betti number change with ratio?\n",
        "3. **Zero modes**: Why does Œî‚ÇÅ have more zero modes at higher ratio?\n",
        "4. **Mode structure**: Is the cos(Œ∏) pattern on S¬π stronger at ratio=1.18?\n",
        "5. **Transition**: Is there a sharp transition at ratio ‚âà 1.3?"
      ],
      "metadata": {
        "id": "questions"
      }
    }
  ]
}
