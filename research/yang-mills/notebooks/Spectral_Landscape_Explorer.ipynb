{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Landscape Explorer\n",
    "\n",
    "## Philosophy: Dezoom & Discover\n",
    "\n",
    "Instead of tunnel-visioning on a specific target value, we **explore the full landscape** of spectral properties across:\n",
    "\n",
    "- **Metric parameters**: ratio, anisotropy, kernel bandwidth\n",
    "- **Topological parameters**: H*, b₂/b₃ split\n",
    "- **Construction variants**: TCS weights, distance functions\n",
    "\n",
    "**Goal**: Find patterns, clusters, phase transitions — let the data speak.\n",
    "\n",
    "---\n",
    "\n",
    "### Approach\n",
    "\n",
    "1. **Fast probes**: Small N (5k-10k) for speed, many configurations\n",
    "2. **Wide grid**: Explore parameter space broadly\n",
    "3. **Visualization**: 2D/3D landscapes, heatmaps\n",
    "4. **ML patterns**: Regression, clustering, anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from itertools import product\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "\n",
    "print(f\"Landscape Explorer initialized - {datetime.now().strftime('%Y-%m-%d %H:%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORE FUNCTIONS (lightweight for fast exploration)\n",
    "# =============================================================================\n",
    "\n",
    "def sample_S3(n, rng):\n",
    "    \"\"\"Uniform sampling on S³.\"\"\"\n",
    "    q = rng.standard_normal((n, 4)).astype(np.float32)\n",
    "    return q / np.linalg.norm(q, axis=1, keepdims=True)\n",
    "\n",
    "def geodesic_S3(Q1, Q2):\n",
    "    \"\"\"Geodesic distance on S³.\"\"\"\n",
    "    dot = np.clip(np.abs(Q1 @ Q2.T), 0, 1)\n",
    "    return 2 * np.arccos(dot)\n",
    "\n",
    "def geodesic_S1(t1, t2):\n",
    "    \"\"\"Geodesic distance on S¹.\"\"\"\n",
    "    diff = np.abs(t1[:, None] - t2[None, :])\n",
    "    return np.minimum(diff, 2*np.pi - diff)\n",
    "\n",
    "def compute_lambda1(D, k, sigma_factor=1.0):\n",
    "    \"\"\"Fast λ₁ computation from distance matrix.\"\"\"\n",
    "    n = D.shape[0]\n",
    "    k = min(k, n-1)\n",
    "    \n",
    "    # Adaptive sigma\n",
    "    knn = np.partition(D, k, axis=1)[:, 1:k+1]\n",
    "    sigma = np.median(knn) * sigma_factor\n",
    "    sigma = max(sigma, 1e-6)\n",
    "    \n",
    "    # Gaussian weights\n",
    "    W = np.exp(-D**2 / (2*sigma**2))\n",
    "    np.fill_diagonal(W, 0)\n",
    "    \n",
    "    # Sparsify\n",
    "    for i in range(n):\n",
    "        thresh = np.partition(W[i], -k)[-k]\n",
    "        W[i, W[i] < thresh] = 0\n",
    "    \n",
    "    W = (W + W.T) / 2\n",
    "    \n",
    "    # Normalized Laplacian\n",
    "    d = np.maximum(W.sum(1), 1e-10)\n",
    "    d_inv = 1/np.sqrt(d)\n",
    "    L = np.eye(n) - (d_inv[:, None] * W * d_inv[None, :])\n",
    "    \n",
    "    try:\n",
    "        eigs, _ = eigsh(sp.csr_matrix(L), k=5, which='SM', tol=1e-6)\n",
    "        eigs = np.sort(np.real(eigs))\n",
    "        for e in eigs:\n",
    "            if e > 1e-7:\n",
    "                return float(e)\n",
    "        return float(eigs[1])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "print(\"✓ Core functions loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURABLE TCS METRIC\n",
    "# =============================================================================\n",
    "\n",
    "def tcs_distance_matrix(\n",
    "    N: int,\n",
    "    seed: int,\n",
    "    # Metric parameters (these are our exploration axes)\n",
    "    ratio: float = 1.0,        # Anisotropy S³₂ vs S³₁\n",
    "    alpha_s1: float = 1.0,     # S¹ weight\n",
    "    det_g: float = 65/32,      # G₂ determinant\n",
    "    mix_mode: str = 'standard' # 'standard', 'equal', 's3_only', 'product'\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute TCS distance matrix with configurable metric.\n",
    "    \n",
    "    mix_mode options:\n",
    "    - 'standard': d² = α·d_S1² + d_S3₁² + r²·d_S3₂² (original TCS)\n",
    "    - 'equal': d² = d_S1² + d_S3₁² + d_S3₂² (democratic)\n",
    "    - 's3_only': d² = d_S3₁² + d_S3₂² (ignore S¹)\n",
    "    - 'product': d = d_S1 × d_S3₁ × d_S3₂ (multiplicative)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Sample components\n",
    "    theta = rng.uniform(0, 2*np.pi, N).astype(np.float32)\n",
    "    q1 = sample_S3(N, rng)\n",
    "    q2 = sample_S3(N, rng)\n",
    "    \n",
    "    # Distances on each factor\n",
    "    d_s1 = geodesic_S1(theta, theta)\n",
    "    d_s3_1 = geodesic_S3(q1, q1)\n",
    "    d_s3_2 = geodesic_S3(q2, q2)\n",
    "    \n",
    "    # Combine according to mode\n",
    "    if mix_mode == 'standard':\n",
    "        alpha = det_g / (ratio**3) * alpha_s1\n",
    "        d_sq = alpha * d_s1**2 + d_s3_1**2 + (ratio**2) * d_s3_2**2\n",
    "        return np.sqrt(np.maximum(d_sq, 0))\n",
    "    \n",
    "    elif mix_mode == 'equal':\n",
    "        d_sq = d_s1**2 + d_s3_1**2 + d_s3_2**2\n",
    "        return np.sqrt(d_sq)\n",
    "    \n",
    "    elif mix_mode == 's3_only':\n",
    "        d_sq = d_s3_1**2 + (ratio**2) * d_s3_2**2\n",
    "        return np.sqrt(d_sq)\n",
    "    \n",
    "    elif mix_mode == 'product':\n",
    "        return (d_s1 + 0.1) * (d_s3_1 + 0.1) * (d_s3_2 + 0.1)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mix_mode: {mix_mode}\")\n",
    "\n",
    "print(\"✓ Configurable TCS metric loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROBE LAUNCHER\n",
    "# =============================================================================\n",
    "\n",
    "def launch_probe(config: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Launch a single probe with given configuration.\n",
    "    Returns results dictionary.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Extract params\n",
    "    N = config.get('N', 5000)\n",
    "    k = config.get('k', 50)\n",
    "    seed = config.get('seed', 42)\n",
    "    H_star = config.get('H_star', 99)\n",
    "    ratio = config.get('ratio', H_star/84)\n",
    "    alpha_s1 = config.get('alpha_s1', 1.0)\n",
    "    det_g = config.get('det_g', 65/32)\n",
    "    mix_mode = config.get('mix_mode', 'standard')\n",
    "    sigma_factor = config.get('sigma_factor', 1.0)\n",
    "    \n",
    "    # Compute\n",
    "    D = tcs_distance_matrix(N, seed, ratio, alpha_s1, det_g, mix_mode)\n",
    "    lambda1 = compute_lambda1(D, k, sigma_factor)\n",
    "    product = lambda1 * H_star if not np.isnan(lambda1) else np.nan\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    return {\n",
    "        **config,\n",
    "        'lambda1': lambda1,\n",
    "        'product': product,\n",
    "        'elapsed': elapsed\n",
    "    }\n",
    "\n",
    "def launch_exploration(configs: list, desc=\"Exploring\") -> pd.DataFrame:\n",
    "    \"\"\"Launch multiple probes and return DataFrame.\"\"\"\n",
    "    results = []\n",
    "    for cfg in tqdm(configs, desc=desc):\n",
    "        results.append(launch_probe(cfg))\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✓ Probe launcher ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploration 1: Ratio Landscape\n",
    "\n",
    "How does λ₁×H* vary with the anisotropy ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration 1: Ratio sweep\n",
    "\n",
    "ratios = np.linspace(0.5, 3.0, 25)\n",
    "configs_ratio = [\n",
    "    {'N': 5000, 'k': 50, 'seed': s, 'H_star': 99, 'ratio': r, 'mix_mode': 'standard'}\n",
    "    for r in ratios\n",
    "    for s in [42, 123]\n",
    "]\n",
    "\n",
    "print(f\"Launching {len(configs_ratio)} probes for ratio exploration...\")\n",
    "df_ratio = launch_exploration(configs_ratio, \"Ratio sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ratio landscape\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "df_agg = df_ratio.groupby('ratio').agg({'product': ['mean', 'std']}).reset_index()\n",
    "df_agg.columns = ['ratio', 'mean', 'std']\n",
    "\n",
    "ax.fill_between(df_agg['ratio'], df_agg['mean']-df_agg['std'], \n",
    "                df_agg['mean']+df_agg['std'], alpha=0.3)\n",
    "ax.plot(df_agg['ratio'], df_agg['mean'], 'o-', markersize=6, linewidth=2)\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(y=13, color='red', linestyle='--', label='Target = 13')\n",
    "ax.axvline(x=99/84, color='green', linestyle=':', alpha=0.7, label=f'H*/84 = {99/84:.2f}')\n",
    "\n",
    "ax.set_xlabel('Ratio (anisotropy parameter)', fontsize=12)\n",
    "ax.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax.set_title('Spectral Landscape: λ₁×H* vs Anisotropy Ratio', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('landscape_ratio.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Find where it crosses 13\n",
    "cross_idx = np.where(np.diff(np.sign(df_agg['mean'] - 13)))[0]\n",
    "if len(cross_idx) > 0:\n",
    "    cross_ratio = df_agg['ratio'].iloc[cross_idx[0]]\n",
    "    print(f\"\\n★ Crosses 13 at ratio ≈ {cross_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploration 2: H* Landscape\n",
    "\n",
    "How does λ₁×H* behave for different topologies (different H* values)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration 2: H* sweep\n",
    "\n",
    "H_values = [20, 40, 60, 80, 99, 120, 150, 200, 300]\n",
    "\n",
    "configs_H = [\n",
    "    {'N': 5000, 'k': 50, 'seed': s, 'H_star': H, 'ratio': H/84, 'mix_mode': 'standard'}\n",
    "    for H in H_values\n",
    "    for s in [42, 123, 456]\n",
    "]\n",
    "\n",
    "print(f\"Launching {len(configs_H)} probes for H* exploration...\")\n",
    "df_H = launch_exploration(configs_H, \"H* sweep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot H* landscape\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: λ₁×H* vs H*\n",
    "ax1 = axes[0]\n",
    "df_H_agg = df_H.groupby('H_star').agg({'product': ['mean', 'std'], 'lambda1': 'mean'}).reset_index()\n",
    "df_H_agg.columns = ['H_star', 'product_mean', 'product_std', 'lambda1_mean']\n",
    "\n",
    "ax1.errorbar(df_H_agg['H_star'], df_H_agg['product_mean'], \n",
    "             yerr=df_H_agg['product_std'], fmt='o-', capsize=5, markersize=8)\n",
    "ax1.axhline(y=13, color='red', linestyle='--', label='Target = 13')\n",
    "ax1.set_xlabel('H* (topology parameter)', fontsize=12)\n",
    "ax1.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax1.set_title('Spectral Product vs Topology', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: λ₁ vs H* (should scale as 1/H*)\n",
    "ax2 = axes[1]\n",
    "ax2.loglog(df_H_agg['H_star'], df_H_agg['lambda1_mean'], 'o-', markersize=8)\n",
    "\n",
    "# Fit power law\n",
    "log_H = np.log(df_H_agg['H_star'])\n",
    "log_lam = np.log(df_H_agg['lambda1_mean'])\n",
    "slope, intercept = np.polyfit(log_H, log_lam, 1)\n",
    "H_fit = np.linspace(df_H_agg['H_star'].min(), df_H_agg['H_star'].max(), 100)\n",
    "lam_fit = np.exp(intercept) * H_fit**slope\n",
    "ax2.plot(H_fit, lam_fit, 'r--', label=f'Fit: λ₁ ∝ H*^{slope:.2f}')\n",
    "\n",
    "ax2.set_xlabel('H*', fontsize=12)\n",
    "ax2.set_ylabel('λ₁', fontsize=12)\n",
    "ax2.set_title(f'Eigenvalue Scaling (slope = {slope:.2f})', fontsize=14)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('landscape_Hstar.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n★ Power law: λ₁ ∝ H*^{slope:.3f}\")\n",
    "print(f\"  If slope ≈ -1, then λ₁×H* = const (universal law)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploration 3: Metric Mode Comparison\n",
    "\n",
    "How do different metric constructions affect the spectral product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration 3: Mix mode comparison\n",
    "\n",
    "modes = ['standard', 'equal', 's3_only']\n",
    "\n",
    "configs_mode = [\n",
    "    {'N': 5000, 'k': 50, 'seed': s, 'H_star': 99, 'ratio': 99/84, 'mix_mode': m}\n",
    "    for m in modes\n",
    "    for s in [42, 123, 456, 789]\n",
    "]\n",
    "\n",
    "print(f\"Launching {len(configs_mode)} probes for mode comparison...\")\n",
    "df_mode = launch_exploration(configs_mode, \"Mode comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mode comparison\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "df_mode_agg = df_mode.groupby('mix_mode')['product'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "bars = ax.bar(df_mode_agg['mix_mode'], df_mode_agg['mean'], \n",
    "              yerr=df_mode_agg['std'], capsize=8, color=['#2E86AB', '#A23B72', '#F18F01'])\n",
    "\n",
    "ax.axhline(y=13, color='red', linestyle='--', linewidth=2, label='Target = 13')\n",
    "\n",
    "ax.set_xlabel('Metric Construction', fontsize=12)\n",
    "ax.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax.set_title('Impact of Metric Construction on Spectral Product', fontsize=14)\n",
    "ax.legend()\n",
    "\n",
    "# Annotate values\n",
    "for bar, row in zip(bars, df_mode_agg.itertuples()):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "            f'{row.mean:.1f}', ha='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('landscape_modes.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploration 4: 2D Parameter Space\n",
    "\n",
    "Heatmap of λ₁×H* across (ratio, k) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration 4: 2D heatmap\n",
    "\n",
    "ratios_2d = np.linspace(0.5, 2.5, 15)\n",
    "ks_2d = [20, 30, 40, 50, 60, 80, 100]\n",
    "\n",
    "configs_2d = [\n",
    "    {'N': 5000, 'k': k, 'seed': 42, 'H_star': 99, 'ratio': r, 'mix_mode': 'standard'}\n",
    "    for r in ratios_2d\n",
    "    for k in ks_2d\n",
    "]\n",
    "\n",
    "print(f\"Launching {len(configs_2d)} probes for 2D heatmap...\")\n",
    "df_2d = launch_exploration(configs_2d, \"2D grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D heatmap\n",
    "\n",
    "pivot = df_2d.pivot(index='k', columns='ratio', values='product')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "im = ax.imshow(pivot.values, aspect='auto', cmap='RdYlGn_r',\n",
    "               extent=[ratios_2d.min(), ratios_2d.max(), ks_2d[-1], ks_2d[0]],\n",
    "               vmin=10, vmax=20)\n",
    "\n",
    "# Contour at 13\n",
    "X, Y = np.meshgrid(ratios_2d, ks_2d)\n",
    "cs = ax.contour(X, Y, pivot.values, levels=[13], colors='black', linewidths=2)\n",
    "ax.clabel(cs, inline=True, fontsize=10, fmt='%.0f')\n",
    "\n",
    "plt.colorbar(im, ax=ax, label='λ₁ × H*')\n",
    "ax.set_xlabel('Ratio (anisotropy)', fontsize=12)\n",
    "ax.set_ylabel('k (neighbors)', fontsize=12)\n",
    "ax.set_title('Spectral Landscape: (ratio, k) → λ₁×H*', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('landscape_2d_heatmap.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploration 5: ML Pattern Discovery\n",
    "\n",
    "Can we find a predictive formula for λ₁×H*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large-scale exploration for ML\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Random sampling of parameter space\n",
    "n_samples = 200\n",
    "\n",
    "configs_ml = []\n",
    "for i in range(n_samples):\n",
    "    configs_ml.append({\n",
    "        'N': 5000,\n",
    "        'k': int(np.random.uniform(20, 100)),\n",
    "        'seed': np.random.randint(1, 10000),\n",
    "        'H_star': int(np.random.uniform(30, 200)),\n",
    "        'ratio': np.random.uniform(0.5, 2.5),\n",
    "        'alpha_s1': np.random.uniform(0.5, 2.0),\n",
    "        'sigma_factor': np.random.uniform(0.5, 2.0),\n",
    "        'mix_mode': 'standard'\n",
    "    })\n",
    "\n",
    "print(f\"Launching {len(configs_ml)} random probes for ML...\")\n",
    "df_ml = launch_exploration(configs_ml, \"ML sampling\")\n",
    "\n",
    "# Clean NaN\n",
    "df_ml = df_ml.dropna(subset=['product'])\n",
    "print(f\"Valid samples: {len(df_ml)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ML model to predict λ₁×H*\n",
    "\n",
    "features = ['k', 'H_star', 'ratio', 'alpha_s1', 'sigma_factor']\n",
    "X = df_ml[features].values\n",
    "y = df_ml['product'].values\n",
    "\n",
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf.fit(X, y)\n",
    "\n",
    "# Feature importance\n",
    "importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n★ Feature Importance (Random Forest):\")\n",
    "print(importance.to_string(index=False))\n",
    "\n",
    "# R² score\n",
    "r2 = rf.score(X, y)\n",
    "print(f\"\\nR² = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Feature importance\n",
    "ax1 = axes[0]\n",
    "ax1.barh(importance['feature'], importance['importance'], color='steelblue')\n",
    "ax1.set_xlabel('Importance', fontsize=12)\n",
    "ax1.set_title('What Drives λ₁×H*?', fontsize=14)\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Right: Predicted vs Actual\n",
    "ax2 = axes[1]\n",
    "y_pred = rf.predict(X)\n",
    "ax2.scatter(y, y_pred, alpha=0.5, s=30)\n",
    "ax2.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', linewidth=2)\n",
    "ax2.set_xlabel('Actual λ₁×H*', fontsize=12)\n",
    "ax2.set_ylabel('Predicted λ₁×H*', fontsize=12)\n",
    "ax2.set_title(f'ML Prediction (R² = {r2:.3f})', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('landscape_ml.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exploration 6: Clustering Analysis\n",
    "\n",
    "Are there distinct \"phases\" in the spectral landscape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering\n",
    "\n",
    "# Prepare features\n",
    "X_cluster = df_ml[['ratio', 'H_star', 'k', 'product']].values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_cluster)\n",
    "\n",
    "# K-Means\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "df_ml['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# t-SNE for visualization\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: t-SNE colored by cluster\n",
    "ax1 = axes[0]\n",
    "scatter1 = ax1.scatter(X_tsne[:, 0], X_tsne[:, 1], c=df_ml['cluster'], \n",
    "                       cmap='tab10', s=50, alpha=0.7)\n",
    "ax1.set_xlabel('t-SNE 1')\n",
    "ax1.set_ylabel('t-SNE 2')\n",
    "ax1.set_title('Spectral Landscape Clusters', fontsize=14)\n",
    "plt.colorbar(scatter1, ax=ax1, label='Cluster')\n",
    "\n",
    "# Right: t-SNE colored by λ₁×H*\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(X_tsne[:, 0], X_tsne[:, 1], c=df_ml['product'], \n",
    "                       cmap='viridis', s=50, alpha=0.7)\n",
    "ax2.set_xlabel('t-SNE 1')\n",
    "ax2.set_ylabel('t-SNE 2')\n",
    "ax2.set_title('Colored by λ₁×H*', fontsize=14)\n",
    "plt.colorbar(scatter2, ax=ax2, label='λ₁×H*')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('landscape_clusters.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Cluster statistics\n",
    "print(\"\\n★ Cluster Statistics:\")\n",
    "print(df_ml.groupby('cluster')['product'].agg(['mean', 'std', 'count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary & Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all results\n",
    "\n",
    "summary = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'explorations': {\n",
    "        'ratio_sweep': len(df_ratio),\n",
    "        'H_sweep': len(df_H),\n",
    "        'mode_comparison': len(df_mode),\n",
    "        '2d_grid': len(df_2d),\n",
    "        'ml_sampling': len(df_ml)\n",
    "    },\n",
    "    'key_findings': {\n",
    "        'eigenvalue_scaling': f'λ₁ ∝ H*^{slope:.3f}',\n",
    "        'ml_r2': float(r2),\n",
    "        'top_feature': importance.iloc[0]['feature'],\n",
    "        'n_clusters': 4\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save\n",
    "with open('landscape_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "# Save full ML dataset\n",
    "df_ml.to_csv('landscape_ml_data.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LANDSCAPE EXPLORATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTotal probes: {len(df_ratio) + len(df_H) + len(df_mode) + len(df_2d) + len(df_ml)}\")\n",
    "print(f\"\\nKey findings:\")\n",
    "print(f\"  • Eigenvalue scaling: λ₁ ∝ H*^{slope:.3f}\")\n",
    "print(f\"  • ML predictability: R² = {r2:.3f}\")\n",
    "print(f\"  • Most important feature: {importance.iloc[0]['feature']}\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  • landscape_*.png (visualizations)\")\n",
    "print(f\"  • landscape_summary.json\")\n",
    "print(f\"  • landscape_ml_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
