{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Spectral Calibration: S¬≥ and T‚Å∑ Benchmarks (v2 - Memory Optimized)\n",
    "\n",
    "**Objectif**: D√©terminer si le biais observ√© sur K‚Çá (13 vs 14) est structurel ou un artefact du pipeline.\n",
    "\n",
    "**FIXES v2**:\n",
    "1. ‚ö° **Sparse kNN graph** - no N√óN dense matrix\n",
    "2. üìê **Proper Laplacian scaling** - matches continuous spectrum\n",
    "3. üß† **Memory efficient** - handles N=100k easily\n",
    "\n",
    "---\n",
    "\n",
    "## Theory Reminder\n",
    "\n",
    "| Space | Œª‚ÇÅ exact | Formula |\n",
    "|-------|----------|--------|\n",
    "| S¬≥ (radius 1) | 3 | Œª‚Çô = n(n+2) |\n",
    "| T‚Å∑ (unit radii) | 1 | Œª = Œ£·µ¢ n·µ¢¬≤ |\n",
    "\n",
    "**Key insight**: The **normalized graph Laplacian** has eigenvalues in [0, 2], which does NOT match the continuous spectrum. We need the **geometric Laplacian** with proper scaling.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# Sparse linear algebra\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "# GPU detection\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.sparse import csr_matrix as cp_csr\n",
    "    from cupyx.scipy.sparse.linalg import eigsh as cp_eigsh\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"‚úì GPU available via CuPy\")\n",
    "    device = cp.cuda.Device()\n",
    "    props = cp.cuda.runtime.getDeviceProperties(device.id)\n",
    "    print(f\"  Device: {props['name'].decode()}\")\n",
    "    print(f\"  Memory: {props['totalGlobalMem'] / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    cp = np\n",
    "    print(\"‚úó CuPy not available - using CPU\")\n",
    "\n",
    "# Try sklearn for fast kNN\n",
    "try:\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"‚úì scikit-learn available for fast kNN\")\n",
    "except ImportError:\n",
    "    SKLEARN_AVAILABLE = False\n",
    "    print(\"‚úó scikit-learn not available\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "# Exact eigenvalues\n",
    "LAMBDA1_S3 = 3.0\n",
    "LAMBDA1_T7 = 1.0\n",
    "H_STAR = 99\n",
    "\n",
    "print(f\"\\nTarget eigenvalues:\")\n",
    "print(f\"  S¬≥: Œª‚ÇÅ = {LAMBDA1_S3}\")\n",
    "print(f\"  T‚Å∑: Œª‚ÇÅ = {LAMBDA1_T7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: S¬≥ Sampling with Geodesic Metric\n",
    "\n",
    "def sample_S3(N: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"Sample N points uniformly on S¬≥ (unit 3-sphere in R‚Å¥).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    points = rng.standard_normal((N, 4)).astype(np.float32)\n",
    "    norms = np.linalg.norm(points, axis=1, keepdims=True)\n",
    "    return points / norms\n",
    "\n",
    "\n",
    "class S3Metric:\n",
    "    \"\"\"Custom metric for S¬≥ geodesic distance compatible with sklearn.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(x, y):\n",
    "        \"\"\"Geodesic distance on S¬≥: d = arccos(x¬∑y).\"\"\"\n",
    "        dot = np.clip(np.dot(x, y), -1.0, 1.0)\n",
    "        return np.arccos(dot)\n",
    "    \n",
    "    @staticmethod\n",
    "    def pairwise_geodesic(X, Y=None):\n",
    "        \"\"\"Compute pairwise geodesic distances.\"\"\"\n",
    "        if Y is None:\n",
    "            Y = X\n",
    "        dots = np.clip(X @ Y.T, -1.0, 1.0)\n",
    "        return np.arccos(dots)\n",
    "\n",
    "\n",
    "# Quick test\n",
    "print(\"Testing S¬≥ sampling...\")\n",
    "test_pts = sample_S3(100)\n",
    "print(f\"  Shape: {test_pts.shape}\")\n",
    "print(f\"  Norms: {np.linalg.norm(test_pts[:5], axis=1)} (should be ~1.0)\")\n",
    "\n",
    "# Test distance\n",
    "d = S3Metric.distance(test_pts[0], test_pts[1])\n",
    "print(f\"  Sample distance: {d:.4f} (range [0, œÄ])\")\n",
    "print(\"‚úì S¬≥ OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: T‚Å∑ Sampling with Toric Metric\n",
    "\n",
    "def sample_T7(N: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"Sample N points uniformly on T‚Å∑ = [0, 2œÄ)‚Å∑.\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return rng.uniform(0, 2*np.pi, (N, 7)).astype(np.float32)\n",
    "\n",
    "\n",
    "class T7Metric:\n",
    "    \"\"\"Toric distance on T‚Å∑.\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def distance(x, y):\n",
    "        \"\"\"Toric distance: min(|Œ∏-œÜ|, 2œÄ-|Œ∏-œÜ|) for each coord, then L2.\"\"\"\n",
    "        diff = np.abs(x - y)\n",
    "        diff_toric = np.minimum(diff, 2*np.pi - diff)\n",
    "        return np.sqrt(np.sum(diff_toric**2))\n",
    "\n",
    "\n",
    "def toric_distance_batch(X, Y):\n",
    "    \"\"\"Batch toric distances between rows of X and Y.\"\"\"\n",
    "    # X: (n, 7), Y: (m, 7) -> output: (n, m)\n",
    "    diff = np.abs(X[:, None, :] - Y[None, :, :])  # (n, m, 7)\n",
    "    diff_toric = np.minimum(diff, 2*np.pi - diff)\n",
    "    return np.sqrt(np.sum(diff_toric**2, axis=2))\n",
    "\n",
    "\n",
    "# Quick test\n",
    "print(\"Testing T‚Å∑ sampling...\")\n",
    "test_angles = sample_T7(100)\n",
    "print(f\"  Shape: {test_angles.shape}\")\n",
    "print(f\"  Range: [{test_angles.min():.2f}, {test_angles.max():.2f}]\")\n",
    "\n",
    "d = T7Metric.distance(test_angles[0], test_angles[1])\n",
    "print(f\"  Sample distance: {d:.4f} (max ~ ‚àö7√óœÄ ‚âà {np.sqrt(7)*np.pi:.2f})\")\n",
    "print(\"‚úì T‚Å∑ OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Memory-Efficient Sparse Graph Laplacian\n",
    "\n",
    "def build_sparse_laplacian_S3(points: np.ndarray, k: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Build sparse graph Laplacian for S¬≥ using geodesic distances.\n",
    "    Memory-efficient: only stores k neighbors per point.\n",
    "    \n",
    "    Uses UNNORMALIZED Laplacian with geometric scaling.\n",
    "    \n",
    "    Returns: (L_sparse, sigma)\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    k = min(k, N - 1)\n",
    "    \n",
    "    # Use sklearn for fast approximate kNN (Euclidean in R‚Å¥ is good proxy for S¬≥)\n",
    "    if SKLEARN_AVAILABLE:\n",
    "        nn = NearestNeighbors(n_neighbors=k+1, algorithm='auto', n_jobs=-1)\n",
    "        nn.fit(points)\n",
    "        distances_eucl, indices = nn.kneighbors(points)\n",
    "        \n",
    "        # Convert Euclidean to geodesic for S¬≥\n",
    "        # d_geo = arccos(1 - d_eucl¬≤/2) for unit sphere\n",
    "        distances_geo = np.arccos(np.clip(1 - distances_eucl**2/2, -1, 1))\n",
    "    else:\n",
    "        # Fallback: compute full distance matrix (slow for large N)\n",
    "        D_full = S3Metric.pairwise_geodesic(points)\n",
    "        indices = np.argsort(D_full, axis=1)[:, :k+1]\n",
    "        distances_geo = np.take_along_axis(D_full, indices, axis=1)\n",
    "    \n",
    "    # Exclude self (distance 0)\n",
    "    distances_geo = distances_geo[:, 1:]\n",
    "    indices = indices[:, 1:]\n",
    "    \n",
    "    # Adaptive bandwidth\n",
    "    sigma = float(np.median(distances_geo[:, -1]))  # k-th neighbor distance\n",
    "    \n",
    "    # Build sparse weight matrix\n",
    "    row = np.repeat(np.arange(N), k)\n",
    "    col = indices.flatten()\n",
    "    weights = np.exp(-distances_geo.flatten()**2 / (2 * sigma**2))\n",
    "    \n",
    "    W = csr_matrix((weights, (row, col)), shape=(N, N))\n",
    "    W = (W + W.T) / 2  # Symmetrize\n",
    "    \n",
    "    # Degree matrix\n",
    "    degrees = np.array(W.sum(axis=1)).flatten()\n",
    "    \n",
    "    # GEOMETRIC LAPLACIAN with proper scaling\n",
    "    # L = (1/œÉ¬≤) √ó (D - W) gives eigenvalues that scale correctly\n",
    "    # For unit sphere, we also need volume correction\n",
    "    D_mat = diags(degrees)\n",
    "    L = D_mat - W\n",
    "    \n",
    "    # Scale by 1/œÉ¬≤ to match continuous Laplacian\n",
    "    L = L / (sigma**2)\n",
    "    \n",
    "    return L.tocsr(), sigma\n",
    "\n",
    "\n",
    "def build_sparse_laplacian_T7(angles: np.ndarray, k: int, batch_size: int = 5000) -> tuple:\n",
    "    \"\"\"\n",
    "    Build sparse graph Laplacian for T‚Å∑ using toric distances.\n",
    "    Memory-efficient with batched computation.\n",
    "    \n",
    "    Returns: (L_sparse, sigma)\n",
    "    \"\"\"\n",
    "    N = angles.shape[0]\n",
    "    k = min(k, N - 1)\n",
    "    \n",
    "    print(f\"    Building kNN graph (N={N}, k={k})...\")\n",
    "    \n",
    "    # Compute kNN in batches to save memory\n",
    "    all_indices = []\n",
    "    all_distances = []\n",
    "    \n",
    "    for start in range(0, N, batch_size):\n",
    "        end = min(start + batch_size, N)\n",
    "        batch = angles[start:end]\n",
    "        \n",
    "        # Compute distances from batch to all points\n",
    "        D_batch = toric_distance_batch(batch, angles)  # (batch_size, N)\n",
    "        \n",
    "        # Get k+1 nearest (including self)\n",
    "        idx = np.argpartition(D_batch, k+1, axis=1)[:, :k+1]\n",
    "        \n",
    "        # Get actual distances for these neighbors\n",
    "        dists = np.take_along_axis(D_batch, idx, axis=1)\n",
    "        \n",
    "        # Sort by distance\n",
    "        sort_idx = np.argsort(dists, axis=1)\n",
    "        idx = np.take_along_axis(idx, sort_idx, axis=1)\n",
    "        dists = np.take_along_axis(dists, sort_idx, axis=1)\n",
    "        \n",
    "        all_indices.append(idx[:, 1:])  # Exclude self\n",
    "        all_distances.append(dists[:, 1:])\n",
    "        \n",
    "        del D_batch\n",
    "        gc.collect()\n",
    "    \n",
    "    indices = np.vstack(all_indices)\n",
    "    distances = np.vstack(all_distances)\n",
    "    \n",
    "    # Adaptive bandwidth\n",
    "    sigma = float(np.median(distances[:, -1]))\n",
    "    \n",
    "    # Build sparse weight matrix\n",
    "    row = np.repeat(np.arange(N), k)\n",
    "    col = indices.flatten()\n",
    "    weights = np.exp(-distances.flatten()**2 / (2 * sigma**2))\n",
    "    \n",
    "    W = csr_matrix((weights, (row, col)), shape=(N, N))\n",
    "    W = (W + W.T) / 2\n",
    "    \n",
    "    # Degree and Laplacian\n",
    "    degrees = np.array(W.sum(axis=1)).flatten()\n",
    "    D_mat = diags(degrees)\n",
    "    L = D_mat - W\n",
    "    \n",
    "    # Scale by 1/œÉ¬≤\n",
    "    L = L / (sigma**2)\n",
    "    \n",
    "    return L.tocsr(), sigma\n",
    "\n",
    "\n",
    "print(\"‚úì Sparse Laplacian builders defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Eigenvalue Computation with Proper Scaling\n",
    "\n",
    "def compute_lambda1(L, use_gpu: bool = True, n_eigs: int = 6) -> float:\n",
    "    \"\"\"\n",
    "    Compute first non-zero eigenvalue.\n",
    "    \n",
    "    Uses 'SM' (smallest magnitude) to find the gap.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if use_gpu and GPU_AVAILABLE:\n",
    "            L_gpu = cp_csr(cp.array(L.toarray(), dtype=cp.float32))\n",
    "            eigs, _ = cp_eigsh(L_gpu, k=n_eigs, which='SA')  # Smallest algebraic\n",
    "            eigs = cp.asnumpy(eigs)\n",
    "        else:\n",
    "            eigs, _ = eigsh(L.astype(np.float64), k=n_eigs, which='SM', tol=1e-10)\n",
    "        \n",
    "        eigs = np.sort(np.real(eigs))\n",
    "        \n",
    "        # Find first eigenvalue > threshold\n",
    "        for ev in eigs:\n",
    "            if ev > 1e-6:\n",
    "                return float(ev)\n",
    "        \n",
    "        return float(eigs[1]) if len(eigs) > 1 else 0.0\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"    Eigensolve error: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "print(\"‚úì Eigensolver ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Configuration\n",
    "\n",
    "# Scaling law from K‚Çá study\n",
    "SCALING_COEFF = 0.74\n",
    "\n",
    "# N values - start smaller, increase if stable\n",
    "N_VALUES = [2000, 5000, 10000, 20000]\n",
    "\n",
    "# For high-N runs (if memory allows)\n",
    "N_VALUES_EXTENDED = [30000, 50000]\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  Scaling: k = {SCALING_COEFF} √ó ‚àöN\")\n",
    "print(f\"  N values: {N_VALUES}\")\n",
    "print(f\"  Extended: {N_VALUES_EXTENDED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: S¬≥ Calibration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"S¬≥ CALIBRATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Exact Œª‚ÇÅ = {LAMBDA1_S3}\")\n",
    "print()\n",
    "\n",
    "s3_results = []\n",
    "\n",
    "print(f\"{'N':>7} | {'k':>5} | {'œÉ':>8} | {'Œª‚ÇÅ':>10} | {'Œª‚ÇÅ exact':>10} | {'Error %':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for N in N_VALUES:\n",
    "    k = max(20, int(SCALING_COEFF * np.sqrt(N)))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Sample\n",
    "    points = sample_S3(N, seed=42)\n",
    "    \n",
    "    # Build Laplacian\n",
    "    L, sigma = build_sparse_laplacian_S3(points, k)\n",
    "    \n",
    "    # Compute Œª‚ÇÅ\n",
    "    lambda1 = compute_lambda1(L, use_gpu=GPU_AVAILABLE)\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    error_pct = (lambda1 - LAMBDA1_S3) / LAMBDA1_S3 * 100\n",
    "    \n",
    "    print(f\"{N:>7} | {k:>5} | {sigma:>8.4f} | {lambda1:>10.4f} | {LAMBDA1_S3:>10.1f} | {error_pct:>+9.2f}%\")\n",
    "    \n",
    "    s3_results.append({\n",
    "        'N': int(N), 'k': int(k), 'sigma': float(sigma),\n",
    "        'lambda1': float(lambda1), 'lambda1_exact': float(LAMBDA1_S3),\n",
    "        'error_pct': float(error_pct), 'time_s': float(elapsed)\n",
    "    })\n",
    "    \n",
    "    del points, L\n",
    "    clear_memory()\n",
    "\n",
    "# Summary\n",
    "best = min(s3_results, key=lambda r: abs(r['error_pct']))\n",
    "print(f\"\\nBest result: N={best['N']}, Œª‚ÇÅ={best['lambda1']:.4f}, error={best['error_pct']:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: T‚Å∑ Calibration\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"T‚Å∑ CALIBRATION (same dimension as K‚Çá)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Exact Œª‚ÇÅ = {LAMBDA1_T7}\")\n",
    "print()\n",
    "\n",
    "t7_results = []\n",
    "\n",
    "print(f\"{'N':>7} | {'k':>5} | {'œÉ':>8} | {'Œª‚ÇÅ':>10} | {'Œª‚ÇÅ exact':>10} | {'Error %':>10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for N in N_VALUES:\n",
    "    k = max(20, int(SCALING_COEFF * np.sqrt(N)))\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Sample\n",
    "    angles = sample_T7(N, seed=42)\n",
    "    \n",
    "    # Build Laplacian\n",
    "    L, sigma = build_sparse_laplacian_T7(angles, k)\n",
    "    \n",
    "    # Compute Œª‚ÇÅ\n",
    "    lambda1 = compute_lambda1(L, use_gpu=GPU_AVAILABLE)\n",
    "    \n",
    "    elapsed = time.time() - t0\n",
    "    error_pct = (lambda1 - LAMBDA1_T7) / LAMBDA1_T7 * 100\n",
    "    \n",
    "    print(f\"{N:>7} | {k:>5} | {sigma:>8.4f} | {lambda1:>10.4f} | {LAMBDA1_T7:>10.1f} | {error_pct:>+9.2f}%\")\n",
    "    \n",
    "    t7_results.append({\n",
    "        'N': int(N), 'k': int(k), 'sigma': float(sigma),\n",
    "        'lambda1': float(lambda1), 'lambda1_exact': float(LAMBDA1_T7),\n",
    "        'error_pct': float(error_pct), 'time_s': float(elapsed)\n",
    "    })\n",
    "    \n",
    "    del angles, L\n",
    "    clear_memory()\n",
    "\n",
    "# Summary\n",
    "best = min(t7_results, key=lambda r: abs(r['error_pct']))\n",
    "print(f\"\\nBest result: N={best['N']}, Œª‚ÇÅ={best['lambda1']:.4f}, error={best['error_pct']:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Extended N (if memory allows)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXTENDED N TEST (memory permitting)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "extended_results = {'S3': [], 'T7': []}\n",
    "\n",
    "for N in N_VALUES_EXTENDED:\n",
    "    k = max(20, int(SCALING_COEFF * np.sqrt(N)))\n",
    "    print(f\"\\nN = {N}, k = {k}\")\n",
    "    \n",
    "    # S¬≥\n",
    "    try:\n",
    "        print(\"  S¬≥...\")\n",
    "        points = sample_S3(N, seed=42)\n",
    "        L, sigma = build_sparse_laplacian_S3(points, k)\n",
    "        lambda1 = compute_lambda1(L)\n",
    "        error = (lambda1 - LAMBDA1_S3) / LAMBDA1_S3 * 100\n",
    "        print(f\"    Œª‚ÇÅ = {lambda1:.4f}, error = {error:+.2f}%\")\n",
    "        extended_results['S3'].append({'N': N, 'lambda1': float(lambda1), 'error_pct': float(error)})\n",
    "        s3_results.append({'N': int(N), 'k': int(k), 'sigma': float(sigma),\n",
    "                          'lambda1': float(lambda1), 'lambda1_exact': float(LAMBDA1_S3),\n",
    "                          'error_pct': float(error)})\n",
    "        del points, L\n",
    "        clear_memory()\n",
    "    except MemoryError:\n",
    "        print(f\"    S¬≥: Out of memory at N={N}\")\n",
    "    \n",
    "    # T‚Å∑\n",
    "    try:\n",
    "        print(\"  T‚Å∑...\")\n",
    "        angles = sample_T7(N, seed=42)\n",
    "        L, sigma = build_sparse_laplacian_T7(angles, k, batch_size=3000)\n",
    "        lambda1 = compute_lambda1(L)\n",
    "        error = (lambda1 - LAMBDA1_T7) / LAMBDA1_T7 * 100\n",
    "        print(f\"    Œª‚ÇÅ = {lambda1:.4f}, error = {error:+.2f}%\")\n",
    "        extended_results['T7'].append({'N': N, 'lambda1': float(lambda1), 'error_pct': float(error)})\n",
    "        t7_results.append({'N': int(N), 'k': int(k), 'sigma': float(sigma),\n",
    "                          'lambda1': float(lambda1), 'lambda1_exact': float(LAMBDA1_T7),\n",
    "                          'error_pct': float(error)})\n",
    "        del angles, L\n",
    "        clear_memory()\n",
    "    except MemoryError:\n",
    "        print(f\"    T‚Å∑: Out of memory at N={N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Analysis and Calibration Factor\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CALIBRATION ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use high-N results for calibration\n",
    "high_n_s3 = [r for r in s3_results if r['N'] >= 10000]\n",
    "high_n_t7 = [r for r in t7_results if r['N'] >= 10000]\n",
    "\n",
    "if high_n_s3:\n",
    "    s3_mean = np.mean([r['lambda1'] for r in high_n_s3])\n",
    "    s3_factor = s3_mean / LAMBDA1_S3\n",
    "    s3_error = np.mean([r['error_pct'] for r in high_n_s3])\n",
    "    print(f\"\\nS¬≥ (N ‚â• 10k):\")\n",
    "    print(f\"  Mean Œª‚ÇÅ = {s3_mean:.4f}\")\n",
    "    print(f\"  Factor = {s3_factor:.4f} (measured/exact)\")\n",
    "    print(f\"  Mean error = {s3_error:+.2f}%\")\n",
    "else:\n",
    "    s3_factor = 1.0\n",
    "    print(\"\\nS¬≥: No high-N results\")\n",
    "\n",
    "if high_n_t7:\n",
    "    t7_mean = np.mean([r['lambda1'] for r in high_n_t7])\n",
    "    t7_factor = t7_mean / LAMBDA1_T7\n",
    "    t7_error = np.mean([r['error_pct'] for r in high_n_t7])\n",
    "    print(f\"\\nT‚Å∑ (N ‚â• 10k):\")\n",
    "    print(f\"  Mean Œª‚ÇÅ = {t7_mean:.4f}\")\n",
    "    print(f\"  Factor = {t7_factor:.4f} (measured/exact)\")\n",
    "    print(f\"  Mean error = {t7_error:+.2f}%\")\n",
    "else:\n",
    "    t7_factor = 1.0\n",
    "    print(\"\\nT‚Å∑: No high-N results\")\n",
    "\n",
    "# Apply to K‚Çá\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(\"APPLICATION TO K‚Çá:\")\n",
    "print(f\"  K‚Çá measured: Œª‚ÇÅ√óH* ‚âà 13.07\")\n",
    "\n",
    "if t7_factor != 1.0:\n",
    "    k7_corrected = 13.07 / t7_factor\n",
    "    print(f\"  Calibration factor (from T‚Å∑): {t7_factor:.4f}\")\n",
    "    print(f\"  K‚Çá corrected: Œª‚ÇÅ√óH* = {k7_corrected:.2f}\")\n",
    "    \n",
    "    if abs(k7_corrected - 14) < 0.5:\n",
    "        print(f\"\\n  ‚ö†Ô∏è CORRECTED VALUE ‚âà 14\")\n",
    "        print(f\"  The 13 was likely a discretization artifact!\")\n",
    "        verdict = \"ARTIFACT\"\n",
    "    elif abs(k7_corrected - 13) < 0.5:\n",
    "        print(f\"\\n  ‚úì CORRECTED VALUE ‚âà 13\")\n",
    "        print(f\"  The 13 is structural (dim(G‚ÇÇ) - h)\")\n",
    "        verdict = \"STRUCTURAL\"\n",
    "    else:\n",
    "        print(f\"\\n  ‚ùì INCONCLUSIVE\")\n",
    "        verdict = \"INCONCLUSIVE\"\n",
    "else:\n",
    "    verdict = \"INSUFFICIENT_DATA\"\n",
    "    k7_corrected = 13.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Visualization\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# S¬≥ convergence\n",
    "ax1 = axes[0]\n",
    "Ns = [r['N'] for r in s3_results]\n",
    "l1s = [r['lambda1'] for r in s3_results]\n",
    "ax1.plot(Ns, l1s, 'bo-', markersize=8, label='Measured')\n",
    "ax1.axhline(LAMBDA1_S3, color='r', linestyle='--', label=f'Exact = {LAMBDA1_S3}')\n",
    "ax1.fill_between([min(Ns), max(Ns)], LAMBDA1_S3*0.9, LAMBDA1_S3*1.1, alpha=0.2, color='g')\n",
    "ax1.set_xlabel('N')\n",
    "ax1.set_ylabel('Œª‚ÇÅ')\n",
    "ax1.set_title('S¬≥ Calibration')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# T‚Å∑ convergence\n",
    "ax2 = axes[1]\n",
    "Ns = [r['N'] for r in t7_results]\n",
    "l1s = [r['lambda1'] for r in t7_results]\n",
    "ax2.plot(Ns, l1s, 'go-', markersize=8, label='Measured')\n",
    "ax2.axhline(LAMBDA1_T7, color='r', linestyle='--', label=f'Exact = {LAMBDA1_T7}')\n",
    "ax2.fill_between([min(Ns), max(Ns)], LAMBDA1_T7*0.9, LAMBDA1_T7*1.1, alpha=0.2, color='b')\n",
    "ax2.set_xlabel('N')\n",
    "ax2.set_ylabel('Œª‚ÇÅ')\n",
    "ax2.set_title('T‚Å∑ Calibration (dim = 7, like K‚Çá)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Error comparison\n",
    "ax3 = axes[2]\n",
    "Ns_s3 = [r['N'] for r in s3_results]\n",
    "errs_s3 = [r['error_pct'] for r in s3_results]\n",
    "Ns_t7 = [r['N'] for r in t7_results]\n",
    "errs_t7 = [r['error_pct'] for r in t7_results]\n",
    "ax3.plot(Ns_s3, errs_s3, 'bo-', label='S¬≥ error')\n",
    "ax3.plot(Ns_t7, errs_t7, 'gs-', label='T‚Å∑ error')\n",
    "ax3.axhline(0, color='gray', linestyle='-')\n",
    "ax3.axhline(-7.7, color='r', linestyle='--', alpha=0.5, label='‚àí7.7% (13‚Üí14)')\n",
    "ax3.set_xlabel('N')\n",
    "ax3.set_ylabel('Error (%)')\n",
    "ax3.set_title('Calibration Error')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Spectral_Calibration_v2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved: Spectral_Calibration_v2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Save Results\n",
    "\n",
    "output = {\n",
    "    \"metadata\": {\n",
    "        \"notebook\": \"Spectral_Calibration_S3_T7_v2.ipynb\",\n",
    "        \"version\": \"v2 - memory optimized\",\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"gpu\": GPU_AVAILABLE,\n",
    "        \"sklearn\": SKLEARN_AVAILABLE,\n",
    "        \"scaling\": f\"k = {SCALING_COEFF} * sqrt(N)\"\n",
    "    },\n",
    "    \"exact_eigenvalues\": {\n",
    "        \"S3\": float(LAMBDA1_S3),\n",
    "        \"T7\": float(LAMBDA1_T7)\n",
    "    },\n",
    "    \"s3_results\": s3_results,\n",
    "    \"t7_results\": t7_results,\n",
    "    \"calibration\": {\n",
    "        \"S3_factor\": float(s3_factor) if 's3_factor' in dir() else None,\n",
    "        \"T7_factor\": float(t7_factor) if 't7_factor' in dir() else None,\n",
    "    },\n",
    "    \"k7_analysis\": {\n",
    "        \"measured\": 13.07,\n",
    "        \"corrected\": float(k7_corrected) if 'k7_corrected' in dir() else 13.07,\n",
    "        \"verdict\": verdict if 'verdict' in dir() else \"UNKNOWN\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"Spectral_Calibration_v2_results.json\", \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úì Saved: Spectral_Calibration_v2_results.json\")\n",
    "print(\"\\nDownload this JSON and the PNG, then share with Claude!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### If T‚Å∑ still crashes:\n",
    "- Reduce `batch_size` in `build_sparse_laplacian_T7` to 2000 or 1000\n",
    "- Reduce N_VALUES to [1000, 2000, 5000]\n",
    "\n",
    "### If eigenvalues are wrong:\n",
    "- The geometric scaling (1/œÉ¬≤) may need adjustment\n",
    "- Try different k values\n",
    "- Check if the manifold embedding is correct\n",
    "\n",
    "### If memory is OK but results are unstable:\n",
    "- Run with multiple seeds\n",
    "- Increase k\n",
    "\n",
    "---\n",
    "\n",
    "*GIFT Spectral Gap Research Program ‚Äî Calibration Study v2*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
