{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Riemann Zeros Toolkit for GIFT Research\n",
    "\n",
    "**Purpose**: Download, cache, and analyze Riemann zeta zeros for GIFT correspondence research.\n",
    "\n",
    "**Features**:\n",
    "- Bulk download from Odlyzko tables (2M+ zeros)\n",
    "- Local caching for fast reload\n",
    "- CuPy GPU acceleration for analysis\n",
    "- mpmath integration for high-precision computation\n",
    "- GIFT correspondence validation tools\n",
    "\n",
    "**Requirements**: Colab Pro+ with A100 recommended for large-scale analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install -q mpmath requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Optional, Tuple, List\n",
    "import warnings\n",
    "\n",
    "# GPU support (optional)\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(f\"✓ CuPy available - GPU: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}\")\n",
    "except ImportError:\n",
    "    cp = np  # Fallback to NumPy\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"⚠ CuPy not available, using NumPy (CPU)\")\n",
    "\n",
    "# High precision (optional)\n",
    "try:\n",
    "    from mpmath import mp, zetazero, zeta\n",
    "    mp.dps = 50  # 50 decimal places default\n",
    "    MPMATH_AVAILABLE = True\n",
    "    print(f\"✓ mpmath available - precision: {mp.dps} digits\")\n",
    "except ImportError:\n",
    "    MPMATH_AVAILABLE = False\n",
    "    print(\"⚠ mpmath not available, high-precision computation disabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Sources Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odlyzko data sources\n",
    "ODLYZKO_BASE = \"https://www-users.cse.umn.edu/~odlyzko/zeta_tables\"\n",
    "\n",
    "ODLYZKO_FILES = {\n",
    "    \"zeros1\": {\n",
    "        \"url\": f\"{ODLYZKO_BASE}/zeros1\",\n",
    "        \"count\": 100000,\n",
    "        \"start_index\": 1,\n",
    "        \"precision\": \"9 decimal places\",\n",
    "        \"description\": \"First 100,000 zeros\"\n",
    "    },\n",
    "    \"zeros2\": {\n",
    "        \"url\": f\"{ODLYZKO_BASE}/zeros2\",\n",
    "        \"count\": 1000,\n",
    "        \"start_index\": 10**12 + 1,\n",
    "        \"precision\": \"9 decimal places\",\n",
    "        \"description\": \"Zeros 10^12+1 to 10^12+1000\"\n",
    "    },\n",
    "    \"zeros3\": {\n",
    "        \"url\": f\"{ODLYZKO_BASE}/zeros3\",\n",
    "        \"count\": 10001,\n",
    "        \"start_index\": 10**21 + 1,\n",
    "        \"precision\": \"12 decimal places\",\n",
    "        \"description\": \"Zeros around 10^21\"\n",
    "    },\n",
    "    \"zeros4\": {\n",
    "        \"url\": f\"{ODLYZKO_BASE}/zeros4\",\n",
    "        \"count\": 10001,\n",
    "        \"start_index\": 10**22 - 10**7 + 1,\n",
    "        \"precision\": \"9 decimal places\",\n",
    "        \"description\": \"Zeros around 10^22\"\n",
    "    },\n",
    "    \"zeros5\": {\n",
    "        \"url\": f\"{ODLYZKO_BASE}/zeros5\",\n",
    "        \"count\": 300000,\n",
    "        \"start_index\": 10**22 + 1,\n",
    "        \"precision\": \"8 decimal places\",\n",
    "        \"description\": \"300,000 zeros starting at 10^22\"\n",
    "    },\n",
    "    \"zeros6\": {\n",
    "        \"url\": f\"{ODLYZKO_BASE}/zeros6.gz\",\n",
    "        \"count\": 2001052,\n",
    "        \"start_index\": 1,\n",
    "        \"precision\": \"8 decimal places\",\n",
    "        \"description\": \"First 2,001,052 zeros (gzipped)\",\n",
    "        \"compressed\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "# High precision sources\n",
    "HIGH_PRECISION = {\n",
    "    \"plouffe_100\": {\n",
    "        \"url\": \"http://www.plouffe.fr/simon/constants/zeta100.html\",\n",
    "        \"count\": 100,\n",
    "        \"precision\": \"1000+ decimal places\",\n",
    "        \"description\": \"First 100 zeros, ultra-high precision\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# GIFT constants for validation\n",
    "GIFT_CONSTANTS = {\n",
    "    \"dim_G2\": 14,\n",
    "    \"b2\": 21,\n",
    "    \"b3\": 77,\n",
    "    \"H_star\": 99,\n",
    "    \"dim_E8\": 248,\n",
    "    \"dim_K7\": 7,\n",
    "    \"rank_E8\": 8,\n",
    "    \"Weyl\": 5,\n",
    "    \"dim_J3O\": 27,\n",
    "    \"F7\": 13,  # 7th Fibonacci\n",
    "    \"kappa_T_inv\": 61\n",
    "}\n",
    "\n",
    "print(f\"Configured {len(ODLYZKO_FILES)} Odlyzko sources\")\n",
    "print(f\"Total zeros available: {sum(f['count'] for f in ODLYZKO_FILES.values()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Cache Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiemannZeroCache:\n",
    "    \"\"\"Manages downloading and caching of Riemann zero tables.\"\"\"\n",
    "    \n",
    "    def __init__(self, cache_dir: str = \"./riemann_cache\"):\n",
    "        self.cache_dir = Path(cache_dir)\n",
    "        self.cache_dir.mkdir(exist_ok=True)\n",
    "        self.metadata_file = self.cache_dir / \"metadata.json\"\n",
    "        self._load_metadata()\n",
    "        \n",
    "    def _load_metadata(self):\n",
    "        if self.metadata_file.exists():\n",
    "            with open(self.metadata_file) as f:\n",
    "                self.metadata = json.load(f)\n",
    "        else:\n",
    "            self.metadata = {\"downloaded\": {}, \"computed\": {}}\n",
    "    \n",
    "    def _save_metadata(self):\n",
    "        with open(self.metadata_file, 'w') as f:\n",
    "            # Convert numpy types to Python types for JSON\n",
    "            json.dump(self.metadata, f, indent=2, default=lambda x: float(x) if hasattr(x, 'item') else x)\n",
    "    \n",
    "    def download_odlyzko(self, name: str, force: bool = False) -> np.ndarray:\n",
    "        \"\"\"Download an Odlyzko table and cache locally.\"\"\"\n",
    "        if name not in ODLYZKO_FILES:\n",
    "            raise ValueError(f\"Unknown file: {name}. Available: {list(ODLYZKO_FILES.keys())}\")\n",
    "        \n",
    "        info = ODLYZKO_FILES[name]\n",
    "        cache_file = self.cache_dir / f\"{name}.npy\"\n",
    "        \n",
    "        # Check cache\n",
    "        if cache_file.exists() and not force:\n",
    "            print(f\"Loading {name} from cache...\")\n",
    "            return np.load(cache_file)\n",
    "        \n",
    "        # Download\n",
    "        print(f\"Downloading {info['description']}...\")\n",
    "        response = requests.get(info['url'], stream=True)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse content\n",
    "        if info.get('compressed'):\n",
    "            import gzip\n",
    "            content = gzip.decompress(response.content).decode('utf-8')\n",
    "        else:\n",
    "            content = response.text\n",
    "        \n",
    "        # Parse zeros (one per line)\n",
    "        zeros = []\n",
    "        for line in tqdm(content.strip().split('\\n'), desc=\"Parsing\"):\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#'):\n",
    "                try:\n",
    "                    zeros.append(float(line))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "        \n",
    "        zeros = np.array(zeros, dtype=np.float64)\n",
    "        \n",
    "        # Cache\n",
    "        np.save(cache_file, zeros)\n",
    "        self.metadata['downloaded'][name] = {\n",
    "            'count': len(zeros),\n",
    "            'min': float(zeros.min()),\n",
    "            'max': float(zeros.max()),\n",
    "            'start_index': info['start_index']\n",
    "        }\n",
    "        self._save_metadata()\n",
    "        \n",
    "        print(f\"✓ Cached {len(zeros):,} zeros to {cache_file}\")\n",
    "        return zeros\n",
    "    \n",
    "    def download_all(self, force: bool = False) -> dict:\n",
    "        \"\"\"Download all Odlyzko tables.\"\"\"\n",
    "        results = {}\n",
    "        for name in ODLYZKO_FILES:\n",
    "            try:\n",
    "                results[name] = self.download_odlyzko(name, force=force)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠ Failed to download {name}: {e}\")\n",
    "        return results\n",
    "    \n",
    "    def get_zeros(self, start: int = 1, end: int = 100000) -> np.ndarray:\n",
    "        \"\"\"Get zeros by index range (1-indexed).\"\"\"\n",
    "        # Load zeros1 (first 100k) or zeros6 (first 2M)\n",
    "        if end <= 100000:\n",
    "            zeros = self.download_odlyzko(\"zeros1\")\n",
    "        else:\n",
    "            zeros = self.download_odlyzko(\"zeros6\")\n",
    "        \n",
    "        # Convert to 0-indexed\n",
    "        return zeros[start-1:end]\n",
    "    \n",
    "    def status(self):\n",
    "        \"\"\"Print cache status.\"\"\"\n",
    "        print(\"\\n=== Riemann Zero Cache Status ===\")\n",
    "        total = 0\n",
    "        for name, info in self.metadata.get('downloaded', {}).items():\n",
    "            print(f\"  {name}: {info['count']:,} zeros (γ ∈ [{info['min']:.2f}, {info['max']:.2f}])\")\n",
    "            total += info['count']\n",
    "        print(f\"  Total cached: {total:,} zeros\")\n",
    "        print(f\"  Cache dir: {self.cache_dir.absolute()}\")\n",
    "\n",
    "# Initialize cache\n",
    "cache = RiemannZeroCache()\n",
    "cache.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Data (Run Once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the main dataset (first 100,000 zeros) - quick\n",
    "zeros_100k = cache.download_odlyzko(\"zeros1\")\n",
    "print(f\"\\nFirst 10 zeros: {zeros_100k[:10]}\")\n",
    "print(f\"γ₁ = {zeros_100k[0]:.10f} (GIFT: dim(G₂) = 14, deviation: {abs(zeros_100k[0] - 14)/14*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Download full 2M dataset (takes longer, ~40MB)\n",
    "# Uncomment to run:\n",
    "# zeros_2M = cache.download_odlyzko(\"zeros6\")\n",
    "# print(f\"Loaded {len(zeros_2M):,} zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GPU-Accelerated Analysis with CuPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIFTRiemannAnalyzer:\n",
    "    \"\"\"GPU-accelerated analysis of GIFT-Riemann correspondences.\"\"\"\n",
    "    \n",
    "    def __init__(self, zeros: np.ndarray, use_gpu: bool = True):\n",
    "        self.use_gpu = use_gpu and GPU_AVAILABLE\n",
    "        self.xp = cp if self.use_gpu else np\n",
    "        \n",
    "        # Transfer to GPU if available\n",
    "        if self.use_gpu:\n",
    "            self.zeros = cp.asarray(zeros)\n",
    "            print(f\"✓ Loaded {len(zeros):,} zeros on GPU\")\n",
    "        else:\n",
    "            self.zeros = zeros\n",
    "            print(f\"✓ Loaded {len(zeros):,} zeros on CPU\")\n",
    "    \n",
    "    def find_near_integer(self, target: int, tolerance: float = 0.5) -> dict:\n",
    "        \"\"\"Find zeros nearest to a target integer.\"\"\"\n",
    "        xp = self.xp\n",
    "        diff = xp.abs(self.zeros - target)\n",
    "        mask = diff < tolerance\n",
    "        \n",
    "        if not xp.any(mask):\n",
    "            # Find closest anyway\n",
    "            idx = int(xp.argmin(diff))\n",
    "            return {\n",
    "                'target': target,\n",
    "                'nearest_index': idx + 1,  # 1-indexed\n",
    "                'value': float(self.zeros[idx]),\n",
    "                'deviation': float(diff[idx]),\n",
    "                'deviation_pct': float(diff[idx] / target * 100)\n",
    "            }\n",
    "        \n",
    "        indices = xp.where(mask)[0]\n",
    "        if self.use_gpu:\n",
    "            indices = indices.get()\n",
    "            values = self.zeros[mask].get()\n",
    "            deviations = diff[mask].get()\n",
    "        else:\n",
    "            values = self.zeros[mask]\n",
    "            deviations = diff[mask]\n",
    "        \n",
    "        best_idx = int(indices[np.argmin(deviations)])\n",
    "        return {\n",
    "            'target': target,\n",
    "            'matches': len(indices),\n",
    "            'nearest_index': best_idx + 1,\n",
    "            'value': float(self.zeros[best_idx]),\n",
    "            'deviation': float(np.min(deviations)),\n",
    "            'deviation_pct': float(np.min(deviations) / target * 100)\n",
    "        }\n",
    "    \n",
    "    def validate_gift_correspondences(self) -> dict:\n",
    "        \"\"\"Validate all GIFT-Riemann correspondences.\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # Known correspondences from research\n",
    "        correspondences = [\n",
    "            (1, 14, \"dim(G₂)\"),\n",
    "            (2, 21, \"b₂\"),\n",
    "            (20, 77, \"b₃\"),\n",
    "            (29, 99, \"H*\"),\n",
    "            (107, 248, \"dim(E₈)\"),\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n=== GIFT-Riemann Correspondences ===\")\n",
    "        print(f\"{'Index':<8} {'γₙ':<12} {'Target':<8} {'Constant':<12} {'Dev %':<10}\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        for idx, target, name in correspondences:\n",
    "            if idx <= len(self.zeros):\n",
    "                gamma = float(self.zeros[idx - 1])  # 0-indexed\n",
    "                dev_pct = abs(gamma - target) / target * 100\n",
    "                results[name] = {\n",
    "                    'index': idx,\n",
    "                    'gamma': gamma,\n",
    "                    'target': target,\n",
    "                    'deviation_pct': dev_pct\n",
    "                }\n",
    "                print(f\"γ_{idx:<5} {gamma:<12.6f} {target:<8} {name:<12} {dev_pct:<10.4f}\")\n",
    "        \n",
    "        mean_dev = np.mean([r['deviation_pct'] for r in results.values()])\n",
    "        print(f\"\\nMean deviation: {mean_dev:.4f}%\")\n",
    "        results['mean_deviation'] = mean_dev\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def test_pell_equation(self) -> dict:\n",
    "        \"\"\"Test the modified Pell equation: γ₂₉² - 49γ₁² + γ₂ + 1 ≈ 0\"\"\"\n",
    "        g1 = float(self.zeros[0])   # γ₁\n",
    "        g2 = float(self.zeros[1])   # γ₂\n",
    "        g29 = float(self.zeros[28]) # γ₂₉\n",
    "        \n",
    "        # Modified Pell: γ₂₉² - 49γ₁² + γ₂ + 1 ≈ 0\n",
    "        pell_value = g29**2 - 49 * g1**2 + g2 + 1\n",
    "        \n",
    "        print(\"\\n=== Modified Pell Equation ===\")\n",
    "        print(f\"γ₁  = {g1:.10f}\")\n",
    "        print(f\"γ₂  = {g2:.10f}\")\n",
    "        print(f\"γ₂₉ = {g29:.10f}\")\n",
    "        print(f\"\\nγ₂₉² - 49γ₁² + γ₂ + 1 = {pell_value:.10f}\")\n",
    "        print(f\"Expected: 0\")\n",
    "        print(f\"Relative error: {abs(pell_value) / g29**2 * 100:.6f}%\")\n",
    "        \n",
    "        return {\n",
    "            'gamma_1': g1,\n",
    "            'gamma_2': g2,\n",
    "            'gamma_29': g29,\n",
    "            'pell_value': pell_value,\n",
    "            'relative_error_pct': abs(pell_value) / g29**2 * 100\n",
    "        }\n",
    "    \n",
    "    def test_recurrence(self, n_test: int = 1000) -> dict:\n",
    "        \"\"\"Test the GIFT recurrence: γₙ ≈ a₅γₙ₋₅ + a₈γₙ₋₈ + a₁₃γₙ₋₁₃ + a₂₇γₙ₋₂₇ + c\"\"\"\n",
    "        xp = self.xp\n",
    "        \n",
    "        # Need at least 28 zeros for lag-27\n",
    "        if len(self.zeros) < 28 + n_test:\n",
    "            n_test = len(self.zeros) - 28\n",
    "        \n",
    "        # GIFT lags: Weyl=5, rank(E₈)=8, F₇=13, dim(J₃(O))=27\n",
    "        lags = [5, 8, 13, 27]\n",
    "        \n",
    "        # Build design matrix for linear regression\n",
    "        # γₙ = a₅γₙ₋₅ + a₈γₙ₋₈ + a₁₃γₙ₋₁₃ + a₂₇γₙ₋₂₇ + c\n",
    "        start = max(lags)\n",
    "        end = start + n_test\n",
    "        \n",
    "        if self.use_gpu:\n",
    "            zeros_cpu = self.zeros.get()\n",
    "        else:\n",
    "            zeros_cpu = self.zeros\n",
    "        \n",
    "        # Design matrix\n",
    "        X = np.column_stack([\n",
    "            zeros_cpu[start - lag:end - lag] for lag in lags\n",
    "        ] + [np.ones(n_test)])  # constant term\n",
    "        \n",
    "        y = zeros_cpu[start:end]\n",
    "        \n",
    "        # Least squares fit\n",
    "        coeffs, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "        \n",
    "        # Predictions and errors\n",
    "        y_pred = X @ coeffs\n",
    "        errors = np.abs(y - y_pred)\n",
    "        rel_errors = errors / y * 100\n",
    "        \n",
    "        print(f\"\\n=== Recurrence Analysis (n={n_test:,}) ===\")\n",
    "        print(f\"\\nFitted coefficients:\")\n",
    "        for lag, coef in zip(lags, coeffs[:-1]):\n",
    "            print(f\"  a_{lag} = {coef:.6f}\")\n",
    "        print(f\"  c   = {coeffs[-1]:.6f}\")\n",
    "        print(f\"\\nError statistics:\")\n",
    "        print(f\"  Mean relative error: {np.mean(rel_errors):.4f}%\")\n",
    "        print(f\"  Max relative error:  {np.max(rel_errors):.4f}%\")\n",
    "        print(f\"  Std relative error:  {np.std(rel_errors):.4f}%\")\n",
    "        \n",
    "        return {\n",
    "            'lags': lags,\n",
    "            'coefficients': {f'a_{lag}': float(c) for lag, c in zip(lags, coeffs[:-1])},\n",
    "            'constant': float(coeffs[-1]),\n",
    "            'mean_rel_error_pct': float(np.mean(rel_errors)),\n",
    "            'max_rel_error_pct': float(np.max(rel_errors)),\n",
    "            'std_rel_error_pct': float(np.std(rel_errors)),\n",
    "            'n_samples': n_test\n",
    "        }\n",
    "    \n",
    "    def scan_for_gift_constants(self, tolerance_pct: float = 1.0) -> list:\n",
    "        \"\"\"Scan all zeros for proximity to GIFT constants.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for name, value in GIFT_CONSTANTS.items():\n",
    "            match = self.find_near_integer(value, tolerance=value * tolerance_pct / 100)\n",
    "            match['gift_constant'] = name\n",
    "            results.append(match)\n",
    "        \n",
    "        print(f\"\\n=== Scan for GIFT Constants (tolerance: {tolerance_pct}%) ===\")\n",
    "        print(f\"{'Constant':<15} {'Value':<8} {'γₙ Index':<10} {'γₙ Value':<12} {'Dev %':<8}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for r in sorted(results, key=lambda x: x['deviation_pct']):\n",
    "            print(f\"{r['gift_constant']:<15} {r['target']:<8} γ_{r['nearest_index']:<7} {r['value']:<12.6f} {r['deviation_pct']:<8.4f}\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = GIFTRiemannAnalyzer(zeros_100k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run GIFT-Riemann Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate known correspondences\n",
    "correspondences = analyzer.validate_gift_correspondences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test modified Pell equation\n",
    "pell = analyzer.test_pell_equation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test recurrence relation\n",
    "recurrence = analyzer.test_recurrence(n_test=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan for all GIFT constants\n",
    "scan = analyzer.scan_for_gift_constants(tolerance_pct=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. High-Precision Computation with mpmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_zeros_mpmath(start: int, count: int, precision: int = 50) -> list:\n",
    "    \"\"\"Compute zeros using mpmath (high precision but slow).\"\"\"\n",
    "    if not MPMATH_AVAILABLE:\n",
    "        raise ImportError(\"mpmath not available\")\n",
    "    \n",
    "    mp.dps = precision\n",
    "    zeros = []\n",
    "    \n",
    "    for n in tqdm(range(start, start + count), desc=f\"Computing zeros (precision={precision})\"):\n",
    "        z = zetazero(n)\n",
    "        zeros.append(float(z.imag))\n",
    "    \n",
    "    return zeros\n",
    "\n",
    "# Example: compute first 10 zeros with 100 digits precision\n",
    "if MPMATH_AVAILABLE:\n",
    "    high_prec_zeros = compute_zeros_mpmath(1, 10, precision=100)\n",
    "    print(\"\\nHigh-precision zeros (100 digits):\")\n",
    "    for i, z in enumerate(high_prec_zeros, 1):\n",
    "        print(f\"  γ_{i} = {z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. GPU-Accelerated Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_analysis_gpu(zeros: np.ndarray, max_freq: int = 1000):\n",
    "    \"\"\"GPU-accelerated FFT analysis of zero spacings.\"\"\"\n",
    "    if not GPU_AVAILABLE:\n",
    "        print(\"GPU not available, using CPU\")\n",
    "        xp = np\n",
    "    else:\n",
    "        xp = cp\n",
    "        zeros = cp.asarray(zeros)\n",
    "    \n",
    "    # Compute spacings\n",
    "    spacings = xp.diff(zeros)\n",
    "    \n",
    "    # Normalize spacings\n",
    "    mean_spacing = xp.mean(spacings)\n",
    "    normalized = spacings / mean_spacing\n",
    "    \n",
    "    # FFT\n",
    "    fft = xp.fft.fft(normalized)\n",
    "    power = xp.abs(fft[:max_freq])**2\n",
    "    freqs = xp.fft.fftfreq(len(normalized))[:max_freq]\n",
    "    \n",
    "    if GPU_AVAILABLE:\n",
    "        power = power.get()\n",
    "        freqs = freqs.get()\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    \n",
    "    return freqs, power\n",
    "\n",
    "# Run spectral analysis\n",
    "freqs, power = spectral_analysis_gpu(zeros_100k)\n",
    "\n",
    "# Find dominant frequencies\n",
    "top_indices = np.argsort(power)[-10:][::-1]\n",
    "print(\"\\n=== Top 10 Spectral Peaks ===\")\n",
    "for i, idx in enumerate(top_indices):\n",
    "    print(f\"  {i+1}. freq={freqs[idx]:.6f}, power={power[idx]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_analysis_results(filename: str = \"gift_riemann_analysis.json\"):\n",
    "    \"\"\"Save all analysis results to JSON.\"\"\"\n",
    "    results = {\n",
    "        'correspondences': correspondences,\n",
    "        'pell_equation': pell,\n",
    "        'recurrence': recurrence,\n",
    "        'gift_constants_scan': [{k: (float(v) if isinstance(v, (np.floating, float)) else v) \n",
    "                                  for k, v in s.items()} for s in scan],\n",
    "        'metadata': {\n",
    "            'n_zeros': len(zeros_100k),\n",
    "            'gpu_used': GPU_AVAILABLE,\n",
    "            'source': 'Odlyzko zeros1'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(results, f, indent=2, default=lambda x: float(x) if hasattr(x, 'item') else str(x))\n",
    "    \n",
    "    print(f\"✓ Results saved to {filename}\")\n",
    "    return results\n",
    "\n",
    "results = save_analysis_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Quick API Reference\n",
    "\n",
    "```python\n",
    "# Initialize cache and download data\n",
    "cache = RiemannZeroCache()\n",
    "zeros = cache.download_odlyzko(\"zeros1\")  # First 100k\n",
    "zeros = cache.download_odlyzko(\"zeros6\")  # First 2M\n",
    "zeros = cache.get_zeros(1, 1000)          # Get range by index\n",
    "\n",
    "# Analyze with GPU\n",
    "analyzer = GIFTRiemannAnalyzer(zeros, use_gpu=True)\n",
    "analyzer.validate_gift_correspondences()\n",
    "analyzer.test_pell_equation()\n",
    "analyzer.test_recurrence(n_test=10000)\n",
    "analyzer.scan_for_gift_constants(tolerance_pct=1.0)\n",
    "analyzer.find_near_integer(target=14)     # Find zeros near any integer\n",
    "\n",
    "# High-precision computation\n",
    "zeros_hp = compute_zeros_mpmath(1, 100, precision=100)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final status\n",
    "cache.status()\n",
    "print(\"\\n✓ Notebook ready for GIFT-Riemann research!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
