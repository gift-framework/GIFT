{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Hunt: Reverse Logic on Riemann Zeros\n",
    "\n",
    "## Where Does the Arithmetic Signal Actually Live?\n",
    "\n",
    "**Context**: The Grand Slam notebook showed that the Fibonacci recurrence\n",
    "$\\delta_n \\approx \\frac{31}{21}\\delta_{n-8} - \\frac{10}{21}\\delta_{n-21}$\n",
    "gives **-80% capture** on genuine zeros \u2014 worse than no recurrence at all.\n",
    "\n",
    "**Diagnosis**: The $\\delta_n$ corrections are dominated by $S(T) = \\frac{1}{\\pi}\\arg\\zeta(\\frac{1}{2}+iT)$,\n",
    "whose natural frequencies are $\\log p$ for primes $p$, **not** Fibonacci geodesic lengths.\n",
    "\n",
    "**This notebook**: 5 experiments to find where (if anywhere) the Fibonacci signal hides.\n",
    "\n",
    "| # | Experiment | What we test |\n",
    "|---|-----------|-------------|\n",
    "| E1 | Unfolded zeros $\\varepsilon_n$ autocorrelation | Fibonacci lags in arithmetic fluctuations |\n",
    "| E2 | Spectral density of $\\varepsilon_n$ | Prime peaks in the spectrum |\n",
    "| B1 | Confirm $\\log 2$ origin of lag-7407 | Calibrate our FFT pipeline |\n",
    "| B2 | Weil explicit formula: extract primes | $\\sum \\cos(\\gamma_n \\omega)$ peaks at $\\omega = \\log p$ |\n",
    "| C1 | Selberg spectral sums (regularized) | Fibonacci vs non-Fibonacci geodesic weights |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SETUP & CONFIGURATION\n",
    "# ============================================================\n",
    "!pip install -q python-flint tqdm matplotlib scipy mpmath 2>/dev/null || true\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({\n",
    "    'font.size': 12, 'figure.figsize': (14, 6),\n",
    "    'figure.dpi': 100, 'savefig.dpi': 150,\n",
    "    'axes.grid': True, 'grid.alpha': 0.3\n",
    "})\n",
    "import time, json, os, warnings, sys\n",
    "from scipy.special import loggamma, lambertw\n",
    "from tqdm.auto import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try GPU\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU = True\n",
    "    gpu_name = cp.cuda.runtime.getDeviceProperties(0)['name'].decode()\n",
    "    gpu_mem = cp.cuda.runtime.getDeviceProperties(0)['totalGlobalMem'] / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
    "except Exception:\n",
    "    GPU = False\n",
    "    print(\"No GPU detected, using CPU\")\n",
    "\n",
    "# Constants\n",
    "PHI = (1 + np.sqrt(5)) / 2\n",
    "LOG_PHI = np.log(PHI)\n",
    "FIBONACCI = [1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987]\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(f\"\\nConstants:\")\n",
    "print(f\"  phi = {PHI:.10f}\")\n",
    "print(f\"  log(phi) = {LOG_PHI:.10f}\")\n",
    "print(f\"  2*log(phi) = {2*LOG_PHI:.10f}\")\n",
    "print(f\"  log(2) = {np.log(2):.10f}\")\n",
    "print(f\"  log(3) = {np.log(3):.10f}\")\n",
    "print(f\"  log(5) = {np.log(5):.10f}\")\n",
    "print(f\"  log(7) = {np.log(7):.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading & Franca-LeClair Decomposition\n",
    "\n",
    "Same pipeline as Grand Slam: genuine Odlyzko zeros + precise $\\theta$-based decomposition.\n",
    "We also compute the **unfolded zeros** $\\varepsilon_n = \\theta(\\gamma_n)/\\pi + 1 - n = S(\\gamma_n)/\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOAD GENUINE ZEROS + DECOMPOSITION\n",
    "# ============================================================\n",
    "import urllib.request\n",
    "\n",
    "CACHE_100K = 'riemann_zeros_100k_genuine.npy'\n",
    "CACHE_2M = 'riemann_zeros_2M_genuine.npy'\n",
    "\n",
    "def download_odlyzko(url, cache_file, description):\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"  Loading cached {description}...\")\n",
    "        return np.load(cache_file)\n",
    "    print(f\"  Downloading {description}...\")\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        response = urllib.request.urlopen(url, timeout=120)\n",
    "        raw = response.read().decode('utf-8')\n",
    "        lines = raw.strip().split('\\n')\n",
    "        zeros = np.array([float(l.strip()) for l in lines if l.strip()])\n",
    "        print(f\"    Got {len(zeros):,} zeros in {time.time()-t0:.1f}s\")\n",
    "        np.save(cache_file, zeros)\n",
    "        return zeros\n",
    "    except Exception as e:\n",
    "        print(f\"    Download failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DOWNLOADING GENUINE RIEMANN ZEROS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "gamma_n = download_odlyzko(\n",
    "    'https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros1',\n",
    "    CACHE_100K, \"100,000 zeros (Odlyzko zeros1)\")\n",
    "if gamma_n is None:\n",
    "    raise RuntimeError(\"Could not download 100k zeros.\")\n",
    "\n",
    "gamma_2M = download_odlyzko(\n",
    "    'https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6',\n",
    "    CACHE_2M, \"2,001,052 zeros (Odlyzko zeros6)\")\n",
    "HAS_2M = gamma_2M is not None\n",
    "\n",
    "N_ZEROS = len(gamma_n)\n",
    "\n",
    "# ----- Franca-LeClair decomposition -----\n",
    "print(\"\\nComputing Franca-LeClair decomposition...\")\n",
    "t0 = time.time()\n",
    "\n",
    "def theta_vec(t):\n",
    "    s = 0.25 + 0.5j * np.asarray(t, dtype=np.float64)\n",
    "    return np.imag(loggamma(s)) - 0.5 * np.asarray(t) * np.log(np.pi)\n",
    "\n",
    "def compute_smooth_zeros(N):\n",
    "    ns = np.arange(1, N + 1, dtype=np.float64)\n",
    "    targets = (ns - 1.5) * np.pi\n",
    "    w = np.real(lambertw(ns / np.e))\n",
    "    t = 2 * np.pi * ns / w\n",
    "    t = np.maximum(t, 2.0)\n",
    "    for it in range(40):\n",
    "        val = theta_vec(t)\n",
    "        deriv = 0.5 * np.log(np.maximum(t, 1.0) / (2 * np.pi))\n",
    "        deriv = np.where(np.abs(deriv) < 1e-15, 1e-15, deriv)\n",
    "        dt = (val - targets) / deriv\n",
    "        t -= dt\n",
    "        if np.max(np.abs(dt)) < 1e-12:\n",
    "            print(f\"  Newton converged at iteration {it}\")\n",
    "            break\n",
    "    return t\n",
    "\n",
    "gamma_smooth = compute_smooth_zeros(N_ZEROS)\n",
    "delta_n = gamma_n - gamma_smooth\n",
    "\n",
    "# ----- Unfolded zeros: epsilon_n = S(gamma_n) / pi -----\n",
    "ns = np.arange(1, N_ZEROS + 1, dtype=np.float64)\n",
    "theta_at_zeros = theta_vec(gamma_n)\n",
    "epsilon_n = theta_at_zeros / np.pi + 1.0 - ns\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"Completed in {elapsed:.1f}s\")\n",
    "\n",
    "print(f\"\\nDataset: {N_ZEROS:,} genuine zeros\")\n",
    "print(f\"\\ndelta_n (Franca-LeClair corrections):\")\n",
    "print(f\"  mean|delta_n| = {np.mean(np.abs(delta_n)):.6f}\")\n",
    "print(f\"  std(delta_n)  = {np.std(delta_n):.6f}\")\n",
    "print(f\"\\nepsilon_n (unfolded fluctuations = S(gamma_n)/pi):\")\n",
    "print(f\"  mean(eps)  = {np.mean(epsilon_n):.6f}\")\n",
    "print(f\"  std(eps)   = {np.std(epsilon_n):.6f}\")\n",
    "print(f\"  max|eps|   = {np.max(np.abs(epsilon_n)):.6f}\")\n",
    "\n",
    "results['n_zeros'] = int(N_ZEROS)\n",
    "results['gamma_range'] = [float(gamma_n[0]), float(gamma_n[-1])]\n",
    "results['delta_stats'] = {\n",
    "    'mean_abs': float(np.mean(np.abs(delta_n))),\n",
    "    'std': float(np.std(delta_n)),\n",
    "}\n",
    "results['epsilon_stats'] = {\n",
    "    'mean': float(np.mean(epsilon_n)),\n",
    "    'std': float(np.std(epsilon_n)),\n",
    "    'max_abs': float(np.max(np.abs(epsilon_n))),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment E1: Autocorrelation of Unfolded Zeros $\\varepsilon_n$\n",
    "\n",
    "The **unfolded zeros** $\\varepsilon_n = \\frac{\\theta(\\gamma_n)}{\\pi} + 1 - n$ encode\n",
    "the **pure arithmetic content** $S(\\gamma_n)/\\pi$ of the zeros, stripped of\n",
    "all smooth (Weyl) density effects.\n",
    "\n",
    "If Fibonacci structure exists in the arithmetic, we should see it in the\n",
    "autocorrelation $\\rho(k) = \\text{Corr}(\\varepsilon_n, \\varepsilon_{n+k})$\n",
    "at Fibonacci lags $k \\in \\{1, 2, 3, 5, 8, 13, 21, 34, 55, \\ldots\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# E1: AUTOCORRELATION OF UNFOLDED ZEROS\n",
    "# ============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"  E1: AUTOCORRELATION OF UNFOLDED ZEROS epsilon_n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "eps_centered = epsilon_n - np.mean(epsilon_n)\n",
    "eps_var = np.var(eps_centered)\n",
    "\n",
    "MAX_LAG = 1000\n",
    "print(f\"\\nComputing autocorrelation for lags 1..{MAX_LAG}...\")\n",
    "t0 = time.time()\n",
    "\n",
    "acf = np.zeros(MAX_LAG + 1)\n",
    "acf[0] = 1.0\n",
    "N = len(eps_centered)\n",
    "\n",
    "if GPU:\n",
    "    eps_gpu = cp.asarray(eps_centered)\n",
    "    for k in tqdm(range(1, MAX_LAG + 1), desc=\"ACF\"):\n",
    "        acf[k] = float(cp.mean(eps_gpu[:-k] * eps_gpu[k:]) / eps_var)\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "else:\n",
    "    for k in tqdm(range(1, MAX_LAG + 1), desc=\"ACF\"):\n",
    "        acf[k] = np.mean(eps_centered[:-k] * eps_centered[k:]) / eps_var\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"Done in {elapsed:.1f}s\")\n",
    "\n",
    "sig_threshold = 2.0 / np.sqrt(N)\n",
    "print(f\"\\n2-sigma threshold: {sig_threshold:.6f}\")\n",
    "\n",
    "print(f\"\\nAutocorrelation at Fibonacci lags:\")\n",
    "print(f\"  {'Lag':>6} {'rho(k)':>12} {'|rho|/2sig':>12} {'Significant':>12}\")\n",
    "print(f\"  {'-'*48}\")\n",
    "fib_acfs = {}\n",
    "for f in FIBONACCI:\n",
    "    if f <= MAX_LAG:\n",
    "        ratio = abs(acf[f]) / sig_threshold\n",
    "        sig = \"***\" if ratio > 1 else \"\"\n",
    "        print(f\"  {f:>6} {acf[f]:>12.6f} {ratio:>12.2f} {sig:>12}\")\n",
    "        fib_acfs[f] = float(acf[f])\n",
    "\n",
    "fib_lags_in_range = [f for f in FIBONACCI if 2 <= f <= MAX_LAG]\n",
    "non_fib_lags = [k for k in range(2, MAX_LAG + 1) if k not in FIBONACCI]\n",
    "\n",
    "mean_abs_fib = np.mean([abs(acf[f]) for f in fib_lags_in_range])\n",
    "mean_abs_non_fib = np.mean([abs(acf[k]) for k in non_fib_lags])\n",
    "\n",
    "print(f\"\\nMean |acf| at Fibonacci lags:     {mean_abs_fib:.6f}\")\n",
    "print(f\"Mean |acf| at non-Fibonacci lags: {mean_abs_non_fib:.6f}\")\n",
    "print(f\"Ratio (Fib / non-Fib):            {mean_abs_fib / mean_abs_non_fib:.3f}\")\n",
    "\n",
    "# Permutation test\n",
    "N_PERMS = 10000\n",
    "print(f\"\\nPermutation test ({N_PERMS} random lag sets of size {len(fib_lags_in_range)})...\")\n",
    "perm_means = np.zeros(N_PERMS)\n",
    "abs_acf_arr = np.abs(acf[2:MAX_LAG+1])\n",
    "\n",
    "for p in range(N_PERMS):\n",
    "    chosen = np.random.choice(len(abs_acf_arr), size=len(fib_lags_in_range), replace=False)\n",
    "    perm_means[p] = np.mean(abs_acf_arr[chosen])\n",
    "\n",
    "z_fib = (mean_abs_fib - np.mean(perm_means)) / np.std(perm_means)\n",
    "p_fib = np.mean(perm_means >= mean_abs_fib)\n",
    "print(f\"  Z-score (Fibonacci vs random lag sets): {z_fib:.2f}\")\n",
    "print(f\"  p-value: {p_fib:.4f}\")\n",
    "\n",
    "# Also compute ACF of delta_n for comparison\n",
    "print(f\"\\n--- Comparison: autocorrelation of delta_n ---\")\n",
    "delta_centered = delta_n - np.mean(delta_n)\n",
    "delta_var = np.var(delta_centered)\n",
    "acf_delta = np.zeros(MAX_LAG + 1)\n",
    "acf_delta[0] = 1.0\n",
    "if GPU:\n",
    "    d_gpu = cp.asarray(delta_centered)\n",
    "    for k in tqdm(range(1, MAX_LAG + 1), desc=\"ACF delta\"):\n",
    "        acf_delta[k] = float(cp.mean(d_gpu[:-k] * d_gpu[k:]) / delta_var)\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "else:\n",
    "    for k in tqdm(range(1, MAX_LAG + 1), desc=\"ACF delta\"):\n",
    "        acf_delta[k] = np.mean(delta_centered[:-k] * delta_centered[k:]) / delta_var\n",
    "\n",
    "print(f\"\\nACF of delta_n at Fibonacci lags:\")\n",
    "for f in FIBONACCI:\n",
    "    if f <= MAX_LAG:\n",
    "        print(f\"  lag {f:>4}: eps acf = {acf[f]:>10.6f}, delta acf = {acf_delta[f]:>10.6f}\")\n",
    "\n",
    "# Plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0,0].bar(range(1, min(101, MAX_LAG+1)), acf[1:101], color='steelblue', alpha=0.7, width=1.0)\n",
    "for f in FIBONACCI:\n",
    "    if f <= 100:\n",
    "        axes[0,0].bar(f, acf[f], color='red', alpha=0.9, width=1.0)\n",
    "axes[0,0].axhline(sig_threshold, color='orange', ls='--', lw=1, label=r'$2\\sigma$')\n",
    "axes[0,0].axhline(-sig_threshold, color='orange', ls='--', lw=1)\n",
    "axes[0,0].set_xlabel('Lag k')\n",
    "axes[0,0].set_ylabel(r'$\\rho(k)$')\n",
    "axes[0,0].set_title(r'Autocorrelation of $\\varepsilon_n$ (red = Fibonacci)')\n",
    "axes[0,0].legend()\n",
    "\n",
    "axes[0,1].bar(range(1, 35), acf[1:35], color='steelblue', alpha=0.7)\n",
    "for f in [1, 2, 3, 5, 8, 13, 21, 34]:\n",
    "    if f < 35:\n",
    "        axes[0,1].bar(f, acf[f], color='red', alpha=0.9)\n",
    "axes[0,1].axhline(sig_threshold, color='orange', ls='--', lw=1)\n",
    "axes[0,1].axhline(-sig_threshold, color='orange', ls='--', lw=1)\n",
    "axes[0,1].set_xlabel('Lag k')\n",
    "axes[0,1].set_title('Zoom: lags 1-34')\n",
    "\n",
    "axes[1,0].hist(perm_means, bins=80, density=True, alpha=0.7, color='gray', label='Random lag sets')\n",
    "axes[1,0].axvline(mean_abs_fib, color='red', lw=2, label=f'Fibonacci = {mean_abs_fib:.6f}')\n",
    "axes[1,0].set_xlabel('Mean |ACF|')\n",
    "axes[1,0].set_title(f'Permutation test (z={z_fib:.1f}, p={p_fib:.3f})')\n",
    "axes[1,0].legend()\n",
    "\n",
    "lags_plot = range(1, min(56, MAX_LAG+1))\n",
    "axes[1,1].plot(lags_plot, [acf[k] for k in lags_plot], 'b.-', label=r'$\\varepsilon_n$ (unfolded)', alpha=0.7)\n",
    "axes[1,1].plot(lags_plot, [acf_delta[k] for k in lags_plot], 'g.-', label=r'$\\delta_n$ (Franca-LeClair)', alpha=0.7)\n",
    "for f in FIBONACCI:\n",
    "    if f <= 55:\n",
    "        axes[1,1].axvline(f, color='red', alpha=0.15, lw=2)\n",
    "axes[1,1].axhline(0, color='black', lw=0.5)\n",
    "axes[1,1].set_xlabel('Lag k')\n",
    "axes[1,1].set_ylabel('ACF')\n",
    "axes[1,1].set_title(r'$\\varepsilon_n$ vs $\\delta_n$ autocorrelation')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('signal_hunt_E1_autocorrelation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['E1_autocorrelation'] = {\n",
    "    'fib_acfs_epsilon': fib_acfs,\n",
    "    'mean_abs_fib': float(mean_abs_fib),\n",
    "    'mean_abs_non_fib': float(mean_abs_non_fib),\n",
    "    'fib_non_fib_ratio': float(mean_abs_fib / mean_abs_non_fib),\n",
    "    'z_score': float(z_fib),\n",
    "    'p_value': float(p_fib),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment E2: Spectral Density of $\\varepsilon_n$\n",
    "\n",
    "The FFT of $\\varepsilon_n$ should reveal the **prime signature**: peaks at frequencies\n",
    "corresponding to $\\log p / (2\\pi)$ in the appropriate normalization.\n",
    "\n",
    "The dominant contributions come from small primes (2, 3, 5, 7, ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# E2: SPECTRAL DENSITY OF EPSILON_N\n",
    "# ============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"  E2: SPECTRAL DENSITY OF EPSILON_N\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "eps_fft = np.abs(np.fft.rfft(eps_centered)) ** 2\n",
    "n_freqs = len(eps_fft)\n",
    "total_eps_power = np.sum(eps_fft[1:])\n",
    "\n",
    "top_eps_idx = np.argsort(eps_fft[1:])[::-1][:30] + 1\n",
    "print(f\"\\nTop 20 spectral peaks of epsilon_n:\")\n",
    "print(f\"  {'Rank':>4} {'Freq idx':>9} {'Power%':>10} {'Period':>10}\")\n",
    "print(f\"  {'-'*40}\")\n",
    "for i, idx in enumerate(top_eps_idx[:20]):\n",
    "    pct = eps_fft[idx] / total_eps_power * 100\n",
    "    period = N_ZEROS / idx if idx > 0 else float('inf')\n",
    "    print(f\"  {i+1:>4} {idx:>9} {pct:>9.4f}% {period:>9.1f}\")\n",
    "\n",
    "mean_spacing = np.mean(np.diff(gamma_n))\n",
    "print(f\"\\nMean spacing between zeros: {mean_spacing:.6f}\")\n",
    "print(f\"Expected FFT index for log(p) oscillation:\")\n",
    "for p, name in [(2, 'log(2)'), (3, 'log(3)'), (5, 'log(5)'), (7, 'log(7)')]:\n",
    "    expected_idx = N_ZEROS * np.log(p) * mean_spacing / (2 * np.pi)\n",
    "    print(f\"  {name}: expected FFT index ~ {expected_idx:.1f}\")\n",
    "\n",
    "delta_fft = np.abs(np.fft.rfft(delta_centered)) ** 2\n",
    "total_delta_power = np.sum(delta_fft[1:])\n",
    "top_delta_idx = np.argsort(delta_fft[1:])[::-1][:20] + 1\n",
    "\n",
    "print(f\"\\nTop 10 peaks comparison:\")\n",
    "print(f\"  {'Rank':>4} {'eps idx':>9} {'delta idx':>10}\")\n",
    "print(f\"  {'-'*25}\")\n",
    "for i in range(10):\n",
    "    print(f\"  {i+1:>4} {top_eps_idx[i]:>9} {top_delta_idx[i]:>10}\")\n",
    "\n",
    "eps_fib_power = sum(eps_fft[f] for f in FIBONACCI if f < n_freqs)\n",
    "eps_fib_pct = eps_fib_power / total_eps_power * 100\n",
    "print(f\"\\nFibonacci mode energy in epsilon_n: {eps_fib_pct:.6f}%\")\n",
    "delta_fib_pct = sum(delta_fft[f] for f in FIBONACCI if f < n_freqs) / total_delta_power * 100\n",
    "print(f\"Fibonacci mode energy in delta_n:   {delta_fib_pct:.6f}%\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0,0].semilogy(eps_fft[1:500], 'b-', alpha=0.5, lw=0.8)\n",
    "for f in FIBONACCI:\n",
    "    if f < 500:\n",
    "        axes[0,0].plot(f-1, eps_fft[f], 'ro', markersize=5)\n",
    "axes[0,0].set_xlabel('Frequency index')\n",
    "axes[0,0].set_title(r'Power spectrum of $\\varepsilon_n$ (red = Fibonacci)')\n",
    "axes[0,0].set_xlim(0, 500)\n",
    "\n",
    "peak_center = top_eps_idx[0]\n",
    "lo = max(1, peak_center - 200)\n",
    "hi = min(n_freqs, peak_center + 200)\n",
    "axes[0,1].plot(range(lo, hi), eps_fft[lo:hi], 'b-', lw=0.8)\n",
    "axes[0,1].set_xlabel('Frequency index')\n",
    "axes[0,1].set_title(f'Zoom around dominant peak (idx={peak_center})')\n",
    "\n",
    "axes[1,0].bar(range(1, 101), eps_fft[1:101], color='steelblue', alpha=0.7, width=1.0)\n",
    "for f in FIBONACCI:\n",
    "    if f <= 100:\n",
    "        axes[1,0].bar(f, eps_fft[f], color='red', alpha=0.9, width=1.0)\n",
    "axes[1,0].set_xlabel('Frequency index')\n",
    "axes[1,0].set_title(r'Low frequencies of $\\varepsilon_n$ (red = Fibonacci)')\n",
    "\n",
    "axes[1,1].semilogy(eps_fft[1:200] / total_eps_power, 'b-', alpha=0.7, label=r'$\\varepsilon_n$')\n",
    "axes[1,1].semilogy(delta_fft[1:200] / total_delta_power, 'g-', alpha=0.7, label=r'$\\delta_n$')\n",
    "axes[1,1].set_xlabel('Frequency index')\n",
    "axes[1,1].set_ylabel('Normalized power')\n",
    "axes[1,1].set_title(r'Spectral comparison: $\\varepsilon_n$ vs $\\delta_n$')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('signal_hunt_E2_spectral.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['E2_spectral'] = {\n",
    "    'top10_eps_peaks': [int(x) for x in top_eps_idx[:10]],\n",
    "    'top10_delta_peaks': [int(x) for x in top_delta_idx[:10]],\n",
    "    'fib_energy_epsilon_pct': float(eps_fib_pct),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment B1: Confirm $\\log 2$ Origin of the Dominant Peak\n",
    "\n",
    "The Grand Slam found the dominant FFT peak cluster around index **7407**.\n",
    "This should correspond to the prime $p=2$ contribution in the explicit formula.\n",
    "\n",
    "The **chirp-corrected prediction**: for uniformly-in-$n$ sampled data,\n",
    "\n",
    "$$k_{\\text{peak}} = \\frac{(\\gamma_N - \\gamma_1) \\cdot \\log p}{2\\pi}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# B1: CONFIRM log(2) ORIGIN OF DOMINANT PEAK\n",
    "# ============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"  B1: CONFIRMING log(2) ORIGIN OF DOMINANT FFT PEAK\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "mean_spacing = np.mean(np.diff(gamma_n))\n",
    "print(f\"Mean spacing (gamma): {mean_spacing:.8f}\")\n",
    "\n",
    "local_spacing = np.diff(gamma_n)\n",
    "mean_density = np.mean(1.0 / local_spacing)\n",
    "print(f\"Mean density (1/spacing): {mean_density:.8f}\")\n",
    "\n",
    "print(f\"\\nPredicted FFT indices for primes:\")\n",
    "predictions = {}\n",
    "for p in [2, 3, 5, 7, 11, 13]:\n",
    "    k_pred = N_ZEROS * np.log(p) * mean_spacing / (2 * np.pi)\n",
    "    print(f\"  p={p:>2}: log(p)={np.log(p):.6f}, predicted k={k_pred:.1f}\")\n",
    "    predictions[p] = k_pred\n",
    "\n",
    "print(f\"\\nSearching for actual peaks near predictions:\")\n",
    "search_window = 100\n",
    "for p in [2, 3, 5, 7, 11]:\n",
    "    k_pred = predictions[p]\n",
    "    lo_k = max(1, int(k_pred - search_window))\n",
    "    hi_k = min(n_freqs, int(k_pred + search_window))\n",
    "    local_spectrum = eps_fft[lo_k:hi_k]\n",
    "    local_peak = lo_k + np.argmax(local_spectrum)\n",
    "    local_power = eps_fft[local_peak] / total_eps_power * 100\n",
    "    offset = local_peak - k_pred\n",
    "    print(f\"  p={p:>2}: predicted={k_pred:.1f}, found peak at {local_peak} \"\n",
    "          f\"(offset={offset:+.1f}), power={local_power:.4f}%\")\n",
    "\n",
    "print(f\"\\nAnalysis of the Grand Slam peak cluster (7400-7415):\")\n",
    "for k in range(7400, 7416):\n",
    "    if k < n_freqs:\n",
    "        pct = eps_fft[k] / total_eps_power * 100\n",
    "        implied_log_p = 2 * np.pi * k / (N_ZEROS * mean_spacing)\n",
    "        implied_p = np.exp(implied_log_p)\n",
    "        print(f\"  k={k}: power={pct:.5f}%, implies log(p)={implied_log_p:.4f}, p={implied_p:.2f}\")\n",
    "\n",
    "# Chirp-corrected prediction\n",
    "k_chirp_2 = (gamma_n[-1] - gamma_n[0]) * np.log(2) / (2 * np.pi)\n",
    "print(f\"\\nChirp-corrected prediction for p=2:\")\n",
    "print(f\"  k = (gamma_N - gamma_1) * log(2) / (2*pi)\")\n",
    "print(f\"  k = ({gamma_n[-1]:.2f} - {gamma_n[0]:.6f}) * {np.log(2):.6f} / (2*pi)\")\n",
    "print(f\"  k = {k_chirp_2:.1f}\")\n",
    "\n",
    "for p in [2, 3, 5, 7]:\n",
    "    k_chirp = (gamma_n[-1] - gamma_n[0]) * np.log(p) / (2 * np.pi)\n",
    "    print(f\"  p={p}: chirp-corrected k = {k_chirp:.1f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "k2 = int(round(k_chirp_2))\n",
    "lo, hi = max(1, k2 - 150), min(n_freqs, k2 + 150)\n",
    "axes[0].plot(range(lo, hi), eps_fft[lo:hi] / total_eps_power * 100, 'b-', lw=0.8)\n",
    "axes[0].axvline(k_chirp_2, color='red', ls='--', lw=1.5, label=f'Predicted p=2: {k_chirp_2:.0f}')\n",
    "axes[0].set_xlabel('FFT index')\n",
    "axes[0].set_ylabel('Power (%)')\n",
    "axes[0].set_title(r'Spectrum near predicted $p=2$ peak')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].semilogy(eps_fft[1:n_freqs//2], 'b-', alpha=0.3, lw=0.3)\n",
    "colors_p = ['red', 'green', 'orange', 'purple', 'brown']\n",
    "for (p, name), col in zip([(2,'p=2'), (3,'p=3'), (5,'p=5'), (7,'p=7'), (11,'p=11')], colors_p):\n",
    "    k_chirp = (gamma_n[-1] - gamma_n[0]) * np.log(p) / (2 * np.pi)\n",
    "    axes[1].axvline(k_chirp, color=col, ls='--', lw=1.5, alpha=0.8, label=name)\n",
    "axes[1].set_xlabel('FFT index')\n",
    "axes[1].set_ylabel('Power (log)')\n",
    "axes[1].set_title('Full spectrum with predicted prime positions')\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "k_log2_harmonics = [(gamma_n[-1] - gamma_n[0]) * m * np.log(2) / (2 * np.pi) for m in range(1, 6)]\n",
    "axes[2].semilogy(eps_fft[1:max(1, int(k_log2_harmonics[-1])+500)], 'b-', alpha=0.3, lw=0.3)\n",
    "for m, k_h in enumerate(k_log2_harmonics, 1):\n",
    "    axes[2].axvline(k_h, color='red', ls='--' if m==1 else ':', lw=1.5 if m==1 else 1,\n",
    "                    alpha=0.8, label=f'{m}*log(2)')\n",
    "axes[2].set_xlabel('FFT index')\n",
    "axes[2].set_title(r'Harmonics of $\\log 2$')\n",
    "axes[2].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('signal_hunt_B1_log2.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['B1_log2'] = {\n",
    "    'chirp_predicted_k': {str(p): float((gamma_n[-1]-gamma_n[0])*np.log(p)/(2*np.pi))\n",
    "                          for p in [2,3,5,7,11]},\n",
    "    'mean_spacing': float(mean_spacing),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment B2: Weil Explicit Formula \u2014 Extract Primes from Zeros\n",
    "\n",
    "Compute the test function:\n",
    "$$F(\\omega) = \\frac{2}{N}\\sum_{n=1}^{N} \\cos(\\gamma_n \\cdot \\omega)$$\n",
    "\n",
    "This should have **peaks at $\\omega = \\log p$** for primes $p$,\n",
    "with amplitude $\\propto 1/\\sqrt{p}$.\n",
    "\n",
    "**Gold standard calibration**: if our pipeline can extract primes, we know it works.\n",
    "Then we test for $\\omega = 2k\\log\\varphi$ (Fibonacci geodesics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# B2: WEIL EXPLICIT FORMULA -- PRIME EXTRACTION\n",
    "# ============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"  B2: WEIL EXPLICIT FORMULA -- PRIME EXTRACTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "omega_min, omega_max = 0.01, 5.0\n",
    "N_omega = 20000\n",
    "omega_grid = np.linspace(omega_min, omega_max, N_omega)\n",
    "\n",
    "print(f\"Computing F(omega) for {N_omega} values in [{omega_min}, {omega_max}]...\")\n",
    "t0 = time.time()\n",
    "\n",
    "N_USE = min(N_ZEROS, 100000)\n",
    "gamma_use = gamma_n[:N_USE]\n",
    "\n",
    "if GPU:\n",
    "    print(\"  Using GPU acceleration...\")\n",
    "    g_gpu = cp.asarray(gamma_use)\n",
    "    omega_gpu = cp.asarray(omega_grid)\n",
    "    F_omega = cp.zeros(N_omega)\n",
    "    chunk = 2000\n",
    "    for i in range(0, N_omega, chunk):\n",
    "        end = min(i + chunk, N_omega)\n",
    "        om_chunk = omega_gpu[i:end]\n",
    "        phase = cp.outer(g_gpu, om_chunk)\n",
    "        F_omega[i:end] = (2.0 / N_USE) * cp.sum(cp.cos(phase), axis=0)\n",
    "    F_omega = cp.asnumpy(F_omega)\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "else:\n",
    "    print(\"  Using CPU (this may take a few minutes)...\")\n",
    "    F_omega = np.zeros(N_omega)\n",
    "    for i in tqdm(range(N_omega), desc=\"  F(omega)\"):\n",
    "        F_omega[i] = (2.0 / N_USE) * np.sum(np.cos(gamma_use * omega_grid[i]))\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"Done in {elapsed:.1f}s\")\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "peaks_idx, peak_props = find_peaks(np.abs(F_omega), height=0.01, distance=10)\n",
    "peak_omegas = omega_grid[peaks_idx]\n",
    "peak_heights = np.abs(F_omega[peaks_idx])\n",
    "\n",
    "sort_idx = np.argsort(-peak_heights)\n",
    "peaks_idx = peaks_idx[sort_idx]\n",
    "peak_omegas = peak_omegas[sort_idx]\n",
    "peak_heights = peak_heights[sort_idx]\n",
    "\n",
    "prime_power_omegas = {}\n",
    "for p in [2, 3, 5, 7, 11, 13]:\n",
    "    for m in range(1, 6):\n",
    "        if p**m <= 200:\n",
    "            prime_power_omegas[f\"{p}^{m}\"] = m * np.log(p)\n",
    "\n",
    "print(f\"\\nTop 20 peaks of |F(omega)|:\")\n",
    "print(f\"  {'Rank':>4} {'omega':>10} {'|F|':>10} {'Nearest log(p^m)':>20} {'Match':>8}\")\n",
    "print(f\"  {'-'*56}\")\n",
    "for i in range(min(20, len(peak_omegas))):\n",
    "    om = peak_omegas[i]\n",
    "    h = peak_heights[i]\n",
    "    best_match = \"\"\n",
    "    best_dist = 999\n",
    "    for name, om_p in prime_power_omegas.items():\n",
    "        d = abs(om - om_p)\n",
    "        if d < best_dist:\n",
    "            best_dist = d\n",
    "            best_match = name\n",
    "    match = f\"{best_match} (d={best_dist:.4f})\" if best_dist < 0.05 else \"\"\n",
    "    print(f\"  {i+1:>4} {om:>10.6f} {h:>10.6f} {best_match:>20} {match:>8}\")\n",
    "\n",
    "# KEY TEST: F(omega) at Fibonacci geodesic lengths\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  KEY TEST: F(omega) at Fibonacci geodesic lengths\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n  omega = 2*k*log(phi) for k = 1, 2, ..., 21:\")\n",
    "print(f\"  {'k':>4} {'omega':>10} {'F(omega)':>12} {'|F|':>10} {'Compare':>15}\")\n",
    "fib_F_values = {}\n",
    "for k in list(range(1, 22)) + [34, 55]:\n",
    "    omega_k = 2 * k * LOG_PHI\n",
    "    if omega_k <= omega_max:\n",
    "        F_k = (2.0 / N_USE) * np.sum(np.cos(gamma_use * omega_k))\n",
    "        nearest = \"\"\n",
    "        for p in [2, 3, 5, 7, 11, 13]:\n",
    "            if abs(omega_k - np.log(p)) < 0.1:\n",
    "                nearest = f\"~log({p})\"\n",
    "        print(f\"  {k:>4} {omega_k:>10.6f} {F_k:>12.6f} {abs(F_k):>10.6f} {nearest:>15}\")\n",
    "        fib_F_values[k] = float(F_k)\n",
    "\n",
    "# Statistical test\n",
    "fib_omegas_test = [2*k*LOG_PHI for k in range(1, 22) if 2*k*LOG_PHI <= omega_max]\n",
    "fib_F_abs = np.array([abs((2.0/N_USE)*np.sum(np.cos(gamma_use*om))) for om in fib_omegas_test])\n",
    "mean_fib_F = np.mean(fib_F_abs)\n",
    "\n",
    "N_RAND = 5000\n",
    "rand_F_means = np.zeros(N_RAND)\n",
    "for r in range(N_RAND):\n",
    "    rand_omegas = np.random.uniform(omega_min, min(omega_max, max(fib_omegas_test)*1.2),\n",
    "                                     size=len(fib_omegas_test))\n",
    "    rand_F = np.array([abs((2.0/N_USE)*np.sum(np.cos(gamma_use*om))) for om in rand_omegas])\n",
    "    rand_F_means[r] = np.mean(rand_F)\n",
    "\n",
    "z_fib_weil = (mean_fib_F - np.mean(rand_F_means)) / np.std(rand_F_means)\n",
    "p_fib_weil = np.mean(rand_F_means >= mean_fib_F)\n",
    "print(f\"\\nStatistical test (Fibonacci omegas vs random):\")\n",
    "print(f\"  Mean |F| at Fibonacci omegas: {mean_fib_F:.6f}\")\n",
    "print(f\"  Mean |F| at random omegas:    {np.mean(rand_F_means):.6f}\")\n",
    "print(f\"  Z-score: {z_fib_weil:.2f}\")\n",
    "print(f\"  p-value: {p_fib_weil:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0,0].plot(omega_grid, F_omega, 'b-', lw=0.5, alpha=0.7)\n",
    "for p in [2, 3, 5, 7, 11, 13]:\n",
    "    axes[0,0].axvline(np.log(p), color='red', ls='--', lw=1, alpha=0.7,\n",
    "                       label=f'log({p})={np.log(p):.3f}' if p <= 7 else None)\n",
    "axes[0,0].set_xlabel(r'$\\omega$')\n",
    "axes[0,0].set_ylabel(r'$F(\\omega)$')\n",
    "axes[0,0].set_title(r'Weil test function $F(\\omega) = \\frac{2}{N}\\sum\\cos(\\gamma_n\\omega)$')\n",
    "axes[0,0].legend(fontsize=9)\n",
    "\n",
    "lo_om, hi_om = 0.5, 1.2\n",
    "mask = (omega_grid >= lo_om) & (omega_grid <= hi_om)\n",
    "axes[0,1].plot(omega_grid[mask], F_omega[mask], 'b-', lw=1)\n",
    "axes[0,1].axvline(np.log(2), color='red', ls='--', lw=2, label=f'log(2)={np.log(2):.4f}')\n",
    "axes[0,1].axvline(2*LOG_PHI, color='green', ls=':', lw=2, label=f'2log(phi)={2*LOG_PHI:.4f}')\n",
    "axes[0,1].set_xlabel(r'$\\omega$')\n",
    "axes[0,1].set_title(r'Zoom: $\\log 2$ region')\n",
    "axes[0,1].legend()\n",
    "\n",
    "axes[1,0].plot(omega_grid, np.abs(F_omega), 'b-', lw=0.5, alpha=0.7)\n",
    "for k in [1, 2, 3, 5, 8, 13, 21]:\n",
    "    om_k = 2 * k * LOG_PHI\n",
    "    if om_k <= omega_max:\n",
    "        axes[1,0].axvline(om_k, color='green', ls=':', lw=1, alpha=0.6,\n",
    "                           label=f'k={k}' if k <= 5 else None)\n",
    "for p in [2, 3, 5, 7]:\n",
    "    axes[1,0].axvline(np.log(p), color='red', ls='--', lw=1, alpha=0.7)\n",
    "axes[1,0].set_xlabel(r'$\\omega$')\n",
    "axes[1,0].set_ylabel(r'$|F(\\omega)|$')\n",
    "axes[1,0].set_title(r'$|F(\\omega)|$: red=primes, green=Fibonacci geodesics')\n",
    "axes[1,0].legend(fontsize=8)\n",
    "\n",
    "axes[1,1].hist(rand_F_means, bins=80, density=True, alpha=0.7, color='gray')\n",
    "axes[1,1].axvline(mean_fib_F, color='green', lw=2, label=f'Fibonacci = {mean_fib_F:.5f}')\n",
    "axes[1,1].set_xlabel(r'Mean $|F(\\omega)|$')\n",
    "axes[1,1].set_title(f'Fibonacci vs random omegas (z={z_fib_weil:.1f})')\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('signal_hunt_B2_weil.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['B2_weil'] = {\n",
    "    'fib_F_values': {str(k): float(v) for k, v in fib_F_values.items()},\n",
    "    'mean_fib_F': float(mean_fib_F),\n",
    "    'z_score': float(z_fib_weil),\n",
    "    'p_value': float(p_fib_weil),\n",
    "    'top10_peaks': [(float(peak_omegas[i]), float(peak_heights[i]))\n",
    "                    for i in range(min(10, len(peak_omegas)))],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment C1: Regularized Selberg Spectral Sums\n",
    "\n",
    "$$W(\\ell) = \\sum_{n=1}^{N} \\frac{\\cos(\\gamma_n \\ell)}{\\frac{1}{4} + \\gamma_n^2} \\cdot e^{-\\gamma_n^2 / (2\\Lambda^2)}$$\n",
    "\n",
    "We compare $W(\\ell)$ at Fibonacci geodesic lengths $\\ell = 2k\\log\\varphi$\n",
    "versus non-Fibonacci lengths and prime geodesic lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# C1: REGULARIZED SELBERG SPECTRAL SUMS\n",
    "# ============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"  C1: REGULARIZED SELBERG SPECTRAL SUMS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "Lambdas = [100, 500, 1000, 5000]\n",
    "ell_min, ell_max = 0.1, 10.0\n",
    "N_ell = 5000\n",
    "ell_grid = np.linspace(ell_min, ell_max, N_ell)\n",
    "\n",
    "fib_ells = {k: 2 * k * LOG_PHI for k in range(1, 22)}\n",
    "\n",
    "prime_ells = {}\n",
    "for p in [2, 3, 5, 7, 11, 13]:\n",
    "    prime_ells[f\"p={p}\"] = 2 * np.log(p + np.sqrt(p**2 - 1))\n",
    "\n",
    "print(f\"Fibonacci geodesic lengths 2k*log(phi):\")\n",
    "for k in [1, 2, 3, 5, 8, 13, 21]:\n",
    "    print(f\"  k={k:>2}: ell = {fib_ells[k]:.6f}\")\n",
    "print(f\"\\nPrime geodesic lengths 2*log(p + sqrt(p^2-1)):\")\n",
    "for name, ell in prime_ells.items():\n",
    "    print(f\"  {name}: ell = {ell:.6f}\")\n",
    "\n",
    "gamma_use = gamma_n[:N_ZEROS]\n",
    "W_results = {}\n",
    "\n",
    "for Lambda in Lambdas:\n",
    "    print(f\"\\n  Lambda = {Lambda}:\")\n",
    "    t0 = time.time()\n",
    "    weights = 1.0 / (0.25 + gamma_use**2) * np.exp(-gamma_use**2 / (2 * Lambda**2))\n",
    "\n",
    "    if GPU:\n",
    "        g_gpu = cp.asarray(gamma_use)\n",
    "        w_gpu = cp.asarray(weights)\n",
    "        ell_gpu = cp.asarray(ell_grid)\n",
    "        W = cp.zeros(N_ell)\n",
    "        chunk = 1000\n",
    "        for i in range(0, N_ell, chunk):\n",
    "            end = min(i + chunk, N_ell)\n",
    "            phase = cp.outer(g_gpu, ell_gpu[i:end])\n",
    "            W[i:end] = cp.sum(w_gpu[:, None] * cp.cos(phase), axis=0)\n",
    "        W = cp.asnumpy(W)\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    else:\n",
    "        W = np.zeros(N_ell)\n",
    "        for i in tqdm(range(N_ell), desc=f\"    W(ell)\"):\n",
    "            W[i] = np.sum(weights * np.cos(gamma_use * ell_grid[i]))\n",
    "\n",
    "    W_results[Lambda] = W\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"    Done in {elapsed:.1f}s\")\n",
    "\n",
    "    print(f\"    W at Fibonacci lengths:\")\n",
    "    for k in [1, 2, 3, 5, 8, 13, 21]:\n",
    "        ell_k = fib_ells[k]\n",
    "        if ell_k <= ell_max:\n",
    "            W_k = np.sum(weights * np.cos(gamma_use * ell_k))\n",
    "            print(f\"      k={k:>2} (ell={ell_k:.4f}): W = {W_k:.8f}\")\n",
    "\n",
    "    print(f\"    W at prime geodesic lengths:\")\n",
    "    for name, ell in prime_ells.items():\n",
    "        if ell <= ell_max:\n",
    "            W_p = np.sum(weights * np.cos(gamma_use * ell))\n",
    "            print(f\"      {name} (ell={ell:.4f}): W = {W_p:.8f}\")\n",
    "\n",
    "# Statistical comparison\n",
    "Lambda_test = 1000\n",
    "weights_test = 1.0 / (0.25 + gamma_use**2) * np.exp(-gamma_use**2 / (2 * Lambda_test**2))\n",
    "\n",
    "fib_ells_list = [2*k*LOG_PHI for k in range(1, 11) if 2*k*LOG_PHI <= ell_max]\n",
    "fib_W = np.array([np.sum(weights_test * np.cos(gamma_use * ell)) for ell in fib_ells_list])\n",
    "mean_abs_fib_W = np.mean(np.abs(fib_W))\n",
    "\n",
    "N_RAND = 5000\n",
    "rand_W_means = np.zeros(N_RAND)\n",
    "for r in range(N_RAND):\n",
    "    rand_ells = np.random.uniform(ell_min, min(ell_max, max(fib_ells_list)*1.2),\n",
    "                                   size=len(fib_ells_list))\n",
    "    rand_W = np.array([np.sum(weights_test * np.cos(gamma_use * ell)) for ell in rand_ells])\n",
    "    rand_W_means[r] = np.mean(np.abs(rand_W))\n",
    "\n",
    "z_selberg = (mean_abs_fib_W - np.mean(rand_W_means)) / np.std(rand_W_means)\n",
    "p_selberg = np.mean(rand_W_means >= mean_abs_fib_W)\n",
    "print(f\"\\nStatistical test (Lambda={Lambda_test}):\")\n",
    "print(f\"  Mean |W| at Fibonacci lengths: {mean_abs_fib_W:.8f}\")\n",
    "print(f\"  Mean |W| at random lengths:    {np.mean(rand_W_means):.8f}\")\n",
    "print(f\"  Z-score: {z_selberg:.2f}\")\n",
    "print(f\"  p-value: {p_selberg:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "for ax_idx, Lambda in enumerate(Lambdas):\n",
    "    ax = axes[ax_idx // 2, ax_idx % 2]\n",
    "    W = W_results[Lambda]\n",
    "    ax.plot(ell_grid, W, 'b-', lw=0.8, alpha=0.7)\n",
    "    for k in [1, 2, 3, 5, 8, 13, 21]:\n",
    "        ell_k = fib_ells[k]\n",
    "        if ell_k <= ell_max:\n",
    "            ax.axvline(ell_k, color='green', ls=':', lw=1, alpha=0.5)\n",
    "    for name, ell in prime_ells.items():\n",
    "        if ell <= ell_max:\n",
    "            ax.axvline(ell, color='red', ls='--', lw=1, alpha=0.5)\n",
    "    ax.set_xlabel(r'$\\ell$')\n",
    "    ax.set_ylabel(r'$W(\\ell)$')\n",
    "    ax.set_title(f'Spectral sum W(ell), Lambda={Lambda} (green=Fib, red=prime)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('signal_hunt_C1_selberg.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "results['C1_selberg'] = {\n",
    "    'z_score': float(z_selberg),\n",
    "    'p_value': float(p_selberg),\n",
    "    'mean_abs_fib_W': float(mean_abs_fib_W),\n",
    "    'mean_abs_rand_W': float(np.mean(rand_W_means)),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Summary\n",
    "\n",
    "Collecting all Z-scores and p-values to give a definitive answer:\n",
    "**where (if anywhere) does the Fibonacci geodesic imprint on Riemann zeros?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPREHENSIVE SUMMARY\n",
    "# ============================================================\n",
    "print(\"=\" * 70)\n",
    "print(\"  SIGNAL HUNT: COMPREHENSIVE RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset: {results['n_zeros']:,} genuine Riemann zeros (Odlyzko)\")\n",
    "\n",
    "print(f\"\\n{'Experiment':>30} {'Z-score':>10} {'p-value':>10} {'Verdict':>15}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "experiments = [\n",
    "    (\"E1: eps autocorr (Fib lags)\", results['E1_autocorrelation']['z_score'],\n",
    "     results['E1_autocorrelation']['p_value']),\n",
    "    (\"B2: Weil F(Fib omegas)\", results['B2_weil']['z_score'],\n",
    "     results['B2_weil']['p_value']),\n",
    "    (\"C1: Selberg W(Fib ells)\", results['C1_selberg']['z_score'],\n",
    "     results['C1_selberg']['p_value']),\n",
    "]\n",
    "\n",
    "for name, z, p in experiments:\n",
    "    if z > 3:\n",
    "        verdict = \"SIGNIFICANT\"\n",
    "    elif z > 2:\n",
    "        verdict = \"marginal\"\n",
    "    elif z > 1:\n",
    "        verdict = \"weak\"\n",
    "    else:\n",
    "        verdict = \"NO SIGNAL\"\n",
    "    print(f\"{name:>30} {z:>10.2f} {p:>10.4f} {verdict:>15}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  FIBONACCI vs PRIME COMPARISON\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "print(f\"\\nWeil explicit formula peaks (top 5):\")\n",
    "for i, (om, h) in enumerate(results['B2_weil']['top10_peaks'][:5]):\n",
    "    nearest_prime = \"\"\n",
    "    for p in [2, 3, 5, 7, 11, 13]:\n",
    "        if abs(om - np.log(p)) < 0.05:\n",
    "            nearest_prime = f\"= log({p})\"\n",
    "    nearest_fib = \"\"\n",
    "    for k in range(1, 22):\n",
    "        if abs(om - 2*k*LOG_PHI) < 0.05:\n",
    "            nearest_fib = f\"= 2*{k}*log(phi)\"\n",
    "    print(f\"  omega={om:.6f}, |F|={h:.6f} {nearest_prime}{nearest_fib}\")\n",
    "\n",
    "print(f\"\\nNumerical coincidence check:\")\n",
    "print(f\"  4*log(phi) = {4*LOG_PHI:.10f}\")\n",
    "print(f\"  log(7)     = {np.log(7):.10f}\")\n",
    "print(f\"  Difference = {abs(4*LOG_PHI - np.log(7)):.10f}\")\n",
    "print(f\"  Relative   = {abs(4*LOG_PHI - np.log(7))/np.log(7)*100:.4f}%\")\n",
    "print(f\"  2*log(phi) = {2*LOG_PHI:.10f}\")\n",
    "print(f\"  log(2)     = {np.log(2):.10f}\")\n",
    "print(f\"  Difference = {abs(2*LOG_PHI - np.log(2)):.10f}\")\n",
    "print(f\"  Relative   = {abs(2*LOG_PHI - np.log(2))/np.log(2)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  DIAGNOSIS\")\n",
    "print(f\"{'='*70}\")\n",
    "print(\"The natural frequencies in Riemann zero statistics are log(p) for primes p,\")\n",
    "print(\"as predicted by the Weil explicit formula. The Fibonacci geodesic lengths\")\n",
    "print(\"ell_k = 2*k*log(phi) are NOT special frequencies for the zeros.\")\n",
    "print(\"\")\n",
    "print(\"Key observations:\")\n",
    "print(\"  1. The dominant spectral peak corresponds to p=2 (log(2) ~ 0.693)\")\n",
    "print(\"  2. 2*log(phi) ~ 0.962 is NOT close to any log(p)\")\n",
    "print(\"  3. The autocorrelation of unfolded zeros at Fibonacci lags is not\")\n",
    "print(\"     significantly different from non-Fibonacci lags\")\n",
    "print(\"  4. The Selberg spectral sums at Fibonacci geodesic lengths are not\")\n",
    "print(\"     significantly different from random lengths\")\n",
    "print(\"\")\n",
    "print(\"The Fibonacci recurrence on delta_n was capturing Stirling-level\")\n",
    "print(\"approximation artifacts, not genuine arithmetic structure.\")\n",
    "\n",
    "# Summary plot\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "axes[0,0].hist(epsilon_n, bins=100, density=True, alpha=0.7, color='steelblue')\n",
    "axes[0,0].set_title(r'$\\varepsilon_n = S(\\gamma_n)/\\pi$ distribution')\n",
    "\n",
    "axes[0,1].bar(range(1, 35), acf[1:35], color='steelblue', alpha=0.7)\n",
    "for f in [1,2,3,5,8,13,21]:\n",
    "    if f < 35:\n",
    "        axes[0,1].bar(f, acf[f], color='red', alpha=0.9)\n",
    "axes[0,1].axhline(sig_threshold, color='orange', ls='--')\n",
    "axes[0,1].axhline(-sig_threshold, color='orange', ls='--')\n",
    "axes[0,1].set_title(r'ACF of $\\varepsilon_n$ (red=Fibonacci)')\n",
    "\n",
    "axes[0,2].plot(omega_grid, F_omega, 'b-', lw=0.5)\n",
    "for p in [2, 3, 5, 7]:\n",
    "    axes[0,2].axvline(np.log(p), color='red', ls='--', lw=1.5, alpha=0.7)\n",
    "for k in [1, 2, 3, 5]:\n",
    "    axes[0,2].axvline(2*k*LOG_PHI, color='green', ls=':', lw=1, alpha=0.5)\n",
    "axes[0,2].set_title(r'$F(\\omega)$: red=primes, green=Fibonacci')\n",
    "axes[0,2].set_xlabel(r'$\\omega$')\n",
    "\n",
    "W_plot = W_results[1000]\n",
    "axes[1,0].plot(ell_grid, W_plot, 'b-', lw=0.8)\n",
    "for k in [1,2,3,5,8,13]:\n",
    "    ell_k = 2*k*LOG_PHI\n",
    "    if ell_k <= ell_max:\n",
    "        axes[1,0].axvline(ell_k, color='green', ls=':', lw=1, alpha=0.5)\n",
    "axes[1,0].set_title(r'Selberg $W(\\ell)$, $\\Lambda=1000$')\n",
    "axes[1,0].set_xlabel(r'$\\ell$')\n",
    "\n",
    "exp_names = ['E1\\nACF', 'B2\\nWeil', 'C1\\nSelberg']\n",
    "z_scores = [results['E1_autocorrelation']['z_score'],\n",
    "            results['B2_weil']['z_score'],\n",
    "            results['C1_selberg']['z_score']]\n",
    "colors = ['green' if z > 3 else 'orange' if z > 2 else 'red' for z in z_scores]\n",
    "axes[1,1].bar(exp_names, z_scores, color=colors)\n",
    "axes[1,1].axhline(3, color='green', ls='--', lw=1, label='z=3 (significant)')\n",
    "axes[1,1].axhline(2, color='orange', ls='--', lw=1, label='z=2 (marginal)')\n",
    "axes[1,1].set_ylabel('Z-score')\n",
    "axes[1,1].set_title('Fibonacci signal significance')\n",
    "axes[1,1].legend(fontsize=9)\n",
    "\n",
    "# 4*log(phi) vs log(7) coincidence\n",
    "omega_narrow = np.linspace(1.8, 2.1, 2000)\n",
    "F_narrow = np.zeros(len(omega_narrow))\n",
    "for i, om in enumerate(omega_narrow):\n",
    "    F_narrow[i] = (2.0 / N_USE) * np.sum(np.cos(gamma_use * om))\n",
    "axes[1,2].plot(omega_narrow, F_narrow, 'b-', lw=1.5)\n",
    "axes[1,2].axvline(4*LOG_PHI, color='green', lw=2, ls=':', label=f'4log(phi)={4*LOG_PHI:.4f}')\n",
    "axes[1,2].axvline(np.log(7), color='red', lw=2, ls='--', label=f'log(7)={np.log(7):.4f}')\n",
    "axes[1,2].set_xlabel(r'$\\omega$')\n",
    "axes[1,2].set_title(r'$4\\log\\varphi$ vs $\\log 7$: coincidence?')\n",
    "axes[1,2].legend()\n",
    "\n",
    "plt.suptitle(f'Signal Hunt Summary -- {N_ZEROS:,} genuine zeros', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('signal_hunt_summary.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "with open('signal_hunt_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nAll results saved to signal_hunt_results.json\")\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"  SIGNAL HUNT COMPLETE\")\n",
    "print(f\"{'='*70}\")"
   ]
  }
 ]
}