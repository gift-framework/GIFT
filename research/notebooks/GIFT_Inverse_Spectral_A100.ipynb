{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probl√®me Spectral Inverse: Des Z√©ros √† l'Op√©rateur\n",
    "\n",
    "## Philosophie\n",
    "\n",
    "**Question centrale**: Si les z√©ros de Riemann Œ≥‚Çô SONT les valeurs propres d'un op√©rateur H,\n",
    "peut-on RECONSTRUIRE H √† partir des Œ≥‚Çô et v√©rifier qu'il a la structure GIFT?\n",
    "\n",
    "### Approche Montgomery-GIFT\n",
    "\n",
    "Montgomery (1973) a montr√© que les z√©ros de Riemann ont des corr√©lations GUE (Gaussian Unitary Ensemble).\n",
    "Mais ceci est un comportement UNIVERSEL qui masque la fine structure.\n",
    "\n",
    "**Notre hypoth√®se**: Sous les corr√©lations GUE, il existe une structure DISCR√àTE aux lags {5, 8, 13, 27}.\n",
    "\n",
    "### M√©thode\n",
    "\n",
    "1. **Matrice de corr√©lation** C[i,j] = corr(Œ≥·µ¢, Œ≥‚±º) des z√©ros\n",
    "2. **Extraction de structure** aux lags GIFT\n",
    "3. **Reconstruction de H** tel que spec(H) ‚âà {Œ≥‚Çô}\n",
    "4. **V√©rification** de la contrainte 8√óH‚Çà = 13√óH‚ÇÅ‚ÇÉ = 36\n",
    "\n",
    "---\n",
    "\n",
    "**GPU**: A100 fortement recommand√© (matrices denses de grande taille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation Colab\n",
    "# !pip install cupy-cuda12x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# GPU Setup\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU_AVAILABLE = True\n",
    "    print(f\"‚úÖ CuPy disponible\")\n",
    "    device_props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    print(f\"   Device: {device_props['name'].decode()}\")\n",
    "    print(f\"   Memory: {device_props['totalGlobalMem'] / 1e9:.1f} GB\")\n",
    "    mempool = cp.get_default_memory_pool()\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  CuPy non disponible\")\n",
    "\n",
    "xp = cp if GPU_AVAILABLE else np\n",
    "print(f\"Backend: {'GPU' if GPU_AVAILABLE else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes GIFT\n",
    "@dataclass\n",
    "class GIFT:\n",
    "    # Lags structurels\n",
    "    LAGS: tuple = (5, 8, 13, 27)\n",
    "    \n",
    "    # Contrainte G‚ÇÇ\n",
    "    H_G2_SQUARED: int = 36  # h_G‚ÇÇ¬≤ = 6¬≤ = 36\n",
    "    \n",
    "    # Topologie K‚Çá\n",
    "    H_STAR: int = 99       # b‚ÇÇ + b‚ÇÉ + 1\n",
    "    DIM_G2: int = 14       # Dimension de G‚ÇÇ\n",
    "    B2: int = 21           # Second Betti number\n",
    "    B3: int = 77           # Third Betti number\n",
    "    \n",
    "    # Alg√®bre\n",
    "    DIM_J3O: int = 27      # Exceptional Jordan algebra\n",
    "    RANK_E8: int = 8       # Rang de E‚Çà\n",
    "    WEYL: int = 5          # Weyl dimension\n",
    "    F7: int = 13           # 7th Fibonacci\n",
    "\n",
    "gift = GIFT()\n",
    "print(f\"GIFT Lags: {gift.LAGS}\")\n",
    "print(f\"Contrainte: 8√óŒ≤‚Çà = 13√óŒ≤‚ÇÅ‚ÇÉ = {gift.H_G2_SQUARED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Chargement des Z√©ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zeros(filepath: str = 'zeros1') -> np.ndarray:\n",
    "    \"\"\"Charge les z√©ros depuis un fichier.\"\"\"\n",
    "    zeros = []\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    try:\n",
    "                        val = float(line.split()[0])\n",
    "                        if val > 0:\n",
    "                            zeros.append(val)\n",
    "                    except:\n",
    "                        continue\n",
    "        return np.array(sorted(set(zeros)))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Fichier {filepath} non trouv√©\")\n",
    "        return None\n",
    "\n",
    "def load_zeros_colab():\n",
    "    \"\"\"Upload interactif pour Colab.\"\"\"\n",
    "    from google.colab import files\n",
    "    print(\"üì§ Upload vos fichiers de z√©ros...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    all_zeros = []\n",
    "    for filename, content in uploaded.items():\n",
    "        for line in content.decode('utf-8').split('\\n'):\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#'):\n",
    "                try:\n",
    "                    all_zeros.append(float(line.split()[0]))\n",
    "                except:\n",
    "                    continue\n",
    "    return np.array(sorted(set(all_zeros)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement\n",
    "gamma_np = load_zeros('zeros1')\n",
    "if gamma_np is None:\n",
    "    try:\n",
    "        gamma_np = load_zeros_colab()\n",
    "    except:\n",
    "        # Donn√©es de test (premiers z√©ros connus)\n",
    "        gamma_np = np.array([\n",
    "            14.134725, 21.022040, 25.010858, 30.424876, 32.935062,\n",
    "            37.586178, 40.918720, 43.327073, 48.005151, 49.773832,\n",
    "            52.970321, 56.446248, 59.347044, 60.831779, 65.112544,\n",
    "            67.079811, 69.546402, 72.067158, 75.704691, 77.144840\n",
    "        ])  # 20 premiers z√©ros exacts\n",
    "\n",
    "N_ZEROS = len(gamma_np)\n",
    "print(f\"\\n‚úÖ {N_ZEROS:,} z√©ros charg√©s\")\n",
    "print(f\"   Œ≥‚ÇÅ = {gamma_np[0]:.6f}\")\n",
    "print(f\"   Œ≥‚ÇÅ‚ÇÄ‚ÇÄ = {gamma_np[99]:.6f}\" if N_ZEROS > 100 else \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Analyse de la Structure de Corr√©lation\n",
    "\n",
    "### Hypoth√®se Montgomery-GIFT\n",
    "\n",
    "Les corr√©lations pair-√†-pair des z√©ros devraient r√©v√©ler une structure aux lags GIFT:\n",
    "\n",
    "$$C(k) = \\langle \\delta\\gamma_n \\cdot \\delta\\gamma_{n-k} \\rangle$$\n",
    "\n",
    "o√π $\\delta\\gamma_n = \\gamma_n - \\langle\\gamma\\rangle_{local}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lag_correlations(gamma: np.ndarray, max_lag: int = 50) -> Dict:\n",
    "    \"\"\"\n",
    "    Calcule les corr√©lations aux diff√©rents lags.\n",
    "    \n",
    "    C(k) = corr(Œ≥‚Çô, Œ≥‚Çô‚Çã‚Çñ) apr√®s normalisation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSE DES CORR√âLATIONS AUX LAGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    N = len(gamma)\n",
    "    \n",
    "    # Normalisation: √©carts √† l'espacement moyen local\n",
    "    spacings = np.diff(gamma)\n",
    "    mean_spacing_local = np.convolve(spacings, np.ones(10)/10, mode='same')\n",
    "    delta_gamma = spacings - mean_spacing_local\n",
    "    \n",
    "    correlations = {}\n",
    "    \n",
    "    for lag in range(1, max_lag + 1):\n",
    "        if lag < len(delta_gamma):\n",
    "            x = delta_gamma[lag:]\n",
    "            y = delta_gamma[:-lag]\n",
    "            \n",
    "            if len(x) > 10:\n",
    "                corr = np.corrcoef(x, y)[0, 1]\n",
    "                correlations[lag] = float(corr) if not np.isnan(corr) else 0.0\n",
    "    \n",
    "    # Affichage aux lags GIFT\n",
    "    print(f\"\\nüìä Corr√©lations aux lags GIFT:\")\n",
    "    print(f\"{'Lag':<8} {'Corr':>12} {'|Corr|':>12} {'Significance':>15}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Baseline: moyenne des corr√©lations non-GIFT\n",
    "    non_gift_corrs = [abs(c) for lag, c in correlations.items() if lag not in gift.LAGS]\n",
    "    baseline = np.mean(non_gift_corrs) if non_gift_corrs else 0\n",
    "    baseline_std = np.std(non_gift_corrs) if non_gift_corrs else 1\n",
    "    \n",
    "    gift_results = []\n",
    "    for lag in gift.LAGS:\n",
    "        if lag in correlations:\n",
    "            corr = correlations[lag]\n",
    "            z_score = (abs(corr) - baseline) / baseline_std if baseline_std > 0 else 0\n",
    "            sig = \"‚òÖ‚òÖ‚òÖ\" if z_score > 3 else \"‚òÖ‚òÖ\" if z_score > 2 else \"‚òÖ\" if z_score > 1 else \"\"\n",
    "            print(f\"{lag:<8} {corr:>12.4f} {abs(corr):>12.4f} {sig:>15}\")\n",
    "            gift_results.append({'lag': lag, 'corr': corr, 'z_score': z_score})\n",
    "    \n",
    "    print(f\"\\n   Baseline (non-GIFT): {baseline:.4f} ¬± {baseline_std:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'all_correlations': correlations,\n",
    "        'gift_lags': gift_results,\n",
    "        'baseline': baseline,\n",
    "        'baseline_std': baseline_std\n",
    "    }\n",
    "\n",
    "corr_results = compute_lag_correlations(gamma_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Reconstruction de l'Op√©rateur H (Probl√®me Inverse)\n",
    "\n",
    "### M√©thode 1: Jacobi Inverse\n",
    "\n",
    "Pour une matrice tridiagonale sym√©trique avec valeurs propres connues,\n",
    "on peut reconstruire la matrice via l'algorithme de Lanczos inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_jacobi_matrix(eigenvalues: np.ndarray, n_keep: int = None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Reconstruit une matrice de Jacobi (tridiagonale sym√©trique) \n",
    "    √† partir de ses valeurs propres.\n",
    "    \n",
    "    Utilise la formule des polyn√¥mes orthogonaux:\n",
    "    P_{n+1}(x) = (x - Œ±‚Çô)P‚Çô(x) - Œ≤‚Çô¬≤P‚Çô‚Çã‚ÇÅ(x)\n",
    "    \n",
    "    o√π Œ±‚Çô = diagonale, Œ≤‚Çô = sous-diagonale\n",
    "    \n",
    "    Returns:\n",
    "        (alpha, beta): coefficients de la matrice tridiagonale\n",
    "    \"\"\"\n",
    "    if n_keep is None:\n",
    "        n_keep = len(eigenvalues)\n",
    "    \n",
    "    Œª = np.sort(eigenvalues[:n_keep])\n",
    "    n = len(Œª)\n",
    "    \n",
    "    # M√©thode des moments\n",
    "    # Œº‚Çñ = Œ£·µ¢ Œª·µ¢·µè (moments spectraux)\n",
    "    moments = np.array([np.sum(Œª**k) for k in range(2*n)])\n",
    "    \n",
    "    # Matrice de Hankel des moments\n",
    "    H = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            H[i, j] = moments[i + j]\n",
    "    \n",
    "    # Factorisation de Cholesky (si d√©finie positive)\n",
    "    try:\n",
    "        # R√©gularisation pour stabilit√© num√©rique\n",
    "        H_reg = H + 1e-10 * np.eye(n)\n",
    "        L = np.linalg.cholesky(H_reg)\n",
    "        \n",
    "        # Extraction des coefficients\n",
    "        alpha = np.zeros(n)\n",
    "        beta = np.zeros(n - 1)\n",
    "        \n",
    "        # Œ±‚ÇÄ = Œº‚ÇÅ/Œº‚ÇÄ = moyenne des valeurs propres\n",
    "        alpha[0] = moments[1] / moments[0]\n",
    "        \n",
    "        for k in range(1, n):\n",
    "            # R√©currence pour Œ±‚Çñ et Œ≤‚Çñ\n",
    "            if k < n:\n",
    "                alpha[k] = L[k, k]**2 / L[k-1, k-1]**2 * alpha[k-1] if L[k-1, k-1] != 0 else alpha[k-1]\n",
    "            if k < n:\n",
    "                beta[k-1] = L[k, k-1] / L[k-1, k-1] if L[k-1, k-1] != 0 else 0\n",
    "        \n",
    "        return alpha, beta\n",
    "        \n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"‚ö†Ô∏è  Matrice de Hankel non d√©finie positive, utilisation de m√©thode alternative\")\n",
    "        # M√©thode simple: moyenne mobile\n",
    "        alpha = np.zeros(n)\n",
    "        beta = np.zeros(n - 1)\n",
    "        \n",
    "        for i in range(n):\n",
    "            alpha[i] = Œª[i]  # Approximation grossi√®re\n",
    "        for i in range(n - 1):\n",
    "            beta[i] = (Œª[i+1] - Œª[i]) / 2  # Espacement\n",
    "        \n",
    "        return alpha, beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de reconstruction\n",
    "N_test = min(100, N_ZEROS)\n",
    "alpha, beta = reconstruct_jacobi_matrix(gamma_np, n_keep=N_test)\n",
    "\n",
    "print(f\"\\nüìä Matrice de Jacobi reconstruite ({N_test}√ó{N_test}):\")\n",
    "print(f\"   Œ± (diagonale): mean = {np.mean(alpha):.2f}, std = {np.std(alpha):.2f}\")\n",
    "print(f\"   Œ≤ (sous-diag): mean = {np.mean(beta):.2f}, std = {np.std(beta):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Extraction de la Structure GIFT\n",
    "\n",
    "### Analyse des √©l√©ments de matrice aux positions {5, 8, 13, 27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gift_structure_in_matrix(gamma: np.ndarray, N_matrix: int = 200) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyse si la matrice de corr√©lation des z√©ros\n",
    "    pr√©sente une structure aux positions GIFT.\n",
    "    \n",
    "    Construit:\n",
    "    M[i,j] = (Œ≥·µ¢ - ‚ü®Œ≥‚ü©)(Œ≥‚±º - ‚ü®Œ≥‚ü©) / œÉ¬≤\n",
    "    \n",
    "    Et examine les bandes aux lags {5, 8, 13, 27}\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STRUCTURE GIFT DANS LA MATRICE DE CORR√âLATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    Œ≥ = gamma[:N_matrix]\n",
    "    N = len(Œ≥)\n",
    "    \n",
    "    # Normalisation\n",
    "    Œ≥_mean = np.mean(Œ≥)\n",
    "    Œ≥_std = np.std(Œ≥)\n",
    "    Œ≥_norm = (Œ≥ - Œ≥_mean) / Œ≥_std\n",
    "    \n",
    "    # Matrice de corr√©lation\n",
    "    M = np.outer(Œ≥_norm, Œ≥_norm)\n",
    "    \n",
    "    # Extraction des bandes\n",
    "    band_values = {}\n",
    "    for lag in gift.LAGS:\n",
    "        if lag < N:\n",
    "            # √âl√©ments de la bande k-diagonale\n",
    "            band = np.array([M[i, i-lag] for i in range(lag, N)])\n",
    "            band_values[lag] = {\n",
    "                'mean': float(np.mean(band)),\n",
    "                'std': float(np.std(band)),\n",
    "                'product_with_lag': float(lag * np.mean(band))\n",
    "            }\n",
    "    \n",
    "    # V√©rification de la contrainte 8√óM‚Çà = 13√óM‚ÇÅ‚ÇÉ = 36\n",
    "    print(f\"\\nüìä Valeurs moyennes des bandes GIFT:\")\n",
    "    print(f\"{'Lag':<8} {'Mean M_k':>12} {'k √ó M_k':>12} {'Target':>12}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for lag in gift.LAGS:\n",
    "        if lag in band_values:\n",
    "            bv = band_values[lag]\n",
    "            target = gift.H_G2_SQUARED if lag in [8, 13] else \"N/A\"\n",
    "            print(f\"{lag:<8} {bv['mean']:>12.4f} {bv['product_with_lag']:>12.2f} {str(target):>12}\")\n",
    "    \n",
    "    # Test de la contrainte\n",
    "    prod_8 = band_values[8]['product_with_lag']\n",
    "    prod_13 = band_values[13]['product_with_lag']\n",
    "    \n",
    "    print(f\"\\nüìê Test de la contrainte G‚ÇÇ:\")\n",
    "    print(f\"   8 √ó M‚Çà = {prod_8:.2f}\")\n",
    "    print(f\"   13 √ó M‚ÇÅ‚ÇÉ = {prod_13:.2f}\")\n",
    "    print(f\"   Ratio = {prod_8/prod_13:.4f} (th√©orique: 1.0)\")\n",
    "    print(f\"   Moyenne = {(prod_8 + prod_13)/2:.2f} (cible: {gift.H_G2_SQUARED})\")\n",
    "    \n",
    "    # √âcart √† la cible\n",
    "    avg_product = (prod_8 + prod_13) / 2\n",
    "    deviation = abs(avg_product - gift.H_G2_SQUARED) / gift.H_G2_SQUARED * 100\n",
    "    \n",
    "    if deviation < 10:\n",
    "        print(f\"\\n   ‚úÖ D√©viation = {deviation:.1f}% (< 10%) - STRUCTURE GIFT D√âTECT√âE\")\n",
    "        verdict = \"DETECTED\"\n",
    "    elif deviation < 30:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  D√©viation = {deviation:.1f}% (< 30%) - Structure partielle\")\n",
    "        verdict = \"PARTIAL\"\n",
    "    else:\n",
    "        print(f\"\\n   ‚ùå D√©viation = {deviation:.1f}% - Pas de structure claire\")\n",
    "        verdict = \"NOT_DETECTED\"\n",
    "    \n",
    "    return {\n",
    "        'band_values': band_values,\n",
    "        'constraint_ratio': float(prod_8 / prod_13),\n",
    "        'constraint_mean': float(avg_product),\n",
    "        'deviation_pct': float(deviation),\n",
    "        'verdict': verdict\n",
    "    }\n",
    "\n",
    "structure_results = analyze_gift_structure_in_matrix(gamma_np, N_matrix=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Construction d'un Op√©rateur Optimal via Optimisation\n",
    "\n",
    "### Probl√®me d'optimisation\n",
    "\n",
    "Trouver H = H(Œ∏) tel que:\n",
    "\n",
    "$$\\min_\\theta \\sum_{n=1}^{N} |\\lambda_n(H) - \\gamma_n|^2$$\n",
    "\n",
    "sous contraintes:\n",
    "- H hermitien\n",
    "- Structure band√©e aux positions {5, 8, 13, 27}\n",
    "- 8√óH‚Çà = 13√óH‚ÇÅ‚ÇÉ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InverseSpectralOptimizer:\n",
    "    \"\"\"\n",
    "    Optimise un op√©rateur H pour reproduire les z√©ros de Riemann\n",
    "    avec structure GIFT.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_eigenvalues: np.ndarray, N_matrix: int = None):\n",
    "        self.target = target_eigenvalues\n",
    "        self.N = N_matrix or len(target_eigenvalues)\n",
    "        self.use_gpu = GPU_AVAILABLE\n",
    "        self.xp = cp if self.use_gpu else np\n",
    "        \n",
    "        # Param√®tres de l'op√©rateur\n",
    "        # Œ∏ = [Œ±‚ÇÄ, Œ±‚ÇÅ, ..., Œ±‚Çô‚Çã‚ÇÅ, Œ≤‚ÇÖ, Œ≤‚Çà, Œ≤‚ÇÅ‚ÇÉ, Œ≤‚ÇÇ‚Çá]\n",
    "        # o√π Œ±·µ¢ = diagonale, Œ≤‚Çñ = coefficient du lag k\n",
    "        \n",
    "        self.n_diag_params = self.N\n",
    "        self.n_band_params = len(gift.LAGS)\n",
    "        self.n_params = self.n_diag_params + self.n_band_params\n",
    "        \n",
    "        print(f\"InverseSpectralOptimizer:\")\n",
    "        print(f\"  N = {self.N}\")\n",
    "        print(f\"  Params: {self.n_diag_params} diag + {self.n_band_params} bandes = {self.n_params}\")\n",
    "    \n",
    "    def build_H_from_params(self, theta: np.ndarray, \n",
    "                             enforce_constraint: bool = True) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Construit H √† partir des param√®tres Œ∏.\n",
    "        \n",
    "        Args:\n",
    "            theta: [Œ±‚ÇÄ...Œ±‚Çô‚Çã‚ÇÅ, Œ≤‚ÇÖ, Œ≤‚Çà, Œ≤‚ÇÅ‚ÇÉ, Œ≤‚ÇÇ‚Çá]\n",
    "            enforce_constraint: Si True, impose 8√óŒ≤‚Çà = 13√óŒ≤‚ÇÅ‚ÇÉ\n",
    "        \"\"\"\n",
    "        N = self.N\n",
    "        \n",
    "        # Extraction des param√®tres\n",
    "        alpha = theta[:N]  # Diagonale\n",
    "        beta_raw = theta[N:]  # Coefficients de bande\n",
    "        \n",
    "        # Application de la contrainte G‚ÇÇ\n",
    "        if enforce_constraint and len(beta_raw) >= 2:\n",
    "            # Œ≤‚Çà et Œ≤‚ÇÅ‚ÇÉ sont contraints: 8√óŒ≤‚Çà = 13√óŒ≤‚ÇÅ‚ÇÉ = c\n",
    "            # On param√©trise par c et on d√©duit Œ≤‚Çà, Œ≤‚ÇÅ‚ÇÉ\n",
    "            c = gift.H_G2_SQUARED  # = 36\n",
    "            beta = np.zeros(len(gift.LAGS))\n",
    "            beta[0] = beta_raw[0]  # Œ≤‚ÇÖ libre\n",
    "            beta[1] = c / 8        # Œ≤‚Çà = 36/8 = 4.5\n",
    "            beta[2] = c / 13       # Œ≤‚ÇÅ‚ÇÉ = 36/13 ‚âà 2.769\n",
    "            beta[3] = beta_raw[3] if len(beta_raw) > 3 else 0  # Œ≤‚ÇÇ‚Çá libre\n",
    "        else:\n",
    "            beta = beta_raw\n",
    "        \n",
    "        # Construction de la matrice\n",
    "        H = np.diag(alpha)\n",
    "        \n",
    "        for idx, lag in enumerate(gift.LAGS):\n",
    "            if lag < N and idx < len(beta):\n",
    "                # Bande inf√©rieure\n",
    "                band = np.ones(N - lag) * beta[idx]\n",
    "                H += np.diag(band, -lag)\n",
    "                # Bande sup√©rieure (sym√©trie)\n",
    "                H += np.diag(band, lag)\n",
    "        \n",
    "        return H\n",
    "    \n",
    "    def loss_function(self, theta: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Fonction de perte: ||Œª(H) - Œ≥||¬≤\n",
    "        \"\"\"\n",
    "        H = self.build_H_from_params(theta)\n",
    "        \n",
    "        # Calcul des valeurs propres\n",
    "        if self.use_gpu:\n",
    "            H_gpu = cp.asarray(H)\n",
    "            eigenvalues = cp.linalg.eigvalsh(H_gpu)\n",
    "            eigenvalues = eigenvalues.get()\n",
    "        else:\n",
    "            eigenvalues = np.linalg.eigvalsh(H)\n",
    "        \n",
    "        eigenvalues = np.sort(eigenvalues)\n",
    "        \n",
    "        # Comparaison aux cibles\n",
    "        n_compare = min(len(eigenvalues), len(self.target))\n",
    "        diff = eigenvalues[:n_compare] - self.target[:n_compare]\n",
    "        \n",
    "        # Perte L2 normalis√©e\n",
    "        loss = np.sum(diff**2) / n_compare\n",
    "        \n",
    "        return float(loss)\n",
    "    \n",
    "    def optimize(self, n_iterations: int = 100, \n",
    "                 learning_rate: float = 0.01) -> Dict:\n",
    "        \"\"\"\n",
    "        Optimisation par descente de gradient.\n",
    "        \"\"\"\n",
    "        print(f\"\\nüîÑ Optimisation ({n_iterations} it√©rations)...\")\n",
    "        \n",
    "        # Initialisation\n",
    "        # Diagonale: initialis√©e aux z√©ros cibles\n",
    "        alpha_init = self.target[:self.N].copy()\n",
    "        # Bandes: petites valeurs\n",
    "        beta_init = np.array([0.1, gift.H_G2_SQUARED/8, gift.H_G2_SQUARED/13, 0.0])\n",
    "        \n",
    "        theta = np.concatenate([alpha_init, beta_init])\n",
    "        \n",
    "        history = []\n",
    "        best_loss = float('inf')\n",
    "        best_theta = theta.copy()\n",
    "        \n",
    "        for i in range(n_iterations):\n",
    "            loss = self.loss_function(theta)\n",
    "            history.append(loss)\n",
    "            \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_theta = theta.copy()\n",
    "            \n",
    "            if i % 20 == 0:\n",
    "                print(f\"   Iter {i}: loss = {loss:.6f}\")\n",
    "            \n",
    "            # Gradient num√©rique (simple)\n",
    "            grad = np.zeros_like(theta)\n",
    "            eps = 1e-5\n",
    "            \n",
    "            for j in range(len(theta)):\n",
    "                theta_plus = theta.copy()\n",
    "                theta_plus[j] += eps\n",
    "                loss_plus = self.loss_function(theta_plus)\n",
    "                grad[j] = (loss_plus - loss) / eps\n",
    "            \n",
    "            # Mise √† jour\n",
    "            theta -= learning_rate * grad\n",
    "        \n",
    "        print(f\"\\n‚úÖ Optimisation termin√©e\")\n",
    "        print(f\"   Meilleure perte: {best_loss:.6f}\")\n",
    "        \n",
    "        return {\n",
    "            'best_theta': best_theta,\n",
    "            'best_loss': float(best_loss),\n",
    "            'history': history,\n",
    "            'beta_values': {\n",
    "                5: float(best_theta[self.N]),\n",
    "                8: float(gift.H_G2_SQUARED / 8),\n",
    "                13: float(gift.H_G2_SQUARED / 13),\n",
    "                27: float(best_theta[self.N + 3]) if len(best_theta) > self.N + 3 else 0\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimisation\n",
    "N_opt = min(50, N_ZEROS)  # Taille r√©duite pour rapidit√©\n",
    "\n",
    "optimizer = InverseSpectralOptimizer(gamma_np, N_matrix=N_opt)\n",
    "opt_results = optimizer.optimize(n_iterations=50, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification du r√©sultat\n",
    "H_opt = optimizer.build_H_from_params(opt_results['best_theta'])\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    eigenvalues = cp.linalg.eigvalsh(cp.asarray(H_opt)).get()\n",
    "else:\n",
    "    eigenvalues = np.linalg.eigvalsh(H_opt)\n",
    "\n",
    "eigenvalues = np.sort(eigenvalues)\n",
    "\n",
    "print(\"\\nüìä Comparaison spectre optimis√© vs z√©ros:\")\n",
    "print(f\"{'n':<5} {'Œª‚Çô(H)':>15} {'Œ≥‚Çô':>15} {'√âcart (%)':>12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(min(10, len(eigenvalues))):\n",
    "    Œª = eigenvalues[i]\n",
    "    Œ≥ = gamma_np[i]\n",
    "    err = abs(Œª - Œ≥) / Œ≥ * 100\n",
    "    print(f\"{i+1:<5} {Œª:>15.4f} {Œ≥:>15.4f} {err:>12.2f}\")\n",
    "\n",
    "# Erreur moyenne\n",
    "n_compare = min(len(eigenvalues), len(gamma_np))\n",
    "errors = np.abs(eigenvalues[:n_compare] - gamma_np[:n_compare]) / gamma_np[:n_compare] * 100\n",
    "print(f\"\\n   Erreur moyenne: {np.mean(errors):.2f}%\")\n",
    "print(f\"   Erreur max: {np.max(errors):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Analyse de la Formule de Trace\n",
    "\n",
    "### Connexion aux nombres premiers\n",
    "\n",
    "La formule explicite de Weil relie les z√©ros aux premiers:\n",
    "\n",
    "$$\\sum_\\gamma h(\\gamma) = h(0) + \\sum_p \\sum_m \\frac{\\log p}{p^{m/2}} \\hat{h}(m \\log p)$$\n",
    "\n",
    "Si H encode les z√©ros, alors Tr(f(H)) devrait encoder les premiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trace_prime_connection(H: np.ndarray, n_primes: int = 20) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyse si Tr(H^k) encode l'information sur les nombres premiers.\n",
    "    \n",
    "    Tr(H^k) = Œ£‚Çô Œª‚Çô·µè ‚àº Œ£‚Çö (log p) √ó contribution de p\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANALYSE FORMULE DE TRACE - CONNEXION AUX PREMIERS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Premiers nombres premiers\n",
    "    def sieve_primes(n_max):\n",
    "        sieve = [True] * (n_max + 1)\n",
    "        sieve[0] = sieve[1] = False\n",
    "        for i in range(2, int(n_max**0.5) + 1):\n",
    "            if sieve[i]:\n",
    "                for j in range(i*i, n_max + 1, i):\n",
    "                    sieve[j] = False\n",
    "        return [i for i in range(n_max + 1) if sieve[i]]\n",
    "    \n",
    "    primes = sieve_primes(100)[:n_primes]\n",
    "    \n",
    "    # Calcul des traces Tr(H^k)\n",
    "    eigenvalues = np.linalg.eigvalsh(H)\n",
    "    \n",
    "    traces = {}\n",
    "    for k in range(1, 11):\n",
    "        traces[k] = float(np.sum(eigenvalues**k))\n",
    "    \n",
    "    print(f\"\\nüìä Traces Tr(H^k):\")\n",
    "    for k, tr in traces.items():\n",
    "        print(f\"   Tr(H^{k}) = {tr:.2f}\")\n",
    "    \n",
    "    # Test de corr√©lation avec log(p)\n",
    "    log_primes = np.log(primes)\n",
    "    trace_values = np.array([traces[k] for k in range(1, min(11, len(primes) + 1))])\n",
    "    \n",
    "    if len(trace_values) >= 3:\n",
    "        corr = np.corrcoef(trace_values[:len(log_primes)], log_primes[:len(trace_values)])[0, 1]\n",
    "        print(f\"\\nüìà Corr√©lation Tr(H^k) vs log(p‚Çñ): {corr:.4f}\")\n",
    "    else:\n",
    "        corr = 0\n",
    "    \n",
    "    return {\n",
    "        'traces': traces,\n",
    "        'primes': primes,\n",
    "        'correlation': float(corr) if not np.isnan(corr) else 0\n",
    "    }\n",
    "\n",
    "if 'H_opt' in dir():\n",
    "    trace_results = analyze_trace_prime_connection(H_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Synth√®se et Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_synthesis():\n",
    "    \"\"\"Synth√®se finale de l'analyse.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SYNTH√àSE: PROBL√àME SPECTRAL INVERSE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    summary = {\n",
    "        'n_zeros': int(N_ZEROS),\n",
    "        'gift_constants': {\n",
    "            'lags': list(gift.LAGS),\n",
    "            'h_G2_squared': gift.H_G2_SQUARED,\n",
    "            'H_star': gift.H_STAR\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Corr√©lations aux lags\n",
    "    if 'corr_results' in dir():\n",
    "        summary['lag_correlations'] = corr_results\n",
    "        print(f\"\\n1. CORR√âLATIONS AUX LAGS GIFT:\")\n",
    "        for r in corr_results.get('gift_lags', []):\n",
    "            print(f\"   Lag {r['lag']}: corr = {r['corr']:.4f}, z = {r['z_score']:.2f}\")\n",
    "    \n",
    "    # Structure dans la matrice\n",
    "    if 'structure_results' in dir():\n",
    "        summary['matrix_structure'] = structure_results\n",
    "        print(f\"\\n2. STRUCTURE GIFT DANS LA MATRICE:\")\n",
    "        print(f\"   Contrainte ratio: {structure_results['constraint_ratio']:.4f} (cible: 1.0)\")\n",
    "        print(f\"   Contrainte mean: {structure_results['constraint_mean']:.2f} (cible: 36)\")\n",
    "        print(f\"   Verdict: {structure_results['verdict']}\")\n",
    "    \n",
    "    # Optimisation\n",
    "    if 'opt_results' in dir():\n",
    "        summary['optimization'] = {\n",
    "            'best_loss': opt_results['best_loss'],\n",
    "            'beta_values': opt_results['beta_values']\n",
    "        }\n",
    "        print(f\"\\n3. OPTIMISATION DE H:\")\n",
    "        print(f\"   Meilleure perte: {opt_results['best_loss']:.6f}\")\n",
    "        print(f\"   Œ≤‚ÇÖ = {opt_results['beta_values'][5]:.4f}\")\n",
    "        print(f\"   Œ≤‚Çà = {opt_results['beta_values'][8]:.4f} (8√óŒ≤‚Çà = {8*opt_results['beta_values'][8]:.1f})\")\n",
    "        print(f\"   Œ≤‚ÇÅ‚ÇÉ = {opt_results['beta_values'][13]:.4f} (13√óŒ≤‚ÇÅ‚ÇÉ = {13*opt_results['beta_values'][13]:.1f})\")\n",
    "        print(f\"   Œ≤‚ÇÇ‚Çá = {opt_results['beta_values'][27]:.4f}\")\n",
    "    \n",
    "    # Formule de trace\n",
    "    if 'trace_results' in dir():\n",
    "        summary['trace_analysis'] = {\n",
    "            'correlation_with_primes': trace_results['correlation']\n",
    "        }\n",
    "        print(f\"\\n4. CONNEXION AUX PREMIERS:\")\n",
    "        print(f\"   Corr√©lation Tr(H^k) vs log(p‚Çñ): {trace_results['correlation']:.4f}\")\n",
    "    \n",
    "    # Conclusions\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"CONCLUSIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    findings = []\n",
    "    \n",
    "    if 'structure_results' in dir() and structure_results['verdict'] == 'DETECTED':\n",
    "        findings.append(\"‚úÖ Structure GIFT d√©tect√©e dans la matrice de corr√©lation\")\n",
    "    \n",
    "    if 'opt_results' in dir() and opt_results['best_loss'] < 1.0:\n",
    "        findings.append(\"‚úÖ Op√©rateur H optimis√© avec faible erreur\")\n",
    "    \n",
    "    if 'corr_results' in dir():\n",
    "        high_z = sum(1 for r in corr_results.get('gift_lags', []) if r['z_score'] > 2)\n",
    "        if high_z >= 2:\n",
    "            findings.append(f\"‚úÖ {high_z} lags GIFT significatifs (z > 2)\")\n",
    "    \n",
    "    for f in findings:\n",
    "        print(f\"   {f}\")\n",
    "    \n",
    "    if not findings:\n",
    "        print(\"   ‚ö†Ô∏è R√©sultats non concluants - plus de donn√©es n√©cessaires\")\n",
    "    \n",
    "    # Export\n",
    "    with open('inverse_spectral_results.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2, default=float)\n",
    "    \n",
    "    print(f\"\\nüíæ R√©sultats sauvegard√©s: inverse_spectral_results.json\")\n",
    "    \n",
    "    return summary\n",
    "\n",
    "final_summary = final_synthesis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Prochaines √âtapes\n",
    "\n",
    "### Directions prometteuses:\n",
    "\n",
    "1. **Plus de z√©ros**: Tester avec 1M+ de z√©ros (Odlyzko)\n",
    "2. **Optimisation avanc√©e**: ADAM, L-BFGS avec contraintes\n",
    "3. **Structure alg√©brique**: Chercher si H admet une d√©composition G‚ÇÇ-invariante\n",
    "4. **Formule de trace explicite**: Relier Tr(e^{-tH}) √† la fonction Œ∂(s)\n",
    "5. **Formalisation Lean 4**: Prouver les propri√©t√©s de H\n",
    "\n",
    "### Question ouverte:\n",
    "\n",
    "Si les z√©ros de Riemann encodent vraiment la structure K‚Çá, \n",
    "alors l'op√©rateur H devrait √™tre le **Laplacien de Hodge** sur K‚Çá:\n",
    "\n",
    "$$H = \\Delta_p = d d^* + d^* d$$\n",
    "\n",
    "agissant sur les p-formes de K‚Çá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüéØ Notebook termin√©\")\n",
    "print(\"   Direction suivante: Tester sur donn√©es √©tendues (Odlyzko 2M zeros)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
