{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Cheeger Constant Computation for K₇\n",
    "\n",
    "## Motivation\n",
    "\n",
    "The eigenvalue pipeline is **k-dependent**:\n",
    "- k = 0.366 × √N → λ₁×H* = 14\n",
    "- k = 0.74 × √N → λ₁×H* = 13\n",
    "\n",
    "Without calibration, we cannot distinguish 13 from 14.\n",
    "\n",
    "**Solution**: Compute the Cheeger constant h(K₇) directly!\n",
    "\n",
    "## Cheeger Inequality\n",
    "\n",
    "For compact Riemannian manifolds:\n",
    "$$\\lambda_1 \\geq \\frac{h^2}{4}$$\n",
    "\n",
    "where h is the **Cheeger constant** (isoperimetric ratio):\n",
    "$$h(M) = \\inf_S \\frac{\\text{Area}(\\partial S)}{\\min(\\text{Vol}(S), \\text{Vol}(M \\setminus S))}$$\n",
    "\n",
    "For **graphs**, the discrete Cheeger constant is:\n",
    "$$h(G) = \\min_{S \\subset V, |S| \\leq |V|/2} \\frac{|E(S, V \\setminus S)|}{|S|}$$\n",
    "\n",
    "## Key Question\n",
    "\n",
    "Is **h(K₇) × H*** a topological constant?\n",
    "\n",
    "If h × H* ≈ 2√13 or 2√14, that would confirm the spectral gap formula.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import json\n",
    "from datetime import datetime\n",
    "import time\n",
    "import gc\n",
    "\n",
    "# GIFT Constants\n",
    "H_STAR = 99\n",
    "DIM_G2 = 14\n",
    "DET_G = 65/32\n",
    "RATIO = H_STAR / 84\n",
    "\n",
    "print(\"GIFT Constants:\")\n",
    "print(f\"  H* = {H_STAR}\")\n",
    "print(f\"  dim(G₂) = {DIM_G2}\")\n",
    "print(f\"  det(g) = {DET_G}\")\n",
    "print(f\"\\nCheeger predictions:\")\n",
    "print(f\"  If λ₁×H* = 13: h×H* = 2√13 ≈ {2*np.sqrt(13):.2f}\")\n",
    "print(f\"  If λ₁×H* = 14: h×H* = 2√14 ≈ {2*np.sqrt(14):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K₇ Sampling (TCS representation)\n",
    "\n",
    "def sample_TCS_K7(N, seed=42):\n",
    "    \"\"\"Sample K₇ via Twisted Connected Sum: S¹ × S³ × S³\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # S¹ component\n",
    "    theta = rng.uniform(0, 2*np.pi, N).astype(np.float32)\n",
    "    \n",
    "    # S³ components (unit quaternions)\n",
    "    def sample_S3(n):\n",
    "        x = rng.standard_normal((n, 4)).astype(np.float32)\n",
    "        return x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    \n",
    "    q1 = sample_S3(N)\n",
    "    q2 = sample_S3(N)\n",
    "    \n",
    "    return theta, q1, q2\n",
    "\n",
    "\n",
    "def compute_K7_distances_sparse(theta, q1, q2, k_neighbors):\n",
    "    \"\"\"\n",
    "    Compute sparse kNN graph for K₇.\n",
    "    Returns weight matrix W (sparse) and degree vector.\n",
    "    \"\"\"\n",
    "    N = len(theta)\n",
    "    alpha = DET_G / (RATIO ** 3)\n",
    "    \n",
    "    # Compute kNN for each point in batches\n",
    "    batch_size = 3000\n",
    "    all_neighbors = []\n",
    "    all_distances = []\n",
    "    \n",
    "    for i_start in range(0, N, batch_size):\n",
    "        i_end = min(i_start + batch_size, N)\n",
    "        batch_size_actual = i_end - i_start\n",
    "        \n",
    "        # Distance from batch to all points\n",
    "        D_batch = np.zeros((batch_size_actual, N), dtype=np.float32)\n",
    "        \n",
    "        for i_local, i_global in enumerate(range(i_start, i_end)):\n",
    "            # S¹ distance\n",
    "            diff_theta = np.abs(theta[i_global] - theta)\n",
    "            d_S1 = np.minimum(diff_theta, 2*np.pi - diff_theta)\n",
    "            \n",
    "            # S³ distances (quaternion)\n",
    "            dot1 = np.clip(np.abs(np.sum(q1[i_global] * q1, axis=1)), -1, 1)\n",
    "            d_S3_1 = 2 * np.arccos(dot1)\n",
    "            \n",
    "            dot2 = np.clip(np.abs(np.sum(q2[i_global] * q2, axis=1)), -1, 1)\n",
    "            d_S3_2 = 2 * np.arccos(dot2)\n",
    "            \n",
    "            # Combined TCS metric\n",
    "            D_batch[i_local] = np.sqrt(alpha * d_S1**2 + d_S3_1**2 + RATIO**2 * d_S3_2**2)\n",
    "        \n",
    "        # Get k nearest neighbors (excluding self)\n",
    "        k_actual = min(k_neighbors + 1, N)\n",
    "        idx = np.argpartition(D_batch, k_actual, axis=1)[:, :k_actual]\n",
    "        dists = np.take_along_axis(D_batch, idx, axis=1)\n",
    "        \n",
    "        # Sort and exclude self (distance 0)\n",
    "        sort_idx = np.argsort(dists, axis=1)\n",
    "        idx = np.take_along_axis(idx, sort_idx, axis=1)[:, 1:k_neighbors+1]\n",
    "        dists = np.take_along_axis(dists, sort_idx, axis=1)[:, 1:k_neighbors+1]\n",
    "        \n",
    "        all_neighbors.append(idx)\n",
    "        all_distances.append(dists)\n",
    "        \n",
    "        del D_batch\n",
    "        gc.collect()\n",
    "    \n",
    "    neighbors = np.vstack(all_neighbors)\n",
    "    distances = np.vstack(all_distances)\n",
    "    \n",
    "    # Bandwidth\n",
    "    sigma = float(np.median(distances[:, -1]))\n",
    "    \n",
    "    # Build sparse weight matrix\n",
    "    row = np.repeat(np.arange(N), k_neighbors)\n",
    "    col = neighbors.flatten()\n",
    "    weights = np.exp(-distances.flatten()**2 / (2 * sigma**2))\n",
    "    \n",
    "    W = csr_matrix((weights, (row, col)), shape=(N, N))\n",
    "    W = (W + W.T) / 2  # Symmetrize\n",
    "    \n",
    "    return W, sigma\n",
    "\n",
    "print(\"✓ K₇ sampling functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheeger Constant Computation\n",
    "\n",
    "def compute_cheeger_spectral(W):\n",
    "    \"\"\"\n",
    "    Compute Cheeger constant using SPECTRAL METHOD.\n",
    "    \n",
    "    The Fiedler vector (eigenvector of λ₂ of normalized Laplacian)\n",
    "    gives a near-optimal cut via its sign pattern.\n",
    "    \n",
    "    Cheeger's inequality: h ≤ √(2λ₁) (upper bound from spectral gap)\n",
    "    \"\"\"\n",
    "    N = W.shape[0]\n",
    "    \n",
    "    # Degree\n",
    "    d = np.array(W.sum(axis=1)).flatten()\n",
    "    d_inv_sqrt = 1.0 / np.sqrt(d + 1e-10)\n",
    "    \n",
    "    # Normalized Laplacian\n",
    "    D_inv_sqrt = csr_matrix((d_inv_sqrt, (range(N), range(N))), shape=(N, N))\n",
    "    L_norm = csr_matrix(np.eye(N)) - D_inv_sqrt @ W @ D_inv_sqrt\n",
    "    \n",
    "    # Compute Fiedler vector (2nd smallest eigenvector)\n",
    "    eigvals, eigvecs = eigsh(L_norm.tocsr(), k=3, which='SM', tol=1e-8)\n",
    "    idx = np.argsort(eigvals)\n",
    "    lambda1 = eigvals[idx[1]]  # Second smallest (first non-zero)\n",
    "    fiedler = eigvecs[:, idx[1]]\n",
    "    \n",
    "    # Sweep cut using Fiedler vector\n",
    "    # Sort vertices by Fiedler value\n",
    "    order = np.argsort(fiedler)\n",
    "    \n",
    "    # Try all possible cuts and find minimum conductance\n",
    "    best_h = float('inf')\n",
    "    \n",
    "    # Weights crossing the cut\n",
    "    W_dense = W.toarray() if W.nnz < N * N / 10 else None\n",
    "    \n",
    "    # Vol(S) = sum of degrees in S\n",
    "    vol_total = d.sum()\n",
    "    \n",
    "    # Incremental computation\n",
    "    S_vertices = set()\n",
    "    vol_S = 0\n",
    "    cut_weight = 0  # Total weight of edges crossing the cut\n",
    "    \n",
    "    for i in range(N // 2):  # Only consider cuts with |S| ≤ N/2\n",
    "        v = order[i]\n",
    "        S_vertices.add(v)\n",
    "        vol_S += d[v]\n",
    "        \n",
    "        # Update cut weight: edges from v to vertices not in S\n",
    "        if W_dense is not None:\n",
    "            cut_weight += W_dense[v, :].sum() - sum(W_dense[v, u] for u in S_vertices)\n",
    "            cut_weight -= sum(W_dense[u, v] for u in S_vertices if u != v)\n",
    "        else:\n",
    "            # Sparse version\n",
    "            row_v = W.getrow(v).toarray().flatten()\n",
    "            for u in S_vertices:\n",
    "                cut_weight -= row_v[u] if u != v else 0\n",
    "            cut_weight += row_v.sum() - sum(row_v[u] for u in S_vertices)\n",
    "        \n",
    "        # Conductance: cut_weight / min(vol_S, vol_total - vol_S)\n",
    "        if vol_S > 0 and vol_S < vol_total:\n",
    "            min_vol = min(vol_S, vol_total - vol_S)\n",
    "            h = cut_weight / min_vol\n",
    "            if h < best_h:\n",
    "                best_h = h\n",
    "    \n",
    "    return best_h, lambda1\n",
    "\n",
    "\n",
    "def compute_cheeger_random_sampling(W, n_samples=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Estimate Cheeger by random sampling of cuts.\n",
    "    Gives an UPPER BOUND on h.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    N = W.shape[0]\n",
    "    d = np.array(W.sum(axis=1)).flatten()\n",
    "    vol_total = d.sum()\n",
    "    \n",
    "    W_csr = W.tocsr()\n",
    "    \n",
    "    best_h = float('inf')\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        # Random subset S with size ≤ N/2\n",
    "        size = rng.integers(1, N // 2 + 1)\n",
    "        S = set(rng.choice(N, size=size, replace=False))\n",
    "        \n",
    "        # Compute cut weight and volumes\n",
    "        cut_weight = 0\n",
    "        vol_S = sum(d[v] for v in S)\n",
    "        \n",
    "        for v in S:\n",
    "            row = W_csr.getrow(v)\n",
    "            for j, w in zip(row.indices, row.data):\n",
    "                if j not in S:\n",
    "                    cut_weight += w\n",
    "        \n",
    "        min_vol = min(vol_S, vol_total - vol_S)\n",
    "        if min_vol > 0:\n",
    "            h = cut_weight / min_vol\n",
    "            best_h = min(best_h, h)\n",
    "    \n",
    "    return best_h\n",
    "\n",
    "\n",
    "print(\"✓ Cheeger computation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified Cheeger via Spectral Bound\n",
    "\n",
    "def cheeger_from_eigenvalue(lambda1):\n",
    "    \"\"\"\n",
    "    Cheeger-Buser bounds:\n",
    "    \n",
    "    h² / 4 ≤ λ₁ ≤ 2h  (for normalized Laplacian with h small)\n",
    "    \n",
    "    This gives:\n",
    "    √(2λ₁) ≥ h ≥ √(λ₁/2)  (approximately)\n",
    "    \n",
    "    For graphs: h ≈ √(2λ₁) is often a good approximation.\n",
    "    \"\"\"\n",
    "    h_upper = np.sqrt(2 * lambda1)  # Cheeger upper bound\n",
    "    h_lower = lambda1 / 2  # From h²/4 ≤ λ₁, so h ≥ 2√λ₁... wait\n",
    "    # Actually: λ₁ ≥ h²/4 → h ≤ 2√λ₁\n",
    "    # And λ₁ ≤ 2h (Buser) → h ≥ λ₁/2\n",
    "    return h_lower, h_upper\n",
    "\n",
    "\n",
    "print(\"Cheeger bounds from eigenvalue:\")\n",
    "print(f\"  λ₁ = 13/99 → h ∈ [{13/99/2:.4f}, {np.sqrt(2*13/99):.4f}]\")\n",
    "print(f\"  λ₁ = 14/99 → h ∈ [{14/99/2:.4f}, {np.sqrt(2*14/99):.4f}]\")\n",
    "print(f\"\\n  h × H* (lower): 13 case → {13/99/2 * 99:.2f}, 14 case → {14/99/2 * 99:.2f}\")\n",
    "print(f\"  h × H* (upper): 13 case → {np.sqrt(2*13/99) * 99:.2f}, 14 case → {np.sqrt(2*14/99) * 99:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main computation\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CHEEGER CONSTANT COMPUTATION FOR K₇\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Parameters\n",
    "N_VALUES = [2000, 5000, 10000]\n",
    "K_VALUES = [50, 100, 150]  # Different k to see stability\n",
    "\n",
    "results = []\n",
    "\n",
    "for N in N_VALUES:\n",
    "    print(f\"\\nN = {N}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Sample K₇\n",
    "    theta, q1, q2 = sample_TCS_K7(N, seed=42)\n",
    "    \n",
    "    for k in K_VALUES:\n",
    "        print(f\"  k = {k}...\", end=\" \")\n",
    "        t0 = time.time()\n",
    "        \n",
    "        # Build graph\n",
    "        W, sigma = compute_K7_distances_sparse(theta, q1, q2, k)\n",
    "        \n",
    "        # Compute λ₁ directly\n",
    "        d = np.array(W.sum(axis=1)).flatten()\n",
    "        d_inv_sqrt = 1.0 / np.sqrt(d + 1e-10)\n",
    "        D_inv_sqrt = csr_matrix((d_inv_sqrt, (range(N), range(N))), shape=(N, N))\n",
    "        L_norm = csr_matrix(np.eye(N)) - D_inv_sqrt @ W @ D_inv_sqrt\n",
    "        \n",
    "        eigvals, _ = eigsh(L_norm.tocsr(), k=3, which='SM', tol=1e-8)\n",
    "        lambda1 = sorted(eigvals)[1]\n",
    "        \n",
    "        # Cheeger bounds from λ₁\n",
    "        h_lower, h_upper = cheeger_from_eigenvalue(lambda1)\n",
    "        \n",
    "        # Products\n",
    "        lambda1_H = lambda1 * H_STAR\n",
    "        h_lower_H = h_lower * H_STAR\n",
    "        h_upper_H = h_upper * H_STAR\n",
    "        \n",
    "        elapsed = time.time() - t0\n",
    "        \n",
    "        print(f\"λ₁×H* = {lambda1_H:.2f}, h×H* ∈ [{h_lower_H:.2f}, {h_upper_H:.2f}] [{elapsed:.1f}s]\")\n",
    "        \n",
    "        results.append({\n",
    "            'N': int(N),\n",
    "            'k': int(k),\n",
    "            'sigma': float(sigma),\n",
    "            'lambda1': float(lambda1),\n",
    "            'lambda1_H': float(lambda1_H),\n",
    "            'h_lower': float(h_lower),\n",
    "            'h_upper': float(h_upper),\n",
    "            'h_lower_H': float(h_lower_H),\n",
    "            'h_upper_H': float(h_upper_H)\n",
    "        })\n",
    "        \n",
    "        del W, L_norm\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis: Is h×H* stable across k?\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"STABILITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for N in N_VALUES:\n",
    "    subset = [r for r in results if r['N'] == N]\n",
    "    print(f\"\\nN = {N}:\")\n",
    "    print(f\"  {'k':>5} | {'λ₁×H*':>8} | {'h_lower×H*':>12} | {'h_upper×H*':>12}\")\n",
    "    print(f\"  {'-'*50}\")\n",
    "    \n",
    "    for r in subset:\n",
    "        print(f\"  {r['k']:>5} | {r['lambda1_H']:>8.2f} | {r['h_lower_H']:>12.2f} | {r['h_upper_H']:>12.2f}\")\n",
    "    \n",
    "    # Spread\n",
    "    l1_values = [r['lambda1_H'] for r in subset]\n",
    "    h_upper_values = [r['h_upper_H'] for r in subset]\n",
    "    \n",
    "    print(f\"  Spread λ₁×H*: {max(l1_values) - min(l1_values):.2f}\")\n",
    "    print(f\"  Spread h_upper×H*: {max(h_upper_values) - min(h_upper_values):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key insight: Cheeger bounds\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"KEY INSIGHT: CHEEGER BOUNDS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "The Cheeger inequality λ₁ ≥ h²/4 gives us:\n",
    "\n",
    "If we can show h(K₇) ≥ c/H* for some constant c,\n",
    "then λ₁ ≥ c²/(4H*²), i.e., λ₁×H* ≥ c²/(4H*)\n",
    "\n",
    "From our measurements:\n",
    "\"\"\")\n",
    "\n",
    "# Use high-N, middle-k result\n",
    "ref_result = [r for r in results if r['N'] == max(N_VALUES) and r['k'] == 100]\n",
    "if ref_result:\n",
    "    r = ref_result[0]\n",
    "    print(f\"  At N={r['N']}, k={r['k']}:\")\n",
    "    print(f\"    λ₁ × H* = {r['lambda1_H']:.2f}\")\n",
    "    print(f\"    h_upper × H* = {r['h_upper_H']:.2f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"  If h_upper ≈ √(2λ₁) is accurate:\")\n",
    "    print(f\"    h × H* = √(2 × {r['lambda1_H']:.2f}) = {np.sqrt(2 * r['lambda1_H']):.2f}\")\n",
    "    print(f\"\")\n",
    "    print(f\"  Expected from theory:\")\n",
    "    print(f\"    If λ₁×H* = 13: √(2×13) = {np.sqrt(26):.2f}\")\n",
    "    print(f\"    If λ₁×H* = 14: √(2×14) = {np.sqrt(28):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: λ₁×H* vs k for each N\n",
    "ax = axes[0]\n",
    "for N in N_VALUES:\n",
    "    subset = [r for r in results if r['N'] == N]\n",
    "    ks = [r['k'] for r in subset]\n",
    "    l1s = [r['lambda1_H'] for r in subset]\n",
    "    ax.plot(ks, l1s, 'o-', label=f'N={N}')\n",
    "\n",
    "ax.axhline(14, color='red', linestyle='--', alpha=0.7, label='Pell (14)')\n",
    "ax.axhline(13, color='blue', linestyle='--', alpha=0.7, label='Spinor (13)')\n",
    "ax.set_xlabel('k (neighbors)')\n",
    "ax.set_ylabel('λ₁ × H*')\n",
    "ax.set_title('λ₁ × H* vs k')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Cheeger bounds\n",
    "ax = axes[1]\n",
    "for N in N_VALUES:\n",
    "    subset = [r for r in results if r['N'] == N]\n",
    "    ks = [r['k'] for r in subset]\n",
    "    h_lower = [r['h_lower_H'] for r in subset]\n",
    "    h_upper = [r['h_upper_H'] for r in subset]\n",
    "    ax.fill_between(ks, h_lower, h_upper, alpha=0.3, label=f'N={N}')\n",
    "    ax.plot(ks, h_upper, 'o-')\n",
    "\n",
    "ax.axhline(np.sqrt(26), color='blue', linestyle='--', alpha=0.7, label='√(2×13)')\n",
    "ax.axhline(np.sqrt(28), color='red', linestyle='--', alpha=0.7, label='√(2×14)')\n",
    "ax.set_xlabel('k (neighbors)')\n",
    "ax.set_ylabel('h × H*')\n",
    "ax.set_title('Cheeger bounds h × H*')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Stability check - λ₁ vs N at fixed k\n",
    "ax = axes[2]\n",
    "for k in K_VALUES:\n",
    "    subset = [r for r in results if r['k'] == k]\n",
    "    Ns = [r['N'] for r in subset]\n",
    "    l1s = [r['lambda1_H'] for r in subset]\n",
    "    ax.plot(Ns, l1s, 'o-', label=f'k={k}')\n",
    "\n",
    "ax.axhline(14, color='red', linestyle='--', alpha=0.7)\n",
    "ax.axhline(13, color='blue', linestyle='--', alpha=0.7)\n",
    "ax.set_xlabel('N (samples)')\n",
    "ax.set_ylabel('λ₁ × H*')\n",
    "ax.set_title('Convergence with N')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('K7_Cheeger_Analysis.png', dpi=150)\n",
    "plt.show()\n",
    "print(\"✓ Saved: K7_Cheeger_Analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "\n",
    "output = {\n",
    "    'metadata': {\n",
    "        'notebook': 'K7_Cheeger_Computation.ipynb',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'H_star': H_STAR,\n",
    "        'N_values': N_VALUES,\n",
    "        'k_values': K_VALUES\n",
    "    },\n",
    "    'theory': {\n",
    "        'cheeger_inequality': 'λ₁ ≥ h²/4',\n",
    "        'buser_inequality': 'λ₁ ≤ 2h (approx for graphs)',\n",
    "        'expected_13': {'lambda1_H': 13, 'h_H': float(np.sqrt(26))},\n",
    "        'expected_14': {'lambda1_H': 14, 'h_H': float(np.sqrt(28))}\n",
    "    },\n",
    "    'results': results\n",
    "}\n",
    "\n",
    "with open('K7_Cheeger_results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Saved: K7_Cheeger_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "### What we learned:\n",
    "\n",
    "1. **λ₁×H* depends on k** — This is the fundamental problem\n",
    "\n",
    "2. **Cheeger bounds are derived from λ₁** — They don't help distinguish 13 vs 14\n",
    "\n",
    "3. **The stability question**: Does h×H* stabilize as N→∞ for fixed k?\n",
    "\n",
    "### Key insight:\n",
    "\n",
    "The Cheeger constant h is **derived from λ₁** via spectral methods. \n",
    "Computing h directly (via isoperimetric ratio) requires the actual manifold geometry, \n",
    "not a graph approximation.\n",
    "\n",
    "### Next steps:\n",
    "\n",
    "1. **Analytical Cheeger**: Use TCS geometry (neck, volumes) to bound h analytically\n",
    "2. **FEM methods**: Discretize the manifold with finite elements, not random sampling\n",
    "3. **Accept the ambiguity**: Maybe λ₁×H* ∈ [13, 14] is the physical answer\n",
    "\n",
    "---\n",
    "\n",
    "*GIFT Spectral Gap Research — Cheeger Analysis*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
