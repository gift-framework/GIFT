{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFT Correction Model: $\\theta(T) = \\frac{10}{7} - \\frac{14}{3\\log T}$\n",
    "\n",
    "**Purpose**: Validate the GIFT-derived variable-$\\theta$ correction model\n",
    "on Odlyzko's 2,001,052 zeros (zeros6 table, $T \\leq 1{,}132{,}490$).\n",
    "\n",
    "**Model**: The cutoff exponent is no longer constant but varies as:\n",
    "$$\\theta(T) = \\frac{10}{7} - \\frac{14}{3\\,\\log T}$$\n",
    "\n",
    "| Parameter | Value | GIFT origin |\n",
    "|-----------|-------|-------------|\n",
    "| $\\theta_\\infty = 10/7$ | 1.4286 | $(\\dim K_7 + N_\\text{gen})/\\dim K_7 = (7+3)/7$ |\n",
    "| Correction coeff $= 14/3$ | 4.6667 | $\\dim(G_2)/N_\\text{gen} = 14/3$ |\n",
    "\n",
    "**Runtime**: ~7h on Colab A100 (same as constant-$\\theta$ notebook).\n",
    "Checkpoints to Drive after every chunk \u2014 safe to resume after timeout.\n",
    "\n",
    "**Validation**: T5 (Monte Carlo), T7 (Bootstrap CI), T8 (Drift test)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import os, sys, time, json, shutil, warnings\n",
    "from scipy.special import loggamma, lambertw\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU detection\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU = True\n",
    "    gpu_name = cp.cuda.runtime.getDeviceProperties(0)['name'].decode()\n",
    "    gpu_mem = cp.cuda.runtime.getDeviceProperties(0)['totalGlobalMem'] / 1e9\n",
    "    print(f\"GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
    "except Exception:\n",
    "    GPU = False\n",
    "    print(\"No GPU \u2014 CPU mode (fine for core analysis)\")\n",
    "\n",
    "print(f\"NumPy {np.__version__}, Python {sys.version.split()[0]}\")\n",
    "\n",
    "# Mount Google Drive\n",
    "DRIVE_DIR = '/content/drive/MyDrive/GIFT_results'\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    os.makedirs(DRIVE_DIR, exist_ok=True)\n",
    "    print(f\"Drive mounted -> {DRIVE_DIR}\")\n",
    "except Exception:\n",
    "    DRIVE_DIR = None\n",
    "    print(\"No Drive \u2014 local storage only\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import urllib.request\n",
    "\n",
    "CACHE_2M = 'riemann_zeros_2M_genuine.npy'\n",
    "\n",
    "def download_odlyzko(url, cache_file, desc):\n",
    "    drive_cache = os.path.join(DRIVE_DIR, cache_file) if DRIVE_DIR else None\n",
    "    if os.path.exists(cache_file):\n",
    "        print(f\"  Loading cached {desc} (local)...\")\n",
    "        return np.load(cache_file)\n",
    "    if drive_cache and os.path.exists(drive_cache):\n",
    "        print(f\"  Loading cached {desc} (Drive)...\")\n",
    "        shutil.copy2(drive_cache, cache_file)\n",
    "        return np.load(cache_file)\n",
    "    print(f\"  Downloading {desc}...\")\n",
    "    t0 = time.time()\n",
    "    response = urllib.request.urlopen(url, timeout=300)\n",
    "    raw = response.read().decode('utf-8')\n",
    "    zeros = np.array([float(l.strip()) for l in raw.strip().split('\\n') if l.strip()])\n",
    "    print(f\"    {len(zeros):,} zeros in {time.time()-t0:.1f}s\")\n",
    "    np.save(cache_file, zeros)\n",
    "    if drive_cache:\n",
    "        shutil.copy2(cache_file, drive_cache)\n",
    "        print(f\"    Backed up to Drive\")\n",
    "    return zeros\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DOWNLOADING RIEMANN ZEROS\")\n",
    "print(\"=\" * 60)\n",
    "gamma_n = download_odlyzko(\n",
    "    'https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6',\n",
    "    CACHE_2M, \"2,001,052 zeros (Odlyzko zeros6)\")\n",
    "\n",
    "if gamma_n is None:\n",
    "    raise RuntimeError(\"Download failed\")\n",
    "\n",
    "N_ZEROS = len(gamma_n)\n",
    "print(f\"\\nLoaded {N_ZEROS:,} zeros, range [{gamma_n[0]:.3f}, {gamma_n[-1]:.3f}]\")\n",
    "\n",
    "KNOWN = [14.134725142, 21.022039639, 25.010857580, 30.424876126, 32.935061588]\n",
    "for i, k in enumerate(KNOWN):\n",
    "    err = abs(gamma_n[i] - k)\n",
    "    print(f\"  gamma_{i+1} = {gamma_n[i]:.9f}  (err: {err:.2e}) [{'OK' if err < 1e-6 else 'BAD'}]\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# \u2500\u2500 Riemann-Siegel theta \u2500\u2500\n",
    "def theta_rs(t):\n",
    "    t = np.asarray(t, dtype=np.float64)\n",
    "    return np.imag(loggamma(0.25 + 0.5j * t)) - 0.5 * t * np.log(np.pi)\n",
    "\n",
    "def theta_deriv(t):\n",
    "    return 0.5 * np.log(np.maximum(np.asarray(t, dtype=np.float64), 1.0) / (2 * np.pi))\n",
    "\n",
    "def smooth_zeros(N):\n",
    "    ns = np.arange(1, N + 1, dtype=np.float64)\n",
    "    targets = (ns - 1.5) * np.pi\n",
    "    w = np.real(lambertw(ns / np.e))\n",
    "    t = np.maximum(2 * np.pi * ns / w, 2.0)\n",
    "    for _ in range(40):\n",
    "        dt = (theta_rs(t) - targets) / np.maximum(np.abs(theta_deriv(t)), 1e-15)\n",
    "        t -= dt\n",
    "        if np.max(np.abs(dt)) < 1e-12:\n",
    "            break\n",
    "    return t\n",
    "\n",
    "def sieve(N):\n",
    "    is_p = np.ones(N + 1, dtype=bool); is_p[:2] = False\n",
    "    for i in range(2, int(N**0.5) + 1):\n",
    "        if is_p[i]: is_p[i*i::i] = False\n",
    "    return np.where(is_p)[0]\n",
    "\n",
    "def w_cosine(x):\n",
    "    return np.where(x < 1.0, np.cos(np.pi * x / 2)**2, 0.0)\n",
    "\n",
    "# \u2500\u2500 GIFT correction model \u2500\u2500\n",
    "THETA_INF = 10 / 7     # (dim(K7) + N_gen) / dim(K7)\n",
    "THETA_COEFF = -14 / 3  # -dim(G2) / N_gen\n",
    "K_MAX = 3\n",
    "\n",
    "def theta_gift(T):\n",
    "    # theta(T) = 10/7 - (14/3)/log(T)\n",
    "    logT = np.log(np.maximum(np.asarray(T, dtype=np.float64), np.e))\n",
    "    return np.clip(THETA_INF + THETA_COEFF / logT, 0.5, 2.0)\n",
    "\n",
    "def prime_sum_var(g0, tp_v, primes, k_max, theta_inf, theta_coeff, w_func):\n",
    "    # Mollified prime sum with theta(T) = theta_inf + theta_coeff/log(T)\n",
    "    # Set theta_coeff=0 for constant theta\n",
    "    S = np.zeros_like(g0)\n",
    "    log_g0 = np.log(np.maximum(g0, 2.0))\n",
    "    if theta_coeff == 0.0:\n",
    "        log_X = theta_inf * log_g0\n",
    "    else:\n",
    "        theta_per = np.clip(theta_inf + theta_coeff / log_g0, 0.5, 2.0)\n",
    "        log_X = theta_per * log_g0\n",
    "\n",
    "    for p in primes:\n",
    "        logp = np.log(float(p))\n",
    "        if logp / np.max(log_X) > 3.0:\n",
    "            break\n",
    "        for m in range(1, k_max + 1):\n",
    "            x = m * logp / log_X\n",
    "            weight = w_func(x)\n",
    "            if np.max(weight) < 1e-15:\n",
    "                continue\n",
    "            S -= weight * np.sin(g0 * m * logp) / (m * p ** (m / 2.0))\n",
    "    return -S / tp_v\n",
    "\n",
    "print(\"Infrastructure loaded.\")\n",
    "print(f\"  GIFT model: theta(T) = {THETA_INF:.6f} - {abs(THETA_COEFF):.6f}/log(T)\")\n",
    "print(f\"  = 10/7 - (14/3)/log(T)\")\n",
    "print(f\"  theta(T=100):   {theta_gift(100):.4f}\")\n",
    "print(f\"  theta(T=10k):   {theta_gift(1e4):.4f}\")\n",
    "print(f\"  theta(T=100k):  {theta_gift(1e5):.4f}\")\n",
    "print(f\"  theta(T=1M):    {theta_gift(1e6):.4f}\")\n",
    "print(f\"  theta(T->inf):  {THETA_INF:.6f} = 10/7\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Computing smooth zeros...\")\n",
    "t0 = time.time()\n",
    "gamma0 = smooth_zeros(N_ZEROS)\n",
    "delta = gamma_n - gamma0\n",
    "tp = theta_deriv(gamma0)\n",
    "print(f\"  Done in {time.time()-t0:.1f}s\")\n",
    "print(f\"  delta: mean={np.mean(delta):.6f}, std={np.std(delta):.4f}\")\n",
    "\n",
    "# Sieve primes\n",
    "P_MAX = 3_000_000\n",
    "print(f\"Sieving primes up to {P_MAX:,}...\")\n",
    "t0 = time.time()\n",
    "primes = sieve(P_MAX)\n",
    "print(f\"  {len(primes):,} primes in {time.time()-t0:.1f}s\")\n",
    "\n",
    "# Preview: theta per window\n",
    "theta_range = theta_gift(gamma0)\n",
    "print(f\"\\ntheta(T) profile across 2M zeros:\")\n",
    "print(f\"  T_min={gamma0[0]:.1f} -> theta={theta_range[0]:.4f}\")\n",
    "print(f\"  T_mid={gamma0[N_ZEROS//2]:.0f} -> theta={theta_range[N_ZEROS//2]:.4f}\")\n",
    "print(f\"  T_max={gamma0[-1]:.0f} -> theta={theta_range[-1]:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CHECKPOINT = 'dp_gift_correction_2M.npy'\n",
    "drive_ckpt = os.path.join(DRIVE_DIR, CHECKPOINT) if DRIVE_DIR else None\n",
    "CHUNK_SIZE = 100_000\n",
    "start_chunk = 0\n",
    "\n",
    "# Resume from checkpoint\n",
    "if drive_ckpt and os.path.exists(drive_ckpt):\n",
    "    delta_pred = np.load(drive_ckpt)\n",
    "    for i in range(N_ZEROS - 1, 0, -1):\n",
    "        if delta_pred[i] != 0.0:\n",
    "            start_chunk = ((i // CHUNK_SIZE) + 1) * CHUNK_SIZE\n",
    "            break\n",
    "    print(f\"Resuming from {start_chunk:,} ({100*start_chunk/N_ZEROS:.1f}%)\")\n",
    "elif os.path.exists(CHECKPOINT):\n",
    "    delta_pred = np.load(CHECKPOINT)\n",
    "    for i in range(N_ZEROS - 1, 0, -1):\n",
    "        if delta_pred[i] != 0.0:\n",
    "            start_chunk = ((i // CHUNK_SIZE) + 1) * CHUNK_SIZE\n",
    "            break\n",
    "    print(f\"Resuming from {start_chunk:,}\")\n",
    "else:\n",
    "    delta_pred = np.zeros(N_ZEROS)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MAIN COMPUTATION: GIFT variable-theta prime sum\")\n",
    "print(f\"  theta(T) = 10/7 - (14/3)/log(T)\")\n",
    "print(f\"  {N_ZEROS:,} zeros in chunks of {CHUNK_SIZE:,}\")\n",
    "print(f\"  {len(primes):,} primes, k_max={K_MAX}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "t0_main = time.time()\n",
    "for i in range(start_chunk, N_ZEROS, CHUNK_SIZE):\n",
    "    j = min(i + CHUNK_SIZE, N_ZEROS)\n",
    "    ct = time.time()\n",
    "    delta_pred[i:j] = prime_sum_var(\n",
    "        gamma0[i:j], tp[i:j], primes, K_MAX,\n",
    "        THETA_INF, THETA_COEFF, w_cosine)\n",
    "    elapsed = time.time() - ct\n",
    "    pct = 100 * j / N_ZEROS\n",
    "    total_el = time.time() - t0_main\n",
    "    done_zeros = j - start_chunk\n",
    "    if done_zeros > 0:\n",
    "        eta = total_el / done_zeros * (N_ZEROS - j)\n",
    "    else:\n",
    "        eta = 0\n",
    "    print(f\"  [{i:>8,}:{j:>8,}) ({pct:5.1f}%) {elapsed:.0f}s  \"\n",
    "          f\"[total {total_el/3600:.1f}h, ETA {eta/3600:.1f}h]\")\n",
    "\n",
    "    # Checkpoint after each chunk\n",
    "    np.save(CHECKPOINT, delta_pred)\n",
    "    if drive_ckpt:\n",
    "        shutil.copy2(CHECKPOINT, drive_ckpt)\n",
    "\n",
    "total_main = time.time() - t0_main\n",
    "print(f\"\\nComputation complete: {total_main:.0f}s ({total_main/3600:.1f}h)\")\n",
    "\n",
    "# Save to Drive immediately\n",
    "if drive_ckpt:\n",
    "    shutil.copy2(CHECKPOINT, drive_ckpt)\n",
    "    print(f\"  Saved to Drive: {drive_ckpt}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "residuals = delta - delta_pred\n",
    "R2_global = float(1.0 - np.var(residuals) / np.var(delta))\n",
    "alpha_OLS = float(np.dot(delta, delta_pred) / np.dot(delta_pred, delta_pred))\n",
    "\n",
    "# Scaled metrics\n",
    "resid_scaled = delta - alpha_OLS * delta_pred\n",
    "R2_scaled = float(1.0 - np.var(resid_scaled) / np.var(delta))\n",
    "\n",
    "# Localization\n",
    "half_gaps = np.diff(gamma_n) / 2.0\n",
    "n_loc = min(len(residuals) - 1, len(half_gaps))\n",
    "localized = np.abs(residuals[1:n_loc+1]) < half_gaps[:n_loc]\n",
    "loc_rate = float(np.mean(localized))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"GLOBAL METRICS -- GIFT CORRECTION MODEL\")\n",
    "print(f\"  theta(T) = 10/7 - (14/3)/log(T)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  alpha (OLS):        {alpha_OLS:+.6f}\")\n",
    "print(f\"  |alpha - 1|:        {abs(alpha_OLS - 1):.6f}\")\n",
    "print(f\"  R2 (alpha=1):       {R2_global:.6f}\")\n",
    "print(f\"  R2 (alpha=OLS):     {R2_scaled:.6f}\")\n",
    "print(f\"  E_rms:              {np.sqrt(np.mean(residuals**2)):.4f}\")\n",
    "print(f\"  E_max:              {np.max(np.abs(residuals)):.4f}\")\n",
    "print(f\"  Localization:       {loc_rate*100:.2f}%\")\n",
    "\n",
    "# Compare to constant model\n",
    "print(f\"\\n  (Constant theta*=0.9941 had: alpha=1.006358, R2=0.9219)\")\n",
    "\n",
    "# Window analysis\n",
    "WINDOWS = [\n",
    "    (0, 100_000), (100_000, 200_000), (200_000, 500_000),\n",
    "    (500_000, 1_000_000), (1_000_000, 1_500_000), (1_500_000, N_ZEROS),\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Window':>20} | {'T range':>25} | {'alpha':>8} | {'R2':>8} | \"\n",
    "      f\"{'theta':>8} | {'Loc%':>8}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "window_results = []\n",
    "for (a, b) in WINDOWS:\n",
    "    d_w = delta[a:b]\n",
    "    dp_w = delta_pred[a:b]\n",
    "    r_w = d_w - dp_w\n",
    "    dot_pp = np.dot(dp_w, dp_w)\n",
    "    alpha_w = float(np.dot(d_w, dp_w) / dot_pp) if dot_pp > 0 else 1.0\n",
    "    R2_w = float(1.0 - np.var(r_w) / np.var(d_w))\n",
    "    T_lo = gamma_n[a]\n",
    "    T_hi = gamma_n[min(b-1, len(gamma_n)-1)]\n",
    "    T_mid = (T_lo + T_hi) / 2\n",
    "    theta_mid = float(theta_gift(T_mid))\n",
    "\n",
    "    hg_a = max(a-1, 0)\n",
    "    hg_b = min(b, len(half_gaps))\n",
    "    n_w = min(b-a-1, hg_b - hg_a)\n",
    "    loc_w = float(np.mean(np.abs(r_w[1:n_w+1]) < half_gaps[hg_a:hg_a+n_w])) if n_w > 0 else 0.0\n",
    "\n",
    "    label = f\"[{a//1000}k, {b//1000}k)\"\n",
    "    print(f\"{label:>20} | [{T_lo:>10.1f}, {T_hi:>10.1f}] | {alpha_w:>+8.4f} | \"\n",
    "          f\"{R2_w:>8.4f} | {theta_mid:>8.4f} | {loc_w*100:>7.2f}%\")\n",
    "    window_results.append({\n",
    "        'window': label, 'T_lo': float(T_lo), 'T_hi': float(T_hi),\n",
    "        'alpha': alpha_w, 'R2': R2_w, 'theta_mid': theta_mid,\n",
    "        'localization': loc_w,\n",
    "    })\n",
    "\n",
    "# Quick checkpoint\n",
    "ckpt_json = 'gift_correction_metrics.json'\n",
    "with open(ckpt_json, 'w') as f:\n",
    "    json.dump({'alpha': alpha_OLS, 'R2': R2_global, 'R2_scaled': R2_scaled,\n",
    "               'loc': loc_rate, 'windows': window_results}, f, indent=2)\n",
    "if DRIVE_DIR:\n",
    "    shutil.copy2(ckpt_json, os.path.join(DRIVE_DIR, ckpt_json))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"VALIDATION TESTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# \u2500\u2500 T7: Bootstrap CI for alpha \u2500\u2500\n",
    "print(\"\\n[T7] Bootstrap Confidence Interval for alpha\")\n",
    "print(\"-\" * 50)\n",
    "B = 5000\n",
    "np.random.seed(123)\n",
    "alpha_boots = np.empty(B)\n",
    "for b in range(B):\n",
    "    idx = np.random.randint(0, N_ZEROS, N_ZEROS)\n",
    "    d_b = delta[idx]\n",
    "    dp_b = delta_pred[idx]\n",
    "    dot_pp = np.dot(dp_b, dp_b)\n",
    "    alpha_boots[b] = np.dot(d_b, dp_b) / dot_pp if dot_pp > 0 else 0.0\n",
    "\n",
    "ci_lo = float(np.percentile(alpha_boots, 2.5))\n",
    "ci_hi = float(np.percentile(alpha_boots, 97.5))\n",
    "T7_pass = ci_lo <= 1.0 <= ci_hi\n",
    "print(f\"  alpha(OLS):    {alpha_OLS:.6f}\")\n",
    "print(f\"  95% CI:        [{ci_lo:.6f}, {ci_hi:.6f}]\")\n",
    "print(f\"  Contains 1.0?  {'YES' if T7_pass else 'NO'}\")\n",
    "print(f\"  Distance:      {min(abs(1-ci_lo), abs(1-ci_hi)):.6f}\")\n",
    "print(f\"  >> {'PASS' if T7_pass else 'FAIL'}\")\n",
    "print(f\"  (Constant model: CI=[1.0057, 1.0070], FAIL)\")\n",
    "\n",
    "# \u2500\u2500 T8: Drift test \u2500\u2500\n",
    "print(f\"\\n[T8] Drift Test (alpha across windows)\")\n",
    "print(\"-\" * 50)\n",
    "alphas_w = np.array([w['alpha'] for w in window_results])\n",
    "slope, intercept, r_val, p_val_drift, se = stats.linregress(\n",
    "    np.arange(len(alphas_w), dtype=float), alphas_w)\n",
    "T8_pass = p_val_drift > 0.05\n",
    "print(f\"  alphas: {[round(a, 4) for a in alphas_w]}\")\n",
    "print(f\"  Slope:  {slope:+.6f}/window\")\n",
    "print(f\"  p-val:  {p_val_drift:.4f}\")\n",
    "print(f\"  >> {'PASS' if T8_pass else 'FAIL'}\")\n",
    "print(f\"  (Constant model: slope=+0.003875, p=0.038, FAIL)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"[T5] Monte Carlo Permutation Tests\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "N_TRIALS = 200\n",
    "N_MC = 200_000\n",
    "np.random.seed(42)\n",
    "\n",
    "d_mc = delta[:N_MC]\n",
    "g0_mc = gamma0[:N_MC]\n",
    "tp_mc = tp[:N_MC]\n",
    "primes_mc = primes[primes <= 50_000]  # ~5k primes for speed\n",
    "\n",
    "# Fair R2 for GIFT model with same prime set\n",
    "print(\"  Computing GIFT model R2 with test prime set...\")\n",
    "t0 = time.time()\n",
    "dp_gift_mc = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n",
    "                           THETA_INF, THETA_COEFF, w_cosine)\n",
    "R2_gift = float(1.0 - np.var(d_mc - dp_gift_mc) / np.var(d_mc))\n",
    "print(f\"  R2(GIFT, 50k primes):  {R2_gift:.6f}  [{time.time()-t0:.0f}s]\")\n",
    "\n",
    "# \u2500\u2500 T5a: vs random constant theta \u2500\u2500\n",
    "print(f\"\\n  T5a: GIFT variable-theta vs {N_TRIALS} random constant thetas\")\n",
    "print(\"-\" * 50)\n",
    "theta_random = np.random.uniform(0.3, 2.0, N_TRIALS)\n",
    "R2_const = []\n",
    "t1 = time.time()\n",
    "for i, th in enumerate(theta_random):\n",
    "    dp_r = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n",
    "                         float(th), 0.0, w_cosine)\n",
    "    R2_const.append(float(1.0 - np.var(d_mc - dp_r) / np.var(d_mc)))\n",
    "    if (i + 1) % 50 == 0:\n",
    "        el = time.time() - t1\n",
    "        eta = el / (i+1) * (N_TRIALS - i - 1)\n",
    "        print(f\"    {i+1}/{N_TRIALS}... [{el:.0f}s, ETA {eta:.0f}s]\")\n",
    "\n",
    "R2_const = np.array(R2_const)\n",
    "margin_a = R2_gift - float(np.max(R2_const))\n",
    "p_val_a = float(np.mean(R2_const >= R2_gift))\n",
    "T5a_pass = margin_a > 0\n",
    "print(f\"\\n  R2(GIFT):       {R2_gift:.6f}\")\n",
    "print(f\"  R2(best const): {np.max(R2_const):.6f}\")\n",
    "print(f\"  Margin:         {margin_a:+.6f}\")\n",
    "print(f\"  p-value:        {p_val_a:.4f}\")\n",
    "print(f\"  >> T5a: {'PASS' if T5a_pass else 'FAIL'}\")\n",
    "\n",
    "# \u2500\u2500 T5b: vs random correction models theta(T) = a + b/log(T) \u2500\u2500\n",
    "print(f\"\\n  T5b: GIFT (10/7, -14/3) vs {N_TRIALS} random correction models\")\n",
    "print(\"-\" * 50)\n",
    "a_rand = np.random.uniform(0.8, 2.0, N_TRIALS)\n",
    "b_rand = np.random.uniform(-10.0, 0.0, N_TRIALS)\n",
    "R2_rand_corr = []\n",
    "t1 = time.time()\n",
    "for i in range(N_TRIALS):\n",
    "    dp_r = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n",
    "                         float(a_rand[i]), float(b_rand[i]), w_cosine)\n",
    "    R2_rand_corr.append(float(1.0 - np.var(d_mc - dp_r) / np.var(d_mc)))\n",
    "    if (i + 1) % 50 == 0:\n",
    "        el = time.time() - t1\n",
    "        eta = el / (i+1) * (N_TRIALS - i - 1)\n",
    "        print(f\"    {i+1}/{N_TRIALS}... [{el:.0f}s, ETA {eta:.0f}s]\")\n",
    "\n",
    "R2_rand_corr = np.array(R2_rand_corr)\n",
    "margin_b = R2_gift - float(np.max(R2_rand_corr))\n",
    "p_val_b = float(np.mean(R2_rand_corr >= R2_gift))\n",
    "T5b_pass = margin_b > 0\n",
    "print(f\"\\n  R2(GIFT):         {R2_gift:.6f}\")\n",
    "print(f\"  R2(best random):  {np.max(R2_rand_corr):.6f}\")\n",
    "print(f\"  Margin:           {margin_b:+.6f}\")\n",
    "print(f\"  p-value:          {p_val_b:.4f}\")\n",
    "print(f\"  >> T5b: {'PASS' if T5b_pass else 'FAIL'}\")\n",
    "\n",
    "T5_pass = T5a_pass and T5b_pass\n",
    "n_pass = sum([T5_pass, T7_pass, T8_pass])\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"VALIDATION SCORE: {n_pass}/3\")\n",
    "print(f\"  T5 (MC):     {'PASS' if T5_pass else 'FAIL'} (a={margin_a:+.4f}, b={margin_b:+.4f})\")\n",
    "print(f\"  T7 (Boot):   {'PASS' if T7_pass else 'FAIL'} CI=[{ci_lo:.4f}, {ci_hi:.4f}]\")\n",
    "print(f\"  T8 (Drift):  {'PASS' if T8_pass else 'FAIL'} slope={slope:+.6f}\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"\\nConstant model was: 1/3 (T5 pass, T7 fail, T8 fail)\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RESIDUAL DIAGNOSTICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ACF\n",
    "res_c = residuals - np.mean(residuals)\n",
    "var_res = np.var(res_c)\n",
    "lags = [1, 2, 3, 5, 8, 13, 21]\n",
    "acf_r = [float(np.mean(res_c[l:]*res_c[:-l])/var_res) for l in lags]\n",
    "wn_bound = 1.96 / np.sqrt(N_ZEROS)\n",
    "\n",
    "print(f\"\\n  Residual ACF (white-noise bound: +/-{wn_bound:.5f}):\")\n",
    "for i, l in enumerate(lags):\n",
    "    sig = \"***\" if abs(acf_r[i]) > wn_bound else \"\"\n",
    "    print(f\"    lag {l:>3}: {acf_r[i]:+.6f} {sig}\")\n",
    "\n",
    "print(f\"\\n  GUE prediction for lag-1: ~-0.47\")\n",
    "print(f\"  Our lag-1 residual ACF:    {acf_r[0]:+.4f}\")\n",
    "\n",
    "# Variance decomposition\n",
    "vd = float(np.var(delta))\n",
    "vp = float(np.var(delta_pred))\n",
    "vr = float(np.var(residuals))\n",
    "print(f\"\\n  Var(delta):     {vd:.6f}\")\n",
    "print(f\"  Var(pred):      {vp:.6f}  ({100*vp/vd:.1f}%)\")\n",
    "print(f\"  Var(residual):  {vr:.6f}  ({100*vr/vd:.1f}%)\")\n",
    "\n",
    "# \u2500\u2500 Figures \u2500\u2500\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# (0,0) Window alphas: GIFT vs constant\n",
    "ax = axes[0, 0]\n",
    "const_alphas = [0.9869, 1.0029, 1.0059, 1.0082, 1.0093, 1.0097]  # from original\n",
    "gift_alphas = [w['alpha'] for w in window_results]\n",
    "x_w = np.arange(len(gift_alphas))\n",
    "ax.bar(x_w - 0.15, const_alphas, 0.3, label='Constant (0.9941)', color='coral', alpha=0.8)\n",
    "ax.bar(x_w + 0.15, gift_alphas, 0.3, label='GIFT correction', color='steelblue', alpha=0.8)\n",
    "ax.axhline(1.0, color='red', ls='--', lw=1.5)\n",
    "ax.set_xticks(x_w)\n",
    "ax.set_xticklabels([w['window'] for w in window_results], rotation=30, fontsize=8)\n",
    "ax.set_ylabel('alpha (OLS)')\n",
    "ax.set_title('Alpha per Window')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# (0,1) Window R2: GIFT vs constant\n",
    "ax = axes[0, 1]\n",
    "const_R2 = [0.9394, 0.9298, 0.9249, 0.9208, 0.9183, 0.9165]\n",
    "gift_R2 = [w['R2'] for w in window_results]\n",
    "ax.bar(x_w - 0.15, const_R2, 0.3, label='Constant', color='coral', alpha=0.8)\n",
    "ax.bar(x_w + 0.15, gift_R2, 0.3, label='GIFT correction', color='steelblue', alpha=0.8)\n",
    "ax.set_xticks(x_w)\n",
    "ax.set_xticklabels([w['window'] for w in window_results], rotation=30, fontsize=8)\n",
    "ax.set_ylabel('R2')\n",
    "ax.set_title('R2 per Window')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# (0,2) Theta profile\n",
    "ax = axes[0, 2]\n",
    "T_plot = np.logspace(1.5, 6.5, 200)\n",
    "ax.plot(np.log10(T_plot), theta_gift(T_plot), 'b-', lw=2, label='GIFT: 10/7 - (14/3)/log(T)')\n",
    "ax.axhline(0.9941, color='coral', ls='--', label='Constant: 0.9941')\n",
    "ax.axhline(THETA_INF, color='gray', ls=':', alpha=0.5, label=f'10/7 = {THETA_INF:.4f}')\n",
    "T_mids = [(w['T_lo']+w['T_hi'])/2 for w in window_results]\n",
    "ax.plot(np.log10(T_mids), [w['theta_mid'] for w in window_results],\n",
    "        'ro', ms=6, label='Window midpoints')\n",
    "ax.set_xlabel('log10(T)')\n",
    "ax.set_ylabel('theta(T)')\n",
    "ax.set_title('GIFT Theta Profile')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# (1,0) Residual histogram\n",
    "ax = axes[1, 0]\n",
    "ax.hist(residuals, bins=200, density=True, alpha=0.7, color='steelblue')\n",
    "from scipy.stats import norm\n",
    "xn = np.linspace(-0.5, 0.5, 300)\n",
    "ax.plot(xn, norm.pdf(xn, np.mean(residuals), np.std(residuals)),\n",
    "        'r-', lw=2, label=f'Normal (std={np.std(residuals):.4f})')\n",
    "ax.set_xlabel('Residual')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Residual Distribution')\n",
    "ax.legend()\n",
    "ax.set_xlim(-0.5, 0.5)\n",
    "\n",
    "# (1,1) ACF bars\n",
    "ax = axes[1, 1]\n",
    "ax.bar(range(len(lags)), acf_r, color='steelblue', alpha=0.8)\n",
    "ax.axhline(0, color='gray', alpha=0.3)\n",
    "ax.axhline(wn_bound, color='red', ls=':', alpha=0.5)\n",
    "ax.axhline(-wn_bound, color='red', ls=':', alpha=0.5)\n",
    "ax.set_xticks(range(len(lags)))\n",
    "ax.set_xticklabels([str(l) for l in lags])\n",
    "ax.set_xlabel('Lag')\n",
    "ax.set_ylabel('ACF')\n",
    "ax.set_title('Residual Autocorrelation')\n",
    "\n",
    "# (1,2) Spacing distribution\n",
    "ax = axes[1, 2]\n",
    "spacings = np.diff(gamma_n) / np.mean(np.diff(gamma_n))\n",
    "ax.hist(spacings, bins=200, range=(0, 4), density=True, alpha=0.6, color='steelblue')\n",
    "s_grid = np.linspace(0.01, 4, 500)\n",
    "P_gue = (32/np.pi**2) * s_grid**2 * np.exp(-4*s_grid**2/np.pi)\n",
    "ax.plot(s_grid, P_gue, 'r-', lw=2, label='GUE Wigner')\n",
    "ax.set_xlabel('Normalized spacing')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Spacing Distribution')\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 3.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gift_correction_2M_results.png', dpi=150, bbox_inches='tight')\n",
    "if DRIVE_DIR:\n",
    "    shutil.copy2('gift_correction_2M_results.png',\n",
    "                 os.path.join(DRIVE_DIR, 'gift_correction_2M_results.png'))\n",
    "print(\"Saved gift_correction_2M_results.png\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {\n",
    "    'metadata': {\n",
    "        'date': time.strftime('%Y-%m-%d'),\n",
    "        'model': 'GIFT correction: theta(T) = 10/7 - (14/3)/log(T)',\n",
    "        'theta_inf': float(THETA_INF),\n",
    "        'theta_coeff': float(THETA_COEFF),\n",
    "        'theta_inf_origin': '(dim(K7) + N_gen) / dim(K7) = 10/7',\n",
    "        'coeff_origin': '-dim(G2) / N_gen = -14/3',\n",
    "        'N_zeros': int(N_ZEROS),\n",
    "        'T_max': float(gamma_n[-1]),\n",
    "        'k_max': K_MAX,\n",
    "        'P_max': int(primes[-1]),\n",
    "        'n_primes': int(len(primes)),\n",
    "        'mollifier': 'cosine',\n",
    "        'source': 'Odlyzko zeros6',\n",
    "    },\n",
    "    'global': {\n",
    "        'alpha_OLS': float(alpha_OLS),\n",
    "        'R2_alpha1': float(R2_global),\n",
    "        'R2_alphaOLS': float(R2_scaled),\n",
    "        'E_rms': float(np.sqrt(np.mean(residuals**2))),\n",
    "        'E_max': float(np.max(np.abs(residuals))),\n",
    "        'localization': float(loc_rate),\n",
    "    },\n",
    "    'comparison_to_constant': {\n",
    "        'constant_alpha': 1.006358,\n",
    "        'constant_R2': 0.9219,\n",
    "        'constant_score': '1/3',\n",
    "    },\n",
    "    'validation': {\n",
    "        'T5': {\n",
    "            'pass': bool(T5_pass),\n",
    "            'T5a_margin': float(margin_a),\n",
    "            'T5a_pval': float(p_val_a),\n",
    "            'T5b_margin': float(margin_b),\n",
    "            'T5b_pval': float(p_val_b),\n",
    "            'n_trials': N_TRIALS,\n",
    "        },\n",
    "        'T7_bootstrap': {\n",
    "            'pass': bool(T7_pass),\n",
    "            'alpha_hat': float(alpha_OLS),\n",
    "            'CI_lo': float(ci_lo),\n",
    "            'CI_hi': float(ci_hi),\n",
    "            'B': B,\n",
    "        },\n",
    "        'T8_drift': {\n",
    "            'pass': bool(T8_pass),\n",
    "            'slope': float(slope),\n",
    "            'p_value': float(p_val_drift),\n",
    "        },\n",
    "        'score': f'{n_pass}/3',\n",
    "    },\n",
    "    'windows': window_results,\n",
    "    'residual_acf': {f'lag_{l}': float(acf_r[i]) for i, l in enumerate(lags)},\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "out_file = 'gift_correction_2M_full_results.json'\n",
    "with open(out_file, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"  {out_file}\")\n",
    "\n",
    "# Save .npy\n",
    "np.save('dp_gift_correction_2M.npy', delta_pred)\n",
    "print(f\"  dp_gift_correction_2M.npy ({delta_pred.nbytes/1e6:.1f} MB)\")\n",
    "\n",
    "# Drive backup\n",
    "if DRIVE_DIR:\n",
    "    for f in [out_file, 'dp_gift_correction_2M.npy',\n",
    "              'gift_correction_2M_results.png']:\n",
    "        if os.path.exists(f):\n",
    "            shutil.copy2(f, os.path.join(DRIVE_DIR, f))\n",
    "            print(f\"  -> Drive: {f}\")\n",
    "\n",
    "# Browser download\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"\\nTriggering browser downloads:\")\n",
    "    files.download(out_file)\n",
    "    files.download('gift_correction_2M_results.png')\n",
    "    print(\"  Downloads triggered (JSON + PNG)\")\n",
    "    # .npy too large for browser, Drive only\n",
    "except ImportError:\n",
    "    print(\"\\nNot in Colab \u2014 files saved locally\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"DONE. GIFT Correction Model Results:\")\n",
    "print(f\"  Score:    {n_pass}/3  (constant model: 1/3)\")\n",
    "print(f\"  alpha:    {alpha_OLS:.6f}  (constant: 1.006358)\")\n",
    "print(f\"  R2:       {R2_global:.6f}  (constant: 0.9219)\")\n",
    "print(f\"  Loc:      {loc_rate*100:.2f}%\")\n",
    "print(f\"{'=' * 60}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}