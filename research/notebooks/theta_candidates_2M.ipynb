{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Theta Candidate Tournament: Screen + Validate + Rational Scan\n\n**Strategy** (like Connes with his first 6 primes):\n1. **Phase 1 — Screening**: Test ALL candidates on **50k zeros** (~5 min/candidate CPU, ~30s GPU)\n2. **Phase 2 — Validation**: Run the **top 2** on full **2M zeros** with T5/T7/T8\n3. **Rational Scan**: Exhaustive grid search over small-denominator rationals $(a/b - c/d / \\log T)$\n4. **Phase 3 — Rational Winner Validation**: Run rational scan winner + GIFT reference on **2M zeros** with T5/T7/T8\n\n**GPU acceleration** (CuPy): Batches primes via `(N, B)` broadcasting instead of looping one-by-one.\n- RTX 2050 (4GB): batch=150, ~10-15x speedup → Phase 1 ~10 min, Phase 2 ~45 min\n- A100 (80GB): batch=2000, ~30-50x speedup → Phase 1 ~3 min, Phase 2 ~15 min\n- No GPU: CPU fallback, Phase 1 ~1.5h, Phase 2 ~7h\n\n**Methodology** (exact replication of `GIFT_Correction_2M_Zeros.ipynb`):\n- Truth: $\\delta_n = \\gamma_n - \\gamma^0_n$ (positional deviation from smooth zeros)\n- Prediction: $\\delta_{\\text{pred}} = -S_w(\\gamma^0) / \\theta'(\\gamma^0)$\n- Metric: $\\alpha = \\langle\\delta, \\delta_{\\text{pred}}\\rangle / \\langle\\delta_{\\text{pred}}, \\delta_{\\text{pred}}\\rangle$, $R^2 = 1 - \\text{Var}(\\delta - \\delta_{\\text{pred}})/\\text{Var}(\\delta)$\n\n**Validation tests** (Phase 2 & 3, on winners):\n- T5a: Beat 200 random constant-$\\theta$ models (R2)\n- T5b: Beat 200 random correction models $a + b/\\log T$ (R2)\n- T7: Bootstrap 95% CI for $\\alpha$ contains 1.0\n- T8: No significant drift in $\\alpha$ across windows ($p > 0.05$)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport os, sys, time, json, shutil, warnings\nfrom scipy.special import loggamma, lambertw\nfrom scipy import stats\nfrom scipy.optimize import minimize_scalar, minimize\nwarnings.filterwarnings('ignore')\n\nprint(f\"NumPy {np.__version__}, Python {sys.version.split()[0]}\")\n\n# ---- GPU DETECTION ----\nGPU = False\nGPU_BATCH = 200  # default conservative batch size\ntry:\n    import cupy as cp\n    gpu_props = cp.cuda.runtime.getDeviceProperties(0)\n    gpu_name = gpu_props['name'].decode()\n    gpu_mem_gb = gpu_props['totalGlobalMem'] / 1e9\n    GPU = True\n    # Adaptive batch size based on VRAM\n    # Memory per batch element: N_zeros * 8 bytes * ~5 arrays = 40 * N bytes\n    # For 50k zeros, batch=200 -> 50k*200*8*5 = 400MB (safe for 4GB)\n    # For 50k zeros, batch=1000 -> 50k*1000*8*5 = 2GB (safe for 8GB+)\n    # For 200k zeros (chunks), batch=500 -> 200k*500*8*5 = 4GB (needs 8GB+)\n    if gpu_mem_gb >= 40:    # A100 (40/80GB)\n        GPU_BATCH = 2000\n    elif gpu_mem_gb >= 8:   # RTX 3070+, T4\n        GPU_BATCH = 500\n    else:                   # RTX 2050 (4GB), etc.\n        GPU_BATCH = 150\n    print(f\"GPU: {gpu_name} ({gpu_mem_gb:.1f} GB) -> batch={GPU_BATCH}\")\nexcept Exception as e:\n    print(f\"No GPU: {e} — using CPU\")\n\n# Mount Google Drive for checkpointing\nDRIVE_DIR = '/content/drive/MyDrive/GIFT_results'\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive', force_remount=False)\n    os.makedirs(DRIVE_DIR, exist_ok=True)\n    print(f\"Drive mounted -> {DRIVE_DIR}\")\nexcept Exception:\n    DRIVE_DIR = None\n    print(\"No Drive — local storage only\")\n\ndef save_to_drive(local_path):\n    \"\"\"Copy a local file to Drive if available.\"\"\"\n    if DRIVE_DIR and os.path.exists(local_path):\n        shutil.copy2(local_path, os.path.join(DRIVE_DIR, os.path.basename(local_path)))\n        return True\n    return False"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Odlyzko Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "CACHE_FILE = 'riemann_zeros_2M_genuine.npy'\n",
    "\n",
    "def download_odlyzko():\n",
    "    \"\"\"Download and cache Odlyzko's 2,001,052 zeros.\"\"\"\n",
    "    # Check local cache\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        print(f\"Loading cached zeros (local)...\")\n",
    "        return np.load(CACHE_FILE)\n",
    "    # Check Drive cache\n",
    "    drive_cache = os.path.join(DRIVE_DIR, CACHE_FILE) if DRIVE_DIR else None\n",
    "    if drive_cache and os.path.exists(drive_cache):\n",
    "        print(f\"Loading cached zeros (Drive)...\")\n",
    "        shutil.copy2(drive_cache, CACHE_FILE)\n",
    "        return np.load(CACHE_FILE)\n",
    "    # Download\n",
    "    url = 'https://www-users.cse.umn.edu/~odlyzko/zeta_tables/zeros6'\n",
    "    print(f\"Downloading from {url}...\")\n",
    "    t0 = time.time()\n",
    "    response = urllib.request.urlopen(url, timeout=300)\n",
    "    raw = response.read().decode('utf-8')\n",
    "    zeros = np.array([float(l.strip()) for l in raw.strip().split('\\n') if l.strip()])\n",
    "    print(f\"  {len(zeros):,} zeros in {time.time()-t0:.1f}s\")\n",
    "    np.save(CACHE_FILE, zeros)\n",
    "    save_to_drive(CACHE_FILE)\n",
    "    return zeros\n",
    "\n",
    "gamma_n = download_odlyzko()\n",
    "N_ZEROS = len(gamma_n)\n",
    "print(f\"\\nLoaded {N_ZEROS:,} zeros, range [{gamma_n[0]:.3f}, {gamma_n[-1]:.3f}]\")\n",
    "\n",
    "# Sanity check\n",
    "KNOWN = [14.134725142, 21.022039639, 25.010857580, 30.424876126, 32.935061588]\n",
    "for i, k in enumerate(KNOWN):\n",
    "    err = abs(gamma_n[i] - k)\n",
    "    status = 'OK' if err < 1e-6 else 'BAD'\n",
    "    print(f\"  gamma_{i+1} = {gamma_n[i]:.9f}  (err: {err:.2e}) [{status}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Infrastructure (exact notebook methodology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# CORE FUNCTIONS (exact methodology from GIFT_Correction_2M_Zeros.ipynb)\n# + GPU-batched acceleration via CuPy when available\n# ================================================================\n\ndef theta_rs(t):\n    \"\"\"Riemann-Siegel theta function.\"\"\"\n    t = np.asarray(t, dtype=np.float64)\n    return np.imag(loggamma(0.25 + 0.5j * t)) - 0.5 * t * np.log(np.pi)\n\ndef theta_deriv(t):\n    \"\"\"theta'(t) ~ 0.5 * log(t/(2*pi)).\"\"\"\n    return 0.5 * np.log(np.maximum(np.asarray(t, dtype=np.float64), 1.0) / (2 * np.pi))\n\ndef smooth_zeros(N):\n    \"\"\"Compute smooth zero positions gamma0_n where theta_RS(gamma0_n) = (n-1.5)*pi.\"\"\"\n    ns = np.arange(1, N + 1, dtype=np.float64)\n    targets = (ns - 1.5) * np.pi\n    w = np.real(lambertw(ns / np.e))\n    t = np.maximum(2 * np.pi * ns / w, 2.0)\n    for _ in range(40):\n        dt = (theta_rs(t) - targets) / np.maximum(np.abs(theta_deriv(t)), 1e-15)\n        t -= dt\n        if np.max(np.abs(dt)) < 1e-12:\n            break\n    return t\n\ndef w_cosine(x):\n    \"\"\"Cosine-squared kernel: w(x) = cos^2(pi*x/2) for x < 1, else 0.\"\"\"\n    return np.where(x < 1.0, np.cos(np.pi * x / 2)**2, 0.0)\n\ndef sieve(N):\n    \"\"\"Sieve of Eratosthenes up to N.\"\"\"\n    is_p = np.ones(N + 1, dtype=bool)\n    is_p[:2] = False\n    for i in range(2, int(N**0.5) + 1):\n        if is_p[i]:\n            is_p[i*i::i] = False\n    return np.where(is_p)[0]\n\n# ================================================================\n# CPU VERSION (fallback)\n# ================================================================\ndef _prime_sum_cpu(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_coeff=0.0):\n    \"\"\"CPU mollified prime sum (original loop-over-primes).\"\"\"\n    S = np.zeros_like(g0)\n    log_g0 = np.log(np.maximum(g0, 2.0))\n\n    if theta_coeff == 0.0 and c_coeff == 0.0:\n        log_X = theta_inf * log_g0\n    else:\n        theta_per = theta_inf + theta_coeff / log_g0\n        if c_coeff != 0.0:\n            theta_per = theta_per + c_coeff / log_g0**2\n        theta_per = np.clip(theta_per, 0.5, 2.0)\n        log_X = theta_per * log_g0\n\n    for p in primes:\n        logp = np.log(float(p))\n        if logp / np.max(log_X) > 3.0:\n            break\n        for m in range(1, k_max + 1):\n            x = m * logp / log_X\n            weight = w_cosine(x)\n            if np.max(weight) < 1e-15:\n                continue\n            S -= weight * np.sin(g0 * m * logp) / (m * p ** (m / 2.0))\n\n    return -S / tp_v\n\n# ================================================================\n# GPU VERSION (batched primes via CuPy broadcasting)\n# ================================================================\ndef _prime_sum_gpu(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_coeff=0.0):\n    \"\"\"GPU-batched mollified prime sum.\n\n    Instead of looping one prime at a time, we process GPU_BATCH primes\n    simultaneously using (N, B) broadcasting:\n      x[i,j] = m * logp[j] / log_X[i]    shape (N, B)\n      S[i] -= sum_j weight[i,j] * sin(g0[i] * m * logp[j]) / (m * p[j]^(m/2))\n\n    This reduces kernel launches by factor GPU_BATCH and maximizes GPU utilization.\n    \"\"\"\n    N = len(g0)\n    BATCH = min(GPU_BATCH, len(primes))\n\n    # Transfer arrays to GPU once\n    g0_d = cp.asarray(g0, dtype=cp.float64)\n    tp_d = cp.asarray(tp_v, dtype=cp.float64)\n    S_d = cp.zeros(N, dtype=cp.float64)\n    log_g0_d = cp.log(cp.maximum(g0_d, 2.0))\n\n    # Compute log_X on GPU\n    if theta_coeff == 0.0 and c_coeff == 0.0:\n        log_X_d = theta_inf * log_g0_d\n    else:\n        theta_per = theta_inf + theta_coeff / log_g0_d\n        if c_coeff != 0.0:\n            theta_per = theta_per + c_coeff / log_g0_d**2\n        theta_per = cp.clip(theta_per, 0.5, 2.0)\n        log_X_d = theta_per * log_g0_d\n\n    max_log_X = float(cp.max(log_X_d))\n\n    # Precompute log(p) on CPU, filter contributing primes\n    logp_all = np.log(primes.astype(np.float64))\n\n    for m in range(1, k_max + 1):\n        # Find max contributing prime for this m\n        max_logp = max_log_X / m  # w_cosine(x)=0 when x>=1, so m*logp/log_X >= 1\n        # Also check the 3.0 cutoff from original code (for m=1)\n        cutoff_logp = min(max_logp, 3.0 * max_log_X) if m == 1 else max_logp\n        contributing = logp_all <= cutoff_logp * 1.01  # small margin\n        n_contrib = int(np.sum(contributing))\n        if n_contrib == 0:\n            continue\n\n        contrib_primes = primes[:n_contrib]  # primes are sorted\n        contrib_logp = logp_all[:n_contrib]\n        contrib_pm = contrib_primes.astype(np.float64) ** (m / 2.0)\n\n        # Process in batches\n        for bi in range(0, n_contrib, BATCH):\n            bj = min(bi + BATCH, n_contrib)\n            B = bj - bi\n\n            logp_d = cp.asarray(contrib_logp[bi:bj])     # (B,)\n            pm_d = cp.asarray(contrib_pm[bi:bj])          # (B,)\n\n            # Broadcasting: (N, 1) op (1, B) -> (N, B)\n            x = m * logp_d[None, :] / log_X_d[:, None]   # (N, B)\n            weight = cp.where(x < 1.0, cp.cos(cp.pi * x / 2)**2, 0.0)  # (N, B)\n\n            # Skip if no weights (entire batch contributes nothing)\n            if float(cp.max(weight)) < 1e-15:\n                continue\n\n            phases = g0_d[:, None] * (m * logp_d[None, :])  # (N, B)\n            contrib = weight * cp.sin(phases) / (m * pm_d[None, :])  # (N, B)\n            S_d -= cp.sum(contrib, axis=1)  # (N,) - reduce over batch dim\n\n    result = -S_d / tp_d\n    out = cp.asnumpy(result)\n\n    # Free GPU memory\n    del g0_d, tp_d, S_d, log_g0_d, log_X_d, result\n    cp.get_default_memory_pool().free_all_blocks()\n\n    return out\n\n# ================================================================\n# DISPATCHER: auto-select CPU or GPU\n# ================================================================\ndef prime_sum_var(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_coeff=0.0):\n    \"\"\"Mollified prime sum with automatic GPU acceleration.\n\n    theta(T) = theta_inf + theta_coeff/log(T) + c_coeff/log^2(T)\n    Convention: theta_coeff is SIGNED (negative for subtraction).\n    Returns: delta_pred = -S_w_raw / tp\n    \"\"\"\n    if GPU and len(g0) >= 1000:  # GPU only worthwhile for decent array sizes\n        return _prime_sum_gpu(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_coeff)\n    return _prime_sum_cpu(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_coeff)\n\n# ================================================================\n# BENCHMARK (quick sanity check)\n# ================================================================\nif GPU:\n    # Warm up GPU with a tiny test\n    _test_g0 = np.linspace(100.0, 200.0, 1000)\n    _test_tp = 0.5 * np.log(_test_g0 / (2 * np.pi))\n    _test_p = np.array([2, 3, 5, 7, 11, 13])\n\n    t0 = time.time()\n    _r_cpu = _prime_sum_cpu(_test_g0, _test_tp, _test_p, 3, 10/7, -14/3)\n    t_cpu = time.time() - t0\n\n    t0 = time.time()\n    _r_gpu = _prime_sum_gpu(_test_g0, _test_tp, _test_p, 3, 10/7, -14/3)\n    t_gpu = time.time() - t0\n\n    err = np.max(np.abs(_r_cpu - _r_gpu))\n    print(f\"GPU sanity check: max_err={err:.2e} (CPU={t_cpu*1000:.1f}ms, GPU={t_gpu*1000:.1f}ms)\")\n    if err > 1e-10:\n        print(\"  WARNING: GPU results differ! Falling back to CPU.\")\n        GPU = False\n    else:\n        print(\"  GPU validated — using batched prime sum.\")\n    del _test_g0, _test_tp, _test_p, _r_cpu, _r_gpu\nelse:\n    print(\"Using CPU prime sum (install cupy-cuda12x for GPU acceleration).\")\n\nprint(f\"Infrastructure loaded. Backend: {'GPU' if GPU else 'CPU'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Smooth Zeros & Sieve Primes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth zeros (takes ~20s for 2M)\n",
    "print(\"Computing smooth zeros for all 2M zeros...\")\n",
    "t0 = time.time()\n",
    "gamma0 = smooth_zeros(N_ZEROS)\n",
    "delta = gamma_n - gamma0\n",
    "tp = theta_deriv(gamma0)\n",
    "print(f\"  Done in {time.time()-t0:.1f}s\")\n",
    "print(f\"  delta: mean={np.mean(delta):.6f}, std={np.std(delta):.4f}\")\n",
    "\n",
    "# Sieve primes up to 3M (same as reference notebook)\n",
    "P_MAX = 3_000_000\n",
    "K_MAX = 3\n",
    "print(f\"\\nSieving primes up to {P_MAX:,}...\")\n",
    "t0 = time.time()\n",
    "primes = sieve(P_MAX)\n",
    "print(f\"  {len(primes):,} primes in {time.time()-t0:.1f}s\")\n",
    "\n",
    "# Also prepare smaller prime set for Monte Carlo (speed)\n",
    "primes_mc = primes[primes <= 50_000]  # ~5k primes\n",
    "print(f\"  MC prime set: {len(primes_mc):,} primes (up to 50k)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Candidate Models\n",
    "\n",
    "Each candidate is $\\theta(T) = a - b/\\log T$ (or with optional $c/\\log^2 T$ term).\n",
    "\n",
    "Candidates with `b=None` will have $b$ optimized to minimize $|\\alpha - 1|$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# CANDIDATE THETA MODELS\n",
    "# Format: (name, theta_inf, b, c)\n",
    "#   theta(T) = theta_inf - b/log(T) - c/log^2(T)\n",
    "#   b=None => optimize b to minimize |alpha - 1|\n",
    "#   theta_inf=None => optimize both a and b\n",
    "# ================================================================\n",
    "\n",
    "CANDIDATES = [\n",
    "    # ---- BASELINES ----\n",
    "    (\"Constant theta*=0.9941\",             0.9941,  0.0,    0.0),\n",
    "\n",
    "    # ---- GIFT FAMILY (theta_inf = 10/7) ----\n",
    "    (\"GIFT 10/7 - (14/3)/logT\",            10/7,   14/3,   0.0),\n",
    "    (\"Spinor 10/7 - (13/3)/logT\",          10/7,   13/3,   0.0),\n",
    "    (\"GIFT 10/7 - (30/7)/logT\",            10/7,   30/7,   0.0),\n",
    "    (\"GIFT 10/7 - (17/4)/logT\",            10/7,   17/4,   0.0),\n",
    "    (\"GIFT 10/7 - (14/3)/logT + c/log2T\",  10/7,   14/3,   None),  # free c\n",
    "\n",
    "    # ---- RANK FAMILY (theta_inf = 8/7) ----\n",
    "    (\"Rank 8/7 - (11/7)/logT\",             8/7,    11/7,   0.0),\n",
    "    (\"8/7 - (8/5)/logT\",                   8/7,    8/5,    0.0),\n",
    "    (\"8/7 - b_fit/logT\",                   8/7,    None,   0.0),\n",
    "\n",
    "    # ---- PELL / H* FAMILY ----\n",
    "    (\"H*/70 = 99/70 - b_fit/logT\",         99/70,  None,   0.0),\n",
    "    (\"98/70 = 7/5 - b_fit/logT\",           98/70,  None,   0.0),\n",
    "    (\"sqrt2 ~ 99/70 - b_fit/logT + c/l2T\", 99/70,  None,   None),  # free b and c\n",
    "\n",
    "    # ---- OTHER RATIONAL theta_inf ----\n",
    "    (\"9/7 - b_fit/logT\",                   9/7,    None,   0.0),\n",
    "    (\"11/7 - b_fit/logT\",                  11/7,   None,   0.0),\n",
    "    (\"6/5 - b_fit/logT\",                   6/5,    None,   0.0),\n",
    "\n",
    "    # ---- FREE FIT ----\n",
    "    (\"Free 2-param\",                        None,   None,   0.0),\n",
    "    (\"Free 3-param\",                        None,   None,   None),\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(CANDIDATES)} candidate models.\")\n",
    "for i, (name, a, b, c) in enumerate(CANDIDATES):\n",
    "    parts = []\n",
    "    if a is not None:\n",
    "        parts.append(f\"a={a:.6f}\")\n",
    "    else:\n",
    "        parts.append(\"a=free\")\n",
    "    if b is not None:\n",
    "        parts.append(f\"b={b:.6f}\")\n",
    "    else:\n",
    "        parts.append(\"b=free\")\n",
    "    if c is None:\n",
    "        parts.append(\"c=free\")\n",
    "    print(f\"  [{i+1:>2}] {name:<45} {', '.join(parts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Metrics & Optimization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha_R2(delta, delta_pred):\n",
    "    \"\"\"OLS alpha and R^2 at alpha=1.\"\"\"\n",
    "    denom = np.dot(delta_pred, delta_pred)\n",
    "    alpha = float(np.dot(delta, delta_pred) / denom) if denom > 0 else 0.0\n",
    "    R2 = float(1.0 - np.var(delta - delta_pred) / np.var(delta))\n",
    "    return alpha, R2\n",
    "\n",
    "def compute_localization(delta, delta_pred, gamma_n):\n",
    "    \"\"\"Fraction of zeros where prediction localizes actual zero.\"\"\"\n",
    "    half_gaps = np.diff(gamma_n) / 2.0\n",
    "    residual = delta - delta_pred\n",
    "    n = min(len(residual) - 1, len(half_gaps))\n",
    "    localized = np.abs(residual[1:n+1]) < half_gaps[:n]\n",
    "    return float(np.mean(localized))\n",
    "\n",
    "# ---- WINDOW ANALYSIS ----\n",
    "WINDOWS = [\n",
    "    (0, 100_000), (100_000, 200_000), (200_000, 500_000),\n",
    "    (500_000, 1_000_000), (1_000_000, 1_500_000), (1_500_000, N_ZEROS),\n",
    "]\n",
    "WINDOW_LABELS = [f\"[{a//1000}k,{b//1000}k)\" for a, b in WINDOWS]\n",
    "\n",
    "def compute_window_alphas(delta, delta_pred):\n",
    "    \"\"\"Alpha per window for drift analysis.\"\"\"\n",
    "    alphas = []\n",
    "    for (lo, hi) in WINDOWS:\n",
    "        hi = min(hi, len(delta))\n",
    "        d_w = delta[lo:hi]\n",
    "        dp_w = delta_pred[lo:hi]\n",
    "        denom = np.dot(dp_w, dp_w)\n",
    "        alphas.append(float(np.dot(d_w, dp_w) / denom) if denom > 0 else 0.0)\n",
    "    return alphas\n",
    "\n",
    "def compute_drift(alphas):\n",
    "    \"\"\"Linear regression of alpha vs window index.\"\"\"\n",
    "    x = np.arange(len(alphas), dtype=float)\n",
    "    slope, intercept, r, p, se = stats.linregress(x, alphas)\n",
    "    return float(slope), float(p)\n",
    "\n",
    "# ---- OPTIMIZATION (on subset for speed) ----\n",
    "# We optimize on the first 200k zeros, then evaluate on all 2M\n",
    "N_OPT = 200_000\n",
    "g0_opt = gamma0[:N_OPT]\n",
    "tp_opt = tp[:N_OPT]\n",
    "delta_opt = delta[:N_OPT]\n",
    "# Use smaller prime set for optimization iterations\n",
    "primes_opt = primes[primes <= 500_000]\n",
    "print(f\"Optimization subset: {N_OPT:,} zeros, {len(primes_opt):,} primes\")\n",
    "\n",
    "def optimize_b(theta_inf, verbose=True):\n",
    "    \"\"\"Find optimal b for fixed theta_inf.\"\"\"\n",
    "    def objective(b):\n",
    "        dp = prime_sum_var(g0_opt, tp_opt, primes_opt, K_MAX, theta_inf, -abs(b))\n",
    "        alpha, _ = compute_alpha_R2(delta_opt, dp)\n",
    "        return (alpha - 1.0) ** 2\n",
    "    result = minimize_scalar(objective, bounds=(0.0, 15.0), method='bounded',\n",
    "                             options={'xatol': 0.02, 'maxiter': 25})\n",
    "    if verbose:\n",
    "        print(f\"    Optimized b={result.x:.4f} (obj={result.fun:.2e})\")\n",
    "    return result.x\n",
    "\n",
    "def optimize_c(theta_inf, b, verbose=True):\n",
    "    \"\"\"Find optimal c for fixed theta_inf and b.\"\"\"\n",
    "    def objective(c):\n",
    "        dp = prime_sum_var(g0_opt, tp_opt, primes_opt, K_MAX, theta_inf, -abs(b), c)\n",
    "        alpha, _ = compute_alpha_R2(delta_opt, dp)\n",
    "        return (alpha - 1.0) ** 2\n",
    "    result = minimize_scalar(objective, bounds=(-50.0, 50.0), method='bounded',\n",
    "                             options={'xatol': 0.1, 'maxiter': 25})\n",
    "    if verbose:\n",
    "        print(f\"    Optimized c={result.x:.4f} (obj={result.fun:.2e})\")\n",
    "    return result.x\n",
    "\n",
    "def optimize_bc(theta_inf, verbose=True):\n",
    "    \"\"\"Find optimal (b, c) for fixed theta_inf.\"\"\"\n",
    "    def objective(params):\n",
    "        b, c = params\n",
    "        dp = prime_sum_var(g0_opt, tp_opt, primes_opt, K_MAX, theta_inf, -abs(b), c)\n",
    "        alpha, _ = compute_alpha_R2(delta_opt, dp)\n",
    "        alphas = compute_window_alphas(delta_opt[:N_OPT], dp[:N_OPT])\n",
    "        # Use 4 equal windows for drift on optimization subset\n",
    "        return (alpha - 1.0)**2 + compute_drift(alphas)[0]**2\n",
    "    result = minimize(objective, x0=[4.5, -10.0], method='Nelder-Mead',\n",
    "                      options={'maxiter': 60, 'xatol': 0.05, 'fatol': 1e-6})\n",
    "    b_opt, c_opt = abs(result.x[0]), result.x[1]\n",
    "    if verbose:\n",
    "        print(f\"    Optimized b={b_opt:.4f}, c={c_opt:.4f}\")\n",
    "    return b_opt, c_opt\n",
    "\n",
    "def optimize_2param(verbose=True):\n",
    "    \"\"\"Find optimal (theta_inf, b).\"\"\"\n",
    "    def objective(params):\n",
    "        a, b = params\n",
    "        dp = prime_sum_var(g0_opt, tp_opt, primes_opt, K_MAX, a, -abs(b))\n",
    "        alpha, _ = compute_alpha_R2(delta_opt, dp)\n",
    "        return (alpha - 1.0) ** 2\n",
    "    result = minimize(objective, x0=[1.4, 4.5], method='Nelder-Mead',\n",
    "                      options={'maxiter': 60, 'xatol': 0.02, 'fatol': 1e-6})\n",
    "    a_opt, b_opt = result.x[0], abs(result.x[1])\n",
    "    if verbose:\n",
    "        print(f\"    Optimized a={a_opt:.6f}, b={b_opt:.4f}\")\n",
    "    return a_opt, b_opt\n",
    "\n",
    "def optimize_3param(verbose=True):\n",
    "    \"\"\"Find optimal (theta_inf, b, c).\"\"\"\n",
    "    def objective(params):\n",
    "        a, b, c = params\n",
    "        dp = prime_sum_var(g0_opt, tp_opt, primes_opt, K_MAX, a, -abs(b), c)\n",
    "        alpha, _ = compute_alpha_R2(delta_opt, dp)\n",
    "        return (alpha - 1.0) ** 2\n",
    "    result = minimize(objective, x0=[1.4, 4.5, -10.0], method='Nelder-Mead',\n",
    "                      options={'maxiter': 80, 'xatol': 0.05, 'fatol': 1e-6})\n",
    "    a_opt, b_opt, c_opt = result.x[0], abs(result.x[1]), result.x[2]\n",
    "    if verbose:\n",
    "        print(f\"    Optimized a={a_opt:.6f}, b={b_opt:.4f}, c={c_opt:.4f}\")\n",
    "    return a_opt, b_opt, c_opt\n",
    "\n",
    "print(\"Metrics and optimization functions loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Phase 1 — Screening: All Candidates on 50k Zeros\n\nLike Connes testing his first 6 primes before scaling up:\n- Evaluate ALL candidates on **50k zeros** (~5 min/candidate)\n- Rank by composite score: $|alpha - 1|$ + $50 \\times |\\text{drift}|$\n- Identify the **winner** for Phase 2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# PHASE 1: SCREENING — All candidates on 50k zeros\n# ================================================================\nN_SCREEN = 50_000\ng0_screen = gamma0[:N_SCREEN]\ntp_screen = tp[:N_SCREEN]\ndelta_screen = delta[:N_SCREEN]\ngamma_screen = gamma_n[:N_SCREEN]\n\n# Screening windows for drift\nSCREEN_WINDOWS = [\n    (0, 12_500), (12_500, 25_000), (25_000, 37_500), (37_500, 50_000),\n]\nSCREEN_LABELS = [f\"[{a//1000}k,{b//1000}k)\" for a, b in SCREEN_WINDOWS]\n\n# Use medium prime set for screening (balance speed vs accuracy)\nprimes_screen = primes[primes <= 500_000]\nprint(f\"Phase 1 screening: {N_SCREEN:,} zeros, {len(primes_screen):,} primes\")\n\nRESULTS_FILE = 'theta_screening_results.json'\n\n# Check for partial results (resume support)\nscreening_results = []\ncompleted_names = set()\ndrive_results = os.path.join(DRIVE_DIR, RESULTS_FILE) if DRIVE_DIR else None\nif drive_results and os.path.exists(drive_results):\n    with open(drive_results) as f:\n        screening_results = json.load(f)\n    completed_names = {r['name'] for r in screening_results}\n    print(f\"Resuming: {len(completed_names)} candidates already done\")\nelif os.path.exists(RESULTS_FILE):\n    with open(RESULTS_FILE) as f:\n        screening_results = json.load(f)\n    completed_names = {r['name'] for r in screening_results}\n    print(f\"Resuming: {len(completed_names)} candidates already done\")\nelse:\n    print(\"Starting fresh.\")\n\nprint(\"=\" * 70)\nprint(f\"PHASE 1 — SCREENING: {len(CANDIDATES)} candidates on {N_SCREEN:,} zeros\")\nprint(\"=\" * 70)\n\nt_phase1 = time.time()\n\nfor idx, (name, theta_inf_raw, b_raw, c_raw) in enumerate(CANDIDATES):\n    if name in completed_names:\n        print(f\"\\n[{idx+1}/{len(CANDIDATES)}] {name} — ALREADY DONE, skipping\")\n        continue\n\n    print(f\"\\n[{idx+1}/{len(CANDIDATES)}] {name}\")\n    t0_cand = time.time()\n\n    # ---- RESOLVE PARAMETERS (optimize on 200k subset) ----\n    actual_a = theta_inf_raw\n    actual_b = b_raw if b_raw is not None else 0.0\n    actual_c = c_raw if c_raw is not None else 0.0\n\n    if theta_inf_raw is None and c_raw is None:\n        print(\"  Optimizing (a, b, c)...\")\n        actual_a, actual_b, actual_c = optimize_3param()\n    elif theta_inf_raw is None:\n        print(\"  Optimizing (a, b)...\")\n        actual_a, actual_b = optimize_2param()\n        actual_c = 0.0\n    elif b_raw is None and c_raw is None:\n        print(f\"  Optimizing (b, c) for a={actual_a:.6f}...\")\n        actual_b, actual_c = optimize_bc(actual_a)\n    elif b_raw is None:\n        print(f\"  Optimizing b for a={actual_a:.6f}...\")\n        actual_b = optimize_b(actual_a)\n        actual_c = c_raw if c_raw is not None else 0.0\n    elif c_raw is None and b_raw is not None:\n        print(f\"  Optimizing c for theta={actual_a:.6f}-{actual_b:.4f}/logT...\")\n        actual_c = optimize_c(actual_a, actual_b)\n\n    theta_coeff = -actual_b  # theta = a + coeff/logT (negative for subtraction)\n\n    print(f\"  theta(T) = {actual_a:.6f} - {actual_b:.6f}/logT\", end=\"\")\n    if actual_c != 0.0:\n        print(f\" + ({actual_c:.4f})/log^2(T)\", end=\"\")\n    print()\n\n    # ---- COMPUTE ON 50k SCREENING SET ----\n    t1 = time.time()\n    delta_pred = prime_sum_var(g0_screen, tp_screen, primes_screen, K_MAX,\n                               actual_a, theta_coeff, actual_c)\n    compute_time = time.time() - t1\n\n    # ---- METRICS ----\n    alpha, R2 = compute_alpha_R2(delta_screen, delta_pred)\n    loc = compute_localization(delta_screen, delta_pred, gamma_screen)\n\n    # Window alphas for drift\n    alphas_w = []\n    for lo, hi in SCREEN_WINDOWS:\n        d_w = delta_screen[lo:hi]\n        dp_w = delta_pred[lo:hi]\n        dot_pp = np.dot(dp_w, dp_w)\n        alphas_w.append(float(np.dot(d_w, dp_w) / dot_pp) if dot_pp > 0 else 0.0)\n    drift_slope, drift_p = compute_drift(alphas_w)\n\n    # Scaled R2\n    resid_scaled = delta_screen - alpha * delta_pred\n    R2_scaled = float(1.0 - np.var(resid_scaled) / np.var(delta_screen))\n\n    # Composite score (lower is better)\n    score = abs(alpha - 1) + abs(drift_slope) * 50\n\n    elapsed = time.time() - t0_cand\n\n    print(f\"  alpha={alpha:+.6f}  |a-1|={abs(alpha-1):.6f}  \"\n          f\"R2={R2:.6f}  drift={drift_slope:+.6f}  \"\n          f\"score={score:.6f}  [{compute_time:.0f}s]\")\n\n    result = {\n        'name': name,\n        'theta_inf': float(actual_a),\n        'b': float(actual_b),\n        'c': float(actual_c),\n        'theta_coeff': float(theta_coeff),\n        'alpha': float(alpha),\n        'abs_alpha_minus_1': float(abs(alpha - 1)),\n        'R2': float(R2),\n        'R2_scaled': float(R2_scaled),\n        'localization': float(loc),\n        'drift_slope': float(drift_slope),\n        'drift_p': float(drift_p),\n        'window_alphas': [float(a) for a in alphas_w],\n        'score': float(score),\n        'compute_time_s': float(compute_time),\n        'total_time_s': float(elapsed),\n    }\n\n    screening_results.append(result)\n\n    # Checkpoint after each candidate\n    with open(RESULTS_FILE, 'w') as f:\n        json.dump(screening_results, f, indent=2)\n    save_to_drive(RESULTS_FILE)\n\ntotal_phase1 = time.time() - t_phase1\nprint(f\"\\n{'='*70}\")\nprint(f\"Phase 1 complete: {total_phase1/60:.1f} min for {len(CANDIDATES)} candidates\")\nprint(f\"{'='*70}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Phase 1 Results — Ranking & Winner Selection"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# PHASE 1 RANKING — Identify the winner\n# ================================================================\nranked = sorted(screening_results, key=lambda r: r['score'])\n\nprint(\"=\" * 100)\nprint(\"PHASE 1 SCREENING RESULTS — ALL CANDIDATES on 50k ZEROS\")\nprint(\"=\" * 100)\nprint(f\"{'Rk':>3} {'Name':<45} {'alpha':>10} {'|a-1|':>8} \"\n      f\"{'R2':>8} {'drift':>10} {'score':>10}\")\nprint(\"-\" * 100)\nfor i, r in enumerate(ranked, 1):\n    marker = \" <<<\" if i == 1 else \"\"\n    print(f\"{i:>3} {r['name']:<45} {r['alpha']:>+10.6f} \"\n          f\"{r['abs_alpha_minus_1']:>8.6f} {r['R2']:>8.4f} \"\n          f\"{r['drift_slope']:>+10.6f} {r['score']:>10.6f}{marker}\")\n\n# ---- WINNER ----\nwinner = ranked[0]\nprint(f\"\\n{'='*70}\")\nprint(f\"WINNER: {winner['name']}\")\nprint(f\"  theta(T) = {winner['theta_inf']:.6f} - {winner['b']:.6f}/logT\", end=\"\")\nif winner['c'] != 0.0:\n    print(f\" + ({winner['c']:.4f})/log^2(T)\", end=\"\")\nprint()\nprint(f\"  alpha     = {winner['alpha']:+.6f}\")\nprint(f\"  |alpha-1| = {winner['abs_alpha_minus_1']:.6f}\")\nprint(f\"  R2        = {winner['R2']:.6f}\")\nprint(f\"  drift     = {winner['drift_slope']:+.6f} (p={winner['drift_p']:.4f})\")\nprint(f\"  score     = {winner['score']:.6f}\")\nprint(f\"{'='*70}\")\n\n# Also show the top 3 for context\nprint(f\"\\nTop 3 will be carried to Phase 2 comparison:\")\ntop3 = ranked[:3]\nfor i, r in enumerate(top3, 1):\n    print(f\"  #{i}: {r['name']} (score={r['score']:.6f})\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 8. Phase 2 — Full Validation: Winner on 2M Zeros\n\nRun the **winner only** on all 2M zeros with:\n- Full prime sum (3M primes)\n- Window analysis (6 windows)\n- T5a: Beat 200 random constant-$\\theta$ models\n- T5b: Beat 200 random correction models\n- T7: Bootstrap 95% CI for $\\alpha$ contains 1.0\n- T8: No drift ($p > 0.05$)\n\nAlso run the **runner-up** for comparison."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ================================================================\n# PHASE 2: FULL VALIDATION — Winner (+runner-up) on 2M zeros\n# ================================================================\nCHUNK_SIZE = 200_000\nN_TRIALS = 200    # Monte Carlo trials for T5\nB_BOOT = 5000     # Bootstrap samples for T7\n\n# Full windows for 2M\nFULL_WINDOWS = [\n    (0, 100_000), (100_000, 200_000), (200_000, 500_000),\n    (500_000, 1_000_000), (1_000_000, 1_500_000), (1_500_000, N_ZEROS),\n]\nFULL_LABELS = [f\"[{a//1000}k,{b//1000}k)\" for a, b in FULL_WINDOWS]\n\n# MC subset for T5 random baselines\nN_MC = 200_000\nd_mc = delta[:N_MC]\ng0_mc = gamma0[:N_MC]\ntp_mc = tp[:N_MC]\nprimes_mc = primes[primes <= 50_000]\n\n# Candidates for Phase 2: winner + runner-up (top 2)\nphase2_candidates = ranked[:min(2, len(ranked))]\n\nprint(\"=\" * 70)\nprint(\"PHASE 2 — FULL VALIDATION ON 2M ZEROS\")\nprint(f\"  Candidates: {[r['name'] for r in phase2_candidates]}\")\nprint(f\"  {N_ZEROS:,} zeros, {len(primes):,} primes (up to {P_MAX:,}), K_max={K_MAX}\")\nprint(f\"  T5: {N_TRIALS} random models, T7: {B_BOOT} bootstrap, T8: {len(FULL_WINDOWS)} windows\")\nprint(\"=\" * 70)\n\n# ---- T5 BASELINES (compute once, reuse for all Phase 2 candidates) ----\nprint(\"\\nGenerating T5a random baseline (constant-theta)...\")\nnp.random.seed(42)\ntheta_random = np.random.uniform(0.3, 2.0, N_TRIALS)\nR2_random_const = []\nt0 = time.time()\nfor i, th in enumerate(theta_random):\n    dp_r = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX, float(th), 0.0)\n    R2_random_const.append(float(1.0 - np.var(d_mc - dp_r) / np.var(d_mc)))\n    if (i+1) % 50 == 0:\n        print(f\"  {i+1}/{N_TRIALS} [{time.time()-t0:.0f}s]\")\nR2_random_const = np.array(R2_random_const)\nprint(f\"  Done: best random const R2 = {np.max(R2_random_const):.6f}\")\n\nprint(\"\\nGenerating T5b random baseline (correction models)...\")\nnp.random.seed(123)\na_rand = np.random.uniform(0.8, 2.0, N_TRIALS)\nb_rand = np.random.uniform(-10.0, 0.0, N_TRIALS)\nR2_random_corr = []\nt0 = time.time()\nfor i in range(N_TRIALS):\n    dp_r = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                         float(a_rand[i]), float(b_rand[i]))\n    R2_random_corr.append(float(1.0 - np.var(d_mc - dp_r) / np.var(d_mc)))\n    if (i+1) % 50 == 0:\n        print(f\"  {i+1}/{N_TRIALS} [{time.time()-t0:.0f}s]\")\nR2_random_corr = np.array(R2_random_corr)\nprint(f\"  Done: best random corr R2 = {np.max(R2_random_corr):.6f}\")\n\n# ---- FULL VALIDATION FOR EACH PHASE 2 CANDIDATE ----\nphase2_results = []\n\nfor cand_idx, cand in enumerate(phase2_candidates):\n    name = cand['name']\n    actual_a = cand['theta_inf']\n    theta_coeff = cand['theta_coeff']\n    actual_c = cand['c']\n\n    print(f\"\\n{'='*70}\")\n    print(f\"PHASE 2 [{cand_idx+1}/{len(phase2_candidates)}]: {name}\")\n    print(f\"  theta(T) = {actual_a:.6f} + ({theta_coeff:.6f})/logT\", end=\"\")\n    if actual_c != 0.0:\n        print(f\" + ({actual_c:.4f})/log^2(T)\", end=\"\")\n    print()\n    print(f\"{'='*70}\")\n\n    # ---- COMPUTE DELTA_PRED ON FULL 2M ZEROS (in chunks) ----\n    print(f\"\\n  Computing prime sum on {N_ZEROS:,} zeros...\")\n    delta_pred_full = np.zeros(N_ZEROS)\n    t1 = time.time()\n    for i in range(0, N_ZEROS, CHUNK_SIZE):\n        j = min(i + CHUNK_SIZE, N_ZEROS)\n        ct = time.time()\n        delta_pred_full[i:j] = prime_sum_var(\n            gamma0[i:j], tp[i:j], primes, K_MAX,\n            actual_a, theta_coeff, actual_c)\n        pct = 100 * j / N_ZEROS\n        el = time.time() - t1\n        eta = el / j * (N_ZEROS - j) if j > 0 else 0\n        print(f\"    [{i:>9,}:{j:>9,}) {pct:5.1f}%  chunk {time.time()-ct:.0f}s  \"\n              f\"[total {el/60:.1f}m, ETA {eta/60:.1f}m]\")\n    compute_time = time.time() - t1\n    print(f\"  Done in {compute_time/60:.1f} min\")\n\n    # ---- FULL METRICS ----\n    alpha_full, R2_full = compute_alpha_R2(delta, delta_pred_full)\n    loc_full = compute_localization(delta, delta_pred_full, gamma_n)\n\n    alphas_w = compute_window_alphas(delta, delta_pred_full)\n    drift_slope, drift_p = compute_drift(alphas_w)\n\n    resid_scaled = delta - alpha_full * delta_pred_full\n    R2_scaled = float(1.0 - np.var(resid_scaled) / np.var(delta))\n\n    print(f\"\\n  FULL 2M METRICS:\")\n    print(f\"    alpha(OLS)      = {alpha_full:+.6f}\")\n    print(f\"    |alpha - 1|     = {abs(alpha_full-1):.6f}\")\n    print(f\"    R2 (alpha=1)    = {R2_full:.6f}\")\n    print(f\"    R2 (alpha=OLS)  = {R2_scaled:.6f}\")\n    print(f\"    Localization    = {loc_full*100:.2f}%\")\n    print(f\"    Drift slope     = {drift_slope:+.6f} (p={drift_p:.4f})\")\n    print(f\"    Window alphas   = {[f'{a:.4f}' for a in alphas_w]}\")\n\n    # ---- T5a: vs random constants ----\n    dp_mc_cand = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                               actual_a, theta_coeff, actual_c)\n    R2_mc = float(1.0 - np.var(d_mc - dp_mc_cand) / np.var(d_mc))\n\n    margin_a = R2_mc - float(np.max(R2_random_const))\n    p_val_a = float(np.mean(R2_random_const >= R2_mc))\n    T5a_pass = margin_a > 0\n\n    # ---- T5b: vs random corrections ----\n    margin_b = R2_mc - float(np.max(R2_random_corr))\n    p_val_b = float(np.mean(R2_random_corr >= R2_mc))\n    T5b_pass = margin_b > 0\n\n    T5_pass = T5a_pass and T5b_pass\n\n    # ---- T7: Bootstrap CI on full 2M ----\n    print(f\"\\n  Running T7 bootstrap ({B_BOOT} samples)...\")\n    t_boot = time.time()\n    np.random.seed(42)\n    alpha_boots = np.empty(B_BOOT)\n    for b_idx in range(B_BOOT):\n        idx = np.random.randint(0, N_ZEROS, N_ZEROS)\n        d_b = delta[idx]\n        dp_b = delta_pred_full[idx]\n        dot_pp = np.dot(dp_b, dp_b)\n        alpha_boots[b_idx] = np.dot(d_b, dp_b) / dot_pp if dot_pp > 0 else 0.0\n\n    ci_lo = float(np.percentile(alpha_boots, 2.5))\n    ci_hi = float(np.percentile(alpha_boots, 97.5))\n    T7_pass = ci_lo <= 1.0 <= ci_hi\n    print(f\"  T7 done in {time.time()-t_boot:.0f}s\")\n\n    # ---- T8: Drift ----\n    T8_pass = drift_p > 0.05\n\n    n_pass = sum([T5_pass, T7_pass, T8_pass])\n\n    print(f\"\\n  VALIDATION TESTS:\")\n    print(f\"  T5a: R2={R2_mc:.6f} vs max_const={np.max(R2_random_const):.6f} \"\n          f\"-> margin={margin_a:+.6f} {'PASS' if T5a_pass else 'FAIL'}\")\n    print(f\"  T5b: R2={R2_mc:.6f} vs max_corr={np.max(R2_random_corr):.6f} \"\n          f\"-> margin={margin_b:+.6f} {'PASS' if T5b_pass else 'FAIL'}\")\n    print(f\"  T7:  CI=[{ci_lo:.6f}, {ci_hi:.6f}] contains 1.0? \"\n          f\"{'PASS' if T7_pass else 'FAIL'}\")\n    print(f\"  T8:  drift={drift_slope:+.6f}, p={drift_p:.4f} \"\n          f\"{'PASS' if T8_pass else 'FAIL'}\")\n    print(f\"  SCORE: {n_pass}/3\")\n\n    result = {\n        **cand,  # carry Phase 1 screening info\n        'alpha_2M': float(alpha_full),\n        'R2_2M': float(R2_full),\n        'R2_scaled_2M': float(R2_scaled),\n        'localization_2M': float(loc_full),\n        'drift_slope_2M': float(drift_slope),\n        'drift_p_2M': float(drift_p),\n        'window_alphas_2M': [float(a) for a in alphas_w],\n        'R2_mc': float(R2_mc),\n        'T5a_pass': bool(T5a_pass),\n        'T5a_margin': float(margin_a),\n        'T5b_pass': bool(T5b_pass),\n        'T5b_margin': float(margin_b),\n        'T5_pass': bool(T5_pass),\n        'T7_pass': bool(T7_pass),\n        'T7_ci_lo': float(ci_lo),\n        'T7_ci_hi': float(ci_hi),\n        'T8_pass': bool(T8_pass),\n        'T8_drift_p_2M': float(drift_p),\n        'validation_score': int(n_pass),\n        'compute_time_2M_s': float(compute_time),\n    }\n    phase2_results.append(result)\n\n    # Save delta_pred for this candidate\n    dp_file = f'dp_2M_{name.replace(\" \", \"_\").replace(\"/\", \"-\").replace(\"=\",\"\")[:40]}.npy'\n    np.save(dp_file, delta_pred_full)\n    save_to_drive(dp_file)\n\n# Checkpoint Phase 2\nPHASE2_FILE = 'theta_phase2_results.json'\nwith open(PHASE2_FILE, 'w') as f:\n    json.dump(phase2_results, f, indent=2)\nsave_to_drive(PHASE2_FILE)\nprint(f\"\\nPhase 2 results saved to {PHASE2_FILE}\")"
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 9. Rational Scan: Best $(a, b)$ with Small Denominators (50k zeros)"
  },
  {
   "cell_type": "code",
   "source": "# Use 50k zeros for the scan (balance speed vs accuracy)\nN_SCAN = 50_000\ng0_scan = gamma0[:N_SCAN]\ntp_scan = tp[:N_SCAN]\ndelta_scan = delta[:N_SCAN]\n\n# Scan windows for drift\nSCAN_WINDOWS = [(0, 12500), (12500, 25000), (25000, 37500), (37500, 50000)]\n\n# Use medium prime set\nprimes_scan = primes[primes <= 200_000]\nprint(f\"Rational scan: {N_SCAN:,} zeros, {len(primes_scan):,} primes\")\n\nfrom math import gcd\n\n# Build a-candidates (denominators up to 10)\na_candidates = set()\nfor den in range(1, 11):\n    for num in range(den, 3*den+1):\n        g = gcd(num, den)\n        a_candidates.add((num//g, den//g))\n# Also add specific candidates of interest\nfor (n, d) in [(99, 70), (98, 70), (10, 7), (8, 7), (9, 7), (11, 7)]:\n    a_candidates.add((n, d))\na_candidates = sorted(a_candidates, key=lambda x: x[0]/x[1])\n\n# Build b-candidates (denominators up to 10)\nb_candidates = set()\nfor den in range(1, 11):\n    for num in range(0, 10*den+1):\n        b_val = num / den\n        if b_val > 10.0:\n            continue\n        g = gcd(num, den)\n        b_candidates.add((num//g, den//g))\nb_candidates = sorted(b_candidates, key=lambda x: x[0]/x[1])\n\ntotal = len(a_candidates) * len(b_candidates)\nprint(f\"  {len(a_candidates)} a-values x {len(b_candidates)} b-values = {total:,} combos\")\nprint(f\"  a range: [{a_candidates[0][0]}/{a_candidates[0][1]}, {a_candidates[-1][0]}/{a_candidates[-1][1]}]\")\nprint(f\"  b range: [0, 10]\")\nprint()\n\n# Score function: |alpha - 1| + 50 * |drift|\nscan_results = []\nbest_score = 999\nt_scan = time.time()\ntested = 0\n\nfor a_num, a_den in a_candidates:\n    a_val = a_num / a_den\n    for b_num, b_den in b_candidates:\n        b_val = b_num / b_den\n        tested += 1\n\n        if tested % 500 == 0:\n            el = time.time() - t_scan\n            eta = el / tested * (total - tested)\n            print(f\"  {tested:>6}/{total} [{el:.0f}s, ETA {eta:.0f}s] \"\n                  f\"best_score={best_score:.6f}\")\n\n        dp = prime_sum_var(g0_scan, tp_scan, primes_scan, K_MAX, a_val, -b_val)\n        alpha_val, R2_val = compute_alpha_R2(delta_scan, dp)\n\n        # Quick drift estimate\n        alphas_sw = []\n        for lo, hi in SCAN_WINDOWS:\n            d_w = delta_scan[lo:hi]\n            dp_w = dp[lo:hi]\n            dot_pp = np.dot(dp_w, dp_w)\n            alphas_sw.append(float(np.dot(d_w, dp_w) / dot_pp) if dot_pp > 0 else 0.0)\n        drift_val = float(stats.linregress(np.arange(4, dtype=float), alphas_sw).slope)\n\n        score = abs(alpha_val - 1) + abs(drift_val) * 50\n\n        # Keep top results\n        if score < best_score * 1.5 or score < 0.05:\n            scan_results.append({\n                'a_num': int(a_num), 'a_den': int(a_den),\n                'b_num': int(b_num), 'b_den': int(b_den),\n                'a': float(a_val), 'b': float(b_val),\n                'alpha': float(alpha_val), 'R2': float(R2_val),\n                'drift': float(drift_val), 'score': float(score),\n                'window_alphas': [float(a) for a in alphas_sw],\n            })\n\n        if score < best_score:\n            best_score = score\n            print(f\"  NEW BEST: theta={a_num}/{a_den} - ({b_num}/{b_den})/logT -> \"\n                  f\"alpha={alpha_val:.6f}, R2={R2_val:.4f}, drift={drift_val:+.6f}, \"\n                  f\"score={score:.6f}\")\n\nscan_time = time.time() - t_scan\nprint(f\"\\nRational scan complete: {tested:,} combos in {scan_time:.0f}s\")\n\n# Rank results\nscan_results.sort(key=lambda x: x['score'])\ntop_scan = scan_results[:30]\n\nprint(f\"\\nTOP 15 RATIONAL CANDIDATES:\")\nprint(f\"{'Rank':>4} {'theta_inf':>12} {'b':>12} {'alpha':>10} {'R2':>8} \"\n      f\"{'drift':>10} {'score':>10}\")\nprint(\"-\" * 70)\nfor i, r in enumerate(top_scan[:15], 1):\n    print(f\"{i:>4} {r['a_num']:>3}/{r['a_den']:<3} = {r['a']:.4f} \"\n          f\"{r['b_num']:>3}/{r['b_den']:<3} = {r['b']:.4f} \"\n          f\"{r['alpha']:>+10.6f} {r['R2']:>8.4f} \"\n          f\"{r['drift']:>+10.6f} {r['score']:>10.6f}\")\n\n# Save\nSCAN_FILE = 'rational_scan_2M_results.json'\nwith open(SCAN_FILE, 'w') as f:\n    json.dump(top_scan, f, indent=2)\nsave_to_drive(SCAN_FILE)\nprint(f\"\\nSaved top {len(top_scan)} scan results to {SCAN_FILE}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Phase 3 — Rational Scan Winner: Full 2M Validation\n\nThe rational scan identifies the best $(a/b, c/d)$ pair with small denominators.\nNow validate the **winner** on the full 2M zeros with the same T5/T7/T8 protocol as Phase 2.\n\nThis is the decisive test: if the rational scan winner passes T5+T7+T8, the topological\nformula is statistically validated. If it fails (like Phase 2 candidates did), the\napparent precision on 50k was noise.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ================================================================\n# PHASE 3: FULL 2M VALIDATION — Rational Scan Winner + GIFT Reference\n# ================================================================\n# Same protocol as Phase 2 (T5/T7/T8) but for the rational scan winner.\n# Also runs GIFT 10/7 - (14/3)/logT as direct comparison.\n# Reuses T5 baselines (R2_random_const, R2_random_corr) from Phase 2.\n\nPHASE3_FILE = 'theta_phase3_results.json'\n\n# The two formulas to validate on 2M\nscan_winner = top_scan[0]\nphase3_models = [\n    {\n        'name': f\"{scan_winner['a_num']}/{scan_winner['a_den']} - ({scan_winner['b_num']}/{scan_winner['b_den']})/logT\",\n        'theta_inf': float(scan_winner['a']),\n        'theta_coeff': -float(scan_winner['b']),\n        'c': 0.0,\n        'a_num': scan_winner['a_num'], 'a_den': scan_winner['a_den'],\n        'b_num': scan_winner['b_num'], 'b_den': scan_winner['b_den'],\n        'source': 'rational_scan_winner',\n        'score_50k': float(scan_winner['score']),\n    },\n    {\n        'name': 'GIFT 10/7 - (14/3)/logT',\n        'theta_inf': 10/7,\n        'theta_coeff': -14/3,\n        'c': 0.0,\n        'a_num': 10, 'a_den': 7,\n        'b_num': 14, 'b_den': 3,\n        'source': 'gift_reference',\n        'score_50k': None,  # may not have been in scan\n    },\n]\n\nprint(\"=\" * 70)\nprint(\"PHASE 3 — RATIONAL SCAN WINNER: FULL 2M VALIDATION\")\nprint(f\"  Models: {[m['name'] for m in phase3_models]}\")\nprint(f\"  {N_ZEROS:,} zeros, {len(primes):,} primes (up to {P_MAX:,})\")\nprint(f\"  Reusing T5 baselines from Phase 2 ({N_TRIALS} random models each)\")\nprint(f\"  T7: {B_BOOT} bootstrap samples, T8: {len(FULL_WINDOWS)} windows\")\nprint(\"=\" * 70)\n\nphase3_results = []\n\nfor m_idx, model in enumerate(phase3_models):\n    name = model['name']\n    actual_a = model['theta_inf']\n    theta_coeff = model['theta_coeff']\n    actual_c = model['c']\n\n    print(f\"\\n{'='*70}\")\n    print(f\"PHASE 3 [{m_idx+1}/{len(phase3_models)}]: {name}\")\n    print(f\"  theta(T) = {actual_a:.6f} + ({theta_coeff:.6f})/logT\")\n    print(f\"  Source: {model['source']}\")\n    print(f\"{'='*70}\")\n\n    # ---- COMPUTE DELTA_PRED ON FULL 2M ZEROS (in chunks) ----\n    print(f\"\\n  Computing prime sum on {N_ZEROS:,} zeros...\")\n    delta_pred_full = np.zeros(N_ZEROS)\n    t1 = time.time()\n    for i in range(0, N_ZEROS, CHUNK_SIZE):\n        j = min(i + CHUNK_SIZE, N_ZEROS)\n        ct = time.time()\n        delta_pred_full[i:j] = prime_sum_var(\n            gamma0[i:j], tp[i:j], primes, K_MAX,\n            actual_a, theta_coeff, actual_c)\n        pct = 100 * j / N_ZEROS\n        el = time.time() - t1\n        eta = el / j * (N_ZEROS - j) if j > 0 else 0\n        print(f\"    [{i:>9,}:{j:>9,}) {pct:5.1f}%  chunk {time.time()-ct:.0f}s  \"\n              f\"[total {el/60:.1f}m, ETA {eta/60:.1f}m]\")\n    compute_time = time.time() - t1\n    print(f\"  Done in {compute_time/60:.1f} min\")\n\n    # ---- FULL METRICS ----\n    alpha_full, R2_full = compute_alpha_R2(delta, delta_pred_full)\n    loc_full = compute_localization(delta, delta_pred_full, gamma_n)\n\n    alphas_w = compute_window_alphas(delta, delta_pred_full)\n    drift_slope, drift_p = compute_drift(alphas_w)\n\n    resid_scaled = delta - alpha_full * delta_pred_full\n    R2_scaled = float(1.0 - np.var(resid_scaled) / np.var(delta))\n\n    print(f\"\\n  FULL 2M METRICS:\")\n    print(f\"    alpha(OLS)      = {alpha_full:+.6f}\")\n    print(f\"    |alpha - 1|     = {abs(alpha_full-1):.6f}\")\n    print(f\"    R2 (alpha=1)    = {R2_full:.6f}\")\n    print(f\"    R2 (alpha=OLS)  = {R2_scaled:.6f}\")\n    print(f\"    Localization    = {loc_full*100:.2f}%\")\n    print(f\"    Drift slope     = {drift_slope:+.6f} (p={drift_p:.4f})\")\n    print(f\"    Window alphas   = {[f'{a:.4f}' for a in alphas_w]}\")\n\n    # ---- T5a: vs random constants (reuse baselines from Phase 2) ----\n    dp_mc_cand = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                               actual_a, theta_coeff, actual_c)\n    R2_mc = float(1.0 - np.var(d_mc - dp_mc_cand) / np.var(d_mc))\n\n    margin_a = R2_mc - float(np.max(R2_random_const))\n    T5a_pass = margin_a > 0\n\n    # ---- T5b: vs random corrections (reuse baselines from Phase 2) ----\n    margin_b = R2_mc - float(np.max(R2_random_corr))\n    T5b_pass = margin_b > 0\n\n    T5_pass = T5a_pass and T5b_pass\n\n    # ---- T7: Bootstrap CI on full 2M ----\n    print(f\"\\n  Running T7 bootstrap ({B_BOOT} samples)...\")\n    t_boot = time.time()\n    np.random.seed(42)\n    alpha_boots = np.empty(B_BOOT)\n    for b_idx in range(B_BOOT):\n        idx = np.random.randint(0, N_ZEROS, N_ZEROS)\n        d_b = delta[idx]\n        dp_b = delta_pred_full[idx]\n        dot_pp = np.dot(dp_b, dp_b)\n        alpha_boots[b_idx] = np.dot(d_b, dp_b) / dot_pp if dot_pp > 0 else 0.0\n\n    ci_lo = float(np.percentile(alpha_boots, 2.5))\n    ci_hi = float(np.percentile(alpha_boots, 97.5))\n    T7_pass = ci_lo <= 1.0 <= ci_hi\n    print(f\"  T7 done in {time.time()-t_boot:.0f}s: CI=[{ci_lo:.6f}, {ci_hi:.6f}]\")\n\n    # ---- T8: Drift ----\n    T8_pass = drift_p > 0.05\n\n    n_pass = sum([T5_pass, T7_pass, T8_pass])\n\n    print(f\"\\n  VALIDATION TESTS:\")\n    print(f\"  T5a: R2={R2_mc:.6f} vs max_const={np.max(R2_random_const):.6f} \"\n          f\"-> margin={margin_a:+.6f} {'PASS' if T5a_pass else 'FAIL'}\")\n    print(f\"  T5b: R2={R2_mc:.6f} vs max_corr={np.max(R2_random_corr):.6f} \"\n          f\"-> margin={margin_b:+.6f} {'PASS' if T5b_pass else 'FAIL'}\")\n    print(f\"  T7:  CI=[{ci_lo:.6f}, {ci_hi:.6f}] contains 1.0? \"\n          f\"{'PASS' if T7_pass else 'FAIL'}\")\n    print(f\"  T8:  drift={drift_slope:+.6f}, p={drift_p:.4f} \"\n          f\"{'PASS' if T8_pass else 'FAIL'}\")\n    print(f\"  SCORE: {n_pass}/3\")\n\n    result = {\n        'name': name,\n        'source': model['source'],\n        'a_num': model['a_num'], 'a_den': model['a_den'],\n        'b_num': model['b_num'], 'b_den': model['b_den'],\n        'theta_inf': float(actual_a),\n        'theta_coeff': float(theta_coeff),\n        'b': float(abs(theta_coeff)),\n        'c': float(actual_c),\n        'score_50k': model['score_50k'],\n        'alpha_2M': float(alpha_full),\n        'abs_alpha_minus_1_2M': float(abs(alpha_full - 1)),\n        'R2_2M': float(R2_full),\n        'R2_scaled_2M': float(R2_scaled),\n        'localization_2M': float(loc_full),\n        'drift_slope_2M': float(drift_slope),\n        'drift_p_2M': float(drift_p),\n        'window_alphas_2M': [float(a) for a in alphas_w],\n        'R2_mc': float(R2_mc),\n        'T5a_pass': bool(T5a_pass),\n        'T5a_margin': float(margin_a),\n        'T5b_pass': bool(T5b_pass),\n        'T5b_margin': float(margin_b),\n        'T5_pass': bool(T5_pass),\n        'T7_pass': bool(T7_pass),\n        'T7_ci_lo': float(ci_lo),\n        'T7_ci_hi': float(ci_hi),\n        'T8_pass': bool(T8_pass),\n        'T8_drift_p_2M': float(drift_p),\n        'bootstrap_mean': float(np.mean(alpha_boots)),\n        'bootstrap_std': float(np.std(alpha_boots)),\n        'validation_score': int(n_pass),\n        'compute_time_2M_s': float(compute_time),\n    }\n    phase3_results.append(result)\n\n    # Save delta_pred for potential further analysis\n    dp_file = f'dp_2M_phase3_{name.replace(\" \", \"_\").replace(\"/\", \"-\").replace(\"(\",\"\").replace(\")\",\"\")[:40]}.npy'\n    np.save(dp_file, delta_pred_full)\n    save_to_drive(dp_file)\n\n# Checkpoint Phase 3\nwith open(PHASE3_FILE, 'w') as f:\n    json.dump(phase3_results, f, indent=2)\nsave_to_drive(PHASE3_FILE)\n\n# ---- PHASE 3 VERDICT ----\np3_winner = max(phase3_results, key=lambda r: (r['validation_score'], -r['abs_alpha_minus_1_2M']))\np3_scan = [r for r in phase3_results if r['source'] == 'rational_scan_winner'][0]\np3_gift = [r for r in phase3_results if r['source'] == 'gift_reference'][0]\n\nprint(f\"\\n{'='*70}\")\nprint(f\"PHASE 3 RESULTS COMPARISON\")\nprint(f\"{'='*70}\")\nprint(f\"{'Metric':<25} {'Scan Winner':>20} {'GIFT 10/7':>20}\")\nprint(f\"{'-'*65}\")\nprint(f\"{'Formula':<25} {p3_scan['name']:>20} {p3_gift['name']:>20}\")\nprint(f\"{'alpha (2M)':<25} {p3_scan['alpha_2M']:>+20.6f} {p3_gift['alpha_2M']:>+20.6f}\")\nprint(f\"{'|alpha-1| (2M)':<25} {p3_scan['abs_alpha_minus_1_2M']:>20.6f} {p3_gift['abs_alpha_minus_1_2M']:>20.6f}\")\nprint(f\"{'R2 (2M)':<25} {p3_scan['R2_2M']:>20.6f} {p3_gift['R2_2M']:>20.6f}\")\nprint(f\"{'Localization':<25} {p3_scan['localization_2M']*100:>19.2f}% {p3_gift['localization_2M']*100:>19.2f}%\")\nprint(f\"{'Drift slope':<25} {p3_scan['drift_slope_2M']:>+20.6f} {p3_gift['drift_slope_2M']:>+20.6f}\")\nprint(f\"{'Drift p-value':<25} {p3_scan['drift_p_2M']:>20.4f} {p3_gift['drift_p_2M']:>20.4f}\")\nprint(f\"{'T5 (beat random)':<25} {'PASS' if p3_scan['T5_pass'] else 'FAIL':>20} {'PASS' if p3_gift['T5_pass'] else 'FAIL':>20}\")\nprint(f\"{'T7 (CI contains 1)':<25} {'PASS' if p3_scan['T7_pass'] else 'FAIL':>20} {'PASS' if p3_gift['T7_pass'] else 'FAIL':>20}\")\nprint(f\"{'T8 (no drift)':<25} {'PASS' if p3_scan['T8_pass'] else 'FAIL':>20} {'PASS' if p3_gift['T8_pass'] else 'FAIL':>20}\")\nprint(f\"{'SCORE':<25} {p3_scan['validation_score']:>20}/3 {p3_gift['validation_score']:>20}/3\")\nprint(f\"{'='*70}\")\nprint(f\"\\nPhase 3 saved to {PHASE3_FILE}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Phase 4 — Subleading Correction: $c/\\log^2 T$ and $c \\cdot \\log\\log T / \\log^2 T$\n\nThe Phase 2 and Phase 3 results show that **all** $\\theta(T) = a - b/\\log T$ models exhibit\nmonotone downward drift in $\\alpha$ on 2M zeros. The source is the **truncated Euler product\ncorrection** (Mertens' theorem), which introduces terms at $O(1/\\log^2 T)$.\n\nTwo candidate functional forms for the subleading correction, both with **zero free parameters**:\n\n**Form A** — Pure expansion: $\\theta(T) = \\frac{11}{9} - \\frac{5}{2\\log T} + \\frac{c}{\\log^2 T}$\n\n**Form B** — Prime distribution: $\\theta(T) = \\frac{11}{9} - \\frac{5}{2\\log T} + \\frac{c \\cdot \\log\\log T}{\\log^2 T}$\n\nAll coefficients are GIFT topological constants — no fitting.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ================================================================\n# PHASE 4: SUBLEADING CORRECTION — c/log²T and c·loglogT/log²T\n# ================================================================\n# Base formula: 11/9 - (5/2)/logT (rational scan winner from Phase 3)\n# Adding topological correction terms at next order.\n# Reuses T5 baselines, full windows, and bootstrap from Phases 2-3.\n\nPHASE4_FILE = 'theta_phase4_results.json'\n\n# --- Helper for Form B (loglogT/log²T) ---\n# loglog(T) varies slowly (~13% across full 2M range), so we process\n# in sub-chunks and use chunk-mean loglog as effective c_coeff.\n# This reuses the existing GPU-accelerated prime_sum_var.\n\ndef prime_sum_loglog(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_loglog):\n    \"\"\"Prime sum with theta(T) = theta_inf + theta_coeff/logT + c_loglog*loglog(T)/log²T.\n    Uses sub-chunks of 50k zeros for accurate loglog approximation.\"\"\"\n    SUBCHUNK = 50_000\n    result = np.zeros(len(g0))\n    for i in range(0, len(g0), SUBCHUNK):\n        j = min(i + SUBCHUNK, len(g0))\n        log_g0_sub = np.log(np.maximum(g0[i:j], 2.0))\n        mean_loglog = float(np.mean(np.log(np.maximum(log_g0_sub, 1.0))))\n        c_eff = c_loglog * mean_loglog  # effective c_coeff for this chunk\n        result[i:j] = prime_sum_var(g0[i:j], tp_v[i:j], primes, k_max,\n                                     theta_inf, theta_coeff, c_eff)\n    return result\n\n# --- Models to test ---\n# All based on 11/9 - 5/(2logT) + correction\nBASE_A = 11/9\nBASE_B = -5/2  # theta_coeff (signed)\n\nphase4_models = [\n    # Form A: c/log²T (pure expansion, next order in 1/logT series)\n    {\n        'name': '11/9 - 5/2·logT + 10/log²T',\n        'label': 'Weyl·p₂ = 10',\n        'form': 'A',\n        'c': 10,\n        'topo': 'Weyl(5) × p₂(2)',\n    },\n    {\n        'name': '11/9 - 5/2·logT + 7/log²T',\n        'label': 'dim_K7 = 7',\n        'form': 'A',\n        'c': 7,\n        'topo': 'dim(K₇)',\n    },\n    {\n        'name': '11/9 - 5/2·logT + 14/log²T',\n        'label': 'dim_G2 = 14',\n        'form': 'A',\n        'c': 14,\n        'topo': 'dim(G₂)',\n    },\n    # Form B: c·loglog(T)/log²T (Mertens-motivated, prime distribution)\n    {\n        'name': '11/9 - 5/2·logT + 3·loglogT/log²T',\n        'label': 'N_gen = 3',\n        'form': 'B',\n        'c': 3,\n        'topo': 'N_gen',\n    },\n    {\n        'name': '11/9 - 5/2·logT + 5·loglogT/log²T',\n        'label': 'Weyl = 5',\n        'form': 'B',\n        'c': 5,\n        'topo': 'Weyl',\n    },\n]\n\nprint(\"=\" * 70)\nprint(\"PHASE 4 — SUBLEADING CORRECTION SCAN\")\nprint(f\"  Base: 11/9 - (5/2)/logT\")\nprint(f\"  {len(phase4_models)} correction models on {N_ZEROS:,} zeros\")\nprint(f\"  Reusing T5 baselines from Phase 2\")\nprint(f\"  T7: {B_BOOT} bootstrap, T8: {len(FULL_WINDOWS)} windows\")\nprint(\"=\" * 70)\nfor m in phase4_models:\n    form_str = f\"c/log²T\" if m['form'] == 'A' else f\"c·loglogT/log²T\"\n    print(f\"  [{m['form']}] c = {m['c']:>2} ({m['topo']:<15}) -> {form_str}\")\n\nphase4_results = []\n\nfor m_idx, model in enumerate(phase4_models):\n    name = model['name']\n    c_val = model['c']\n    form = model['form']\n\n    print(f\"\\n{'='*70}\")\n    print(f\"PHASE 4 [{m_idx+1}/{len(phase4_models)}]: {name}\")\n    print(f\"  Form {form}, c = {c_val} ({model['topo']})\")\n    print(f\"{'='*70}\")\n\n    # ---- COMPUTE DELTA_PRED ON FULL 2M ZEROS ----\n    print(f\"\\n  Computing prime sum on {N_ZEROS:,} zeros...\")\n    delta_pred_full = np.zeros(N_ZEROS)\n    t1 = time.time()\n\n    if form == 'A':\n        # Form A: use prime_sum_var directly (c_coeff parameter)\n        for i in range(0, N_ZEROS, CHUNK_SIZE):\n            j = min(i + CHUNK_SIZE, N_ZEROS)\n            ct = time.time()\n            delta_pred_full[i:j] = prime_sum_var(\n                gamma0[i:j], tp[i:j], primes, K_MAX,\n                BASE_A, BASE_B, float(c_val))\n            pct = 100 * j / N_ZEROS\n            el = time.time() - t1\n            eta = el / j * (N_ZEROS - j) if j > 0 else 0\n            print(f\"    [{i:>9,}:{j:>9,}) {pct:5.1f}%  \"\n                  f\"[{el/60:.1f}m, ETA {eta/60:.1f}m]\")\n    else:\n        # Form B: use loglog wrapper (sub-chunked)\n        for i in range(0, N_ZEROS, CHUNK_SIZE):\n            j = min(i + CHUNK_SIZE, N_ZEROS)\n            ct = time.time()\n            delta_pred_full[i:j] = prime_sum_loglog(\n                gamma0[i:j], tp[i:j], primes, K_MAX,\n                BASE_A, BASE_B, float(c_val))\n            pct = 100 * j / N_ZEROS\n            el = time.time() - t1\n            eta = el / j * (N_ZEROS - j) if j > 0 else 0\n            print(f\"    [{i:>9,}:{j:>9,}) {pct:5.1f}%  \"\n                  f\"[{el/60:.1f}m, ETA {eta/60:.1f}m]\")\n\n    compute_time = time.time() - t1\n    print(f\"  Done in {compute_time/60:.1f} min\")\n\n    # ---- FULL METRICS ----\n    alpha_full, R2_full = compute_alpha_R2(delta, delta_pred_full)\n    loc_full = compute_localization(delta, delta_pred_full, gamma_n)\n\n    alphas_w = compute_window_alphas(delta, delta_pred_full)\n    drift_slope, drift_p = compute_drift(alphas_w)\n\n    resid_scaled = delta - alpha_full * delta_pred_full\n    R2_scaled = float(1.0 - np.var(resid_scaled) / np.var(delta))\n\n    print(f\"\\n  FULL 2M METRICS:\")\n    print(f\"    alpha(OLS)      = {alpha_full:+.6f}\")\n    print(f\"    |alpha - 1|     = {abs(alpha_full-1):.6f}\")\n    print(f\"    R2 (alpha=1)    = {R2_full:.6f}\")\n    print(f\"    Localization    = {loc_full*100:.2f}%\")\n    print(f\"    Drift slope     = {drift_slope:+.6f} (p={drift_p:.4f})\")\n    print(f\"    Window alphas   = {[f'{a:.4f}' for a in alphas_w]}\")\n\n    # ---- T5a/T5b: vs random baselines (reuse from Phase 2) ----\n    if form == 'A':\n        dp_mc = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                              BASE_A, BASE_B, float(c_val))\n    else:\n        dp_mc = prime_sum_loglog(g0_mc, tp_mc, primes_mc, K_MAX,\n                                 BASE_A, BASE_B, float(c_val))\n    R2_mc = float(1.0 - np.var(d_mc - dp_mc) / np.var(d_mc))\n\n    margin_a = R2_mc - float(np.max(R2_random_const))\n    T5a_pass = margin_a > 0\n    margin_b = R2_mc - float(np.max(R2_random_corr))\n    T5b_pass = margin_b > 0\n    T5_pass = T5a_pass and T5b_pass\n\n    # ---- T7: Bootstrap CI on full 2M ----\n    print(f\"  Running T7 bootstrap ({B_BOOT} samples)...\")\n    t_boot = time.time()\n    np.random.seed(42)\n    alpha_boots = np.empty(B_BOOT)\n    for b_idx in range(B_BOOT):\n        idx = np.random.randint(0, N_ZEROS, N_ZEROS)\n        d_b = delta[idx]\n        dp_b = delta_pred_full[idx]\n        dot_pp = np.dot(dp_b, dp_b)\n        alpha_boots[b_idx] = np.dot(d_b, dp_b) / dot_pp if dot_pp > 0 else 0.0\n\n    ci_lo = float(np.percentile(alpha_boots, 2.5))\n    ci_hi = float(np.percentile(alpha_boots, 97.5))\n    T7_pass = ci_lo <= 1.0 <= ci_hi\n    print(f\"  T7 done in {time.time()-t_boot:.0f}s: CI=[{ci_lo:.6f}, {ci_hi:.6f}]\")\n\n    # ---- T8: Drift ----\n    T8_pass = drift_p > 0.05\n\n    n_pass = sum([T5_pass, T7_pass, T8_pass])\n\n    print(f\"\\n  VALIDATION TESTS:\")\n    print(f\"  T5a: R2_mc={R2_mc:.6f} vs max_const={np.max(R2_random_const):.6f} \"\n          f\"-> margin={margin_a:+.6f} {'PASS' if T5a_pass else 'FAIL'}\")\n    print(f\"  T5b: R2_mc={R2_mc:.6f} vs max_corr={np.max(R2_random_corr):.6f} \"\n          f\"-> margin={margin_b:+.6f} {'PASS' if T5b_pass else 'FAIL'}\")\n    print(f\"  T7:  CI=[{ci_lo:.6f}, {ci_hi:.6f}] {'PASS' if T7_pass else 'FAIL'}\")\n    print(f\"  T8:  drift={drift_slope:+.6f}, p={drift_p:.4f} {'PASS' if T8_pass else 'FAIL'}\")\n    print(f\"  SCORE: {n_pass}/3\")\n\n    result = {\n        'name': name,\n        'label': model['label'],\n        'form': form,\n        'c': c_val,\n        'topo': model['topo'],\n        'theta_inf': float(BASE_A),\n        'theta_coeff': float(BASE_B),\n        'c_coeff': float(c_val),\n        'alpha_2M': float(alpha_full),\n        'abs_alpha_minus_1_2M': float(abs(alpha_full - 1)),\n        'R2_2M': float(R2_full),\n        'R2_scaled_2M': float(R2_scaled),\n        'localization_2M': float(loc_full),\n        'drift_slope_2M': float(drift_slope),\n        'drift_p_2M': float(drift_p),\n        'window_alphas_2M': [float(a) for a in alphas_w],\n        'R2_mc': float(R2_mc),\n        'T5a_pass': bool(T5a_pass), 'T5a_margin': float(margin_a),\n        'T5b_pass': bool(T5b_pass), 'T5b_margin': float(margin_b),\n        'T5_pass': bool(T5_pass),\n        'T7_pass': bool(T7_pass),\n        'T7_ci_lo': float(ci_lo), 'T7_ci_hi': float(ci_hi),\n        'T8_pass': bool(T8_pass),\n        'bootstrap_mean': float(np.mean(alpha_boots)),\n        'bootstrap_std': float(np.std(alpha_boots)),\n        'validation_score': int(n_pass),\n        'compute_time_2M_s': float(compute_time),\n    }\n    phase4_results.append(result)\n\n# ---- Save ----\nwith open(PHASE4_FILE, 'w') as f:\n    json.dump(phase4_results, f, indent=2)\nsave_to_drive(PHASE4_FILE)\n\n# ---- COMPARISON TABLE ----\n# Include Phase 3 reference (11/9 - 5/2, no correction) for context\nprint(f\"\\n{'='*90}\")\nprint(f\"PHASE 4 RESULTS — SUBLEADING CORRECTION COMPARISON\")\nprint(f\"{'='*90}\")\nprint(f\"{'Model':<38} {'alpha':>8} {'|a-1|':>8} {'drift':>10} {'p':>8} {'T5':>4} {'T7':>4} {'T8':>4} {'Tot':>4}\")\nprint(f\"{'-'*90}\")\n\n# Phase 3 reference (no correction)\nprint(f\"{'[REF] 11/9 - 5/2·logT (no corr.)':<38} \"\n      f\"{p3_scan['alpha_2M']:>+8.4f} {p3_scan['abs_alpha_minus_1_2M']:>8.4f} \"\n      f\"{p3_scan['drift_slope_2M']:>+10.6f} {p3_scan['drift_p_2M']:>8.4f} \"\n      f\"{'P' if p3_scan['T5_pass'] else 'F':>4} \"\n      f\"{'P' if p3_scan['T7_pass'] else 'F':>4} \"\n      f\"{'P' if p3_scan['T8_pass'] else 'F':>4} \"\n      f\"{p3_scan['validation_score']:>3}/3\")\n\nfor r in phase4_results:\n    print(f\"{'['+r['form']+'] '+r['label']:<38} \"\n          f\"{r['alpha_2M']:>+8.4f} {r['abs_alpha_minus_1_2M']:>8.4f} \"\n          f\"{r['drift_slope_2M']:>+10.6f} {r['drift_p_2M']:>8.4f} \"\n          f\"{'P' if r['T5_pass'] else 'F':>4} \"\n          f\"{'P' if r['T7_pass'] else 'F':>4} \"\n          f\"{'P' if r['T8_pass'] else 'F':>4} \"\n          f\"{r['validation_score']:>3}/3\")\n\n# Best Phase 4\nif phase4_results:\n    p4_best = max(phase4_results, key=lambda r: (r['validation_score'],\n                                                   -r['abs_alpha_minus_1_2M']))\n    print(f\"\\n{'='*70}\")\n    print(f\"PHASE 4 BEST: {p4_best['name']}\")\n    print(f\"  Topological origin: {p4_best['topo']}\")\n    print(f\"  alpha(2M) = {p4_best['alpha_2M']:+.6f}\")\n    print(f\"  drift_p   = {p4_best['drift_p_2M']:.4f}\")\n    print(f\"  score     = {p4_best['validation_score']}/3\")\n    improvement = p3_scan['abs_alpha_minus_1_2M'] - p4_best['abs_alpha_minus_1_2M']\n    print(f\"  |alpha-1| improvement vs no-correction: {improvement:+.6f}\")\n    print(f\"{'='*70}\")\n\nprint(f\"\\nPhase 4 saved to {PHASE4_FILE}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ================================================================\n# PHASE 5: 3D TOPOLOGICAL SCAN — θ(T) = a - b/logT + c/log²T\n# ================================================================\n# ML-style exploration bounded by GIFT topology + mathematical constants.\n# Stage 1: Fast 50k scan over ~20k (a,b,c) triplets (GPU, small primes)\n# Stage 2: Refine top 200 with medium primes\n# Stage 3: Validate top 3 on 2M with T5/T7/T8\n#\n# ALL candidate values constructed from:\n#   - GIFT topological integers: 2,3,5,7,8,11,14,21,27,77,99\n#   - Mathematical constants: φ, π, e, γ (Euler), √2\n#   - Simple rational combinations: p/q, p±q\n\nimport math as _m\nfrom itertools import product as cartesian\n\nPHASE5_FILE = 'theta_phase5_3d_results.json'\n\n# ================================================================\n# 1. ATOM POOLS — the vocabulary of topology + math\n# ================================================================\n\n# GIFT integers (core topological invariants)\nGIFT_INTS = [2, 3, 5, 7, 8, 11, 14, 21, 27]\n\n# Mathematical constants\nPHI = (1 + _m.sqrt(5)) / 2   # golden ratio\nEULER_GAMMA = 0.5772156649    # Euler-Mascheroni\nSQRT2 = _m.sqrt(2)\nLOG2 = _m.log(2)\nLOG2PI = _m.log(2 * _m.pi)\n\n# ---- Generate a-candidates (theta_inf, range [0.90, 1.65]) ----\na_pool = set()\n\n# Rational p/q from GIFT integers\nfor p in range(1, 30):\n    for q in range(1, 22):\n        r = p / q\n        if 0.90 <= r <= 1.65:\n            a_pool.add(round(r, 10))\n\n# Math constants and simple expressions\nfor v in [1.0, PHI, PHI - 0.5, 1/PHI + 0.5, _m.pi/3, _m.pi/_m.e,\n          _m.e/_m.pi + 0.5, SQRT2, SQRT2 - 0.2, EULER_GAMMA + 0.5,\n          EULER_GAMMA + 1, 1 + 1/_m.pi, 1 + LOG2, 1 + 1/_m.e,\n          _m.e/2, _m.pi/2 - 0.3, (1 + SQRT2)/2, PHI/SQRT2,\n          2*_m.pi/7, 3*_m.pi/7, (_m.e + 1)/(_m.pi + 1),\n          PHI**2 - 1, _m.log(_m.pi), SQRT2/LOG2PI]:\n    if 0.90 <= v <= 1.65:\n        a_pool.add(round(v, 8))\n\na_vals = sorted(a_pool)\nprint(f\"a-candidates: {len(a_vals)} values in [{min(a_vals):.4f}, {max(a_vals):.4f}]\")\n\n# ---- Generate b-candidates (correction, range [0.3, 8.0]) ----\nb_pool = set()\n\n# Rational p/q from GIFT integers\nfor p in range(1, 60):\n    for q in range(1, 22):\n        r = p / q\n        if 0.3 <= r <= 8.0:\n            b_pool.add(round(r, 10))\n\n# Math constants\nfor v in [PHI, _m.pi, _m.e, 2*PHI, PHI + 1, _m.pi + EULER_GAMMA,\n          _m.e + EULER_GAMMA, SQRT2, 2*SQRT2, 3*SQRT2, _m.pi*SQRT2/2,\n          _m.e*PHI/2, _m.pi/PHI, _m.e/PHI, PHI**2, LOG2PI,\n          2*_m.pi, _m.pi**2/3, _m.e**2/2, PHI*_m.pi/2,\n          EULER_GAMMA*7, EULER_GAMMA*11, EULER_GAMMA*5]:\n    if 0.3 <= v <= 8.0:\n        b_pool.add(round(v, 8))\n\nb_vals = sorted(b_pool)\nprint(f\"b-candidates: {len(b_vals)} values in [{min(b_vals):.4f}, {max(b_vals):.4f}]\")\n\n# ---- Generate c-candidates (subleading, range [-15, 15]) ----\nc_pool = {0.0}  # always include c=0 (no correction)\n\n# Integers and simple rationals from GIFT\nfor v in GIFT_INTS:\n    for sign in [1, -1]:\n        sv = sign * v\n        if -15 <= sv <= 15:\n            c_pool.add(float(sv))\n\n# Half-integers and thirds\nfor p in range(-30, 31):\n    for q in [2, 3, 5, 7]:\n        r = p / q\n        if -15 <= r <= 15 and abs(r) >= 0.3:\n            c_pool.add(round(r, 10))\n\n# Math constants\nfor v in [PHI, _m.pi, _m.e, EULER_GAMMA, SQRT2, LOG2,\n          PHI**2, _m.pi**2, _m.e**2, PHI*_m.pi, _m.e*PHI,\n          _m.pi*SQRT2, _m.e*SQRT2, PHI*EULER_GAMMA,\n          2*_m.pi, 2*_m.e, 2*PHI, 3*PHI, 5*PHI]:\n    for sign in [1, -1]:\n        sv = sign * v\n        if -15 <= sv <= 15:\n            c_pool.add(round(sv, 8))\n\nc_vals = sorted(c_pool)\nprint(f\"c-candidates: {len(c_vals)} values in [{min(c_vals):.4f}, {max(c_vals):.4f}]\")\n\ntotal = len(a_vals) * len(b_vals) * len(c_vals)\nprint(f\"\\nTotal 3D grid: {len(a_vals)} × {len(b_vals)} × {len(c_vals)} = {total:,} triplets\")\n\n# ================================================================\n# 2. STAGE 1 — Fast GPU scan on 50k zeros\n# ================================================================\n# Use small prime set for speed (~5k primes)\nN_3D = 50_000\ng0_3d = gamma0[:N_3D]\ntp_3d = tp[:N_3D]\ndelta_3d = delta[:N_3D]\n\n# 4-window drift for 50k\nWINDOWS_3D = [(0, 12500), (12500, 25000), (25000, 37500), (37500, 50000)]\n\n# Small prime set for fast screening\nprimes_fast = primes[primes <= 50_000]\nprint(f\"\\nStage 1: {N_3D:,} zeros, {len(primes_fast):,} primes\")\nprint(f\"Estimated time: {total * 0.06 / 60:.0f}-{total * 0.12 / 60:.0f} min on A100\")\n\n# Pre-allocate results (only keep top candidates)\nTOP_KEEP = 500  # keep top 500 from Stage 1\ntop_results = []\nbest_score = 999.0\nt_start = time.time()\ntested = 0\n\n# Iterate over all triplets\nfor a_val in a_vals:\n    for b_val in b_vals:\n        for c_val in c_vals:\n            tested += 1\n\n            if tested % 5000 == 0:\n                el = time.time() - t_start\n                rate = tested / el if el > 0 else 0\n                eta = (total - tested) / rate if rate > 0 else 0\n                print(f\"  {tested:>8,}/{total:,} [{el/60:.1f}m, {rate:.0f}/s, \"\n                      f\"ETA {eta/60:.1f}m] best={best_score:.6f}\")\n\n            # Compute prime sum\n            dp = prime_sum_var(g0_3d, tp_3d, primes_fast, K_MAX,\n                               a_val, -b_val, c_val)\n\n            # Alpha and R2\n            denom = np.dot(dp, dp)\n            if denom <= 0:\n                continue\n            alpha_val = float(np.dot(delta_3d, dp) / denom)\n            R2_val = float(1.0 - np.var(delta_3d - dp) / np.var(delta_3d))\n\n            # Quick 4-window drift\n            alphas_w = []\n            for lo, hi in WINDOWS_3D:\n                d_w = delta_3d[lo:hi]\n                dp_w = dp[lo:hi]\n                dot_pp = np.dot(dp_w, dp_w)\n                alphas_w.append(float(np.dot(d_w, dp_w) / dot_pp) if dot_pp > 0 else 0.0)\n            drift_val = float(stats.linregress(np.arange(4, dtype=float), alphas_w).slope)\n\n            # Composite score\n            score = abs(alpha_val - 1) + abs(drift_val) * 50\n\n            # Track if among the best\n            if score < best_score:\n                best_score = score\n                if tested <= 50000 or tested % 1000 == 0:\n                    print(f\"  ** NEW BEST: a={a_val:.6f} b={b_val:.6f} c={c_val:.4f} \"\n                          f\"-> alpha={alpha_val:.6f}, drift={drift_val:+.6f}, score={score:.6f}\")\n\n            # Keep top results (insert-sort into bounded list)\n            if len(top_results) < TOP_KEEP or score < top_results[-1]['score']:\n                entry = {\n                    'a': float(a_val), 'b': float(b_val), 'c': float(c_val),\n                    'alpha': float(alpha_val), 'R2': float(R2_val),\n                    'drift': float(drift_val), 'score': float(score),\n                    'window_alphas': [float(x) for x in alphas_w],\n                }\n                top_results.append(entry)\n                top_results.sort(key=lambda x: x['score'])\n                if len(top_results) > TOP_KEEP:\n                    top_results = top_results[:TOP_KEEP]\n\nscan_time = time.time() - t_start\nprint(f\"\\nStage 1 complete: {tested:,} triplets in {scan_time/60:.1f} min \"\n      f\"({tested/scan_time:.0f}/s)\")\n\n# ================================================================\n# 3. STAGE 1 RESULTS — Top 30\n# ================================================================\n\ndef describe_val(v, name=''):\n    \"\"\"Try to identify a value as a topological/math expression.\"\"\"\n    # Check exact GIFT rationals\n    for p in range(1, 100):\n        for q in range(1, 30):\n            if abs(v - p/q) < 1e-6 and _m.gcd(p, q) == 1:\n                return f\"{p}/{q}\"\n    # Check math constants\n    for label, ref in [('φ', PHI), ('π', _m.pi), ('e', _m.e), ('γ', EULER_GAMMA),\n                       ('√2', SQRT2), ('π/e', _m.pi/_m.e), ('e/2', _m.e/2),\n                       ('φ²−1', PHI**2-1), ('log(π)', _m.log(_m.pi)),\n                       ('2π/7', 2*_m.pi/7), ('3π/7', 3*_m.pi/7),\n                       ('π/3', _m.pi/3), ('φ/√2', PHI/SQRT2),\n                       ('(1+√2)/2', (1+SQRT2)/2)]:\n        if abs(v - ref) < 1e-6:\n            return label\n    # Check negative math\n    for label, ref in [('−φ', -PHI), ('−π', -_m.pi), ('−e', -_m.e),\n                       ('−√2', -SQRT2), ('−γ', -EULER_GAMMA)]:\n        if abs(v - ref) < 1e-6:\n            return label\n    return f\"{v:.4f}\"\n\nprint(f\"\\n{'='*110}\")\nprint(f\"STAGE 1 — TOP 30 CANDIDATES (50k zeros, fast primes)\")\nprint(f\"{'='*110}\")\nprint(f\"{'Rk':>3} {'a (θ∞)':>12} {'b (corr)':>12} {'c (sub)':>12} \"\n      f\"{'alpha':>10} {'R2':>8} {'drift':>10} {'score':>10} {'Formula':>30}\")\nprint(\"-\" * 110)\n\nfor i, r in enumerate(top_results[:30], 1):\n    a_str = describe_val(r['a'])\n    b_str = describe_val(r['b'])\n    c_str = describe_val(r['c']) if r['c'] != 0 else '0'\n    formula = f\"{a_str} - {b_str}/logT\"\n    if r['c'] != 0:\n        sign = '+' if r['c'] > 0 else ''\n        formula += f\" {sign}{c_str}/log²T\"\n    print(f\"{i:>3} {r['a']:>12.6f} {r['b']:>12.6f} {r['c']:>12.4f} \"\n          f\"{r['alpha']:>+10.6f} {r['R2']:>8.4f} {r['drift']:>+10.6f} \"\n          f\"{r['score']:>10.6f} {formula:>30}\")\n\n# ================================================================\n# 4. STAGE 2 — Refine top 200 with medium primes on 50k\n# ================================================================\nprint(f\"\\n{'='*70}\")\nprint(f\"STAGE 2 — REFINING TOP 200 WITH MEDIUM PRIMES\")\nprint(f\"{'='*70}\")\n\nprimes_med = primes[primes <= 200_000]\nprint(f\"  {N_3D:,} zeros, {len(primes_med):,} primes\")\n\nrefined = []\nfor i, r in enumerate(top_results[:200]):\n    dp = prime_sum_var(g0_3d, tp_3d, primes_med, K_MAX,\n                       r['a'], -r['b'], r['c'])\n    alpha_val, R2_val = compute_alpha_R2(delta_3d, dp)\n    alphas_w = []\n    for lo, hi in WINDOWS_3D:\n        d_w = delta_3d[lo:hi]\n        dp_w = dp[lo:hi]\n        dot_pp = np.dot(dp_w, dp_w)\n        alphas_w.append(float(np.dot(d_w, dp_w) / dot_pp) if dot_pp > 0 else 0.0)\n    drift_val = float(stats.linregress(np.arange(4, dtype=float), alphas_w).slope)\n    score = abs(alpha_val - 1) + abs(drift_val) * 50\n\n    refined.append({\n        **r,\n        'alpha_ref': float(alpha_val), 'R2_ref': float(R2_val),\n        'drift_ref': float(drift_val), 'score_ref': float(score),\n        'window_alphas_ref': [float(x) for x in alphas_w],\n    })\n\nrefined.sort(key=lambda x: x['score_ref'])\nprint(f\"  Done. Best refined score: {refined[0]['score_ref']:.6f}\")\n\nprint(f\"\\n{'='*110}\")\nprint(f\"STAGE 2 — TOP 20 REFINED CANDIDATES\")\nprint(f\"{'='*110}\")\nprint(f\"{'Rk':>3} {'a':>10} {'b':>10} {'c':>10} \"\n      f\"{'alpha':>10} {'drift':>10} {'score':>10} {'Formula'}\")\nprint(\"-\" * 110)\nfor i, r in enumerate(refined[:20], 1):\n    a_str = describe_val(r['a'])\n    b_str = describe_val(r['b'])\n    c_str = describe_val(r['c']) if r['c'] != 0 else '0'\n    formula = f\"θ = {a_str} − {b_str}/logT\"\n    if r['c'] != 0:\n        sign = '+' if r['c'] > 0 else ''\n        formula += f\" {sign}{c_str}/log²T\"\n    print(f\"{i:>3} {r['a']:>10.6f} {r['b']:>10.6f} {r['c']:>10.4f} \"\n          f\"{r['alpha_ref']:>+10.6f} {r['drift_ref']:>+10.6f} \"\n          f\"{r['score_ref']:>10.6f}  {formula}\")\n\n# ================================================================\n# 5. STAGE 3 — Validate top 3 on full 2M zeros with T5/T7/T8\n# ================================================================\nprint(f\"\\n{'='*70}\")\nprint(f\"STAGE 3 — FULL 2M VALIDATION (TOP 3)\")\nprint(f\"{'='*70}\")\n\nphase5_validated = []\n\nfor v_idx, cand in enumerate(refined[:3]):\n    a_val, b_val, c_val = cand['a'], cand['b'], cand['c']\n    a_str = describe_val(a_val)\n    b_str = describe_val(b_val)\n    c_str = describe_val(c_val) if c_val != 0 else '0'\n    name = f\"{a_str} - {b_str}/logT\"\n    if c_val != 0:\n        sign = '+' if c_val > 0 else ''\n        name += f\" {sign}{c_str}/log²T\"\n\n    print(f\"\\n  [{v_idx+1}/3] {name}\")\n    print(f\"    a={a_val:.6f}, b={b_val:.6f}, c={c_val:.4f}\")\n\n    # Full 2M prime sum\n    delta_pred_full = np.zeros(N_ZEROS)\n    t1 = time.time()\n    for i in range(0, N_ZEROS, CHUNK_SIZE):\n        j = min(i + CHUNK_SIZE, N_ZEROS)\n        delta_pred_full[i:j] = prime_sum_var(\n            gamma0[i:j], tp[i:j], primes, K_MAX,\n            a_val, -b_val, c_val)\n        pct = 100 * j / N_ZEROS\n        el = time.time() - t1\n        eta = el / j * (N_ZEROS - j) if j > 0 else 0\n        print(f\"      [{j:>9,}/{N_ZEROS:,}] {pct:5.1f}%  [{el/60:.1f}m, ETA {eta/60:.1f}m]\")\n    compute_time = time.time() - t1\n\n    # Metrics\n    alpha_full, R2_full = compute_alpha_R2(delta, delta_pred_full)\n    loc_full = compute_localization(delta, delta_pred_full, gamma_n)\n    alphas_w = compute_window_alphas(delta, delta_pred_full)\n    drift_slope, drift_p = compute_drift(alphas_w)\n\n    print(f\"    alpha(2M)={alpha_full:+.6f}  |a-1|={abs(alpha_full-1):.6f}  \"\n          f\"drift={drift_slope:+.6f} (p={drift_p:.4f})\")\n    print(f\"    windows={[f'{a:.4f}' for a in alphas_w]}\")\n\n    # T5\n    dp_mc = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                          a_val, -b_val, c_val)\n    R2_mc = float(1.0 - np.var(d_mc - dp_mc) / np.var(d_mc))\n    T5a = R2_mc > float(np.max(R2_random_const))\n    T5b = R2_mc > float(np.max(R2_random_corr))\n    T5 = T5a and T5b\n\n    # T7 bootstrap\n    print(f\"    Running T7 bootstrap ({B_BOOT} samples)...\")\n    np.random.seed(42)\n    alpha_boots = np.empty(B_BOOT)\n    for b_idx in range(B_BOOT):\n        idx = np.random.randint(0, N_ZEROS, N_ZEROS)\n        d_b = delta[idx]; dp_b = delta_pred_full[idx]\n        dot_pp = np.dot(dp_b, dp_b)\n        alpha_boots[b_idx] = np.dot(d_b, dp_b) / dot_pp if dot_pp > 0 else 0.0\n    ci_lo = float(np.percentile(alpha_boots, 2.5))\n    ci_hi = float(np.percentile(alpha_boots, 97.5))\n    T7 = ci_lo <= 1.0 <= ci_hi\n\n    # T8\n    T8 = drift_p > 0.05\n\n    n_pass = sum([T5, T7, T8])\n    print(f\"    T5={'PASS' if T5 else 'FAIL'} (a:{'+' if T5a else '-'} b:{'+' if T5b else '-'})  \"\n          f\"T7={'PASS' if T7 else 'FAIL'} CI=[{ci_lo:.4f},{ci_hi:.4f}]  \"\n          f\"T8={'PASS' if T8 else 'FAIL'} (p={drift_p:.4f})  \"\n          f\"SCORE={n_pass}/3\")\n\n    phase5_validated.append({\n        'name': name,\n        'a': float(a_val), 'b': float(b_val), 'c': float(c_val),\n        'a_formula': a_str, 'b_formula': b_str, 'c_formula': c_str,\n        'alpha_50k': float(cand['alpha_ref']),\n        'score_50k': float(cand['score_ref']),\n        'alpha_2M': float(alpha_full),\n        'abs_alpha_minus_1_2M': float(abs(alpha_full - 1)),\n        'R2_2M': float(R2_full),\n        'localization_2M': float(loc_full),\n        'drift_slope_2M': float(drift_slope),\n        'drift_p_2M': float(drift_p),\n        'window_alphas_2M': [float(a) for a in alphas_w],\n        'R2_mc': float(R2_mc),\n        'T5_pass': bool(T5), 'T5a_pass': bool(T5a), 'T5b_pass': bool(T5b),\n        'T7_pass': bool(T7), 'T7_ci_lo': float(ci_lo), 'T7_ci_hi': float(ci_hi),\n        'T8_pass': bool(T8),\n        'validation_score': int(n_pass),\n        'compute_time_s': float(compute_time),\n    })\n\n# ================================================================\n# 6. SAVE & SUMMARY\n# ================================================================\nphase5_output = {\n    'metadata': {\n        'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n        'n_a': len(a_vals), 'n_b': len(b_vals), 'n_c': len(c_vals),\n        'total_triplets': total,\n        'scan_time_min': round(scan_time / 60, 1),\n        'N_scan': N_3D,\n    },\n    'top50_stage1': top_results[:50],\n    'top20_refined': [r for r in refined[:20]],\n    'validated_2M': phase5_validated,\n}\n\nwith open(PHASE5_FILE, 'w') as f:\n    json.dump(phase5_output, f, indent=2)\nsave_to_drive(PHASE5_FILE)\n\nprint(f\"\\n{'='*70}\")\nprint(f\"PHASE 5 COMPLETE — 3D TOPOLOGICAL SCAN\")\nprint(f\"  Scanned: {total:,} (a,b,c) triplets in {scan_time/60:.1f} min\")\nprint(f\"  Refined: top 200 with medium primes\")\nprint(f\"  Validated: top 3 on {N_ZEROS:,} zeros\")\nprint(f\"{'='*70}\")\nfor r in phase5_validated:\n    print(f\"  {r['name']}\")\n    print(f\"    50k: alpha={r['alpha_50k']:+.6f}, score={r['score_50k']:.6f}\")\n    print(f\"    2M:  alpha={r['alpha_2M']:+.6f}, T5/T7/T8 = {r['validation_score']}/3\")\nprint(f\"{'='*70}\")\nprint(f\"Saved to {PHASE5_FILE}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 12. Final Summary & Plots"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams.update({'font.size': 11})\n\n# ================================================================\n# FINAL SUMMARY\n# ================================================================\nprint(\"=\" * 100)\nprint(\"PHASE 1 SCREENING RESULTS (50k zeros, all candidates)\")\nprint(\"=\" * 100)\nprint(f\"{'Rk':>3} {'Name':<45} {'alpha':>10} {'|a-1|':>8} \"\n      f\"{'R2':>8} {'drift':>10} {'score':>10}\")\nprint(\"-\" * 100)\nfor i, r in enumerate(ranked, 1):\n    marker = \" *\" if r['name'] in [p['name'] for p in phase2_results] else \"\"\n    print(f\"{i:>3} {r['name']:<45} {r['alpha']:>+10.6f} \"\n          f\"{r['abs_alpha_minus_1']:>8.6f} {r['R2']:>8.4f} \"\n          f\"{r['drift_slope']:>+10.6f} {r['score']:>10.6f}{marker}\")\nprint(\"\\n  * = advanced to Phase 2\\n\")\n\nprint(\"=\" * 100)\nprint(\"PHASE 2 VALIDATION RESULTS (2M zeros, top candidates)\")\nprint(\"=\" * 100)\nfor r in phase2_results:\n    sc = r['validation_score']\n    T5 = 'PASS' if r.get('T5_pass', False) else 'FAIL'\n    T7 = 'PASS' if r.get('T7_pass', False) else 'FAIL'\n    T8 = 'PASS' if r.get('T8_pass', False) else 'FAIL'\n    print(f\"\\n  {r['name']}\")\n    print(f\"    alpha(50k)  = {r['alpha']:+.6f}  ->  alpha(2M) = {r['alpha_2M']:+.6f}\")\n    print(f\"    T5: {T5}  T7: {T7} (CI=[{r['T7_ci_lo']:.4f}, {r['T7_ci_hi']:.4f}])  T8: {T8} (p={r['T8_drift_p_2M']:.4f})\")\n    print(f\"    SCORE: {sc}/3\")\n\nprint(f\"\\n{'='*100}\")\nprint(\"PHASE 3 VALIDATION RESULTS (2M zeros, rational scan winner + GIFT reference)\")\nprint(\"=\" * 100)\nfor r in phase3_results:\n    sc = r['validation_score']\n    T5 = 'PASS' if r.get('T5_pass', False) else 'FAIL'\n    T7 = 'PASS' if r.get('T7_pass', False) else 'FAIL'\n    T8 = 'PASS' if r.get('T8_pass', False) else 'FAIL'\n    print(f\"\\n  {r['name']} [{r['source']}]\")\n    print(f\"    alpha(2M) = {r['alpha_2M']:+.6f}  |alpha-1| = {r['abs_alpha_minus_1_2M']:.6f}\")\n    print(f\"    T5: {T5}  T7: {T7} (CI=[{r['T7_ci_lo']:.4f}, {r['T7_ci_hi']:.4f}])  T8: {T8} (p={r['T8_drift_p_2M']:.4f})\")\n    print(f\"    SCORE: {sc}/3\")\n\nprint(f\"\\n{'='*100}\")\nprint(\"PHASE 4 — SUBLEADING CORRECTION RESULTS (2M zeros)\")\nprint(\"=\" * 100)\nprint(f\"{'Model':<38} {'alpha':>8} {'|a-1|':>8} {'drift':>10} {'p':>8} {'T5':>4} {'T7':>4} {'T8':>4} {'Tot':>4}\")\nprint(\"-\" * 90)\n# Reference\nprint(f\"{'[REF] 11/9 - 5/2 (no correction)':<38} \"\n      f\"{p3_scan['alpha_2M']:>+8.4f} {p3_scan['abs_alpha_minus_1_2M']:>8.4f} \"\n      f\"{p3_scan['drift_slope_2M']:>+10.6f} {p3_scan['drift_p_2M']:>8.4f} \"\n      f\"{'P' if p3_scan['T5_pass'] else 'F':>4} \"\n      f\"{'P' if p3_scan['T7_pass'] else 'F':>4} \"\n      f\"{'P' if p3_scan['T8_pass'] else 'F':>4} \"\n      f\"{p3_scan['validation_score']:>3}/3\")\nfor r in phase4_results:\n    print(f\"{'['+r['form']+'] '+r['label']:<38} \"\n          f\"{r['alpha_2M']:>+8.4f} {r['abs_alpha_minus_1_2M']:>8.4f} \"\n          f\"{r['drift_slope_2M']:>+10.6f} {r['drift_p_2M']:>8.4f} \"\n          f\"{'P' if r['T5_pass'] else 'F':>4} \"\n          f\"{'P' if r['T7_pass'] else 'F':>4} \"\n          f\"{'P' if r['T8_pass'] else 'F':>4} \"\n          f\"{r['validation_score']:>3}/3\")\n\n# Overall best across ALL phases\nall_validated = phase2_results + phase3_results + phase4_results\nbest = max(all_validated, key=lambda r: (r['validation_score'], -r.get('abs_alpha_minus_1_2M', r.get('abs_alpha_minus_1', 1))))\nprint(f\"\\n{'='*70}\")\nprint(f\"OVERALL BEST: {best.get('name', 'unknown')}\")\nprint(f\"  Validation score: {best['validation_score']}/3\")\nprint(f\"  alpha (2M zeros): {best['alpha_2M']:+.6f}\")\nprint(f\"  R2 (2M zeros):    {best['R2_2M']:.6f}\")\nprint(f\"{'='*70}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ---- PLOTS ----\nfig, axes = plt.subplots(3, 3, figsize=(22, 18))\n\n# (0,0) Phase 1: Alpha bar chart (all candidates)\nax = axes[0, 0]\nnames_short = [r['name'][:25] for r in ranked]\nalphas_ranked = [r['alpha'] for r in ranked]\ncolors = ['green' if r['name'] == best['name'] else\n          'steelblue' if r['name'] in [p['name'] for p in phase2_results] else\n          'lightgray' for r in ranked]\nax.barh(range(len(ranked)), alphas_ranked, color=colors, alpha=0.8)\nax.axvline(1.0, color='red', ls='--', lw=2)\nax.set_yticks(range(len(ranked)))\nax.set_yticklabels(names_short, fontsize=8)\nax.set_xlabel('alpha (OLS)')\nax.set_title('Phase 1: Alpha Screening (50k zeros)')\nax.invert_yaxis()\n\n# (0,1) Phase 1: R2 bar chart\nax = axes[0, 1]\nR2s = [r['R2'] for r in ranked]\nax.barh(range(len(ranked)), R2s, color=colors, alpha=0.8)\nax.set_yticks(range(len(ranked)))\nax.set_yticklabels(names_short, fontsize=8)\nax.set_xlabel('R2 (alpha=1)')\nax.set_title('Phase 1: R2 Screening (50k zeros)')\nax.invert_yaxis()\n\n# (0,2) Phase 1: Score bar chart\nax = axes[0, 2]\nscores = [r['score'] for r in ranked]\nax.barh(range(len(ranked)), scores, color=colors, alpha=0.8)\nax.set_yticks(range(len(ranked)))\nax.set_yticklabels(names_short, fontsize=8)\nax.set_xlabel('Composite Score (lower = better)')\nax.set_title('Phase 1: Score Ranking')\nax.invert_yaxis()\n\n# (1,0) Phase 2: Window alphas (winner + runner-up on 2M)\nax = axes[1, 0]\nfor r in phase2_results:\n    alphas_w = r.get('window_alphas_2M', [])\n    if alphas_w:\n        c = 'green' if r['name'] == best['name'] else 'steelblue'\n        ax.plot(range(len(alphas_w)), alphas_w, 'o-',\n                label=r['name'][:30], color=c, lw=2, ms=8)\nax.axhline(1.0, color='red', ls='--', lw=1.5)\nax.set_xticks(range(len(FULL_WINDOWS)))\nax.set_xticklabels(FULL_LABELS, rotation=30, fontsize=8)\nax.set_ylabel('alpha')\nax.set_title('Phase 2: Window Alpha (2M zeros)')\nax.legend(fontsize=8, loc='best')\n\n# (1,1) Phase 2: Bootstrap CI\nax = axes[1, 1]\nfor i, r in enumerate(phase2_results):\n    ci_lo = r.get('T7_ci_lo', r['alpha_2M'] - 0.01)\n    ci_hi = r.get('T7_ci_hi', r['alpha_2M'] + 0.01)\n    color = 'green' if r.get('T7_pass', False) else 'red'\n    ax.plot([ci_lo, ci_hi], [i, i], '-', color=color, lw=4)\n    ax.plot(r['alpha_2M'], i, 'D', color=color, ms=10)\n    ax.annotate(r['name'][:30], (ci_hi + 0.001, i), fontsize=9, va='center')\nax.axvline(1.0, color='red', ls='--', lw=2)\nax.set_xlabel('alpha (95% Bootstrap CI)')\nax.set_title('Phase 2: T7 Bootstrap CI (2M zeros)')\nax.set_yticks([])\n\n# (1,2) Theta profiles (all candidates)\nax = axes[1, 2]\nT_plot = np.logspace(1.5, 6.5, 300)\nlogT = np.log(T_plot)\nfor r in ranked[:8]:\n    a, b, c = r['theta_inf'], r['b'], r['c']\n    theta_vals = a - b / logT\n    if c != 0.0:\n        theta_vals -= c / logT**2\n    theta_vals = np.clip(theta_vals, 0.5, 2.0)\n    c_plot = 'green' if r['name'] == best['name'] else \\\n             'steelblue' if r['name'] in [p['name'] for p in phase2_results] else 'gray'\n    ax.plot(np.log10(T_plot), theta_vals, label=r['name'][:25],\n            color=c_plot, alpha=0.8, lw=1.5 if c_plot != 'gray' else 0.8)\n# Also plot Phase 3 models\nfor r in phase3_results:\n    theta_vals = r['theta_inf'] - r['b'] / logT\n    theta_vals = np.clip(theta_vals, 0.5, 2.0)\n    c_plot = 'darkorange' if r['source'] == 'rational_scan_winner' else 'purple'\n    ax.plot(np.log10(T_plot), theta_vals, label=r['name'][:25],\n            color=c_plot, alpha=0.9, lw=2.5, ls='--')\nax.set_xlabel('log10(T)')\nax.set_ylabel('theta(T)')\nax.set_title('Theta Profiles (top candidates)')\nax.legend(fontsize=6, loc='best')\n\n# ---- ROW 3: PHASE 3 PLOTS ----\n\n# (2,0) Phase 3: Window alphas (scan winner + GIFT)\nax = axes[2, 0]\np3_colors = {'rational_scan_winner': 'darkorange', 'gift_reference': 'purple'}\nfor r in phase3_results:\n    alphas_w = r.get('window_alphas_2M', [])\n    if alphas_w:\n        c = p3_colors.get(r['source'], 'gray')\n        ax.plot(range(len(alphas_w)), alphas_w, 'o-',\n                label=f\"{r['name'][:25]} ({r['validation_score']}/3)\",\n                color=c, lw=2.5, ms=8)\nax.axhline(1.0, color='red', ls='--', lw=1.5)\nax.set_xticks(range(len(FULL_WINDOWS)))\nax.set_xticklabels(FULL_LABELS, rotation=30, fontsize=8)\nax.set_ylabel('alpha')\nax.set_title('Phase 3: Window Alpha (2M zeros)')\nax.legend(fontsize=8, loc='best')\n\n# (2,1) Phase 3: Bootstrap CI\nax = axes[2, 1]\nfor i, r in enumerate(phase3_results):\n    ci_lo = r.get('T7_ci_lo', r['alpha_2M'] - 0.01)\n    ci_hi = r.get('T7_ci_hi', r['alpha_2M'] + 0.01)\n    color = 'green' if r.get('T7_pass', False) else 'red'\n    c_edge = p3_colors.get(r['source'], 'gray')\n    ax.plot([ci_lo, ci_hi], [i, i], '-', color=c_edge, lw=5)\n    ax.plot(r['alpha_2M'], i, 'D', color=c_edge, ms=12, markeredgecolor='black')\n    label = f\"{r['name'][:25]}  [{r['validation_score']}/3]\"\n    ax.annotate(label, (max(ci_hi, r['alpha_2M']) + 0.0005, i), fontsize=9, va='center')\nax.axvline(1.0, color='red', ls='--', lw=2)\nax.set_xlabel('alpha (95% Bootstrap CI)')\nax.set_title('Phase 3: T7 Bootstrap CI (2M zeros)')\nax.set_yticks([])\n\n# (2,2) Phase 3: Validation scorecard\nax = axes[2, 2]\nax.axis('off')\ntests = ['T5a\\n(beat const)', 'T5b\\n(beat corr)', 'T7\\n(CI has 1)', 'T8\\n(no drift)', 'TOTAL']\ny_pos = np.arange(len(phase3_results))\nx_pos = np.arange(len(tests))\n\nfor i, r in enumerate(phase3_results):\n    results = [r['T5a_pass'], r['T5b_pass'], r['T7_pass'], r['T8_pass']]\n    for j, passed in enumerate(results):\n        color = '#2ecc71' if passed else '#e74c3c'\n        ax.add_patch(plt.Rectangle((j - 0.4, i - 0.35), 0.8, 0.7, \n                                    facecolor=color, alpha=0.7, edgecolor='white', lw=2))\n        ax.text(j, i, 'PASS' if passed else 'FAIL', ha='center', va='center',\n                fontsize=10, fontweight='bold', color='white')\n    # Total score\n    sc = r['validation_score']\n    color = '#2ecc71' if sc >= 2 else '#f39c12' if sc >= 1 else '#e74c3c'\n    ax.add_patch(plt.Rectangle((len(tests)-1 - 0.4, i - 0.35), 0.8, 0.7,\n                                facecolor=color, alpha=0.7, edgecolor='white', lw=2))\n    ax.text(len(tests)-1, i, f'{sc}/3', ha='center', va='center',\n            fontsize=11, fontweight='bold', color='white')\n\n# Labels\nfor j, t in enumerate(tests):\n    ax.text(j, -0.8, t, ha='center', va='center', fontsize=9, fontweight='bold')\nfor i, r in enumerate(phase3_results):\n    src = 'SCAN' if r['source'] == 'rational_scan_winner' else 'GIFT'\n    ax.text(-0.7, i, f\"[{src}]\\n{r['name'][:20]}\", ha='right', va='center', fontsize=8)\n\nax.set_xlim(-1.5, len(tests) - 0.3)\nax.set_ylim(-1.2, len(phase3_results) - 0.3)\nax.set_title('Phase 3: Validation Scorecard', fontsize=12, fontweight='bold')\n\nplt.suptitle('Theta Candidate Tournament — Screen (50k) + Validate (2M) + Phase 3 Rational',\n             fontsize=14, y=1.01)\nplt.tight_layout()\nPLOT_FILE = 'theta_tournament_plots.png'\nplt.savefig(PLOT_FILE, dpi=150, bbox_inches='tight')\nsave_to_drive(PLOT_FILE)\nprint(f\"Saved {PLOT_FILE}\")\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 13. Save Final Results & Download"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ---- COMPREHENSIVE OUTPUT ----\nfinal_output = {\n    'metadata': {\n        'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n        'strategy': '4-phase: screen 50k + validate 2M + rational scan + subleading corrections',\n        'N_zeros_total': int(N_ZEROS),\n        'N_zeros_screening': int(N_SCREEN),\n        'T_range': [float(gamma_n[0]), float(gamma_n[-1])],\n        'P_max': int(P_MAX),\n        'n_primes': int(len(primes)),\n        'K_max': K_MAX,\n        'mollifier': 'cosine-squared',\n        'source': 'Odlyzko zeros6 (2,001,052 zeros)',\n        'n_candidates': len(CANDIDATES),\n        'n_phase2': len(phase2_results),\n        'n_phase3': len(phase3_results),\n        'n_phase4': len(phase4_results),\n        'T5_trials': N_TRIALS,\n        'T7_bootstrap_B': B_BOOT,\n    },\n    'phase1_screening': ranked,\n    'phase2_validation': phase2_results,\n    'rational_scan_top30': top_scan if 'top_scan' in dir() else [],\n    'phase3_validation': phase3_results,\n    'phase4_subleading': phase4_results,\n    'summary': {\n        'phase1_winner': ranked[0]['name'] if ranked else 'none',\n        'phase2_best_score': max(phase2_results, key=lambda r: r['validation_score'])['validation_score'] if phase2_results else 0,\n        'phase3_scan_winner': p3_scan['name'],\n        'phase3_scan_score': p3_scan['validation_score'],\n        'phase3_gift_score': p3_gift['validation_score'],\n        'phase4_results': [{\n            'name': r['name'], 'label': r['label'], 'form': r['form'],\n            'c': r['c'], 'topo': r['topo'],\n            'alpha_2M': r['alpha_2M'], 'validation_score': r['validation_score'],\n            'drift_p': r['drift_p_2M'],\n        } for r in phase4_results],\n        'overall_best': best.get('name', 'unknown'),\n        'overall_best_validation_score': best['validation_score'],\n        'overall_best_alpha_2M': best['alpha_2M'],\n        'overall_best_R2_2M': best['R2_2M'],\n    },\n}\n\nFINAL_FILE = 'theta_tournament_final.json'\nwith open(FINAL_FILE, 'w') as f:\n    json.dump(final_output, f, indent=2)\nsave_to_drive(FINAL_FILE)\nprint(f\"Saved {FINAL_FILE}\")\n\n# Trigger downloads in Colab\ntry:\n    from google.colab import files\n    files.download(FINAL_FILE)\n    files.download(PLOT_FILE)\n    files.download(PHASE3_FILE)\n    files.download(PHASE4_FILE)\n    print(\"Downloads triggered.\")\nexcept ImportError:\n    print(\"Not in Colab — files saved locally.\")\n\nprint(f\"\\n{'='*70}\")\nprint(f\"TOURNAMENT COMPLETE — ALL 4 PHASES\")\nprint(f\"  Phase 1: {len(CANDIDATES)} candidates screened on {N_SCREEN:,} zeros\")\nprint(f\"  Phase 2: {len(phase2_results)} candidates validated on {N_ZEROS:,} zeros\")\nprint(f\"  Phase 3: {len(phase3_results)} models validated on {N_ZEROS:,} zeros\")\nprint(f\"  Phase 4: {len(phase4_results)} correction models on {N_ZEROS:,} zeros\")\nprint(f\"{'='*70}\")\nprint(f\"  OVERALL BEST: {best.get('name', 'unknown')}\")\nprint(f\"    alpha (2M) = {best['alpha_2M']:.6f}\")\nprint(f\"    R2 (2M)    = {best['R2_2M']:.6f}\")\nprint(f\"    score      = {best['validation_score']}/3\")\nprint(f\"{'='*70}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}