#!/usr/bin/env python3
"""
GIFT Phase 2.8: RG by Decimation
================================

Proposition de GPT: D√©finir le RG explicitement par d√©cimation/coarse-graining.

Au lieu de FITTER les Œ≤, on les D√âRIVE comme valeurs propres du Jacobien
de la transformation RG pr√®s du point fixe.

D√©cimation: Œ≥‚Çô^(m) = Œ≥_{mn} (garder 1 z√©ro sur m)

Si les courbes a_i^(m)(Œ≥) se superposent apr√®s rescaling ‚Üí structure RG r√©elle
Les Œ≤ deviennent des "scaling dimensions" calculables.
"""

import numpy as np
from typing import List, Tuple, Dict
import json

# ============================================================
# RECURRENCE FITTING
# ============================================================

def fit_recurrence(gamma: np.ndarray, lags: List[int],
                   start: int = None, end: int = None) -> Tuple[np.ndarray, float]:
    """Fit r√©currence lin√©aire."""
    max_lag = max(lags)
    if start is None:
        start = max_lag
    if end is None:
        end = len(gamma)

    n_points = end - start
    n_params = len(lags) + 1

    X = np.zeros((n_points, n_params))
    for i, lag in enumerate(lags):
        X[:, i] = gamma[start - lag:end - lag]
    X[:, -1] = 1.0

    y = gamma[start:end]
    coeffs, _, _, _ = np.linalg.lstsq(X, y, rcond=None)

    y_pred = X @ coeffs
    errors = np.abs(y_pred - y)

    return coeffs, np.mean(errors)

# ============================================================
# DECIMATION RG
# ============================================================

def decimate(gamma: np.ndarray, m: int) -> np.ndarray:
    """
    D√©cimation: garder 1 z√©ro sur m.
    Œ≥‚Çô^(m) = Œ≥_{mn}
    """
    return gamma[::m]

def block_average(gamma: np.ndarray, m: int) -> np.ndarray:
    """
    Moyennage par blocs de taille m.
    Œ≥ÃÉ‚Çô^(m) = (1/m) Œ£‚±º Œ≥_{mn+j}
    """
    n_blocks = len(gamma) // m
    return np.array([np.mean(gamma[i*m:(i+1)*m]) for i in range(n_blocks)])

def analyze_at_scale(gamma: np.ndarray, lags: List[int],
                     window_size: int = 10000, n_windows: int = 10) -> List[Dict]:
    """
    Analyse par fen√™tres glissantes √† une √©chelle donn√©e.
    """
    results = []
    step = (len(gamma) - window_size) // (n_windows - 1) if n_windows > 1 else 0

    for i in range(n_windows):
        start_idx = i * step
        end_idx = start_idx + window_size

        if end_idx > len(gamma):
            break

        window = gamma[start_idx:end_idx]
        stable_start = int(window_size * 0.7)

        try:
            coeffs, error = fit_recurrence(window, lags, stable_start, window_size)
            # Estimer gamma moyen de la fen√™tre
            gamma_mid = np.mean(window)

            results.append({
                'gamma_mid': float(gamma_mid),
                'coefficients': {f'a_{lag}': float(coeffs[i]) for i, lag in enumerate(lags)},
                'c': float(coeffs[-1]),
                'error': float(error)
            })
        except Exception as e:
            pass

    return results

# ============================================================
# MAIN ANALYSIS
# ============================================================

def main():
    print("="*70)
    print("GIFT Phase 2.8: RG BY DECIMATION")
    print("="*70)

    # Charger les donn√©es
    print("\nüìÇ Chargement des donn√©es...")

    try:
        gammas = []
        # Try zeros6 first, then zeros1
        for filename in ['zeta/zeros6', 'zeta/zeros1']:
            try:
                with open(filename, 'r') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            try:
                                gammas.append(float(line.split()[0]))
                            except:
                                continue
                print(f"   Charg√© {len(gammas):,} z√©ros depuis {filename}")
                break
            except FileNotFoundError:
                continue

        if not gammas:
            print("   ‚ùå Aucun fichier de z√©ros trouv√©")
            return

        gammas = np.array(sorted(gammas))

    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return

    lags = [5, 8, 13, 27]

    # ============================================================
    # ANALYSE √Ä DIFF√âRENTES √âCHELLES DE D√âCIMATION
    # ============================================================

    print("\n" + "="*70)
    print("ANALYSE RG PAR D√âCIMATION")
    print("="*70)

    decimation_factors = [1, 2, 3, 5, 8, 13]  # Inclut des Fibonacci!
    all_results = {}

    for m in decimation_factors:
        print(f"\n{'‚îÄ'*60}")
        print(f"üìä √âchelle m = {m} (1 z√©ro sur {m})")
        print(f"{'‚îÄ'*60}")

        # D√©cimer
        gamma_m = decimate(gammas, m)
        print(f"   N z√©ros apr√®s d√©cimation: {len(gamma_m):,}")

        if len(gamma_m) < 5000:
            print(f"   ‚ö†Ô∏è Pas assez de donn√©es, skip")
            continue

        # Les lags effectifs restent les m√™mes (on pr√©dit Œ≥‚Çô^(m) depuis Œ≥‚Çô‚Çã‚Çñ^(m))
        # Mais la signification physique change: lag k √† l'√©chelle m = lag k√óm en z√©ros originaux

        # Analyser
        results = analyze_at_scale(gamma_m, lags, window_size=min(10000, len(gamma_m)//2))

        if not results:
            print(f"   ‚ö†Ô∏è Pas de r√©sultats")
            continue

        all_results[m] = results

        # Afficher les coefficients moyens
        avg_coeffs = {}
        for lag in lags:
            key = f'a_{lag}'
            values = [r['coefficients'][key] for r in results]
            avg_coeffs[key] = np.mean(values)
            std_coeffs = np.std(values)
            print(f"   <a_{lag}> = {avg_coeffs[key]:.4f} ¬± {std_coeffs:.4f}")

        avg_c = np.mean([r['c'] for r in results])
        print(f"   <c> = {avg_c:.4f}")

        # Calculer lag √ó coeff (devrait donner les invariants GIFT)
        print(f"\n   Produits lag √ó <a_lag>:")
        for lag in lags:
            prod = lag * avg_coeffs[f'a_{lag}']
            print(f"   {lag} √ó <a_{lag}> = {prod:.4f}")

    # ============================================================
    # TEST DE SUPERPOSITION (SCALING COLLAPSE)
    # ============================================================

    print("\n" + "="*70)
    print("TEST DE SUPERPOSITION (SCALING COLLAPSE)")
    print("="*70)

    if len(all_results) < 2:
        print("\n‚ö†Ô∏è Pas assez d'√©chelles pour tester la superposition")
        return

    # Pour chaque coefficient, v√©rifier si les courbes se superposent
    # apr√®s rescaling Œ≥ ‚Üí Œ≥/m

    print("\nüìä Coefficients moyens par √©chelle de d√©cimation")
    print(f"\n   {'m':<5}", end="")
    for lag in lags:
        print(f"{'a_'+str(lag):>12}", end="")
    print(f"{'c':>12}")
    print("   " + "-"*60)

    scale_data = {}
    for m in sorted(all_results.keys()):
        results = all_results[m]
        print(f"   {m:<5}", end="")
        scale_data[m] = {}
        for lag in lags:
            key = f'a_{lag}'
            avg = np.mean([r['coefficients'][key] for r in results])
            scale_data[m][key] = avg
            print(f"{avg:>12.4f}", end="")
        avg_c = np.mean([r['c'] for r in results])
        scale_data[m]['c'] = avg_c
        print(f"{avg_c:>12.4f}")

    # ============================================================
    # ANALYSE DU FLOW RG
    # ============================================================

    print("\n" + "="*70)
    print("FLOW RG: VARIATION DES COEFFICIENTS AVEC L'√âCHELLE")
    print("="*70)

    # Calculer les "Œ≤ effectifs" depuis la variation avec m
    # Si a(m) ~ m^(-Œ≤), alors Œ≤ = -d(log a)/d(log m)

    print("\nüìä Exposants de scaling (Œ≤ effectifs)")
    print("   Si a(m) ~ m^(-Œ≤), alors Œ≤ = -Œîlog(a)/Œîlog(m)")

    m_values = sorted(all_results.keys())
    if len(m_values) >= 2:
        print(f"\n   {'Coeff':<10} {'Œ≤_eff':>10} {'Interpr√©tation':>25}")
        print("   " + "-"*50)

        for lag in lags:
            key = f'a_{lag}'
            # R√©gression log-log
            log_m = np.log(m_values)
            log_a = np.log([abs(scale_data[m][key]) + 1e-10 for m in m_values])

            # Fit lin√©aire
            if len(log_m) >= 2:
                slope, intercept = np.polyfit(log_m, log_a, 1)
                beta_eff = -slope

                # Interpr√©tation
                interp = ""
                if abs(beta_eff) < 0.1:
                    interp = "~constant (point fixe)"
                elif abs(beta_eff - 1) < 0.2:
                    interp = "~1/m (marginal)"
                else:
                    interp = f"scaling non-trivial"

                print(f"   a_{lag:<6} {beta_eff:>10.3f} {interp:>25}")

    # ============================================================
    # TEST: LES INVARIANTS lag√óa SONT-ILS PRESERV√âS?
    # ============================================================

    print("\n" + "="*70)
    print("TEST: INVARIANTS lag √ó a SOUS D√âCIMATION")
    print("="*70)

    print(f"\n   {'m':<5} {'5√óa_5':>10} {'8√óa_8':>10} {'13√óa_13':>10} {'27√óa_27':>10}")
    print("   " + "-"*50)

    for m in sorted(all_results.keys()):
        print(f"   {m:<5}", end="")
        for lag in lags:
            prod = lag * scale_data[m][f'a_{lag}']
            print(f"{prod:>10.3f}", end="")
        print()

    # V√©rifier si 8√óa_8 ‚âà 13√óa_13 √† chaque √©chelle
    print(f"\n   V√©rification 8√óa_8 ‚âà 13√óa_13:")
    for m in sorted(all_results.keys()):
        prod_8 = 8 * scale_data[m]['a_8']
        prod_13 = 13 * scale_data[m]['a_13']
        diff = abs(prod_8 - prod_13)
        avg = (prod_8 + prod_13) / 2
        dev_pct = diff / avg * 100 if avg != 0 else 0
        status = "‚úì" if dev_pct < 5 else "‚úó"
        print(f"   m={m}: 8√óa_8={prod_8:.3f}, 13√óa_13={prod_13:.3f}, Œî={dev_pct:.1f}% {status}")

    # ============================================================
    # EXPORT
    # ============================================================

    output = {
        'decimation_analysis': {
            str(m): {
                'n_zeros': len(decimate(gammas, m)),
                'avg_coefficients': scale_data[m]
            }
            for m in all_results.keys()
        },
        'scaling_test': {
            'decimation_factors': list(all_results.keys()),
            'invariant_8_times_a8_equals_13_times_a13': {
                str(m): {
                    '8_times_a8': 8 * scale_data[m]['a_8'],
                    '13_times_a13': 13 * scale_data[m]['a_13'],
                    'deviation_pct': abs(8*scale_data[m]['a_8'] - 13*scale_data[m]['a_13']) /
                                    ((8*scale_data[m]['a_8'] + 13*scale_data[m]['a_13'])/2) * 100
                }
                for m in all_results.keys()
            }
        }
    }

    with open('phase28_rg_decimation.json', 'w') as f:
        json.dump(output, f, indent=2)

    print(f"\nüíæ R√©sultats sauvegard√©s dans phase28_rg_decimation.json")

if __name__ == "__main__":
    main()
