{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFT-Riemann Phase 1 : Hybrid Lags + Log-Correction\n",
    "\n",
    "## GPU-Accelerated Validation (CuPy/A100)\n",
    "\n",
    "Ce notebook impl√©mente les tests prioritaires identifi√©s par le conseil des IAs :\n",
    "\n",
    "### Tests Impl√©ment√©s\n",
    "\n",
    "| Test | Question | GPU Acceleration |\n",
    "|------|----------|------------------|\n",
    "| **1. Hybrid Lags** | [1,2,3,4] + GIFT lag optimal ? | Parallel search |\n",
    "| **2. Log-Correction** | a·µ¢(n) = a·µ¢^‚àû + b·µ¢/log(n) ? | Vectorized fitting |\n",
    "| **3. GIFT Asymptotic** | Limites ‚Üí constantes GIFT ? | Batch regression |\n",
    "| **4. Stability Map** | Coefficients par fen√™tre | Parallel windows |\n",
    "\n",
    "### Objectifs\n",
    "\n",
    "- Trouver la combinaison hybride optimale\n",
    "- V√©rifier si les coefficients convergent vers GIFT quand n‚Üí‚àû\n",
    "- Produire une carte de stabilit√© des coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation si n√©cessaire (Colab)\n",
    "# !pip install cupy-cuda12x  # Pour CUDA 12.x\n",
    "# !pip install cupy-cuda11x  # Pour CUDA 11.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "from itertools import combinations\n",
    "\n",
    "# GPU Setup\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.linalg import lstsq as cp_lstsq\n",
    "    GPU_AVAILABLE = True\n",
    "    print(f\"‚úÖ CuPy disponible - GPU: {cp.cuda.runtime.getDeviceCount()} device(s)\")\n",
    "    print(f\"   Device: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}\")\n",
    "    mempool = cp.get_default_memory_pool()\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  CuPy non disponible - fallback NumPy\")\n",
    "    cp = np\n",
    "\n",
    "# Adaptive backend\n",
    "xp = cp if GPU_AVAILABLE else np\n",
    "print(f\"\\nBackend: {'CuPy (GPU)' if GPU_AVAILABLE else 'NumPy (CPU)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des Z√©ros\n",
    "\n",
    "Uploadez vos fichiers de z√©ros (zeros1, zeros2, etc.) ou utilisez le file picker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zeros_from_files(file_paths: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Charge les z√©ros depuis plusieurs fichiers.\n",
    "    Supporte diff√©rents formats (une valeur par ligne).\n",
    "    \"\"\"\n",
    "    all_zeros = []\n",
    "    \n",
    "    for path in file_paths:\n",
    "        print(f\"Chargement: {path}\")\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    # Skip comments and headers\n",
    "                    if not line or line.startswith('#') or line.startswith('Values'):\n",
    "                        continue\n",
    "                    try:\n",
    "                        val = float(line.split()[0])  # Premier nombre de la ligne\n",
    "                        if val > 0:  # Z√©ros positifs uniquement\n",
    "                            all_zeros.append(val)\n",
    "                    except (ValueError, IndexError):\n",
    "                        continue\n",
    "            print(f\"  ‚Üí {len(all_zeros)} z√©ros cumul√©s\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  ‚ö†Ô∏è Fichier non trouv√©: {path}\")\n",
    "    \n",
    "    # Trier et d√©dupliquer\n",
    "    all_zeros = sorted(set(all_zeros))\n",
    "    return np.array(all_zeros)\n",
    "\n",
    "# Pour Colab: upload interactif\n",
    "def load_zeros_colab():\n",
    "    \"\"\"Upload interactif pour Google Colab.\"\"\"\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print(\"Uploadez vos fichiers de z√©ros...\")\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        all_zeros = []\n",
    "        for filename, content in uploaded.items():\n",
    "            print(f\"Traitement: {filename}\")\n",
    "            lines = content.decode('utf-8').split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    try:\n",
    "                        val = float(line.split()[0])\n",
    "                        if val > 0:\n",
    "                            all_zeros.append(val)\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        all_zeros = sorted(set(all_zeros))\n",
    "        print(f\"\\nTotal: {len(all_zeros)} z√©ros charg√©s\")\n",
    "        return np.array(all_zeros)\n",
    "    except ImportError:\n",
    "        print(\"Pas sur Colab - utilisez load_zeros_from_files()\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CHARGEMENT DES DONN√âES\n",
    "# ============================================================\n",
    "\n",
    "# Option 1: Fichiers locaux\n",
    "gamma_np = load_zeros_from_files(['zeros1'])  # Ajoutez vos fichiers ici\n",
    "\n",
    "# Option 2: Colab upload (d√©commenter)\n",
    "# gamma_np = load_zeros_colab()\n",
    "\n",
    "# Transfert GPU\n",
    "gamma = xp.asarray(gamma_np)\n",
    "N_ZEROS = len(gamma)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DONN√âES CHARG√âES\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Nombre de z√©ros: {N_ZEROS:,}\")\n",
    "print(f\"Plage: Œ≥‚ÇÅ = {float(gamma[0]):.4f} √† Œ≥_{N_ZEROS} = {float(gamma[-1]):.4f}\")\n",
    "print(f\"Stockage: {gamma.nbytes / 1e6:.2f} MB sur {'GPU' if GPU_AVAILABLE else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fonctions Utilitaires GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_spacing_vec(T: xp.ndarray) -> xp.ndarray:\n",
    "    \"\"\"\n",
    "    Espacement moyen local (vectoris√©).\n",
    "    Œî(T) ‚âà 2œÄ / log(T / 2œÄ)\n",
    "    \"\"\"\n",
    "    two_pi = 2 * xp.pi\n",
    "    safe_T = xp.maximum(T, two_pi + 1e-10)\n",
    "    return two_pi / xp.log(safe_T / two_pi)\n",
    "\n",
    "\n",
    "def fit_recurrence_gpu(gamma: xp.ndarray, lags: List[int], \n",
    "                       start: int = None, end: int = None) -> Tuple[xp.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Fit r√©currence lin√©aire sur GPU.\n",
    "    Œ≥‚Çô = Œ£·µ¢ a·µ¢ Œ≥‚Çô‚Çã‚Çó·µ¢ + c\n",
    "    \n",
    "    Returns: (coefficients, mean_rel_error_pct, mean_unfolded_error)\n",
    "    \"\"\"\n",
    "    max_lag = max(lags)\n",
    "    if start is None:\n",
    "        start = max_lag\n",
    "    if end is None:\n",
    "        end = len(gamma)\n",
    "    \n",
    "    n_points = end - start\n",
    "    n_params = len(lags) + 1  # +1 pour constante\n",
    "    \n",
    "    # Construction matricielle vectoris√©e\n",
    "    indices = xp.arange(start, end)\n",
    "    \n",
    "    # X matrix: chaque colonne = gamma[n - lag] pour chaque lag\n",
    "    X = xp.zeros((n_points, n_params), dtype=xp.float64)\n",
    "    for i, lag in enumerate(lags):\n",
    "        X[:, i] = gamma[indices - lag]\n",
    "    X[:, -1] = 1.0  # Colonne constante\n",
    "    \n",
    "    # y vector\n",
    "    y = gamma[indices]\n",
    "    \n",
    "    # Least squares (GPU ou CPU)\n",
    "    if GPU_AVAILABLE:\n",
    "        # CuPy lstsq\n",
    "        coeffs, residuals, rank, s = xp.linalg.lstsq(X, y, rcond=None)\n",
    "    else:\n",
    "        coeffs, residuals, rank, s = np.linalg.lstsq(X, y, rcond=None)\n",
    "    \n",
    "    # Pr√©dictions et erreurs\n",
    "    y_pred = X @ coeffs\n",
    "    errors_abs = xp.abs(y_pred - y)\n",
    "    errors_rel_pct = errors_abs / y * 100\n",
    "    \n",
    "    # Erreur unfolded\n",
    "    spacings = local_spacing_vec(y)\n",
    "    errors_unfolded = errors_abs / spacings\n",
    "    \n",
    "    mean_rel = float(xp.mean(errors_rel_pct))\n",
    "    mean_unf = float(xp.mean(errors_unfolded))\n",
    "    \n",
    "    return coeffs, mean_rel, mean_unf\n",
    "\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Lib√®re la m√©moire GPU.\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        mempool.free_all_blocks()\n",
    "        cp.cuda.Stream.null.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 1 : Recherche Hybride Optimale\n",
    "\n",
    "Tester toutes les combinaisons [1,2,3,4] + 1 lag GIFT suppl√©mentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hybrid_lags(gamma: xp.ndarray, base_lags: List[int] = [1, 2, 3, 4],\n",
    "                     additional_lags: List[int] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    TEST 1: Recherche de la combinaison hybride optimale.\n",
    "    \n",
    "    Teste: base_lags + chaque lag additionnel\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 1 : RECHERCHE HYBRIDE OPTIMALE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if additional_lags is None:\n",
    "        # Lags GIFT et voisins int√©ressants\n",
    "        additional_lags = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, \n",
    "                          20, 21, 22, 27, 28, 30, 35, 40]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Baseline: juste les lags de base\n",
    "    print(f\"\\nüìä Baseline {base_lags}...\")\n",
    "    coeffs_base, err_pct_base, err_unf_base = fit_recurrence_gpu(gamma, base_lags)\n",
    "    results.append({\n",
    "        'lags': base_lags.copy(),\n",
    "        'extra': None,\n",
    "        'error_pct': err_pct_base,\n",
    "        'error_unf': err_unf_base,\n",
    "        'coeffs': [float(c) for c in coeffs_base]\n",
    "    })\n",
    "    print(f\"   Erreur: {err_pct_base:.4f}% / {err_unf_base:.4f} spacings\")\n",
    "    \n",
    "    # Test avec chaque lag additionnel\n",
    "    print(f\"\\nüîç Test hybrides {base_lags} + [x]...\")\n",
    "    \n",
    "    for extra_lag in additional_lags:\n",
    "        if extra_lag in base_lags:\n",
    "            continue\n",
    "        \n",
    "        hybrid_lags = sorted(base_lags + [extra_lag])\n",
    "        \n",
    "        try:\n",
    "            coeffs, err_pct, err_unf = fit_recurrence_gpu(gamma, hybrid_lags)\n",
    "            \n",
    "            improvement = (err_unf_base - err_unf) / err_unf_base * 100\n",
    "            \n",
    "            results.append({\n",
    "                'lags': hybrid_lags,\n",
    "                'extra': extra_lag,\n",
    "                'error_pct': err_pct,\n",
    "                'error_unf': err_unf,\n",
    "                'improvement': improvement,\n",
    "                'coeffs': [float(c) for c in coeffs]\n",
    "            })\n",
    "            \n",
    "            status = \"‚òÖ\" if improvement > 5 else \"‚úì\" if improvement > 0 else \"\"\n",
    "            print(f\"   +[{extra_lag:2d}] ‚Üí {err_unf:.4f} spacings ({improvement:+.1f}%) {status}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   +[{extra_lag:2d}] ‚Üí Erreur: {e}\")\n",
    "    \n",
    "    # Test avec 2 lags additionnels (GIFT pairs)\n",
    "    print(f\"\\nüîç Test hybrides {base_lags} + [x, y]...\")\n",
    "    gift_pairs = [\n",
    "        [5, 8], [5, 13], [5, 27], [8, 13], [8, 14], [8, 21], [8, 27],\n",
    "        [13, 27], [14, 21], [14, 27], [21, 27]\n",
    "    ]\n",
    "    \n",
    "    for pair in gift_pairs:\n",
    "        hybrid_lags = sorted(base_lags + pair)\n",
    "        \n",
    "        try:\n",
    "            coeffs, err_pct, err_unf = fit_recurrence_gpu(gamma, hybrid_lags)\n",
    "            improvement = (err_unf_base - err_unf) / err_unf_base * 100\n",
    "            \n",
    "            results.append({\n",
    "                'lags': hybrid_lags,\n",
    "                'extra': pair,\n",
    "                'error_pct': err_pct,\n",
    "                'error_unf': err_unf,\n",
    "                'improvement': improvement,\n",
    "                'coeffs': [float(c) for c in coeffs]\n",
    "            })\n",
    "            \n",
    "            status = \"‚òÖ\" if improvement > 10 else \"‚úì\" if improvement > 0 else \"\"\n",
    "            print(f\"   +{pair} ‚Üí {err_unf:.4f} spacings ({improvement:+.1f}%) {status}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   +{pair} ‚Üí Erreur: {e}\")\n",
    "    \n",
    "    # Tri par erreur\n",
    "    results_sorted = sorted(results, key=lambda x: x['error_unf'])\n",
    "    \n",
    "    # Top 10\n",
    "    print(f\"\\nüèÜ TOP 10 COMBINAISONS:\")\n",
    "    print(f\"{'Rank':<5} {'Lags':<25} {'Err(%)':>10} {'Err(spac)':>12} {'Improv':>10}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for i, r in enumerate(results_sorted[:10]):\n",
    "        lags_str = str(r['lags'])\n",
    "        improv = r.get('improvement', 0)\n",
    "        print(f\"{i+1:<5} {lags_str:<25} {r['error_pct']:>10.4f} {r['error_unf']:>12.4f} {improv:>+10.1f}%\")\n",
    "    \n",
    "    # Meilleur r√©sultat\n",
    "    best = results_sorted[0]\n",
    "    print(f\"\\nüéØ MEILLEURE COMBINAISON: {best['lags']}\")\n",
    "    print(f\"   Erreur: {best['error_pct']:.4f}% / {best['error_unf']:.4f} spacings\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return {\n",
    "        'best': best,\n",
    "        'baseline': results[0],\n",
    "        'all_results': results_sorted\n",
    "    }\n",
    "\n",
    "# Ex√©cution\n",
    "hybrid_results = test_hybrid_lags(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 2 : Coefficients Log-D√©pendants\n",
    "\n",
    "Tester si a·µ¢(n) = a·µ¢^‚àû + b·µ¢/log(n) stabilise les coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_log_dependent_coefficients(gamma: xp.ndarray, \n",
    "                                     lags: List[int] = [5, 8, 13, 27],\n",
    "                                     n_windows: int = 20,\n",
    "                                     window_size: int = None) -> Dict:\n",
    "    \"\"\"\n",
    "    TEST 2: Analyse des coefficients par fen√™tres glissantes.\n",
    "    \n",
    "    V√©rifie si a·µ¢(n) = a·µ¢^‚àû + b·µ¢/log(n)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 2 : COEFFICIENTS LOG-D√âPENDANTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    N = len(gamma)\n",
    "    max_lag = max(lags)\n",
    "    \n",
    "    if window_size is None:\n",
    "        window_size = (N - max_lag) // n_windows\n",
    "    \n",
    "    print(f\"\\nüìä Configuration:\")\n",
    "    print(f\"   Lags: {lags}\")\n",
    "    print(f\"   Fen√™tres: {n_windows} √ó {window_size} points\")\n",
    "    \n",
    "    # Extraction des coefficients par fen√™tre\n",
    "    window_data = []\n",
    "    \n",
    "    print(f\"\\nüîÑ Extraction des coefficients par fen√™tre...\")\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        start = max_lag + i * window_size\n",
    "        end = start + window_size\n",
    "        \n",
    "        if end > N:\n",
    "            break\n",
    "        \n",
    "        # Indice central et gamma central\n",
    "        n_center = (start + end) // 2\n",
    "        gamma_center = float(gamma[n_center])\n",
    "        log_n = np.log(n_center)\n",
    "        \n",
    "        # Fit sur cette fen√™tre\n",
    "        coeffs, err_pct, err_unf = fit_recurrence_gpu(gamma, lags, start=start, end=end)\n",
    "        \n",
    "        window_data.append({\n",
    "            'window': i,\n",
    "            'n_center': n_center,\n",
    "            'gamma_center': gamma_center,\n",
    "            'log_n': log_n,\n",
    "            'inv_log_n': 1.0 / log_n,\n",
    "            'coeffs': [float(c) for c in coeffs],\n",
    "            'error_pct': err_pct,\n",
    "            'error_unf': err_unf\n",
    "        })\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(f\"   Fen√™tre {i+1}/{n_windows}: n={n_center}, err={err_unf:.4f} spac\")\n",
    "    \n",
    "    # Analyse: fit lin√©aire a·µ¢ vs 1/log(n)\n",
    "    print(f\"\\nüìà R√©gression a·µ¢(n) = a·µ¢^‚àû + b·µ¢/log(n)...\")\n",
    "    \n",
    "    inv_log_n = np.array([w['inv_log_n'] for w in window_data])\n",
    "    n_params = len(lags) + 1\n",
    "    \n",
    "    regression_results = []\n",
    "    \n",
    "    # GIFT theoretical values\n",
    "    gift_theory = {\n",
    "        5: 0.5,           # N_gen/h_G‚ÇÇ = 3/6\n",
    "        8: 56/99,         # fund(E‚Çá)/H*\n",
    "        13: -14/99,       # -dim(G‚ÇÇ)/H*\n",
    "        27: 1/27,         # 1/dim(J‚ÇÉùïÜ)\n",
    "        'c': 99/5         # H*/Weyl\n",
    "    }\n",
    "    \n",
    "    for j in range(n_params):\n",
    "        coeff_values = np.array([w['coeffs'][j] for w in window_data])\n",
    "        \n",
    "        # R√©gression lin√©aire: coeff = a_inf + b * (1/log(n))\n",
    "        X_reg = np.column_stack([np.ones_like(inv_log_n), inv_log_n])\n",
    "        params, residuals, rank, s = np.linalg.lstsq(X_reg, coeff_values, rcond=None)\n",
    "        \n",
    "        a_inf = params[0]  # Limite asymptotique\n",
    "        b = params[1]      # Correction log\n",
    "        \n",
    "        # R¬≤ score\n",
    "        y_pred = X_reg @ params\n",
    "        ss_res = np.sum((coeff_values - y_pred)**2)\n",
    "        ss_tot = np.sum((coeff_values - np.mean(coeff_values))**2)\n",
    "        r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "        \n",
    "        # Coefficient de variation\n",
    "        cv = np.std(coeff_values) / np.abs(np.mean(coeff_values)) * 100 if np.mean(coeff_values) != 0 else float('inf')\n",
    "        \n",
    "        # Comparaison GIFT\n",
    "        if j < len(lags):\n",
    "            lag = lags[j]\n",
    "            name = f\"a_{lag}\"\n",
    "            gift_val = gift_theory.get(lag, None)\n",
    "        else:\n",
    "            name = \"c\"\n",
    "            gift_val = gift_theory.get('c', None)\n",
    "        \n",
    "        gift_diff = abs(a_inf - gift_val) / abs(gift_val) * 100 if gift_val else None\n",
    "        \n",
    "        regression_results.append({\n",
    "            'name': name,\n",
    "            'a_inf': a_inf,\n",
    "            'b': b,\n",
    "            'r_squared': r_squared,\n",
    "            'cv_raw': cv,\n",
    "            'gift_theory': gift_val,\n",
    "            'gift_diff_pct': gift_diff,\n",
    "            'values': coeff_values.tolist()\n",
    "        })\n",
    "    \n",
    "    # Affichage\n",
    "    print(f\"\\n{'Coeff':<8} {'a_inf':>10} {'b':>10} {'R¬≤':>8} {'CV(%)':>8} {'GIFT':>10} {'√âcart':>10}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for r in regression_results:\n",
    "        gift_str = f\"{r['gift_theory']:.4f}\" if r['gift_theory'] else \"N/A\"\n",
    "        diff_str = f\"{r['gift_diff_pct']:.1f}%\" if r['gift_diff_pct'] else \"N/A\"\n",
    "        print(f\"{r['name']:<8} {r['a_inf']:>10.4f} {r['b']:>10.2f} {r['r_squared']:>8.3f} {r['cv_raw']:>8.1f} {gift_str:>10} {diff_str:>10}\")\n",
    "    \n",
    "    # Test de stabilisation\n",
    "    print(f\"\\nüéØ ANALYSE:\")\n",
    "    \n",
    "    high_r2 = sum(1 for r in regression_results if r['r_squared'] > 0.5)\n",
    "    close_to_gift = sum(1 for r in regression_results if r['gift_diff_pct'] and r['gift_diff_pct'] < 20)\n",
    "    \n",
    "    print(f\"   Coefficients avec R¬≤ > 0.5 (log-d√©pendance): {high_r2}/{len(regression_results)}\")\n",
    "    print(f\"   Coefficients proches GIFT (<20%): {close_to_gift}/{len(regression_results)}\")\n",
    "    \n",
    "    if high_r2 >= 3:\n",
    "        print(f\"\\n   ‚úÖ STRUCTURE LOG-D√âPENDANTE CONFIRM√âE\")\n",
    "        verdict = \"PASS\"\n",
    "    elif high_r2 >= 1:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  STRUCTURE PARTIELLE\")\n",
    "        verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"\\n   ‚ùå PAS DE STRUCTURE LOG-D√âPENDANTE CLAIRE\")\n",
    "        verdict = \"FAIL\"\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return {\n",
    "        'verdict': verdict,\n",
    "        'regression': regression_results,\n",
    "        'window_data': window_data,\n",
    "        'high_r2_count': high_r2,\n",
    "        'close_to_gift_count': close_to_gift\n",
    "    }\n",
    "\n",
    "# Ex√©cution\n",
    "log_results = test_log_dependent_coefficients(gamma, lags=[5, 8, 13, 27], n_windows=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 3 : Carte de Stabilit√© des Coefficients\n",
    "\n",
    "Visualisation de l'√©volution des coefficients sur toute la plage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stability_map(gamma: xp.ndarray, lags: List[int] = [5, 8, 13, 27],\n",
    "                  n_windows: int = 50) -> Dict:\n",
    "    \"\"\"\n",
    "    TEST 3: Carte de stabilit√© des coefficients.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 3 : CARTE DE STABILIT√â\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    N = len(gamma)\n",
    "    max_lag = max(lags)\n",
    "    window_size = (N - max_lag) // n_windows\n",
    "    \n",
    "    print(f\"\\nüìä Calcul de {n_windows} fen√™tres...\")\n",
    "    \n",
    "    stability_data = []\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        start = max_lag + i * window_size\n",
    "        end = start + window_size\n",
    "        \n",
    "        if end > N:\n",
    "            break\n",
    "        \n",
    "        coeffs, err_pct, err_unf = fit_recurrence_gpu(gamma, lags, start=start, end=end)\n",
    "        \n",
    "        stability_data.append({\n",
    "            'n_center': (start + end) // 2,\n",
    "            'coeffs': {f'a_{lag}': float(coeffs[j]) for j, lag in enumerate(lags)},\n",
    "            'c': float(coeffs[-1]),\n",
    "            'error_unf': err_unf\n",
    "        })\n",
    "    \n",
    "    # Statistiques de stabilit√©\n",
    "    print(f\"\\nüìà Statistiques de stabilit√©:\")\n",
    "    print(f\"{'Coeff':<8} {'Mean':>10} {'Std':>10} {'CV(%)':>10} {'Min':>10} {'Max':>10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    stability_stats = {}\n",
    "    \n",
    "    for j, lag in enumerate(lags):\n",
    "        key = f'a_{lag}'\n",
    "        values = [d['coeffs'][key] for d in stability_data]\n",
    "        mean = np.mean(values)\n",
    "        std = np.std(values)\n",
    "        cv = std / abs(mean) * 100 if mean != 0 else float('inf')\n",
    "        \n",
    "        stability_stats[key] = {\n",
    "            'mean': mean, 'std': std, 'cv': cv,\n",
    "            'min': min(values), 'max': max(values)\n",
    "        }\n",
    "        \n",
    "        print(f\"{key:<8} {mean:>10.4f} {std:>10.4f} {cv:>10.1f} {min(values):>10.4f} {max(values):>10.4f}\")\n",
    "    \n",
    "    # Constante\n",
    "    c_values = [d['c'] for d in stability_data]\n",
    "    mean_c = np.mean(c_values)\n",
    "    std_c = np.std(c_values)\n",
    "    cv_c = std_c / abs(mean_c) * 100 if mean_c != 0 else float('inf')\n",
    "    stability_stats['c'] = {'mean': mean_c, 'std': std_c, 'cv': cv_c}\n",
    "    print(f\"{'c':<8} {mean_c:>10.4f} {std_c:>10.4f} {cv_c:>10.1f} {min(c_values):>10.4f} {max(c_values):>10.4f}\")\n",
    "    \n",
    "    # Erreur moyenne\n",
    "    mean_err = np.mean([d['error_unf'] for d in stability_data])\n",
    "    print(f\"\\n   Erreur unfolded moyenne: {mean_err:.4f} spacings\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return {\n",
    "        'data': stability_data,\n",
    "        'stats': stability_stats\n",
    "    }\n",
    "\n",
    "# Ex√©cution\n",
    "stability_results = stability_map(gamma, lags=[5, 8, 13, 27], n_windows=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 4 : Comparaison GIFT Pure vs Hybride vs [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_all_approaches(gamma: xp.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    TEST 4: Comparaison compl√®te de toutes les approches.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 4 : COMPARAISON COMPL√àTE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    approaches = [\n",
    "        ([1, 2, 3, 4], \"Cons√©cutifs\"),\n",
    "        ([5, 8, 13, 27], \"GIFT Fibonacci\"),\n",
    "        ([3, 5, 8, 13], \"Fibonacci pur\"),\n",
    "        ([8, 14, 21, 27], \"GIFT constants\"),\n",
    "        ([1, 2, 3, 4, 8], \"Hybrid +8\"),\n",
    "        ([1, 2, 3, 4, 14], \"Hybrid +14\"),\n",
    "        ([1, 2, 3, 4, 21], \"Hybrid +21\"),\n",
    "        ([1, 2, 3, 4, 27], \"Hybrid +27\"),\n",
    "        ([1, 2, 3, 4, 8, 14], \"Hybrid +8+14\"),\n",
    "        ([1, 2, 3, 4, 8, 27], \"Hybrid +8+27\"),\n",
    "        ([1, 2, 3, 4, 5, 8, 13, 27], \"Full Hybrid\"),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(f\"\\n{'Approche':<20} {'Lags':<25} {'Err(%)':>10} {'Err(spac)':>12}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    for lags, name in approaches:\n",
    "        try:\n",
    "            coeffs, err_pct, err_unf = fit_recurrence_gpu(gamma, lags)\n",
    "            results.append({\n",
    "                'name': name,\n",
    "                'lags': lags,\n",
    "                'error_pct': err_pct,\n",
    "                'error_unf': err_unf,\n",
    "                'coeffs': [float(c) for c in coeffs]\n",
    "            })\n",
    "            print(f\"{name:<20} {str(lags):<25} {err_pct:>10.4f} {err_unf:>12.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"{name:<20} {str(lags):<25} {'ERROR':>10}\")\n",
    "    \n",
    "    # Classement\n",
    "    results_sorted = sorted(results, key=lambda x: x['error_unf'])\n",
    "    \n",
    "    print(f\"\\nüèÜ CLASSEMENT:\")\n",
    "    for i, r in enumerate(results_sorted[:5]):\n",
    "        print(f\"   {i+1}. {r['name']}: {r['error_unf']:.4f} spacings\")\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return {\n",
    "        'results': results_sorted,\n",
    "        'best': results_sorted[0]\n",
    "    }\n",
    "\n",
    "# Ex√©cution\n",
    "comparison_results = compare_all_approaches(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 5 : Train/Test avec Meilleure Combinaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_validation(gamma: xp.ndarray, lags: List[int], \n",
    "                          train_ratio: float = 0.5) -> Dict:\n",
    "    \"\"\"\n",
    "    TEST 5: Validation train/test avec coefficients gel√©s.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TEST 5 : TRAIN/TEST VALIDATION\")\n",
    "    print(f\"Lags: {lags}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    N = len(gamma)\n",
    "    max_lag = max(lags)\n",
    "    split = int(N * train_ratio)\n",
    "    \n",
    "    print(f\"\\nüìä Split:\")\n",
    "    print(f\"   TRAIN: n = {max_lag+1} √† {split} ({split - max_lag} points)\")\n",
    "    print(f\"   TEST:  n = {split+1} √† {N} ({N - split} points)\")\n",
    "    \n",
    "    # Fit sur TRAIN\n",
    "    coeffs_train, err_train_pct, err_train_unf = fit_recurrence_gpu(\n",
    "        gamma, lags, start=max_lag, end=split\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüîß Coefficients (TRAIN):\")\n",
    "    for i, lag in enumerate(lags):\n",
    "        print(f\"   a_{lag} = {float(coeffs_train[i]):.6f}\")\n",
    "    print(f\"   c = {float(coeffs_train[-1]):.6f}\")\n",
    "    \n",
    "    # Test avec coefficients gel√©s\n",
    "    indices_test = xp.arange(split, N)\n",
    "    n_test = len(indices_test)\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    y_pred = xp.zeros(n_test)\n",
    "    for i, lag in enumerate(lags):\n",
    "        y_pred += coeffs_train[i] * gamma[indices_test - lag]\n",
    "    y_pred += coeffs_train[-1]\n",
    "    \n",
    "    y_true = gamma[indices_test]\n",
    "    errors_abs = xp.abs(y_pred - y_true)\n",
    "    spacings = local_spacing_vec(y_true)\n",
    "    errors_unf = errors_abs / spacings\n",
    "    \n",
    "    err_test_unf = float(xp.mean(errors_unf))\n",
    "    err_test_pct = float(xp.mean(errors_abs / y_true * 100))\n",
    "    \n",
    "    ratio = err_test_unf / err_train_unf\n",
    "    \n",
    "    print(f\"\\nüìà R√©sultats:\")\n",
    "    print(f\"   TRAIN: {err_train_unf:.4f} spacings\")\n",
    "    print(f\"   TEST:  {err_test_unf:.4f} spacings\")\n",
    "    print(f\"   Ratio: {ratio:.2f}x\")\n",
    "    \n",
    "    if ratio <= 1.5:\n",
    "        print(f\"\\nüéØ VERDICT: ‚úÖ PASS (ratio ‚â§ 1.5)\")\n",
    "        verdict = \"PASS\"\n",
    "    elif ratio <= 2.0:\n",
    "        print(f\"\\nüéØ VERDICT: ‚ö†Ô∏è MARGINAL (ratio ‚â§ 2.0)\")\n",
    "        verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"\\nüéØ VERDICT: ‚ùå FAIL (ratio > 2.0)\")\n",
    "        verdict = \"FAIL\"\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    return {\n",
    "        'verdict': verdict,\n",
    "        'train_error': err_train_unf,\n",
    "        'test_error': err_test_unf,\n",
    "        'ratio': ratio,\n",
    "        'coefficients': [float(c) for c in coeffs_train]\n",
    "    }\n",
    "\n",
    "# Ex√©cution avec la meilleure combinaison trouv√©e\n",
    "best_lags = comparison_results['best']['lags']\n",
    "print(f\"\\nValidation avec meilleure combinaison: {best_lags}\")\n",
    "traintest_results = train_test_validation(gamma, best_lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Synth√®se Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_synthesis(hybrid_res, log_res, stability_res, comparison_res, traintest_res):\n",
    "    \"\"\"\n",
    "    Synth√®se finale de tous les tests.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SYNTH√àSE PHASE 1 - GPU VALIDATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nüìä R√âSULTATS:\")\n",
    "    print(f\"\\n   1. HYBRID OPTIMAL: {hybrid_res['best']['lags']}\")\n",
    "    print(f\"      Erreur: {hybrid_res['best']['error_unf']:.4f} spacings\")\n",
    "    print(f\"      vs baseline [1,2,3,4]: {hybrid_res['baseline']['error_unf']:.4f} spacings\")\n",
    "    \n",
    "    print(f\"\\n   2. LOG-CORRECTION: {log_res['verdict']}\")\n",
    "    print(f\"      Coeffs avec R¬≤ > 0.5: {log_res['high_r2_count']}\")\n",
    "    print(f\"      Coeffs proches GIFT: {log_res['close_to_gift_count']}\")\n",
    "    \n",
    "    print(f\"\\n   3. COMPARAISON GLOBALE:\")\n",
    "    for i, r in enumerate(comparison_res['results'][:3]):\n",
    "        print(f\"      {i+1}. {r['name']}: {r['error_unf']:.4f} spacings\")\n",
    "    \n",
    "    print(f\"\\n   4. TRAIN/TEST: {traintest_res['verdict']}\")\n",
    "    print(f\"      Ratio: {traintest_res['ratio']:.2f}x\")\n",
    "    \n",
    "    # Export JSON\n",
    "    summary = {\n",
    "        'n_zeros': int(N_ZEROS),\n",
    "        'hybrid': {\n",
    "            'best_lags': hybrid_res['best']['lags'],\n",
    "            'best_error': hybrid_res['best']['error_unf'],\n",
    "            'baseline_error': hybrid_res['baseline']['error_unf']\n",
    "        },\n",
    "        'log_correction': {\n",
    "            'verdict': log_res['verdict'],\n",
    "            'high_r2_count': log_res['high_r2_count'],\n",
    "            'coefficients': log_res['regression']\n",
    "        },\n",
    "        'comparison': {\n",
    "            'ranking': [{'name': r['name'], 'error': r['error_unf']} \n",
    "                       for r in comparison_res['results'][:5]]\n",
    "        },\n",
    "        'train_test': {\n",
    "            'verdict': traintest_res['verdict'],\n",
    "            'ratio': traintest_res['ratio'],\n",
    "            'lags': best_lags\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"EXPORT JSON\")\n",
    "    print(\"=\"*70)\n",
    "    print(json.dumps(summary, indent=2, default=float))\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Synth√®se\n",
    "final_summary = final_synthesis(\n",
    "    hybrid_results, \n",
    "    log_results, \n",
    "    stability_results, \n",
    "    comparison_results,\n",
    "    traintest_results\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des r√©sultats\n",
    "with open('phase1_gpu_results.json', 'w') as f:\n",
    "    json.dump(final_summary, f, indent=2, default=float)\n",
    "print(\"\\nüíæ R√©sultats sauvegard√©s dans phase1_gpu_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Visualisations (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # 1. √âvolution des coefficients\n",
    "    ax1 = axes[0, 0]\n",
    "    for r in log_results['regression']:\n",
    "        n_centers = [w['n_center'] for w in log_results['window_data']]\n",
    "        ax1.plot(n_centers, r['values'], 'o-', label=r['name'], alpha=0.7)\n",
    "    ax1.set_xlabel('n (indice du z√©ro)')\n",
    "    ax1.set_ylabel('Valeur du coefficient')\n",
    "    ax1.set_title('√âvolution des coefficients par fen√™tre')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Coefficient vs 1/log(n)\n",
    "    ax2 = axes[0, 1]\n",
    "    for r in log_results['regression']:\n",
    "        inv_log_n = [w['inv_log_n'] for w in log_results['window_data']]\n",
    "        ax2.scatter(inv_log_n, r['values'], label=r['name'], alpha=0.7)\n",
    "        # Ligne de r√©gression\n",
    "        x_line = np.linspace(min(inv_log_n), max(inv_log_n), 100)\n",
    "        y_line = r['a_inf'] + r['b'] * x_line\n",
    "        ax2.plot(x_line, y_line, '--', alpha=0.5)\n",
    "    ax2.set_xlabel('1/log(n)')\n",
    "    ax2.set_ylabel('Coefficient')\n",
    "    ax2.set_title(f'R√©gression: a·µ¢(n) = a·µ¢‚àû + b·µ¢/log(n)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Comparaison des approches\n",
    "    ax3 = axes[1, 0]\n",
    "    names = [r['name'] for r in comparison_results['results']]\n",
    "    errors = [r['error_unf'] for r in comparison_results['results']]\n",
    "    colors = ['green' if e == min(errors) else 'steelblue' for e in errors]\n",
    "    ax3.barh(names, errors, color=colors)\n",
    "    ax3.set_xlabel('Erreur (spacings)')\n",
    "    ax3.set_title('Comparaison des approches')\n",
    "    ax3.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # 4. Stabilit√© par fen√™tre\n",
    "    ax4 = axes[1, 1]\n",
    "    n_centers = [d['n_center'] for d in stability_results['data']]\n",
    "    errors_unf = [d['error_unf'] for d in stability_results['data']]\n",
    "    ax4.plot(n_centers, errors_unf, 'o-', color='purple')\n",
    "    ax4.set_xlabel('n (indice central)')\n",
    "    ax4.set_ylabel('Erreur (spacings)')\n",
    "    ax4.set_title('Erreur par fen√™tre')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('phase1_gpu_visualization.png', dpi=150)\n",
    "    plt.show()\n",
    "    print(\"\\nüìä Visualisation sauvegard√©e dans phase1_gpu_visualization.png\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"matplotlib non disponible - visualisation ignor√©e\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
