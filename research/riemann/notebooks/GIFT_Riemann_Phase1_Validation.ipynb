{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFT-Riemann Phase 1 Validation\n",
    "\n",
    "## R√©ponse au Conseil des IAs\n",
    "\n",
    "Ce notebook impl√©mente les 4 tests critiques recommand√©s par le conseil (Opus, Gemini, Grok, Kimi, GPT).\n",
    "\n",
    "### Tests Impl√©ment√©s\n",
    "\n",
    "| Test | Question | M√©trique |\n",
    "|------|----------|----------|\n",
    "| **1. Unfolded Error** | Pr√©dit-on la structure fine ou juste la tendance? | Erreur en spacings |\n",
    "| **2. Detrending** | Le signal survit-il apr√®s retrait de l'asymptotique? | Erreur sur r√©sidus |\n",
    "| **3. Train/Test Gel√©** | G√©n√©ralisation hors √©chantillon? | Erreur test vs train |\n",
    "| **4. Sensibilit√© Lags** | Les lags Fibonacci sont-ils sp√©ciaux? | Comparaison erreurs |\n",
    "\n",
    "### Crit√®re de Succ√®s\n",
    "\n",
    "- **Test 1** : Erreur unfolded moyenne < 1 spacing (id√©alement < 0.5)\n",
    "- **Test 2** : Signal persiste apr√®s d√©trendage (erreur < baseline)\n",
    "- **Test 3** : Erreur test ‚â§ 1.5√ó erreur train\n",
    "- **Test 4** : Lags [5,8,13,27] significativement meilleurs que voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from typing import List, Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Phase 1 Validation - Conseil des IAs\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Donn√©es\n",
    "\n",
    "Charger les z√©ros de Riemann (fichier ZEROS.txt ou g√©n√©ration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tentative de chargement du fichier ZEROS.txt\n",
    "import os\n",
    "\n",
    "def load_zeros(filepath: str = None) -> np.ndarray:\n",
    "    \"\"\"Charge les z√©ros depuis fichier ou utilise les premiers connus.\"\"\"\n",
    "    \n",
    "    # Essayer plusieurs chemins possibles\n",
    "    possible_paths = [\n",
    "        filepath,\n",
    "        'ZEROS.txt',\n",
    "        '../ZEROS.txt',\n",
    "        '/content/ZEROS.txt',\n",
    "        'zeros.txt'\n",
    "    ]\n",
    "    \n",
    "    for path in possible_paths:\n",
    "        if path and os.path.exists(path):\n",
    "            print(f\"Chargement depuis {path}...\")\n",
    "            zeros = []\n",
    "            with open(path, 'r') as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line and not line.startswith('#'):\n",
    "                        try:\n",
    "                            zeros.append(float(line))\n",
    "                        except ValueError:\n",
    "                            continue\n",
    "            if zeros:\n",
    "                print(f\"Charg√© {len(zeros)} z√©ros\")\n",
    "                return np.array(zeros)\n",
    "    \n",
    "    # Fallback: premiers 1000 z√©ros (approximation haute pr√©cision)\n",
    "    print(\"Fichier non trouv√© - utilisation des z√©ros int√©gr√©s\")\n",
    "    print(\"Pour des r√©sultats complets, uploadez ZEROS.txt\")\n",
    "    \n",
    "    # Premiers 100 z√©ros avec haute pr√©cision (Odlyzko)\n",
    "    first_100 = [\n",
    "        14.134725141734693, 21.022039638771554, 25.010857580145688,\n",
    "        30.424876125859513, 32.935061587739189, 37.586178158825671,\n",
    "        40.918719012147495, 43.327073280914999, 48.005150881167159,\n",
    "        49.773832477672302, 52.970321477714460, 56.446247697063394,\n",
    "        59.347044002602353, 60.831778524609809, 65.112544048081606,\n",
    "        67.079810529494173, 69.546401711173979, 72.067157674481907,\n",
    "        75.704690699083933, 77.144840068874805, 79.337375020249367,\n",
    "        82.910380854086030, 84.735492980517050, 87.425274613125229,\n",
    "        88.809111207634465, 92.491899270558484, 94.651344040519848,\n",
    "        95.870634228245309, 98.831194218193692, 101.31785100573139,\n",
    "        103.72553804047833, 105.44662305232609, 107.16861118427640,\n",
    "        111.02953554316967, 111.87465917699263, 114.32022091545271,\n",
    "        116.22668032085755, 118.79078286597621, 121.37012500242064,\n",
    "        122.94682929355258, 124.25681855434576, 127.51668387959649,\n",
    "        129.57870419995605, 131.08768853093265, 133.49773720299758,\n",
    "        134.75650975337387, 138.11604205453344, 139.73620895212138,\n",
    "        141.12370740402112, 143.11184580762063, 146.00098248149497,\n",
    "        147.42276534331817, 150.05352042078194, 150.92525769811311,\n",
    "        153.02469388971455, 156.11290929488189, 157.59759166468790,\n",
    "        158.84998819298678, 161.18896413581623, 163.03070933026669,\n",
    "        165.53706943428540, 167.18443987337141, 169.09451541594776,\n",
    "        169.91197647941924, 173.41153673461777, 174.75419152717550,\n",
    "        176.44143402671451, 178.37740777581620, 179.91648402025142,\n",
    "        182.20707848436646, 184.87446784737076, 185.59878367569748,\n",
    "        187.22892258423594, 189.41615865188581, 192.02665636225166,\n",
    "        193.07972660984527, 195.26539667784402, 196.87648178679182,\n",
    "        198.01530951432770, 201.26475194370426, 202.49359427372137,\n",
    "        204.18967180042432, 205.39469720895602, 207.90625898483556,\n",
    "        209.57650984378520, 211.69086259334878, 213.34791926879517,\n",
    "        214.54704478344582, 216.16953848996527, 219.06759635319410,\n",
    "        220.71491881384926, 221.43070552767637, 224.00700025498247,\n",
    "        224.98325235953609, 227.42144502665364, 229.33741330917844,\n",
    "        231.25018870093929, 231.98715902637730, 233.69340417045408,\n",
    "        236.52422966581694\n",
    "    ]\n",
    "    return np.array(first_100)\n",
    "\n",
    "gamma = load_zeros()\n",
    "N_zeros = len(gamma)\n",
    "print(f\"\\nPlage: Œ≥‚ÇÅ = {gamma[0]:.4f} √† Œ≥_{N_zeros} = {gamma[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions Utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_spacing(T: float) -> float:\n",
    "    \"\"\"\n",
    "    Espacement moyen local entre z√©ros √† hauteur T.\n",
    "    Œî(T) ‚âà 2œÄ / log(T / 2œÄ)\n",
    "    \n",
    "    Ref: Montgomery pair correlation, Odlyzko\n",
    "    \"\"\"\n",
    "    if T <= 2 * np.pi:\n",
    "        return 1.0  # Fallback pour petits T\n",
    "    return 2 * np.pi / np.log(T / (2 * np.pi))\n",
    "\n",
    "\n",
    "def riemann_asymptotic(n: int) -> float:\n",
    "    \"\"\"\n",
    "    Approximation asymptotique de Œ≥‚Çô via Riemann-von Mangoldt.\n",
    "    \n",
    "    N(T) ‚âà (T/2œÄ) log(T/2œÄ) - T/2œÄ + 7/8\n",
    "    \n",
    "    Inversion: Œ≥‚Çô ‚âà 2œÄn / log(n) pour grands n\n",
    "    Correction: Œ≥‚Çô ‚âà 2œÄn / W(n/e) o√π W = Lambert W\n",
    "    \"\"\"\n",
    "    if n <= 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Approximation de Lambert W via it√©ration\n",
    "    # W(x) ‚âà log(x) - log(log(x)) pour grand x\n",
    "    x = n / np.e\n",
    "    if x < 1:\n",
    "        return 2 * np.pi * n / max(np.log(n + 1), 1)\n",
    "    \n",
    "    w = np.log(x)\n",
    "    if w > 1:\n",
    "        w = w - np.log(w)\n",
    "    \n",
    "    # Raffinement Newton (quelques it√©rations)\n",
    "    for _ in range(5):\n",
    "        ew = np.exp(w)\n",
    "        w = w - (w * ew - x) / (ew * (w + 1))\n",
    "    \n",
    "    return 2 * np.pi * n / w\n",
    "\n",
    "\n",
    "def fit_recurrence(gamma: np.ndarray, lags: List[int], \n",
    "                   start: int = None, end: int = None) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fit une r√©currence lin√©aire Œ≥‚Çô = Œ£·µ¢ a·µ¢ Œ≥‚Çô‚Çã‚Çó·µ¢ + c\n",
    "    \n",
    "    Retourne: (coefficients, predictions, errors)\n",
    "    \"\"\"\n",
    "    max_lag = max(lags)\n",
    "    if start is None:\n",
    "        start = max_lag\n",
    "    if end is None:\n",
    "        end = len(gamma)\n",
    "    \n",
    "    # Construction matrice\n",
    "    X = []\n",
    "    y = []\n",
    "    indices = []\n",
    "    \n",
    "    for n in range(start, end):\n",
    "        row = [gamma[n - lag] for lag in lags] + [1.0]  # +1 pour constante\n",
    "        X.append(row)\n",
    "        y.append(gamma[n])\n",
    "        indices.append(n)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Least squares\n",
    "    coeffs, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = X @ coeffs\n",
    "    \n",
    "    return coeffs, y_pred, y, np.array(indices)\n",
    "\n",
    "\n",
    "# Test rapide\n",
    "print(f\"Spacing √† Œ≥‚ÇÅ‚ÇÄ‚ÇÄ ‚âà {gamma[99]:.1f}: Œî = {local_spacing(gamma[99]):.4f}\")\n",
    "print(f\"Asymptotique Œ≥‚ÇÅ‚ÇÄ‚ÇÄ th√©orique: {riemann_asymptotic(100):.2f}\")\n",
    "print(f\"Valeur r√©elle Œ≥‚ÇÅ‚ÇÄ‚ÇÄ: {gamma[99]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 1 : Erreur Unfolded (en Spacings)\n",
    "\n",
    "**Question** : Pr√©dit-on la structure fine ou juste la tendance lisse ?\n",
    "\n",
    "**M√©trique** : \n",
    "$$e_n = \\frac{\\hat{\\gamma}_n - \\gamma_n}{\\Delta(\\gamma_n)}$$\n",
    "\n",
    "o√π $\\Delta(T) \\approx \\frac{2\\pi}{\\log(T/2\\pi)}$ est l'espacement moyen local.\n",
    "\n",
    "**Crit√®re de succ√®s** : |e‚Çô| < 1 en moyenne (id√©alement < 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_unfolded_error(gamma: np.ndarray, lags: List[int] = [5, 8, 13, 27]):\n",
    "    \"\"\"\n",
    "    TEST 1: Calcule l'erreur en unit√©s d'espacement (unfolded).\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 1 : ERREUR UNFOLDED (en spacings)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    max_lag = max(lags)\n",
    "    if len(gamma) <= max_lag + 10:\n",
    "        print(f\"‚ö†Ô∏è  Pas assez de donn√©es (n={len(gamma)}, besoin > {max_lag + 10})\")\n",
    "        return None\n",
    "    \n",
    "    # Fit sur toutes les donn√©es disponibles\n",
    "    coeffs, y_pred, y_true, indices = fit_recurrence(gamma, lags)\n",
    "    \n",
    "    print(f\"\\nCoefficients fitt√©s (lags {lags}):\")\n",
    "    for i, lag in enumerate(lags):\n",
    "        print(f\"  a_{lag} = {coeffs[i]:.6f}\")\n",
    "    print(f\"  c = {coeffs[-1]:.6f}\")\n",
    "    \n",
    "    # Calcul erreurs\n",
    "    errors_abs = y_pred - y_true\n",
    "    errors_rel_pct = np.abs(errors_abs) / y_true * 100\n",
    "    \n",
    "    # Erreurs unfolded (en spacings)\n",
    "    spacings = np.array([local_spacing(g) for g in y_true])\n",
    "    errors_unfolded = np.abs(errors_abs) / spacings\n",
    "    \n",
    "    print(f\"\\nüìä Statistiques sur n={len(y_true)} points:\")\n",
    "    print(f\"\\n  Erreur relative (%) - ancienne m√©trique:\")\n",
    "    print(f\"    Moyenne: {np.mean(errors_rel_pct):.4f}%\")\n",
    "    print(f\"    M√©diane: {np.median(errors_rel_pct):.4f}%\")\n",
    "    \n",
    "    print(f\"\\n  Erreur UNFOLDED (spacings) - nouvelle m√©trique:\")\n",
    "    print(f\"    Moyenne: {np.mean(errors_unfolded):.4f} spacings\")\n",
    "    print(f\"    M√©diane: {np.median(errors_unfolded):.4f} spacings\")\n",
    "    print(f\"    Max: {np.max(errors_unfolded):.4f} spacings\")\n",
    "    print(f\"    Std: {np.std(errors_unfolded):.4f} spacings\")\n",
    "    \n",
    "    # Distribution par quantiles\n",
    "    print(f\"\\n  Distribution erreur unfolded:\")\n",
    "    for q in [50, 75, 90, 95, 99]:\n",
    "        val = np.percentile(errors_unfolded, q)\n",
    "        print(f\"    {q}th percentile: {val:.4f} spacings\")\n",
    "    \n",
    "    # Verdict\n",
    "    mean_unfolded = np.mean(errors_unfolded)\n",
    "    print(f\"\\nüéØ VERDICT TEST 1:\")\n",
    "    if mean_unfolded < 0.5:\n",
    "        print(f\"   ‚úÖ PASS (erreur moyenne = {mean_unfolded:.3f} < 0.5 spacings)\")\n",
    "        print(f\"   ‚Üí On pr√©dit la STRUCTURE FINE des z√©ros!\")\n",
    "        verdict = \"PASS\"\n",
    "    elif mean_unfolded < 1.0:\n",
    "        print(f\"   ‚ö†Ô∏è  MARGINAL (erreur moyenne = {mean_unfolded:.3f} < 1.0 spacing)\")\n",
    "        print(f\"   ‚Üí Pr√©diction √† ~1 z√©ro pr√®s en moyenne\")\n",
    "        verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"   ‚ùå FAIL (erreur moyenne = {mean_unfolded:.3f} > 1.0 spacing)\")\n",
    "        print(f\"   ‚Üí On pr√©dit surtout la TENDANCE, pas la structure fine\")\n",
    "        verdict = \"FAIL\"\n",
    "    \n",
    "    return {\n",
    "        'verdict': verdict,\n",
    "        'mean_unfolded': float(mean_unfolded),\n",
    "        'median_unfolded': float(np.median(errors_unfolded)),\n",
    "        'mean_pct': float(np.mean(errors_rel_pct)),\n",
    "        'coefficients': coeffs.tolist(),\n",
    "        'n_points': len(y_true)\n",
    "    }\n",
    "\n",
    "# Ex√©cution Test 1\n",
    "test1_results = test_unfolded_error(gamma, lags=[5, 8, 13, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 2 : D√©trendage (Signal vs Tendance)\n",
    "\n",
    "**Question** : Le signal survit-il apr√®s retrait de la tendance asymptotique ?\n",
    "\n",
    "**M√©thode** : \n",
    "1. Calculer $g(n) = $ approximation asymptotique de $\\gamma_n$\n",
    "2. D√©finir r√©sidus $r_n = \\gamma_n - g(n)$\n",
    "3. Fitter la r√©currence sur les r√©sidus\n",
    "4. Comparer √† une baseline (AR simple ou moyenne mobile)\n",
    "\n",
    "**Crit√®re** : Si l'erreur sur r√©sidus est significativement meilleure que baseline, le signal est r√©el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_detrending(gamma: np.ndarray, lags: List[int] = [5, 8, 13, 27]):\n",
    "    \"\"\"\n",
    "    TEST 2: Test si le signal persiste apr√®s d√©trendage.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 2 : D√âTRENDAGE (Signal vs Tendance)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_zeros = len(gamma)\n",
    "    max_lag = max(lags)\n",
    "    \n",
    "    if n_zeros <= max_lag + 10:\n",
    "        print(f\"‚ö†Ô∏è  Pas assez de donn√©es\")\n",
    "        return None\n",
    "    \n",
    "    # Calcul de la tendance asymptotique\n",
    "    trend = np.array([riemann_asymptotic(n+1) for n in range(n_zeros)])\n",
    "    residuals = gamma - trend\n",
    "    \n",
    "    print(f\"\\nüìà Tendance asymptotique:\")\n",
    "    print(f\"   Erreur tendance moyenne: {np.mean(np.abs(residuals)):.4f}\")\n",
    "    print(f\"   Erreur tendance relative: {np.mean(np.abs(residuals)/gamma)*100:.4f}%\")\n",
    "    \n",
    "    # Fit r√©currence sur r√©sidus\n",
    "    print(f\"\\nüîÑ Fit r√©currence sur R√âSIDUS (r‚Çô = Œ≥‚Çô - g(n)):\")\n",
    "    \n",
    "    coeffs_res, y_pred_res, y_true_res, indices = fit_recurrence(residuals, lags)\n",
    "    errors_res = np.abs(y_pred_res - y_true_res)\n",
    "    \n",
    "    print(f\"   Coefficients sur r√©sidus:\")\n",
    "    for i, lag in enumerate(lags):\n",
    "        print(f\"     a_{lag} = {coeffs_res[i]:.6f}\")\n",
    "    print(f\"     c = {coeffs_res[-1]:.6f}\")\n",
    "    \n",
    "    # Baseline 1: AR(1) simple sur r√©sidus\n",
    "    print(f\"\\nüìä Comparaison avec baselines:\")\n",
    "    \n",
    "    # AR(1): r‚Çô ‚âà Œ±¬∑r‚Çô‚Çã‚ÇÅ + c\n",
    "    coeffs_ar1, y_pred_ar1, y_true_ar1, _ = fit_recurrence(residuals, [1])\n",
    "    errors_ar1 = np.abs(y_pred_ar1 - y_true_ar1)\n",
    "    \n",
    "    # Moyenne mobile: r‚Çô ‚âà moyenne des k derniers\n",
    "    k = 5\n",
    "    y_pred_ma = []\n",
    "    y_true_ma = []\n",
    "    for n in range(k, n_zeros):\n",
    "        y_pred_ma.append(np.mean(residuals[n-k:n]))\n",
    "        y_true_ma.append(residuals[n])\n",
    "    errors_ma = np.abs(np.array(y_pred_ma) - np.array(y_true_ma))\n",
    "    \n",
    "    # Stats comparatives\n",
    "    mean_gift = np.mean(errors_res)\n",
    "    mean_ar1 = np.mean(errors_ar1)\n",
    "    mean_ma = np.mean(errors_ma)\n",
    "    \n",
    "    print(f\"\\n   Erreur moyenne absolue sur r√©sidus:\")\n",
    "    print(f\"     GIFT [5,8,13,27]: {mean_gift:.6f}\")\n",
    "    print(f\"     AR(1) baseline:   {mean_ar1:.6f}\")\n",
    "    print(f\"     MA(5) baseline:   {mean_ma:.6f}\")\n",
    "    \n",
    "    # Am√©lioration vs baselines\n",
    "    improv_ar1 = (mean_ar1 - mean_gift) / mean_ar1 * 100\n",
    "    improv_ma = (mean_ma - mean_gift) / mean_ma * 100\n",
    "    \n",
    "    print(f\"\\n   Am√©lioration GIFT vs baselines:\")\n",
    "    print(f\"     vs AR(1): {improv_ar1:+.2f}%\")\n",
    "    print(f\"     vs MA(5): {improv_ma:+.2f}%\")\n",
    "    \n",
    "    # Verdict\n",
    "    print(f\"\\nüéØ VERDICT TEST 2:\")\n",
    "    if improv_ar1 > 20 and improv_ma > 20:\n",
    "        print(f\"   ‚úÖ PASS - Signal significatif apr√®s d√©trendage\")\n",
    "        print(f\"   ‚Üí La r√©currence capture plus que la tendance lisse!\")\n",
    "        verdict = \"PASS\"\n",
    "    elif improv_ar1 > 10 or improv_ma > 10:\n",
    "        print(f\"   ‚ö†Ô∏è  MARGINAL - L√©g√®re am√©lioration vs baselines\")\n",
    "        verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"   ‚ùå FAIL - Pas d'am√©lioration significative\")\n",
    "        print(f\"   ‚Üí La r√©currence capture principalement la tendance\")\n",
    "        verdict = \"FAIL\"\n",
    "    \n",
    "    return {\n",
    "        'verdict': verdict,\n",
    "        'mean_error_gift': float(mean_gift),\n",
    "        'mean_error_ar1': float(mean_ar1),\n",
    "        'mean_error_ma': float(mean_ma),\n",
    "        'improvement_vs_ar1': float(improv_ar1),\n",
    "        'improvement_vs_ma': float(improv_ma)\n",
    "    }\n",
    "\n",
    "# Ex√©cution Test 2\n",
    "test2_results = test_detrending(gamma, lags=[5, 8, 13, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 3 : Train/Test Gel√© (G√©n√©ralisation)\n",
    "\n",
    "**Question** : Les coefficients g√©n√©ralisent-ils hors √©chantillon ?\n",
    "\n",
    "**M√©thode** :\n",
    "1. Fitter sur [max_lag, N/2] (TRAIN)\n",
    "2. **Geler** les coefficients\n",
    "3. Pr√©dire sur [N/2+1, N] (TEST)\n",
    "4. Comparer les erreurs\n",
    "\n",
    "**Crit√®re** : Erreur TEST ‚â§ 1.5√ó erreur TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_test_split(gamma: np.ndarray, lags: List[int] = [5, 8, 13, 27]):\n",
    "    \"\"\"\n",
    "    TEST 3: Validation train/test avec coefficients gel√©s.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 3 : TRAIN/TEST GEL√â (G√©n√©ralisation)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_zeros = len(gamma)\n",
    "    max_lag = max(lags)\n",
    "    \n",
    "    if n_zeros <= max_lag + 20:\n",
    "        print(f\"‚ö†Ô∏è  Pas assez de donn√©es pour split\")\n",
    "        return None\n",
    "    \n",
    "    # Split 50/50\n",
    "    split_idx = n_zeros // 2\n",
    "    \n",
    "    print(f\"\\nüìä Split des donn√©es:\")\n",
    "    print(f\"   TRAIN: n = {max_lag+1} √† {split_idx} ({split_idx - max_lag} points)\")\n",
    "    print(f\"   TEST:  n = {split_idx+1} √† {n_zeros} ({n_zeros - split_idx} points)\")\n",
    "    \n",
    "    # Fit sur TRAIN uniquement\n",
    "    coeffs_train, y_pred_train, y_true_train, _ = fit_recurrence(\n",
    "        gamma, lags, start=max_lag, end=split_idx\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüîß Coefficients (fit sur TRAIN seulement):\")\n",
    "    for i, lag in enumerate(lags):\n",
    "        print(f\"   a_{lag} = {coeffs_train[i]:.6f}\")\n",
    "    print(f\"   c = {coeffs_train[-1]:.6f}\")\n",
    "    \n",
    "    # Appliquer coefficients gel√©s sur TEST\n",
    "    y_pred_test = []\n",
    "    y_true_test = []\n",
    "    \n",
    "    for n in range(split_idx, n_zeros):\n",
    "        pred = sum(coeffs_train[i] * gamma[n - lag] for i, lag in enumerate(lags))\n",
    "        pred += coeffs_train[-1]  # constante\n",
    "        y_pred_test.append(pred)\n",
    "        y_true_test.append(gamma[n])\n",
    "    \n",
    "    y_pred_test = np.array(y_pred_test)\n",
    "    y_true_test = np.array(y_true_test)\n",
    "    \n",
    "    # Erreurs relatives\n",
    "    errors_train_pct = np.abs(y_pred_train - y_true_train) / y_true_train * 100\n",
    "    errors_test_pct = np.abs(y_pred_test - y_true_test) / y_true_test * 100\n",
    "    \n",
    "    # Erreurs unfolded\n",
    "    spacings_train = np.array([local_spacing(g) for g in y_true_train])\n",
    "    spacings_test = np.array([local_spacing(g) for g in y_true_test])\n",
    "    \n",
    "    errors_train_unf = np.abs(y_pred_train - y_true_train) / spacings_train\n",
    "    errors_test_unf = np.abs(y_pred_test - y_true_test) / spacings_test\n",
    "    \n",
    "    print(f\"\\nüìà R√©sultats:\")\n",
    "    print(f\"\\n   Erreur relative (%):\")\n",
    "    print(f\"     TRAIN: {np.mean(errors_train_pct):.4f}%\")\n",
    "    print(f\"     TEST:  {np.mean(errors_test_pct):.4f}%\")\n",
    "    print(f\"     Ratio TEST/TRAIN: {np.mean(errors_test_pct)/np.mean(errors_train_pct):.2f}x\")\n",
    "    \n",
    "    print(f\"\\n   Erreur unfolded (spacings):\")\n",
    "    print(f\"     TRAIN: {np.mean(errors_train_unf):.4f}\")\n",
    "    print(f\"     TEST:  {np.mean(errors_test_unf):.4f}\")\n",
    "    ratio_unf = np.mean(errors_test_unf) / np.mean(errors_train_unf)\n",
    "    print(f\"     Ratio TEST/TRAIN: {ratio_unf:.2f}x\")\n",
    "    \n",
    "    # Verdict\n",
    "    print(f\"\\nüéØ VERDICT TEST 3:\")\n",
    "    if ratio_unf <= 1.5:\n",
    "        print(f\"   ‚úÖ PASS (ratio = {ratio_unf:.2f} ‚â§ 1.5)\")\n",
    "        print(f\"   ‚Üí Bonne g√©n√©ralisation hors √©chantillon!\")\n",
    "        verdict = \"PASS\"\n",
    "    elif ratio_unf <= 2.0:\n",
    "        print(f\"   ‚ö†Ô∏è  MARGINAL (ratio = {ratio_unf:.2f} ‚â§ 2.0)\")\n",
    "        verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"   ‚ùå FAIL (ratio = {ratio_unf:.2f} > 2.0)\")\n",
    "        print(f\"   ‚Üí Overfitting probable\")\n",
    "        verdict = \"FAIL\"\n",
    "    \n",
    "    return {\n",
    "        'verdict': verdict,\n",
    "        'train_error_pct': float(np.mean(errors_train_pct)),\n",
    "        'test_error_pct': float(np.mean(errors_test_pct)),\n",
    "        'train_error_unf': float(np.mean(errors_train_unf)),\n",
    "        'test_error_unf': float(np.mean(errors_test_unf)),\n",
    "        'ratio': float(ratio_unf),\n",
    "        'coefficients_frozen': coeffs_train.tolist()\n",
    "    }\n",
    "\n",
    "# Ex√©cution Test 3\n",
    "test3_results = test_train_test_split(gamma, lags=[5, 8, 13, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# TEST 4 : Sensibilit√© aux Lags (Structure Fibonacci)\n",
    "\n",
    "**Question** : Les lags [5,8,13,27] sont-ils vraiment sp√©ciaux ?\n",
    "\n",
    "**M√©thode** :\n",
    "1. Tester des lags voisins (¬±1 sur chaque composante)\n",
    "2. Tester des lags arithm√©tiques et al√©atoires\n",
    "3. Comparer les erreurs\n",
    "\n",
    "**Crit√®re** : Lags Fibonacci doivent √™tre significativement meilleurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lag_sensitivity(gamma: np.ndarray, reference_lags: List[int] = [5, 8, 13, 27]):\n",
    "    \"\"\"\n",
    "    TEST 4: Test de sensibilit√© aux lags.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST 4 : SENSIBILIT√â AUX LAGS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    n_zeros = len(gamma)\n",
    "    max_lag = max(reference_lags)\n",
    "    \n",
    "    if n_zeros <= max_lag + 10:\n",
    "        print(f\"‚ö†Ô∏è  Pas assez de donn√©es\")\n",
    "        return None\n",
    "    \n",
    "    def get_error(lags: List[int]) -> float:\n",
    "        \"\"\"Retourne l'erreur unfolded moyenne pour des lags donn√©s.\"\"\"\n",
    "        try:\n",
    "            max_l = max(lags)\n",
    "            if max_l >= n_zeros - 5:\n",
    "                return float('inf')\n",
    "            coeffs, y_pred, y_true, _ = fit_recurrence(gamma, lags)\n",
    "            spacings = np.array([local_spacing(g) for g in y_true])\n",
    "            errors = np.abs(y_pred - y_true) / spacings\n",
    "            return np.mean(errors)\n",
    "        except:\n",
    "            return float('inf')\n",
    "    \n",
    "    # Erreur de r√©f√©rence (Fibonacci)\n",
    "    error_ref = get_error(reference_lags)\n",
    "    print(f\"\\nüìä R√©f√©rence GIFT [5,8,13,27]: {error_ref:.6f} spacings\")\n",
    "    print(f\"   Propri√©t√©s: 5+8=13 ‚úì, 5√ó8-13=27 ‚úì\")\n",
    "    \n",
    "    # Test 4a: Lags voisins (perturbation ¬±1)\n",
    "    print(f\"\\nüîç Test 4a: Lags voisins (perturbation ¬±1)\")\n",
    "    neighbor_tests = [\n",
    "        [4, 8, 13, 27],  # -1 sur 5\n",
    "        [6, 8, 13, 27],  # +1 sur 5\n",
    "        [5, 7, 13, 27],  # -1 sur 8\n",
    "        [5, 9, 13, 27],  # +1 sur 8\n",
    "        [5, 8, 12, 27],  # -1 sur 13\n",
    "        [5, 8, 14, 27],  # +1 sur 13 (14 = dim(G‚ÇÇ)!)\n",
    "        [5, 8, 13, 26],  # -1 sur 27\n",
    "        [5, 8, 13, 28],  # +1 sur 27\n",
    "    ]\n",
    "    \n",
    "    neighbor_errors = []\n",
    "    for lags in neighbor_tests:\n",
    "        err = get_error(lags)\n",
    "        neighbor_errors.append(err)\n",
    "        status = \"‚úì\" if err > error_ref else \"‚úó\"\n",
    "        fib_check = \"\" \n",
    "        if lags[0] + lags[1] == lags[2]:\n",
    "            fib_check += f\" ({lags[0]}+{lags[1]}={lags[2]})\"\n",
    "        print(f\"   {lags}: {err:.6f} {status}{fib_check}\")\n",
    "    \n",
    "    # Test 4b: Lags alternatifs structur√©s\n",
    "    print(f\"\\nüîç Test 4b: Lags alternatifs structur√©s\")\n",
    "    alt_tests = [\n",
    "        ([3, 5, 8, 13], \"Fibonacci pur\"),\n",
    "        ([5, 8, 13, 21], \"Fibonacci √©tendu (21=b‚ÇÇ)\"),\n",
    "        ([7, 14, 21, 28], \"Multiples de 7 (dim K‚Çá)\"),\n",
    "        ([8, 14, 21, 27], \"GIFT: rank(E‚Çà), dim(G‚ÇÇ), b‚ÇÇ, J‚ÇÉùïÜ\"),\n",
    "        ([5, 10, 15, 20], \"Arithm√©tique (pas=5)\"),\n",
    "        ([4, 8, 12, 16], \"Puissances de 2 √ó\"),\n",
    "    ]\n",
    "    \n",
    "    alt_errors = []\n",
    "    for lags, desc in alt_tests:\n",
    "        if max(lags) < n_zeros - 5:\n",
    "            err = get_error(lags)\n",
    "            alt_errors.append((lags, err, desc))\n",
    "            status = \"‚úì\" if err > error_ref else \"‚òÖ\"\n",
    "            print(f\"   {lags} ({desc}): {err:.6f} {status}\")\n",
    "    \n",
    "    # Test 4c: Lags al√©atoires (baseline)\n",
    "    print(f\"\\nüîç Test 4c: 20 sets de lags al√©atoires\")\n",
    "    np.random.seed(42)\n",
    "    random_errors = []\n",
    "    for i in range(20):\n",
    "        rand_lags = sorted(np.random.choice(range(3, min(30, n_zeros-5)), 4, replace=False).tolist())\n",
    "        err = get_error(rand_lags)\n",
    "        random_errors.append(err)\n",
    "    \n",
    "    print(f\"   Erreur moyenne random: {np.mean(random_errors):.6f}\")\n",
    "    print(f\"   Erreur min random: {np.min(random_errors):.6f}\")\n",
    "    print(f\"   Erreur max random: {np.max(random_errors):.6f}\")\n",
    "    \n",
    "    # Analyse\n",
    "    print(f\"\\nüìà Analyse:\")\n",
    "    \n",
    "    n_neighbors_worse = sum(1 for e in neighbor_errors if e > error_ref)\n",
    "    print(f\"   Voisins pires que [5,8,13,27]: {n_neighbors_worse}/{len(neighbor_errors)}\")\n",
    "    \n",
    "    percentile = sum(1 for e in random_errors if e > error_ref) / len(random_errors) * 100\n",
    "    print(f\"   Percentile vs random: {percentile:.1f}%\")\n",
    "    \n",
    "    # Trouver si un autre set est meilleur\n",
    "    all_tested = [(reference_lags, error_ref, \"GIFT Fibonacci\")]\n",
    "    all_tested.extend([(neighbor_tests[i], neighbor_errors[i], f\"Voisin #{i+1}\") \n",
    "                       for i in range(len(neighbor_tests))])\n",
    "    all_tested.extend(alt_errors)\n",
    "    \n",
    "    best = min(all_tested, key=lambda x: x[1])\n",
    "    print(f\"\\n   üèÜ Meilleur set trouv√©: {best[0]} ({best[2]})\")\n",
    "    print(f\"      Erreur: {best[1]:.6f}\")\n",
    "    \n",
    "    # Verdict\n",
    "    print(f\"\\nüéØ VERDICT TEST 4:\")\n",
    "    \n",
    "    is_best = (best[0] == reference_lags)\n",
    "    neighbors_stable = n_neighbors_worse >= 6  # Au moins 6/8 voisins pires\n",
    "    beats_random = percentile >= 80\n",
    "    \n",
    "    if is_best and neighbors_stable:\n",
    "        print(f\"   ‚úÖ PASS - [5,8,13,27] est optimal et stable\")\n",
    "        print(f\"   ‚Üí Structure Fibonacci confirm√©e!\")\n",
    "        verdict = \"PASS\"\n",
    "    elif neighbors_stable or beats_random:\n",
    "        print(f\"   ‚ö†Ô∏è  MARGINAL - Lags bons mais pas uniques\")\n",
    "        if not is_best:\n",
    "            print(f\"   ‚Üí {best[0]} est l√©g√®rement meilleur\")\n",
    "        verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"   ‚ùå FAIL - Lags [5,8,13,27] pas sp√©ciaux\")\n",
    "        verdict = \"FAIL\"\n",
    "    \n",
    "    return {\n",
    "        'verdict': verdict,\n",
    "        'reference_error': float(error_ref),\n",
    "        'neighbors_worse_count': n_neighbors_worse,\n",
    "        'percentile_vs_random': float(percentile),\n",
    "        'best_lags': best[0],\n",
    "        'best_error': float(best[1]),\n",
    "        'best_description': best[2]\n",
    "    }\n",
    "\n",
    "# Ex√©cution Test 4\n",
    "test4_results = test_lag_sensitivity(gamma, reference_lags=[5, 8, 13, 27])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Synth√®se des 4 Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_synthesis(test1, test2, test3, test4):\n",
    "    \"\"\"\n",
    "    Synth√®se finale des 4 tests.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SYNTH√àSE PHASE 1 - VALIDATION CONSEIL IAs\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    tests = [\n",
    "        (\"Test 1: Erreur Unfolded\", test1),\n",
    "        (\"Test 2: D√©trendage\", test2),\n",
    "        (\"Test 3: Train/Test Gel√©\", test3),\n",
    "        (\"Test 4: Sensibilit√© Lags\", test4),\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    print(\"\\nüìã R√©sultats:\")\n",
    "    print()\n",
    "    \n",
    "    for name, result in tests:\n",
    "        if result is None:\n",
    "            verdict = \"SKIP\"\n",
    "            icon = \"‚è≠Ô∏è\"\n",
    "        else:\n",
    "            verdict = result.get('verdict', 'UNKNOWN')\n",
    "            icon = {\"PASS\": \"‚úÖ\", \"MARGINAL\": \"‚ö†Ô∏è\", \"FAIL\": \"‚ùå\"}.get(verdict, \"‚ùì\")\n",
    "        \n",
    "        results.append(verdict)\n",
    "        print(f\"   {icon} {name}: {verdict}\")\n",
    "    \n",
    "    # Comptage\n",
    "    n_pass = results.count(\"PASS\")\n",
    "    n_marginal = results.count(\"MARGINAL\")\n",
    "    n_fail = results.count(\"FAIL\")\n",
    "    n_skip = results.count(\"SKIP\")\n",
    "    \n",
    "    print(f\"\\nüìä Score: {n_pass} PASS, {n_marginal} MARGINAL, {n_fail} FAIL, {n_skip} SKIP\")\n",
    "    \n",
    "    # Verdict global\n",
    "    print(f\"\\n\" + \"=\"*60)\n",
    "    print(\"VERDICT GLOBAL\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if n_pass >= 3:\n",
    "        print(\"\\nüèÜ VALIDATION FORTE\")\n",
    "        print(\"   La r√©currence GIFT-Riemann passe les tests critiques.\")\n",
    "        print(\"   ‚Üí Pr√™t pour Phase 2 (th√©orie)\")\n",
    "        global_verdict = \"STRONG\"\n",
    "    elif n_pass >= 2 and n_fail == 0:\n",
    "        print(\"\\n‚úÖ VALIDATION MOD√âR√âE\")\n",
    "        print(\"   Signal r√©el d√©tect√©, mais avec r√©serves.\")\n",
    "        print(\"   ‚Üí Investigation suppl√©mentaire recommand√©e\")\n",
    "        global_verdict = \"MODERATE\"\n",
    "    elif n_pass >= 1 and n_fail <= 1:\n",
    "        print(\"\\n‚ö†Ô∏è  VALIDATION FAIBLE\")\n",
    "        print(\"   R√©sultats mitig√©s - prudence requise.\")\n",
    "        global_verdict = \"WEAK\"\n",
    "    else:\n",
    "        print(\"\\n‚ùå VALIDATION √âCHOU√âE\")\n",
    "        print(\"   La r√©currence ne passe pas les tests critiques.\")\n",
    "        print(\"   ‚Üí Probablement un artefact de fitting\")\n",
    "        global_verdict = \"FAILED\"\n",
    "    \n",
    "    # Recommandations\n",
    "    print(f\"\\nüìù Recommandations:\")\n",
    "    \n",
    "    if test1 and test1.get('verdict') != 'PASS':\n",
    "        print(\"   ‚Ä¢ Test 1: Tester sur plus de donn√©es (LMFDB 10M+ z√©ros)\")\n",
    "    \n",
    "    if test2 and test2.get('verdict') != 'PASS':\n",
    "        print(\"   ‚Ä¢ Test 2: Explorer coefficients fonction de n: a·µ¢(n) = a·µ¢‚Å∞/log(n)\")\n",
    "    \n",
    "    if test3 and test3.get('verdict') != 'PASS':\n",
    "        print(\"   ‚Ä¢ Test 3: √âtendre le test set, utiliser cross-validation\")\n",
    "    \n",
    "    if test4 and test4.get('verdict') != 'PASS':\n",
    "        print(\"   ‚Ä¢ Test 4: Explorer r√©currence √† 5 termes (ajouter lag 14 ou 21)\")\n",
    "    \n",
    "    # Export r√©sultats\n",
    "    summary = {\n",
    "        'global_verdict': global_verdict,\n",
    "        'scores': {'pass': n_pass, 'marginal': n_marginal, 'fail': n_fail, 'skip': n_skip},\n",
    "        'test1': test1,\n",
    "        'test2': test2,\n",
    "        'test3': test3,\n",
    "        'test4': test4,\n",
    "        'n_zeros': int(len(gamma)),\n",
    "        'lags': [5, 8, 13, 27]\n",
    "    }\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Synth√®se finale\n",
    "summary = final_synthesis(test1_results, test2_results, test3_results, test4_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export JSON pour analyse ult√©rieure\n",
    "import json\n",
    "\n",
    "def convert_to_serializable(obj):\n",
    "    \"\"\"Convertit les types numpy en types Python natifs.\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_to_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_to_serializable(v) for v in obj]\n",
    "    elif isinstance(obj, (np.integer, np.floating)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "summary_clean = convert_to_serializable(summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXPORT JSON\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(summary_clean, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Notes pour Tests avec Donn√©es Compl√®tes\n",
    "\n",
    "## Comment obtenir plus de z√©ros\n",
    "\n",
    "1. **LMFDB** : https://www.lmfdb.org/zeros/zeta/ (jusqu'√† 10‚Åπ z√©ros)\n",
    "2. **Odlyzko** : Tables haute pr√©cision disponibles\n",
    "3. **mpmath** : `from mpmath import zetazero; zetazero(n)` (lent mais pr√©cis)\n",
    "\n",
    "## Prochaines √©tapes si validation passe\n",
    "\n",
    "1. **Phase 2a** : Coefficients fonction de n (stabilisation)\n",
    "2. **Phase 2b** : R√©currence 5-termes avec lag 14 ou 21\n",
    "3. **Phase 3** : Connexion trace formula (Weil explicit formula)\n",
    "4. **Phase 4** : PINN op√©rateur spectral"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
