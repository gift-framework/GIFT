{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFT Phase 3: Blind Challenge Validation\n",
    "\n",
    "**Purpose**: Rigorous validation following AI council recommendations\n",
    "\n",
    "## Protocol (Pre-registered)\n",
    "\n",
    "1. **Blind Challenge**: Pre-registered \"Primary + 2×Primary\" conductors vs controls\n",
    "2. **Null Grammars**: 100 alternative grammars of same complexity\n",
    "3. **A Priori Predictions**: Test specific predictions BEFORE seeing data\n",
    "4. **GPU Acceleration**: CuPy for Monte Carlo and bootstrap\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-Registered Predictions (LOCKED BEFORE COMPUTATION)\n",
    "\n",
    "### Prediction 1: Primary + 2×Primary conductors will outperform controls\n",
    "- **GIFT conductors**: q = 43, 49, 35, 31, 17, 38, 56\n",
    "- **Control conductors**: q = 23, 29, 37, 47, 53, 59, 61\n",
    "\n",
    "### Prediction 2: q = 42 will show special structure\n",
    "- If 42 is truly universal, L(s, χ₄₂) should show strong Fibonacci constraint\n",
    "\n",
    "### Prediction 3: GIFT grammar will beat 95%+ of null grammars\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Detect GPU and import accordingly\n",
    "# ============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Tuple, Optional, Set\n",
    "from dataclasses import dataclass\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# Try GPU (CuPy)\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy import sparse as cp_sparse\n",
    "    GPU_AVAILABLE = True\n",
    "    xp = cp  # Use CuPy as array library\n",
    "    print(f\"✓ GPU available: {cp.cuda.runtime.getDeviceCount()} device(s)\")\n",
    "    print(f\"  Device: {cp.cuda.Device().name}\")\n",
    "    print(f\"  Memory: {cp.cuda.Device().mem_info[1] / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    xp = np  # Fallback to NumPy\n",
    "    print(\"⚠ GPU not available, using CPU (NumPy)\")\n",
    "\n",
    "# mpmath for L-function computation (always CPU)\n",
    "import mpmath as mp\n",
    "mp.mp.dps = 25\n",
    "print(f\"✓ mpmath precision: {mp.mp.dps} digits\")\n",
    "\n",
    "# scipy for statistics\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: GIFT Constants and Grammars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# GIFT CONSTANTS (the \"atoms\" and \"primaries\")\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class GIFTConstants:\n",
    "    \"\"\"All GIFT topological constants.\"\"\"\n",
    "    # Atoms\n",
    "    p2: int = 2             # Pontryagin class\n",
    "    N_gen: int = 3          # Generations\n",
    "    dim_K7: int = 7         # K₇ dimension\n",
    "    D_bulk: int = 11        # Bulk dimension\n",
    "    \n",
    "    # Fibonacci primes (secondary atoms)\n",
    "    Weyl: int = 5           # F₅\n",
    "    F7: int = 13            # F₇\n",
    "    \n",
    "    # Primaries (products of atoms)\n",
    "    rank_E8: int = 8        # 2³\n",
    "    dim_G2: int = 14        # 2 × 7\n",
    "    b2: int = 21            # 3 × 7\n",
    "    dim_J3O: int = 27       # 3³\n",
    "    b3: int = 77            # 7 × 11\n",
    "    H_star: int = 99        # 3² × 11\n",
    "    \n",
    "    # Derived\n",
    "    chi_K7: int = 42        # 2 × 3 × 7\n",
    "    dim_E8: int = 248       # E₈ dimension\n",
    "    h_G2: int = 6           # Coxeter number\n",
    "\n",
    "GIFT = GIFTConstants()\n",
    "\n",
    "# Atoms and primaries as sets\n",
    "ATOMS = {2, 3, 7, 11}\n",
    "FIBONACCI_ATOMS = {5, 13}\n",
    "PRIMARIES = {8, 14, 21, 27, 77, 99}\n",
    "ALL_GIFT = ATOMS | FIBONACCI_ATOMS | PRIMARIES | {42, 248}\n",
    "\n",
    "print(f\"GIFT Atoms: {ATOMS}\")\n",
    "print(f\"Fibonacci Atoms: {FIBONACCI_ATOMS}\")\n",
    "print(f\"Primaries: {PRIMARIES}\")\n",
    "print(f\"All GIFT constants: {sorted(ALL_GIFT)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PRE-REGISTERED CONDUCTOR LISTS (LOCKED)\n",
    "# ============================================================================\n",
    "\n",
    "# Conductors following \"Primary + 2×Primary\" pattern\n",
    "GIFT_CONDUCTORS = {\n",
    "    # Primary + 2×Primary pattern\n",
    "    43: 'b₂ + 2×D_bulk = 21 + 22',\n",
    "    35: 'b₂ + 2×dim(K₇) = 21 + 14',\n",
    "    49: 'b₂ + 2×dim(G₂) = 21 + 28',\n",
    "    56: 'dim(G₂) + 2×b₂ = 14 + 42',\n",
    "    38: '2×(b₂ - 2) = 2×19 or dim(G₂) + 3×rank(E₈)',\n",
    "    31: 'N_gen + 2×dim(G₂) = 3 + 28',\n",
    "    \n",
    "    # Direct GIFT primes\n",
    "    5: 'Weyl (F₅)',\n",
    "    7: 'dim(K₇)',\n",
    "    11: 'D_bulk',\n",
    "    13: 'F₇',\n",
    "    \n",
    "    # Composites with GIFT meaning\n",
    "    17: 'dim(G₂) + N_gen = 14 + 3',\n",
    "    21: 'b₂ (Second Betti)',\n",
    "    77: 'b₃ (Third Betti)',\n",
    "    42: 'χ_K7 = 2×b₂ (THE 42 TEST)',\n",
    "}\n",
    "\n",
    "# Control conductors (no obvious GIFT decomposition)\n",
    "CONTROL_CONDUCTORS = {\n",
    "    23: 'Prime (no GIFT)',\n",
    "    29: 'Prime (no GIFT)',\n",
    "    37: 'Prime (no GIFT)',\n",
    "    47: 'Prime (no GIFT)',\n",
    "    53: 'Prime (no GIFT)',\n",
    "    59: 'Prime (no GIFT)',\n",
    "    61: 'Prime (no GIFT)',\n",
    "    67: 'Prime (no GIFT)',\n",
    "    71: 'Prime (no GIFT)',\n",
    "    73: 'Prime (no GIFT)',\n",
    "}\n",
    "\n",
    "# All conductors to test\n",
    "ALL_CONDUCTORS = {**GIFT_CONDUCTORS, **CONTROL_CONDUCTORS}\n",
    "\n",
    "print(f\"GIFT conductors ({len(GIFT_CONDUCTORS)}): {sorted(GIFT_CONDUCTORS.keys())}\")\n",
    "print(f\"Control conductors ({len(CONTROL_CONDUCTORS)}): {sorted(CONTROL_CONDUCTORS.keys())}\")\n",
    "print(f\"\\nTotal conductors to test: {len(ALL_CONDUCTORS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: L-Function Computation (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# L-FUNCTION COMPUTATION (mpmath, CPU only) - OPTIMIZED\n# ============================================================================\n\ndef legendre_symbol(a: int, p: int) -> int:\n    \"\"\"Compute Legendre symbol (a/p).\"\"\"\n    if a % p == 0:\n        return 0\n    result = pow(a % p, (p - 1) // 2, p)\n    return 1 if result == 1 else -1\n\n\ndef kronecker_symbol(a: int, n: int) -> int:\n    \"\"\"Compute Kronecker symbol (a/n) for general n.\"\"\"\n    if n == 1:\n        return 1\n    if n == 0:\n        return 1 if abs(a) == 1 else 0\n    \n    # Factor out powers of 2\n    v = 0\n    n_copy = abs(n)\n    while n_copy % 2 == 0:\n        v += 1\n        n_copy //= 2\n    \n    if v > 0:\n        if a % 2 == 0:\n            k2 = 0\n        else:\n            r = a % 8\n            k2 = 1 if r in [1, 7] else -1\n        k2 = k2 ** v\n    else:\n        k2 = 1\n    \n    if n_copy == 1:\n        return k2\n    \n    # Odd part via Legendre\n    return k2 * legendre_symbol(a, n_copy)\n\n\ndef dirichlet_L_function(s, q: int, terms: int = 8000):\n    \"\"\"Compute Dirichlet L-function L(s, χ_q) where χ is quadratic character.\"\"\"\n    result = mp.mpc(0)\n    for n in range(1, terms + 1):\n        if q == 2:\n            chi_n = 1 if n % 2 == 1 else 0\n        else:\n            chi_n = kronecker_symbol(n, q)\n        if chi_n != 0:\n            result += mp.mpc(chi_n) / mp.power(n, s)\n    return result\n\n\ndef find_zeros_dirichlet(q: int, num_zeros: int = 50, T_max: float = 90, \n                         step: float = 0.25, terms: int = 8000) -> List[float]:\n    \"\"\"Find zeros of L(1/2 + it, χ_q) by sign changes. OPTIMIZED VERSION.\"\"\"\n    zeros = []\n    t = 1.0\n    prev_val = dirichlet_L_function(mp.mpc(0.5, t), q, terms)\n    prev_sign = 1 if prev_val.real > 0 else -1\n    \n    while len(zeros) < num_zeros and t < T_max:\n        t += step\n        curr_val = dirichlet_L_function(mp.mpc(0.5, t), q, terms)\n        curr_sign = 1 if curr_val.real > 0 else -1\n        \n        if curr_sign != prev_sign and prev_sign != 0:\n            # Bisection to refine zero (15 iterations = sufficient precision)\n            t_low, t_high = t - step, t\n            for _ in range(15):\n                t_mid = (t_low + t_high) / 2\n                val_mid = dirichlet_L_function(mp.mpc(0.5, t_mid), q, terms)\n                sign_mid = 1 if val_mid.real > 0 else -1\n                val_low = dirichlet_L_function(mp.mpc(0.5, t_low), q, terms)\n                sign_low = 1 if val_low.real > 0 else -1\n                if sign_low != sign_mid:\n                    t_high = t_mid\n                else:\n                    t_low = t_mid\n            zero_t = (t_low + t_high) / 2\n            if not zeros or abs(zero_t - zeros[-1]) > 0.1:\n                zeros.append(zero_t)\n        \n        prev_val = curr_val\n        prev_sign = curr_sign\n    \n    return zeros\n\nprint(\"✓ L-function computation ready (OPTIMIZED: 8000 terms, 15 bisection iter)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Recurrence Analysis (GPU-accelerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RECURRENCE FITTING (GPU/CPU adaptive)\n",
    "# ============================================================================\n",
    "\n",
    "# GIFT lags (Fibonacci-based)\n",
    "GIFT_LAGS = [5, 8, 13, 21]\n",
    "\n",
    "def fit_recurrence(zeros: np.ndarray, lags: List[int] = GIFT_LAGS, \n",
    "                   use_gpu: bool = GPU_AVAILABLE) -> Tuple[Optional[np.ndarray], float, float]:\n",
    "    \"\"\"\n",
    "    Fit linear recurrence γ_n = Σ a_i × γ_{n-lag_i} + c.\n",
    "    \n",
    "    Returns: (coefficients, RMSE, R²)\n",
    "    \"\"\"\n",
    "    max_lag = max(lags)\n",
    "    n_points = len(zeros) - max_lag\n",
    "    \n",
    "    if n_points < 10:\n",
    "        return None, float('inf'), 0.0\n",
    "    \n",
    "    # Build design matrix\n",
    "    X = np.zeros((n_points, len(lags) + 1))\n",
    "    y = np.zeros(n_points)\n",
    "    \n",
    "    for i in range(n_points):\n",
    "        idx = i + max_lag\n",
    "        y[i] = zeros[idx]\n",
    "        for j, lag in enumerate(lags):\n",
    "            X[i, j] = zeros[idx - lag]\n",
    "        X[i, -1] = 1  # Constant term\n",
    "    \n",
    "    # Solve least squares\n",
    "    if use_gpu and GPU_AVAILABLE:\n",
    "        X_gpu = cp.asarray(X)\n",
    "        y_gpu = cp.asarray(y)\n",
    "        coeffs_gpu, _, _, _ = cp.linalg.lstsq(X_gpu, y_gpu, rcond=None)\n",
    "        coeffs = cp.asnumpy(coeffs_gpu)\n",
    "        y_pred = cp.asnumpy(X_gpu @ coeffs_gpu)\n",
    "    else:\n",
    "        coeffs, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n",
    "        y_pred = X @ coeffs\n",
    "    \n",
    "    # Compute metrics\n",
    "    rmse = float(np.sqrt(np.mean((y - y_pred)**2)))\n",
    "    ss_res = np.sum((y - y_pred)**2)\n",
    "    ss_tot = np.sum((y - np.mean(y))**2)\n",
    "    r2 = float(1 - ss_res / ss_tot) if ss_tot > 0 else 0.0\n",
    "    \n",
    "    return coeffs, rmse, r2\n",
    "\n",
    "\n",
    "def compute_fibonacci_ratio(coeffs: np.ndarray, lags: List[int] = GIFT_LAGS) -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Compute the Fibonacci constraint ratio R = (8×a₈)/(13×a₁₃).\n",
    "    Should be ≈ 1 if Fibonacci structure holds.\n",
    "    \"\"\"\n",
    "    if coeffs is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        idx_8 = lags.index(8)\n",
    "        idx_13 = lags.index(13)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    a8 = coeffs[idx_8]\n",
    "    a13 = coeffs[idx_13]\n",
    "    \n",
    "    if abs(a13) < 1e-10:\n",
    "        return None\n",
    "    \n",
    "    return float((8 * a8) / (13 * a13))\n",
    "\n",
    "\n",
    "print(f\"✓ Recurrence fitting ready (GPU: {GPU_AVAILABLE})\")\n",
    "print(f\"  GIFT lags: {GIFT_LAGS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Null Grammar Generation (GPU-accelerated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NULL GRAMMAR TESTING\n",
    "# ============================================================================\n",
    "\n",
    "def generate_null_grammar(seed: int = None) -> Tuple[Set[int], Set[int]]:\n",
    "    \"\"\"\n",
    "    Generate a random \"grammar\" of same complexity as GIFT.\n",
    "    - 4 atoms (primes from 2-20)\n",
    "    - 6 primaries (products of atoms)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    # Random 4 primes from small primes\n",
    "    small_primes = [2, 3, 5, 7, 11, 13, 17, 19]\n",
    "    atoms = set(random.sample(small_primes, 4))\n",
    "    \n",
    "    # Generate primaries as products\n",
    "    atom_list = list(atoms)\n",
    "    primaries = set()\n",
    "    \n",
    "    # Products of pairs\n",
    "    for i in range(len(atom_list)):\n",
    "        for j in range(i, len(atom_list)):\n",
    "            p = atom_list[i] * atom_list[j]\n",
    "            if p < 150:  # Keep reasonable size\n",
    "                primaries.add(p)\n",
    "    \n",
    "    # Limit to 6 primaries like GIFT\n",
    "    if len(primaries) > 6:\n",
    "        primaries = set(random.sample(list(primaries), 6))\n",
    "    \n",
    "    return atoms, primaries\n",
    "\n",
    "\n",
    "def grammar_generates_conductor(q: int, atoms: Set[int], primaries: Set[int]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if conductor q can be expressed as:\n",
    "    - A single atom/primary\n",
    "    - Sum of two primaries\n",
    "    - Primary + 2×Primary\n",
    "    \"\"\"\n",
    "    all_constants = atoms | primaries\n",
    "    \n",
    "    # Direct match\n",
    "    if q in all_constants:\n",
    "        return True\n",
    "    \n",
    "    # Sum of two\n",
    "    for c1 in all_constants:\n",
    "        for c2 in all_constants:\n",
    "            if c1 + c2 == q:\n",
    "                return True\n",
    "            if c1 + 2*c2 == q:  # Primary + 2×Primary\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "def test_grammar_on_results(results: List[Dict], atoms: Set[int], primaries: Set[int]) -> float:\n",
    "    \"\"\"\n",
    "    Test how well a grammar separates \"good\" from \"bad\" conductors.\n",
    "    Returns mean |R-1| for conductors the grammar claims to generate.\n",
    "    \"\"\"\n",
    "    grammar_conductors = []\n",
    "    \n",
    "    for r in results:\n",
    "        q = r['q']\n",
    "        if grammar_generates_conductor(q, atoms, primaries):\n",
    "            grammar_conductors.append(r['R_deviation'])\n",
    "    \n",
    "    if not grammar_conductors:\n",
    "        return float('inf')\n",
    "    \n",
    "    return float(np.mean(grammar_conductors))\n",
    "\n",
    "\n",
    "print(\"✓ Null grammar generation ready\")\n",
    "\n",
    "# Test\n",
    "test_atoms, test_primaries = generate_null_grammar(seed=42)\n",
    "print(f\"  Example null grammar: atoms={test_atoms}, primaries={test_primaries}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: GPU-Accelerated Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BOOTSTRAP CONFIDENCE INTERVALS (GPU-accelerated)\n",
    "# ============================================================================\n",
    "\n",
    "def bootstrap_mean_diff(group1: np.ndarray, group2: np.ndarray, \n",
    "                        n_bootstrap: int = 10000, \n",
    "                        use_gpu: bool = GPU_AVAILABLE) -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence interval for mean difference.\n",
    "    \n",
    "    Returns: (observed_diff, ci_lower, ci_upper)\n",
    "    \"\"\"\n",
    "    observed_diff = np.mean(group1) - np.mean(group2)\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    \n",
    "    if use_gpu and GPU_AVAILABLE:\n",
    "        # GPU-accelerated bootstrap\n",
    "        g1_gpu = cp.asarray(group1)\n",
    "        g2_gpu = cp.asarray(group2)\n",
    "        \n",
    "        # Generate all bootstrap indices at once\n",
    "        idx1 = cp.random.randint(0, n1, size=(n_bootstrap, n1))\n",
    "        idx2 = cp.random.randint(0, n2, size=(n_bootstrap, n2))\n",
    "        \n",
    "        # Compute all bootstrap means\n",
    "        boot_means1 = cp.mean(g1_gpu[idx1], axis=1)\n",
    "        boot_means2 = cp.mean(g2_gpu[idx2], axis=1)\n",
    "        boot_diffs = boot_means1 - boot_means2\n",
    "        \n",
    "        # Get percentiles\n",
    "        ci_lower = float(cp.percentile(boot_diffs, 2.5))\n",
    "        ci_upper = float(cp.percentile(boot_diffs, 97.5))\n",
    "        \n",
    "        # Clean up GPU memory\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    else:\n",
    "        # CPU fallback\n",
    "        boot_diffs = np.zeros(n_bootstrap)\n",
    "        for i in range(n_bootstrap):\n",
    "            boot1 = np.random.choice(group1, size=n1, replace=True)\n",
    "            boot2 = np.random.choice(group2, size=n2, replace=True)\n",
    "            boot_diffs[i] = np.mean(boot1) - np.mean(boot2)\n",
    "        \n",
    "        ci_lower = float(np.percentile(boot_diffs, 2.5))\n",
    "        ci_upper = float(np.percentile(boot_diffs, 97.5))\n",
    "    \n",
    "    return observed_diff, ci_lower, ci_upper\n",
    "\n",
    "\n",
    "def bootstrap_p_value(group1: np.ndarray, group2: np.ndarray,\n",
    "                      n_bootstrap: int = 10000,\n",
    "                      use_gpu: bool = GPU_AVAILABLE) -> float:\n",
    "    \"\"\"\n",
    "    Compute bootstrap p-value for H₀: mean(group1) >= mean(group2).\n",
    "    \"\"\"\n",
    "    observed_diff = np.mean(group1) - np.mean(group2)\n",
    "    combined = np.concatenate([group1, group2])\n",
    "    n1 = len(group1)\n",
    "    n_total = len(combined)\n",
    "    \n",
    "    if use_gpu and GPU_AVAILABLE:\n",
    "        combined_gpu = cp.asarray(combined)\n",
    "        \n",
    "        # Permutation test\n",
    "        count_more_extreme = 0\n",
    "        batch_size = min(1000, n_bootstrap)\n",
    "        \n",
    "        for _ in range(n_bootstrap // batch_size):\n",
    "            # Shuffle and split\n",
    "            indices = cp.random.permutation(n_total)\n",
    "            shuffled = combined_gpu[indices]\n",
    "            \n",
    "            perm_diff = cp.mean(shuffled[:n1]) - cp.mean(shuffled[n1:])\n",
    "            if float(perm_diff) <= observed_diff:\n",
    "                count_more_extreme += batch_size\n",
    "        \n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        p_value = count_more_extreme / n_bootstrap\n",
    "    else:\n",
    "        count_more_extreme = 0\n",
    "        for _ in range(n_bootstrap):\n",
    "            np.random.shuffle(combined)\n",
    "            perm_diff = np.mean(combined[:n1]) - np.mean(combined[n1:])\n",
    "            if perm_diff <= observed_diff:\n",
    "                count_more_extreme += 1\n",
    "        p_value = count_more_extreme / n_bootstrap\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "\n",
    "print(f\"✓ Bootstrap methods ready (GPU: {GPU_AVAILABLE})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Main Computation\n",
    "\n",
    "⏱️ **Estimated time**: 45-60 minutes for all conductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# CONFIGURATION (optimized - matches proven working parameters)\n# ============================================================================\n\nNUM_ZEROS = 50          # Zeros per conductor (sufficient for statistics)\nT_MAX = 90              # Max imaginary part to search  \nSTEP = 0.25             # Initial step size (faster scan)\nTERMS = 8000            # Series terms for L-function (sufficient precision)\n\nN_NULL_GRAMMARS = 100   # Number of null grammars to test\nN_BOOTSTRAP = 10000     # Bootstrap samples\n\n# Estimated time: ~2-3 min per conductor, ~50-70 min total\nprint(f\"Configuration (OPTIMIZED):\")\nprint(f\"  Zeros per conductor: {NUM_ZEROS}\")\nprint(f\"  T_max: {T_MAX}\")\nprint(f\"  Step size: {STEP}\")\nprint(f\"  Series terms: {TERMS}\")\nprint(f\"  Null grammars: {N_NULL_GRAMMARS}\")\nprint(f\"  Bootstrap samples: {N_BOOTSTRAP}\")\nprint(f\"  GPU acceleration: {GPU_AVAILABLE}\")\nprint(f\"\\n⏱️ Estimated: ~2-3 min/conductor, ~50-70 min total\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================================\n# COMPUTE ZEROS FOR ALL CONDUCTORS\n# ============================================================================\n\nresults = []\nzeros_cache = {}\n\nsorted_conductors = sorted(ALL_CONDUCTORS.keys())\n\nprint(f\"\\nComputing zeros for {len(sorted_conductors)} conductors...\")\nprint(f\"Parameters: {NUM_ZEROS} zeros, T_max={T_MAX}, step={STEP}, terms={TERMS}\")\nprint(\"=\" * 70)\n\ntotal_start = time.time()\n\nfor i, q in enumerate(sorted_conductors):\n    desc = ALL_CONDUCTORS[q]\n    category = 'gift' if q in GIFT_CONDUCTORS else 'control'\n    \n    print(f\"[{i+1}/{len(sorted_conductors)}] q={q:3d} ({category:7s})...\", end=\" \", flush=True)\n    start = time.time()\n    \n    # Skip q=2 (trivial character)\n    if q == 2:\n        print(\"SKIPPED (trivial)\")\n        continue\n    \n    # Compute zeros with OPTIMIZED parameters\n    zeros = find_zeros_dirichlet(q, NUM_ZEROS, T_MAX, STEP, TERMS)\n    elapsed = time.time() - start\n    \n    if len(zeros) >= 35:  # Minimum 35 zeros (like original notebook)\n        zeros_array = np.array(zeros)\n        zeros_cache[q] = zeros_array\n        \n        # Fit recurrence\n        coeffs, rmse, r2 = fit_recurrence(zeros_array, GIFT_LAGS)\n        R = compute_fibonacci_ratio(coeffs, GIFT_LAGS)\n        \n        if R is not None:\n            R_dev = abs(R - 1)\n            results.append({\n                'q': q,\n                'category': category,\n                'description': desc,\n                'num_zeros': len(zeros),\n                'coeffs': coeffs.tolist() if coeffs is not None else None,\n                'R': float(R),\n                'R_deviation': float(R_dev),\n                'rmse': float(rmse),\n                'r2': float(r2),\n            })\n            print(f\"{len(zeros)} zeros, R={R:.3f}, |R-1|={R_dev:.3f} ({elapsed:.0f}s)\")\n        else:\n            print(f\"{len(zeros)} zeros, R=N/A ({elapsed:.0f}s)\")\n    else:\n        print(f\"only {len(zeros)} zeros - SKIPPED ({elapsed:.0f}s)\")\n\ntotal_elapsed = time.time() - total_start\nprint(\"=\" * 70)\nprint(f\"\\n✓ Completed in {total_elapsed/60:.1f} minutes\")\nprint(f\"✓ {len(results)} conductors with valid results\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Blind Challenge Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BLIND CHALLENGE: GIFT vs CONTROL\n",
    "# ============================================================================\n",
    "\n",
    "gift_results = [r for r in results if r['category'] == 'gift']\n",
    "control_results = [r for r in results if r['category'] == 'control']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BLIND CHALLENGE: GIFT vs CONTROL CONDUCTORS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nGIFT conductors ({len(gift_results)}):\")\n",
    "for r in sorted(gift_results, key=lambda x: x['R_deviation']):\n",
    "    print(f\"  q={r['q']:3d}: |R-1|={r['R_deviation']:.4f} ({r['description'][:40]})\")\n",
    "\n",
    "print(f\"\\nControl conductors ({len(control_results)}):\")\n",
    "for r in sorted(control_results, key=lambda x: x['R_deviation']):\n",
    "    print(f\"  q={r['q']:3d}: |R-1|={r['R_deviation']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STATISTICAL TESTS\n",
    "# ============================================================================\n",
    "\n",
    "if gift_results and control_results:\n",
    "    gift_devs = np.array([r['R_deviation'] for r in gift_results])\n",
    "    control_devs = np.array([r['R_deviation'] for r in control_results])\n",
    "    \n",
    "    gift_mean = np.mean(gift_devs)\n",
    "    control_mean = np.mean(control_devs)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"STATISTICAL ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"\\nGroup Statistics:\")\n",
    "    print(f\"  GIFT:    n={len(gift_devs)}, mean={gift_mean:.4f}, std={np.std(gift_devs):.4f}\")\n",
    "    print(f\"  Control: n={len(control_devs)}, mean={control_mean:.4f}, std={np.std(control_devs):.4f}\")\n",
    "    \n",
    "    if gift_mean < control_mean:\n",
    "        ratio = control_mean / gift_mean\n",
    "        print(f\"\\n  → GIFT is {ratio:.2f}× BETTER (lower |R-1|)\")\n",
    "    else:\n",
    "        ratio = gift_mean / control_mean\n",
    "        print(f\"\\n  → Control is {ratio:.2f}× better (unexpected!)\")\n",
    "    \n",
    "    # t-test\n",
    "    t_stat, p_ttest = stats.ttest_ind(gift_devs, control_devs)\n",
    "    print(f\"\\nt-test:\")\n",
    "    print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"  p-value (two-tailed): {p_ttest:.4f}\")\n",
    "    print(f\"  p-value (one-tailed): {p_ttest/2:.4f}\")\n",
    "    \n",
    "    # Mann-Whitney U\n",
    "    u_stat, p_mann = stats.mannwhitneyu(gift_devs, control_devs, alternative='less')\n",
    "    print(f\"\\nMann-Whitney U:\")\n",
    "    print(f\"  U-statistic: {u_stat:.1f}\")\n",
    "    print(f\"  p-value (one-tailed): {p_mann:.4f}\")\n",
    "    \n",
    "    # Bootstrap CI\n",
    "    print(f\"\\nBootstrap ({N_BOOTSTRAP} samples):\")\n",
    "    obs_diff, ci_low, ci_high = bootstrap_mean_diff(gift_devs, control_devs, N_BOOTSTRAP)\n",
    "    print(f\"  Observed diff (GIFT - Control): {obs_diff:.4f}\")\n",
    "    print(f\"  95% CI: [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "    \n",
    "    if ci_high < 0:\n",
    "        print(f\"  → GIFT significantly better (CI entirely negative) ✓\")\n",
    "    elif ci_low > 0:\n",
    "        print(f\"  → Control significantly better (unexpected)\")\n",
    "    else:\n",
    "        print(f\"  → No significant difference (CI includes 0)\")\n",
    "else:\n",
    "    print(\"\\n⚠ Not enough data for statistical analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: The 42 Test (Pre-registered Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# THE 42 TEST\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SPECIAL TEST: q = 42 (χ_K7 = 2×3×7)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "q42_result = next((r for r in results if r['q'] == 42), None)\n",
    "\n",
    "if q42_result:\n",
    "    print(f\"\\nq = 42 Results:\")\n",
    "    print(f\"  Zeros found: {q42_result['num_zeros']}\")\n",
    "    print(f\"  R = {q42_result['R']:.4f}\")\n",
    "    print(f\"  |R-1| = {q42_result['R_deviation']:.4f}\")\n",
    "    print(f\"  R² = {q42_result['r2']:.6f}\")\n",
    "    \n",
    "    # Rank among all conductors\n",
    "    sorted_by_dev = sorted(results, key=lambda x: x['R_deviation'])\n",
    "    rank_42 = next(i+1 for i, r in enumerate(sorted_by_dev) if r['q'] == 42)\n",
    "    percentile = (len(results) - rank_42) / len(results) * 100\n",
    "    \n",
    "    print(f\"\\n  Rank: #{rank_42} out of {len(results)} conductors\")\n",
    "    print(f\"  Percentile: {percentile:.1f}%\")\n",
    "    \n",
    "    # Pre-registered prediction: 42 should be in top 25%\n",
    "    if rank_42 <= len(results) // 4:\n",
    "        print(f\"\\n  ✓ PREDICTION CONFIRMED: q=42 is in top 25%\")\n",
    "        q42_verdict = \"PASS\"\n",
    "    elif rank_42 <= len(results) // 2:\n",
    "        print(f\"\\n  ~ MARGINAL: q=42 is in top 50% but not top 25%\")\n",
    "        q42_verdict = \"MARGINAL\"\n",
    "    else:\n",
    "        print(f\"\\n  ✗ PREDICTION FAILED: q=42 is NOT in top 50%\")\n",
    "        q42_verdict = \"FAIL\"\n",
    "else:\n",
    "    print(\"\\n⚠ q=42 not in results (insufficient zeros?)\")\n",
    "    q42_verdict = \"NO DATA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 9: Null Grammar Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# NULL GRAMMAR COMPETITION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"NULL GRAMMAR COMPETITION ({N_NULL_GRAMMARS} random grammars)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# GIFT grammar performance\n",
    "gift_grammar_score = test_grammar_on_results(results, ATOMS | FIBONACCI_ATOMS, PRIMARIES)\n",
    "print(f\"\\nGIFT grammar mean |R-1|: {gift_grammar_score:.4f}\")\n",
    "\n",
    "# Test null grammars\n",
    "print(f\"\\nTesting {N_NULL_GRAMMARS} null grammars...\")\n",
    "\n",
    "null_scores = []\n",
    "better_than_gift = 0\n",
    "\n",
    "for i in range(N_NULL_GRAMMARS):\n",
    "    atoms, primaries = generate_null_grammar(seed=i)\n",
    "    score = test_grammar_on_results(results, atoms, primaries)\n",
    "    null_scores.append(score)\n",
    "    \n",
    "    if score <= gift_grammar_score:\n",
    "        better_than_gift += 1\n",
    "    \n",
    "    if (i + 1) % 20 == 0:\n",
    "        print(f\"  {i+1}/{N_NULL_GRAMMARS} tested...\")\n",
    "\n",
    "null_scores = np.array([s for s in null_scores if s != float('inf')])\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Valid null grammars: {len(null_scores)}\")\n",
    "print(f\"  Null grammar mean |R-1|: {np.mean(null_scores):.4f} ± {np.std(null_scores):.4f}\")\n",
    "print(f\"  GIFT grammar mean |R-1|: {gift_grammar_score:.4f}\")\n",
    "print(f\"  Null grammars better than GIFT: {better_than_gift}\")\n",
    "\n",
    "p_value_grammar = better_than_gift / N_NULL_GRAMMARS\n",
    "percentile_gift = (1 - p_value_grammar) * 100\n",
    "\n",
    "print(f\"\\n  GIFT percentile: {percentile_gift:.1f}%\")\n",
    "print(f\"  p-value: {p_value_grammar:.4f}\")\n",
    "\n",
    "# Pre-registered prediction: GIFT should beat 95% of null grammars\n",
    "if percentile_gift >= 95:\n",
    "    print(f\"\\n  ✓ PREDICTION CONFIRMED: GIFT beats {percentile_gift:.0f}% of null grammars\")\n",
    "    grammar_verdict = \"STRONG PASS\"\n",
    "elif percentile_gift >= 80:\n",
    "    print(f\"\\n  ~ MARGINAL: GIFT beats {percentile_gift:.0f}% (target: 95%)\")\n",
    "    grammar_verdict = \"MARGINAL\"\n",
    "else:\n",
    "    print(f\"\\n  ✗ PREDICTION FAILED: GIFT only beats {percentile_gift:.0f}%\")\n",
    "    grammar_verdict = \"FAIL\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 10: Complete Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE RANKING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPLETE RANKING (lower |R-1| = better Fibonacci constraint)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "sorted_results = sorted(results, key=lambda x: x['R_deviation'])\n",
    "\n",
    "print(f\"\\n{'Rank':<5} {'q':<4} {'Cat':<8} {'R':>8} {'|R-1|':>8} {'R²':>10} Description\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, r in enumerate(sorted_results, 1):\n",
    "    marker = \"★\" if r['category'] == 'gift' else \"·\"\n",
    "    special = \" ← 42!\" if r['q'] == 42 else \"\"\n",
    "    print(f\"{i:<5} {r['q']:<4} {r['category']:<8} {r['R']:>8.3f} {r['R_deviation']:>8.4f} {r['r2']:>10.6f} {r['description'][:25]}{special} {marker}\")\n",
    "\n",
    "print(\"\\nLegend: ★ = GIFT conductor, · = Control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 11: Final Verdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL VERDICT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"#\" * 70)\n",
    "print(\"#\" + \" PHASE 3 VALIDATION: FINAL VERDICT \".center(68) + \"#\")\n",
    "print(\"#\" * 70)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRE-REGISTERED PREDICTIONS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Prediction 1: GIFT vs Control\n",
    "if gift_results and control_results:\n",
    "    if gift_mean < control_mean and p_ttest/2 < 0.05:\n",
    "        pred1 = \"✓ PASS\"\n",
    "        pred1_detail = f\"GIFT {control_mean/gift_mean:.1f}× better, p={p_ttest/2:.4f}\"\n",
    "    elif gift_mean < control_mean:\n",
    "        pred1 = \"~ MARGINAL\"\n",
    "        pred1_detail = f\"GIFT better but p={p_ttest/2:.4f} > 0.05\"\n",
    "    else:\n",
    "        pred1 = \"✗ FAIL\"\n",
    "        pred1_detail = \"Control outperformed GIFT\"\n",
    "else:\n",
    "    pred1 = \"? NO DATA\"\n",
    "    pred1_detail = \"Insufficient results\"\n",
    "\n",
    "print(f\"\\n1. GIFT conductors outperform controls: {pred1}\")\n",
    "print(f\"   {pred1_detail}\")\n",
    "\n",
    "# Prediction 2: q=42\n",
    "print(f\"\\n2. q=42 shows special structure: {q42_verdict}\")\n",
    "if q42_result:\n",
    "    print(f\"   Rank #{rank_42}/{len(results)}, |R-1|={q42_result['R_deviation']:.4f}\")\n",
    "\n",
    "# Prediction 3: Grammar competition\n",
    "print(f\"\\n3. GIFT grammar beats 95% of nulls: {grammar_verdict}\")\n",
    "print(f\"   Actually beats {percentile_gift:.1f}%\")\n",
    "\n",
    "# Overall\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "verdicts = [pred1, q42_verdict, grammar_verdict]\n",
    "pass_count = sum(1 for v in verdicts if 'PASS' in v)\n",
    "fail_count = sum(1 for v in verdicts if 'FAIL' in v)\n",
    "\n",
    "if pass_count >= 2 and fail_count == 0:\n",
    "    overall = \"STRONG EVIDENCE\"\n",
    "    overall_detail = \"Fractal encoding hypothesis SUPPORTED\"\n",
    "elif pass_count >= 1 and fail_count <= 1:\n",
    "    overall = \"MODERATE EVIDENCE\"\n",
    "    overall_detail = \"Partial support, some caveats\"\n",
    "elif fail_count >= 2:\n",
    "    overall = \"WEAK EVIDENCE\"\n",
    "    overall_detail = \"Hypothesis NOT well supported\"\n",
    "else:\n",
    "    overall = \"INCONCLUSIVE\"\n",
    "    overall_detail = \"Mixed results\"\n",
    "\n",
    "print(f\"OVERALL: {overall}\")\n",
    "print(f\"         {overall_detail}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n\" + \"#\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "output = {\n",
    "    'test': 'GIFT Phase 3 Blind Challenge',\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'gpu_used': GPU_AVAILABLE,\n",
    "    'parameters': {\n",
    "        'num_zeros': NUM_ZEROS,\n",
    "        'T_max': T_MAX,\n",
    "        'series_terms': TERMS,\n",
    "        'n_null_grammars': N_NULL_GRAMMARS,\n",
    "        'n_bootstrap': N_BOOTSTRAP,\n",
    "        'gift_lags': GIFT_LAGS,\n",
    "    },\n",
    "    'results': results,\n",
    "    'predictions': {\n",
    "        'pred1_gift_vs_control': {\n",
    "            'verdict': pred1,\n",
    "            'gift_mean': float(gift_mean) if gift_results else None,\n",
    "            'control_mean': float(control_mean) if control_results else None,\n",
    "            'p_value': float(p_ttest/2) if gift_results and control_results else None,\n",
    "        },\n",
    "        'pred2_q42': {\n",
    "            'verdict': q42_verdict,\n",
    "            'rank': rank_42 if q42_result else None,\n",
    "            'R_deviation': q42_result['R_deviation'] if q42_result else None,\n",
    "        },\n",
    "        'pred3_grammar': {\n",
    "            'verdict': grammar_verdict,\n",
    "            'percentile': float(percentile_gift),\n",
    "            'p_value': float(p_value_grammar),\n",
    "        },\n",
    "    },\n",
    "    'overall_verdict': overall,\n",
    "}\n",
    "\n",
    "output_path = 'GIFT_Phase3_Blind_Challenge_Results.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Results saved to '{output_path}'\")\n",
    "print(f\"\\nPlease share this file for verification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This Phase 3 validation implements the AI council recommendations:\n",
    "\n",
    "1. **Blind Challenge**: Pre-registered GIFT vs Control conductors\n",
    "2. **The 42 Test**: Special test for the \"universal constant\"\n",
    "3. **Null Grammar Competition**: GIFT vs 100 random grammars\n",
    "4. **Statistical Rigor**: Bootstrap CIs, permutation tests, Mann-Whitney U\n",
    "5. **GPU Acceleration**: CuPy for heavy statistics (when available)\n",
    "\n",
    "The pre-registered predictions allow falsification - if they fail, the fractal encoding hypothesis is weakened.\n",
    "\n",
    "---\n",
    "*GIFT Framework — Phase 3 Validation*\n",
    "*February 2026*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}