{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GIFT Yukawa Tensor from Atlas G₂ Metric\n",
    "\n",
    "**Phase 3**: Atlas metric → Harmonic forms → Yukawa couplings → Mass ratios\n",
    "\n",
    "**Hardware**: A100 GPU (Colab)\n",
    "**Depends on**: `colab_atlas_g2_metric.ipynb` (Phase 2 — atlas A1 weights)\n",
    "\n",
    "## Pipeline\n",
    "1. **Load atlas**: Neck + Bulk_L + Bulk_R PINNs from A1 checkpoints\n",
    "2. **Harmonic 2-forms**: 21 basis elements of H²(K₇) via metric inner product\n",
    "3. **Harmonic 3-forms**: 77 basis elements of H³(K₇) (35 local + 42 global)\n",
    "4. **Yukawa tensor**: Y_{IJA} = ∫_{K₇} ω_I ∧ ω_J ∧ ρ_A (MC integration)\n",
    "5. **Physics**: Mass matrices, mixing angles, Koide formula\n",
    "\n",
    "## Key Formula\n",
    "From the 11D Chern-Simons coupling C₃ ∧ G₄ ∧ G₄, dimensionally reduced on K₇:\n",
    "\n",
    "$$Y_{IJA} = \\int_{K_7} \\omega_I \\wedge \\omega_J \\wedge \\rho_A$$\n",
    "\n",
    "where ω_I ∈ H²(K₇) (b₂=21) and ρ_A ∈ H³(K₇) (b₃=77).\n",
    "This is a (2+2+3=7)-form, integrated over the 7-manifold.\n",
    "\n",
    "**References**: Acharya-Witten (2001), Atiyah-Witten (2002)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 1: Setup & Dependencies\n",
    "# ============================================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from itertools import combinations\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.float64\n",
    "\n",
    "print(f'PyTorch {torch.__version__}')\n",
    "print(f'Device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f'Memory: {props.total_memory / 1e9:.1f} GB')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "T_START = time.time()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 2: GIFT Constants & TCS Domain Layout\n",
    "# ============================================================\n",
    "DIM = 7\n",
    "B2 = 21                          # b_2(K_7)\n",
    "B3 = 77                          # b_3(K_7)\n",
    "H_STAR = B2 + B3 + 1            # = 99\n",
    "DIM_G2 = 14\n",
    "DET_G_TARGET = 65 / 32          # = 2.03125\n",
    "SCALE_FACTOR = DET_G_TARGET ** (1 / 14)  # ~ 1.0543\n",
    "KAPPA_T = 1.0 / 61\n",
    "\n",
    "# TCS building blocks\n",
    "B2_M1, B3_M1 = 11, 40           # Quintic CY3\n",
    "B2_M2, B3_M2 = 10, 37           # CI(2,2,2) CY3\n",
    "\n",
    "# Atlas domain layout (t = coord[0])\n",
    "DOMAIN_BULK_L = (0.00, 0.40)\n",
    "DOMAIN_NECK   = (0.25, 0.75)\n",
    "DOMAIN_BULK_R = (0.60, 1.00)\n",
    "\n",
    "# Number of independent components for k-forms in 7D\n",
    "N_2FORM = 21   # C(7,2)\n",
    "N_3FORM = 35   # C(7,3)\n",
    "N_4FORM = 35   # C(7,4)\n",
    "\n",
    "# All ordered index tuples\n",
    "IDX_2 = list(combinations(range(DIM), 2))\n",
    "IDX_3 = list(combinations(range(DIM), 3))\n",
    "IDX_4 = list(combinations(range(DIM), 4))\n",
    "\n",
    "# Lookup tables\n",
    "IDX_2_MAP = {t: i for i, t in enumerate(IDX_2)}\n",
    "IDX_3_MAP = {t: i for i, t in enumerate(IDX_3)}\n",
    "IDX_4_MAP = {t: i for i, t in enumerate(IDX_4)}\n",
    "\n",
    "print(f'GIFT Yukawa Pipeline')\n",
    "print(f'  b_2={B2}, b_3={B3}, H*={H_STAR}, dim(G_2)={DIM_G2}')\n",
    "print(f'  det(g) target = {DET_G_TARGET}')\n",
    "print(f'  Yukawa tensor: {B2} x {B2} x {B3} = {B2*B2*B3:,} components')\n",
    "print(f'  M1 (Quintic): b2={B2_M1}, b3={B3_M1}')\n",
    "print(f'  M2 (CI(2,2,2)): b2={B2_M2}, b3={B3_M2}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 3: G2 Algebraic Infrastructure\n",
    "# ============================================================\n",
    "\n",
    "# Standard G2 form: 7 Fano triples with signs\n",
    "STANDARD_G2_FORM = [\n",
    "    ((0, 1, 3), +1), ((1, 2, 4), +1), ((2, 3, 5), +1),\n",
    "    ((3, 4, 6), +1), ((4, 5, 0), +1), ((5, 6, 1), +1), ((6, 0, 2), +1),\n",
    "]\n",
    "FANO_LINES = [(0,1,3),(1,2,4),(2,3,5),(3,4,6),(4,5,0),(5,6,1),(6,0,2)]\n",
    "\n",
    "\n",
    "def build_phi0_tensor():\n",
    "    \"\"\"Full 7x7x7 antisymmetric tensor for the standard G2 form.\"\"\"\n",
    "    phi0 = np.zeros((7, 7, 7), dtype=np.float64)\n",
    "    for (indices, sign) in STANDARD_G2_FORM:\n",
    "        i, j, k = indices\n",
    "        phi0[i,j,k] = sign;  phi0[j,k,i] = sign;  phi0[k,i,j] = sign\n",
    "        phi0[j,i,k] = -sign; phi0[i,k,j] = -sign; phi0[k,j,i] = -sign\n",
    "    return phi0\n",
    "\n",
    "\n",
    "PHI0_TENSOR = build_phi0_tensor()\n",
    "\n",
    "\n",
    "def phi0_components(normalize=True):\n",
    "    \"\"\"Standard G2 3-form as 35 independent components.\"\"\"\n",
    "    phi0 = np.zeros(35, dtype=np.float64)\n",
    "    idx = 0\n",
    "    for i in range(7):\n",
    "        for j in range(i+1, 7):\n",
    "            for k in range(j+1, 7):\n",
    "                phi0[idx] = PHI0_TENSOR[i, j, k]\n",
    "                idx += 1\n",
    "    if normalize:\n",
    "        phi0 *= SCALE_FACTOR\n",
    "    return phi0\n",
    "\n",
    "\n",
    "def g2_generators():\n",
    "    \"\"\"14 generators of G2 in so(7).\"\"\"\n",
    "    gens = np.zeros((14, 7, 7), dtype=np.float64)\n",
    "    for idx, (i, j, k) in enumerate(FANO_LINES):\n",
    "        gens[idx, i, j] = 1;  gens[idx, j, i] = -1\n",
    "    for idx in range(7):\n",
    "        i, j, k = idx, (idx + 1) % 7, (idx + 3) % 7\n",
    "        gens[7 + idx, i, k] = 1;    gens[7 + idx, k, i] = -1\n",
    "        gens[7 + idx, j, k] = 0.5;  gens[7 + idx, k, j] = -0.5\n",
    "    for idx in range(14):\n",
    "        norm = np.linalg.norm(gens[idx])\n",
    "        if norm > 1e-10:\n",
    "            gens[idx] /= norm\n",
    "    return gens\n",
    "\n",
    "\n",
    "def compute_lie_derivatives():\n",
    "    \"\"\"Lie derivatives L_X phi0 for each G2 generator X. Shape: (14, 35).\"\"\"\n",
    "    gens = g2_generators()\n",
    "    phi0 = phi0_components(normalize=True)\n",
    "    lie = np.zeros((14, 35), dtype=np.float64)\n",
    "    for g_idx in range(14):\n",
    "        X = gens[g_idx]\n",
    "        c_idx = 0\n",
    "        for i in range(7):\n",
    "            for j in range(i+1, 7):\n",
    "                for k in range(j+1, 7):\n",
    "                    val = 0.0\n",
    "                    for m in range(7):\n",
    "                        val += X[i,m] * PHI0_TENSOR[m,j,k] * SCALE_FACTOR\n",
    "                        val += X[j,m] * PHI0_TENSOR[i,m,k] * SCALE_FACTOR\n",
    "                        val += X[k,m] * PHI0_TENSOR[i,j,m] * SCALE_FACTOR\n",
    "                    lie[g_idx, c_idx] = val\n",
    "                    c_idx += 1\n",
    "    return lie\n",
    "\n",
    "\n",
    "LIE_DERIVATIVES = compute_lie_derivatives()\n",
    "print(f'G2 generators: 14 matrices in so(7)')\n",
    "print(f'Lie derivative matrix: {LIE_DERIVATIVES.shape}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 4: PINN Architecture (reproduced from atlas notebook)\n",
    "# ============================================================\n",
    "\n",
    "class FourierFeatures(nn.Module):\n",
    "    \"\"\"Random Fourier features with periodic-aware encoding.\"\"\"\n",
    "    def __init__(self, input_dim=7, num_random_freq=24, num_periodic_freq=8, scale=1.0):\n",
    "        super().__init__()\n",
    "        n_nonperiodic = input_dim - 2\n",
    "        B_rand = torch.randn(num_random_freq, n_nonperiodic, dtype=dtype) * scale\n",
    "        self.register_buffer('B_rand', B_rand)\n",
    "        k = torch.arange(1, num_periodic_freq + 1, dtype=dtype).unsqueeze(1)\n",
    "        self.register_buffer('k_periodic', k)\n",
    "        self.output_dim = 2 * num_random_freq + 4 * num_periodic_freq\n",
    "        self.num_periodic_freq = num_periodic_freq\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_nonper = torch.stack([x[:,0], x[:,2], x[:,3], x[:,4], x[:,5]], dim=1)\n",
    "        proj = 2 * math.pi * x_nonper @ self.B_rand.T\n",
    "        feat_rand = torch.cat([torch.cos(proj), torch.sin(proj)], dim=-1)\n",
    "        theta = 2 * math.pi * x[:, 1:2]\n",
    "        psi = 2 * math.pi * x[:, 6:7]\n",
    "        k = self.k_periodic.T\n",
    "        feat_per = torch.cat([\n",
    "            torch.cos(theta * k), torch.sin(theta * k),\n",
    "            torch.cos(psi * k), torch.sin(psi * k)\n",
    "        ], dim=-1)\n",
    "        return torch.cat([feat_rand, feat_per], dim=-1)\n",
    "\n",
    "\n",
    "class NeckPINN(nn.Module):\n",
    "    \"\"\"G2-native PINN for the TCS neck region.\"\"\"\n",
    "    def __init__(self, num_random_freq=24, num_periodic_freq=8,\n",
    "                 hidden_dims=None, perturbation_scale=0.2):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 256, 256, 128]\n",
    "        self.perturbation_scale = perturbation_scale\n",
    "        self.register_buffer('phi0', torch.from_numpy(phi0_components(True)).to(dtype))\n",
    "        self.register_buffer('lie_derivs', torch.from_numpy(LIE_DERIVATIVES).to(dtype))\n",
    "        self.fourier = FourierFeatures(7, num_random_freq, num_periodic_freq)\n",
    "        layers = []\n",
    "        in_dim = self.fourier.output_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(in_dim, h, dtype=dtype), nn.SiLU()]\n",
    "            in_dim = h\n",
    "        layers.append(nn.Linear(in_dim, 14, dtype=dtype))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        adj = self.mlp(self.fourier(x))\n",
    "        delta_phi = adj @ self.lie_derivs\n",
    "        return self.phi0.unsqueeze(0) + self.perturbation_scale * delta_phi\n",
    "\n",
    "    def phi_tensor(self, x):\n",
    "        comp = self.forward(x)\n",
    "        N = comp.shape[0]\n",
    "        phi = torch.zeros(N, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
    "        idx = 0\n",
    "        for i in range(7):\n",
    "            for j in range(i+1, 7):\n",
    "                for k in range(j+1, 7):\n",
    "                    v = comp[:, idx]\n",
    "                    phi[:,i,j,k] = v;  phi[:,j,k,i] = v;  phi[:,k,i,j] = v\n",
    "                    phi[:,j,i,k] = -v; phi[:,i,k,j] = -v; phi[:,k,j,i] = -v\n",
    "                    idx += 1\n",
    "        return phi\n",
    "\n",
    "    def metric(self, x):\n",
    "        phi = self.phi_tensor(x)\n",
    "        return torch.einsum('nikl,njkl->nij', phi, phi) / 6.0\n",
    "\n",
    "    def det_g(self, x):\n",
    "        return torch.linalg.det(self.metric(x))\n",
    "\n",
    "\n",
    "class BulkCYPINN(nn.Module):\n",
    "    \"\"\"Cholesky-parameterized PINN for ACyl CY3 x S1 bulk regions.\"\"\"\n",
    "    def __init__(self, num_random_freq=24, num_periodic_freq=8,\n",
    "                 hidden_dims=None, perturbation_scale=0.2, base_diag=None):\n",
    "        super().__init__()\n",
    "        if hidden_dims is None:\n",
    "            hidden_dims = [256, 256, 256, 128]\n",
    "        self.perturbation_scale = perturbation_scale\n",
    "        if base_diag is None:\n",
    "            base_diag = [1.0, 1.0, SCALE_FACTOR, SCALE_FACTOR,\n",
    "                         SCALE_FACTOR, SCALE_FACTOR, 1.0]\n",
    "        L0 = torch.zeros(7, 7, dtype=dtype)\n",
    "        for i in range(7):\n",
    "            L0[i, i] = base_diag[i]\n",
    "        tril_idx = torch.tril_indices(7, 7)\n",
    "        self.register_buffer('tril_row', tril_idx[0])\n",
    "        self.register_buffer('tril_col', tril_idx[1])\n",
    "        self.register_buffer('L0_flat', L0[tril_idx[0], tril_idx[1]])\n",
    "        self.fourier = FourierFeatures(7, num_random_freq, num_periodic_freq)\n",
    "        layers = []\n",
    "        in_dim = self.fourier.output_dim\n",
    "        for h in hidden_dims:\n",
    "            layers += [nn.Linear(in_dim, h, dtype=dtype), nn.SiLU()]\n",
    "            in_dim = h\n",
    "        layers.append(nn.Linear(in_dim, 28, dtype=dtype))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def cholesky_factor(self, x):\n",
    "        N = x.shape[0]\n",
    "        delta_L = self.mlp(self.fourier(x))\n",
    "        L = torch.zeros(N, 7, 7, device=x.device, dtype=x.dtype)\n",
    "        for i in range(28):\n",
    "            val = self.L0_flat[i] + self.perturbation_scale * delta_L[:, i]\n",
    "            r, c = self.tril_row[i].item(), self.tril_col[i].item()\n",
    "            if r == c:\n",
    "                val = F.softplus(val)\n",
    "            L[:, r, c] = val\n",
    "        return L\n",
    "\n",
    "    def metric(self, x):\n",
    "        L = self.cholesky_factor(x)\n",
    "        return torch.bmm(L, L.transpose(1, 2))\n",
    "\n",
    "    def det_g(self, x):\n",
    "        L = self.cholesky_factor(x)\n",
    "        log_det = 2 * torch.sum(torch.log(torch.diagonal(L, dim1=1, dim2=2)), dim=1)\n",
    "        return torch.exp(log_det)\n",
    "\n",
    "\n",
    "print('PINN architectures defined: NeckPINN, BulkCYPINN')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Load Atlas A1 Weights\n",
    "\n",
    "Load the trained PINN models from the atlas A1 run.\n",
    "Weight files: `atlas_neck_pinn.pt`, `atlas_bulk_L_pinn.pt`, `atlas_bulk_R_pinn.pt`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 5: Load Atlas Weights & Verify\n# ============================================================\nprint('\\n' + '=' * 70)\nprint('  PHASE 1: Load Atlas A1 Weights')\nprint('=' * 70)\n\n# Instantiate models\nneck_pinn = NeckPINN().to(device)\nbulk_L_pinn = BulkCYPINN().to(device)\nbulk_R_pinn = BulkCYPINN().to(device)\n\n# Load weights\nCKPT_DIR = 'outputs'\nneck_pinn.load_state_dict(torch.load(f'{CKPT_DIR}/atlas_neck_pinn.pt',\n                                      map_location=device, weights_only=True))\nbulk_L_pinn.load_state_dict(torch.load(f'{CKPT_DIR}/atlas_bulk_L_pinn.pt',\n                                        map_location=device, weights_only=True))\nbulk_R_pinn.load_state_dict(torch.load(f'{CKPT_DIR}/atlas_bulk_R_pinn.pt',\n                                        map_location=device, weights_only=True))\n\nneck_pinn.eval()\nbulk_L_pinn.eval()\nbulk_R_pinn.eval()\n\nn_params = sum(sum(p.numel() for p in m.parameters())\n               for m in [neck_pinn, bulk_L_pinn, bulk_R_pinn])\nprint(f'  Total parameters: {n_params:,}')\n\n\ndef kovalev_twist_coords(x_neck):\n    \"\"\"Apply Kovalev transition: Neck -> Bulk_R coordinates.\"\"\"\n    x_bulk = x_neck.clone()\n    x_bulk[:, 1] = x_neck[:, 6]         # theta_bulk = psi_neck\n    x_bulk[:, 6] = x_neck[:, 1]         # psi_bulk = theta_neck\n    x_bulk[:, 2] = torch.fmod(-x_neck[:, 3] + 1.0, 1.0)\n    x_bulk[:, 3] = x_neck[:, 5]\n    x_bulk[:, 4] = x_neck[:, 2]\n    x_bulk[:, 5] = x_neck[:, 4]\n    return x_bulk\n\n\n@torch.no_grad()\ndef global_metric_at(x):\n    \"\"\"Evaluate assembled global metric at points x. Returns (N,7,7).\"\"\"\n    t = x[:, 0]\n    N = x.shape[0]\n    g = torch.zeros(N, 7, 7, device=x.device, dtype=x.dtype)\n\n    # Smooth partition of unity\n    def bump(t_val, lo, hi):\n        mid = (lo + hi) / 2\n        half = (hi - lo) / 2\n        return torch.exp(-1.0 / (1.0 - ((t_val - mid) / half).clamp(-0.999, 0.999) ** 2))\n\n    w_N = bump(t, 0.25, 0.75)\n    w_L = bump(t, 0.00, 0.40)\n    w_R = bump(t, 0.60, 1.00)\n\n    # Zero out weights outside domains (cast bool to float64, not float32)\n    w_N = w_N * ((t >= 0.25) & (t <= 0.75)).to(x.dtype)\n    w_L = w_L * ((t >= 0.00) & (t <= 0.40)).to(x.dtype)\n    w_R = w_R * ((t >= 0.60) & (t <= 1.00)).to(x.dtype)\n\n    w_total = w_N + w_L + w_R + 1e-10\n    w_N = w_N / w_total\n    w_L = w_L / w_total\n    w_R = w_R / w_total\n\n    # Neck contribution\n    mask_N = (t >= 0.25) & (t <= 0.75)\n    if mask_N.any():\n        g_neck = neck_pinn.metric(x[mask_N])\n        g[mask_N] += w_N[mask_N].unsqueeze(-1).unsqueeze(-1) * g_neck\n\n    # Bulk_L contribution\n    mask_L = (t >= 0.00) & (t <= 0.40)\n    if mask_L.any():\n        g_L = bulk_L_pinn.metric(x[mask_L])\n        g[mask_L] += w_L[mask_L].unsqueeze(-1).unsqueeze(-1) * g_L\n\n    # Bulk_R contribution (with Kovalev twist)\n    mask_R = (t >= 0.60) & (t <= 1.00)\n    if mask_R.any():\n        x_R = kovalev_twist_coords(x[mask_R])\n        g_R = bulk_R_pinn.metric(x_R)\n        g[mask_R] += w_R[mask_R].unsqueeze(-1).unsqueeze(-1) * g_R\n\n    return g\n\n\n# Quick verification\nx_test = torch.rand(1000, 7, device=device, dtype=dtype)\ng_test = global_metric_at(x_test)\ndet_test = torch.linalg.det(g_test)\neig_test = torch.linalg.eigvalsh(g_test)\n\nprint(f'\\n  Quick verification (1000 random points):')\nprint(f'    det(g) mean: {det_test.mean().item():.6f} (target: {DET_G_TARGET:.6f})')\nprint(f'    det(g) std:  {det_test.std().item():.6e}')\nprint(f'    min eigenvalue: {eig_test.min().item():.6f}')\nprint(f'    all positive definite: {(eig_test.min(dim=1).values > 0).all().item()}')\nprint(f'\\n  Atlas loaded and verified.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Harmonic Form Basis\n",
    "\n",
    "Construct approximate harmonic forms on K₇ using the PINN metric.\n",
    "\n",
    "**Strategy**: On a nearly-flat metric, constant-coefficient forms are\n",
    "approximately harmonic. We orthonormalize them using the L² inner\n",
    "product induced by the metric:\n",
    "\n",
    "$$\\langle \\omega, \\eta \\rangle_g = \\int_{K_7} g^{ik} g^{jl} \\omega_{ij} \\eta_{kl} \\sqrt{\\det g} \\, d^7x$$\n",
    "\n",
    "- **2-forms**: 21 = C(7,2) constant basis elements dxⁱ ∧ dxʲ\n",
    "- **3-forms**: 35 local + 21 M₁-global + 21 M₂-global = 77 total"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 6: MC Sample Points & Volume Elements\n# ============================================================\nprint('\\n' + '=' * 70)\nprint('  PHASE 2: Harmonic Form Basis')\nprint('=' * 70)\n\nN_MC = 50000  # Monte Carlo sample points\nBATCH = 5000  # batch size for GPU evaluation\n\nprint(f'  Sampling {N_MC:,} points in [0,1]^7...')\nx_mc = torch.rand(N_MC, 7, device=device, dtype=dtype)\n\n# Evaluate metric at all MC points\nprint(f'  Evaluating metric at {N_MC:,} points (batched)...')\ng_mc_list = []\nginv_mc_list = []\nsqrtdet_mc_list = []\ndet_mc_list = []\n\nt_eval = time.time()\nfor i in range(0, N_MC, BATCH):\n    x_batch = x_mc[i:i+BATCH]\n    g_batch = global_metric_at(x_batch)\n    det_batch = torch.linalg.det(g_batch)\n    g_mc_list.append(g_batch)\n    det_mc_list.append(det_batch)\n    ginv_mc_list.append(torch.linalg.inv(g_batch))\n    sqrtdet_mc_list.append(torch.sqrt(det_batch.clamp(min=1e-10)))\n\ng_mc = torch.cat(g_mc_list, dim=0)\nginv_mc = torch.cat(ginv_mc_list, dim=0)\nsqrtdet_mc = torch.cat(sqrtdet_mc_list, dim=0)\ndet_mc = torch.cat(det_mc_list, dim=0)\n\nprint(f'  Metric evaluation: {time.time()-t_eval:.1f}s')\nprint(f'  det(g): mean={det_mc.mean().item():.6f}, std={det_mc.std().item():.2e}')\nprint(f'  det(g): min={det_mc.min().item():.6e}, max={det_mc.max().item():.6e}')\n\n# --- Filter outlier MC points ---\n# Points where det(g) is extreme or ginv has huge entries corrupt the overlap matrices.\n# Use robust statistics (median + MAD) to identify good points.\ndet_median = det_mc.median().item()\ndet_mad = (det_mc - det_median).abs().median().item() * 1.4826  # MAD -> sigma\nginv_maxabs = ginv_mc.abs().amax(dim=(1,2))  # max |g^{ij}| at each point\nginv_threshold = ginv_maxabs.median().item() + 10 * ginv_maxabs.std().item()\n\nmask_good = (\n    (det_mc > max(1e-6, det_median - 10 * det_mad)) &\n    (det_mc < det_median + 10 * det_mad) &\n    (ginv_maxabs < max(ginv_threshold, 100.0)) &\n    (~torch.isnan(det_mc)) &\n    (~torch.isinf(ginv_maxabs))\n)\n\nn_good = mask_good.sum().item()\nn_bad = N_MC - n_good\nprint(f'\\n  Outlier filter: {n_good:,} good / {N_MC:,} total ({n_bad} removed)')\nif n_bad > 0:\n    bad_det = det_mc[~mask_good]\n    print(f'    Removed det(g) range: [{bad_det.min().item():.2e}, {bad_det.max().item():.2e}]')\n    bad_ginv = ginv_maxabs[~mask_good]\n    print(f'    Removed max|ginv| range: [{bad_ginv.min().item():.2e}, {bad_ginv.max().item():.2e}]')\n\n# Apply filter\nx_mc = x_mc[mask_good]\ng_mc = g_mc[mask_good]\nginv_mc = ginv_mc[mask_good]\nsqrtdet_mc = sqrtdet_mc[mask_good]\nN_MC_EFF = n_good\n\nvol_K7 = sqrtdet_mc.mean().item()\nprint(f'  Volume density <sqrt(det g)>: {vol_K7:.6f}')\nprint(f'  Filtered det(g): mean={torch.linalg.det(g_mc).mean().item():.6f}, '\n      f'std={torch.linalg.det(g_mc).std().item():.2e}')\nprint(f'  max|ginv|: {ginv_mc.abs().max().item():.4f}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 7: Harmonic 2-Form Basis (b_2 = 21)\n# ============================================================\nprint('\\n  --- Harmonic 2-Forms ---')\nprint(f'  Building {B2} constant-coefficient 2-forms dx^i ^ dx^j...')\n\nprint('  Computing L^2 overlap matrix S_{IJ} = <omega_I, omega_J>_g...')\nt_s = time.time()\n\nS2 = torch.zeros(B2, B2, device=device, dtype=dtype)\n\nfor I in range(B2):\n    a_I, b_I = IDX_2[I]\n    for J in range(I, B2):\n        a_J, b_J = IDX_2[J]\n        val = (ginv_mc[:, a_I, a_J] * ginv_mc[:, b_I, b_J]\n             - ginv_mc[:, a_I, b_J] * ginv_mc[:, b_I, a_J]) * sqrtdet_mc\n        S2[I, J] = val.mean()\n        S2[J, I] = S2[I, J]\n\n# --- Robust eigendecomposition on CPU with Tikhonov regularization ---\nS2_np = S2.cpu().double().numpy()\nS2_np = 0.5 * (S2_np + S2_np.T)  # enforce symmetry\nS2_np = np.nan_to_num(S2_np, nan=0.0, posinf=0.0, neginf=0.0)\n\n# Tikhonov: S2_reg = S2 + eta * I  (bounds condition number)\neta2 = max(1e-10, 1e-6 * np.abs(np.diag(S2_np)).mean())\nS2_reg = S2_np + eta2 * np.eye(B2)\nprint(f'  S2 diag range: [{np.diag(S2_np).min():.4e}, {np.diag(S2_np).max():.4e}]')\nprint(f'  Tikhonov eta = {eta2:.2e}')\n\ntry:\n    eig2_np, vec2_np = np.linalg.eigh(S2_reg)\n    print(f'  numpy eigh succeeded')\nexcept np.linalg.LinAlgError:\n    print(f'  numpy eigh failed, using SVD...')\n    U, s, Vt = np.linalg.svd(S2_reg, full_matrices=True)\n    eig2_np = s\n    vec2_np = U\n    idx_sort = np.argsort(eig2_np)\n    eig2_np = eig2_np[idx_sort]\n    vec2_np = vec2_np[:, idx_sort]\n\neig2 = torch.from_numpy(eig2_np).to(device=device, dtype=dtype)\nvec2 = torch.from_numpy(vec2_np).to(device=device, dtype=dtype)\n\neig2_clamped = eig2.clamp(min=eta2)\ncond2 = eig2_clamped.max().item() / eig2_clamped.min().item()\nprint(f'  S2 eigenvalues: min={eig2.min().item():.6e}, max={eig2.max().item():.6e}')\nprint(f'  S2 condition number: {cond2:.2e}')\n\n# Orthonormalize\nS2_inv_sqrt = vec2 @ torch.diag(1.0 / torch.sqrt(eig2_clamped)) @ vec2.T\nT2 = S2_inv_sqrt  # (21, 21)\n\n# Verify\nS2_gpu = S2.to(device)\nS2_check = T2.T @ S2_gpu @ T2\noff_diag_err = (S2_check - torch.eye(B2, device=device, dtype=dtype)).abs().max().item()\nprint(f'  Orthonormality check: max|S_new - I| = {off_diag_err:.2e}')\nprint(f'  2-form basis ready: {B2} orthonormal forms ({time.time()-t_s:.1f}s)')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 8: Harmonic 3-Form Basis (b_3 = 77)\n# ============================================================\nprint('\\n  --- Harmonic 3-Forms ---')\nprint(f'  Target: {B3} forms = 35 local + 21 M1-global + 21 M2-global')\n\n# Cutoff functions\nt_mc = x_mc[:, 0]\n\ndef smooth_cutoff_left(t, t_max=0.40, width=0.10):\n    x = (t - (t_max - width)) / width\n    return torch.where(x < 0, torch.ones_like(x),\n           torch.where(x > 1, torch.zeros_like(x),\n                       0.5 * (1 + torch.cos(math.pi * x))))\n\ndef smooth_cutoff_right(t, t_min=0.60, width=0.10):\n    x = ((t_min + width) - t) / width\n    return torch.where(x < 0, torch.ones_like(x),\n           torch.where(x > 1, torch.zeros_like(x),\n                       0.5 * (1 + torch.cos(math.pi * x))))\n\nchi_L = smooth_cutoff_left(t_mc)\nchi_R = smooth_cutoff_right(t_mc)\n\nprint(f'  Cutoff weights: <chi_L>={chi_L.mean():.3f}, <chi_R>={chi_R.mean():.3f}')\n\nK3_PAIRS = list(combinations([2, 3, 4, 5], 2))  # 6 pairs\nN_GLOBAL_PER_SIDE = 21\n\ndef get_3form_index(i, j, k):\n    triple = tuple(sorted([i, j, k]))\n    return IDX_3_MAP.get(triple, -1)\n\n# Build 3-form coefficients: shape (77, N_MC_EFF, 35)\nprint(f'  Building 3-form basis coefficients ({N_MC_EFF} MC points)...')\nform3_coeffs = torch.zeros(B3, N_MC_EFF, N_3FORM, device=device, dtype=dtype)\n\n# Local forms (0..34): constant\nfor a in range(N_3FORM):\n    form3_coeffs[a, :, a] = 1.0\n\n# M1-global forms (35..55): chi_L(t) * cos(n*pi*u) * sigma ^ dtheta\nfor a_idx in range(N_GLOBAL_PER_SIDE):\n    form_id = N_3FORM + a_idx\n    pair_idx = a_idx % len(K3_PAIRS)\n    freq = a_idx // len(K3_PAIRS) + 1\n    p, q = K3_PAIRS[pair_idx]\n    comp_idx = get_3form_index(1, p, q)\n    if comp_idx >= 0:\n        modulation = chi_L * torch.cos(freq * math.pi * x_mc[:, p])\n        form3_coeffs[form_id, :, comp_idx] = modulation\n\n# M2-global forms (56..76): chi_R(t) * cos(n*pi*u) * sigma ^ dpsi\nfor b_idx in range(N_GLOBAL_PER_SIDE):\n    form_id = N_3FORM + N_GLOBAL_PER_SIDE + b_idx\n    pair_idx = b_idx % len(K3_PAIRS)\n    freq = b_idx // len(K3_PAIRS) + 1\n    p, q = K3_PAIRS[pair_idx]\n    comp_idx = get_3form_index(6, p, q)\n    if comp_idx < 0:\n        comp_idx = get_3form_index(min(6,p,q), sorted([6,p,q])[1], max(6,p,q))\n    if comp_idx >= 0:\n        modulation = chi_R * torch.cos(freq * math.pi * x_mc[:, p])\n        form3_coeffs[form_id, :, comp_idx] = modulation\n\nprint(f'  3-form basis shape: {form3_coeffs.shape}')\nprint(f'  Local forms:  0..34  (constant on K7)')\nprint(f'  M1 global:   35..55  (localized to left bulk)')\nprint(f'  M2 global:   56..76  (localized to right bulk)')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 9: Orthonormalize 3-Forms with Metric Inner Product\n# ============================================================\nprint('\\n  Computing L^2 overlap matrix for 3-forms...')\nt_s3 = time.time()\n\n# For basis 3-forms e^alpha, e^beta with ordered triples:\n# <e^alpha, e^beta>_g = det(G_sub) where G_sub is the 3x3 submatrix\n# of g^{-1} with rows from alpha and cols from beta.\n\nprint('  Building 3-form metric tensor G3 (35x35) at MC points...')\n\nS3 = torch.zeros(B3, B3, device=device, dtype=dtype)\n\nfor batch_start in range(0, N_MC_EFF, BATCH):\n    batch_end = min(batch_start + BATCH, N_MC_EFF)\n    bs = batch_end - batch_start\n    ginv_b = ginv_mc[batch_start:batch_end]  # (bs, 7, 7)\n    sqrtdet_b = sqrtdet_mc[batch_start:batch_end]  # (bs,)\n    \n    # Build G3 at these points: shape (bs, 35, 35)\n    G3_b = torch.zeros(bs, N_3FORM, N_3FORM, device=device, dtype=dtype)\n    for alpha in range(N_3FORM):\n        i1, j1, k1 = IDX_3[alpha]\n        for beta in range(alpha, N_3FORM):\n            i2, j2, k2 = IDX_3[beta]\n            # det(G_sub) via Leibniz formula\n            val = torch.zeros(bs, device=device, dtype=dtype)\n            for (a,b,c), sgn1 in [((i1,j1,k1),1),((j1,k1,i1),1),((k1,i1,j1),1),\n                                   ((j1,i1,k1),-1),((i1,k1,j1),-1),((k1,j1,i1),-1)]:\n                val += sgn1 * (ginv_b[:,a,i2] * ginv_b[:,b,j2] * ginv_b[:,c,k2])\n            G3_b[:, alpha, beta] = val\n            G3_b[:, beta, alpha] = val\n    \n    forms_b = form3_coeffs[:, batch_start:batch_end, :]  # (77, bs, 35)\n    G3_forms = torch.einsum('xab,Axb->Axa', G3_b, forms_b)  # (77, bs, 35)\n    S3 += torch.einsum('Axc,Bxc->AB', forms_b * sqrtdet_b.unsqueeze(0).unsqueeze(-1),\n                       G3_forms) / N_MC_EFF\n\n# Symmetrize\nS3 = 0.5 * (S3 + S3.T)\n\n# --- Robust eigendecomposition with Tikhonov regularization ---\nprint(f'  S3 diagnostics:')\nS3_np = S3.cpu().double().numpy()\nprint(f'    range: [{S3_np.min():.4e}, {S3_np.max():.4e}]')\nprint(f'    diag range: [{np.diag(S3_np).min():.4e}, {np.diag(S3_np).max():.4e}]')\nprint(f'    NaN: {np.isnan(S3_np).any()}, Inf: {np.isinf(S3_np).any()}')\n\nS3_np = np.nan_to_num(S3_np, nan=0.0, posinf=0.0, neginf=0.0)\n\n# Tikhonov: S3_reg = S3 + eta * I  (bounds condition number)\neta3 = max(1e-10, 1e-6 * np.abs(np.diag(S3_np)).mean())\nS3_reg = S3_np + eta3 * np.eye(B3)\nprint(f'  Tikhonov eta3 = {eta3:.2e}')\n\ntry:\n    eig3_np, vec3_np = np.linalg.eigh(S3_reg)\n    print(f'  numpy eigh succeeded')\nexcept np.linalg.LinAlgError:\n    print(f'  numpy eigh failed, using SVD fallback...')\n    U, s, Vt = np.linalg.svd(S3_reg, full_matrices=True)\n    eig3_np = s\n    vec3_np = U\n    idx_sort = np.argsort(eig3_np)\n    eig3_np = eig3_np[idx_sort]\n    vec3_np = vec3_np[:, idx_sort]\n\neig3 = torch.from_numpy(eig3_np).to(device=device, dtype=dtype)\nvec3 = torch.from_numpy(vec3_np).to(device=device, dtype=dtype)\n\nn_positive = (eig3 > 1e-10).sum().item()\nprint(f'  S3 eigenvalues: {n_positive} positive out of {B3}')\nif n_positive > 0:\n    pos_eigs = eig3[eig3 > 1e-10]\n    print(f'  S3 eig range: [{pos_eigs.min().item():.6e}, {pos_eigs.max().item():.6e}]')\n    print(f'  S3 condition (positive modes): {pos_eigs.max().item()/pos_eigs.min().item():.2e}')\n\n# Keep only well-conditioned positive eigenvalues\neig_max = eig3.max().item()\nthreshold = max(1e-8, 1e-6 * eig_max)\nmask3 = eig3 > threshold\nn_effective = mask3.sum().item()\neig3_pos = eig3[mask3]\nvec3_pos = vec3[:, mask3]\n\nprint(f'  Threshold: {threshold:.2e}, keeping {n_effective} modes')\n\n# Orthonormalize\nT3 = vec3_pos @ torch.diag(1.0 / torch.sqrt(eig3_pos))  # (77, n_eff)\n\n# Pad to full size if needed\nif n_effective < B3:\n    print(f'  Warning: only {n_effective}/{B3} linearly independent 3-forms')\n    print(f'  Padding with zeros (these modes have zero Yukawa coupling)')\n    T3_full = torch.zeros(B3, B3, device=device, dtype=dtype)\n    T3_full[:, :n_effective] = T3\n    T3 = T3_full\n\nprint(f'  3-form basis ready: {n_effective} effective forms ({time.time()-t_s3:.1f}s)')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Yukawa Tensor\n",
    "\n",
    "Compute Y_{IJA} = ∫_{K₇} ω_I ∧ ω_J ∧ ρ_A via Monte Carlo integration.\n",
    "\n",
    "The wedge product of two 2-forms and one 3-form gives a 7-form (top form),\n",
    "which is a scalar density we integrate over K₇."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 10: Wedge Product Infrastructure\n",
    "# ============================================================\n",
    "print('\\n' + '=' * 70)\n",
    "print('  PHASE 3: Yukawa Tensor Computation')\n",
    "print('=' * 70)\n",
    "\n",
    "def permutation_sign(perm):\n",
    "    \"\"\"Sign of a permutation.\"\"\"\n",
    "    n = len(perm)\n",
    "    inv = sum(1 for i in range(n) for j in range(i+1, n) if perm[i] > perm[j])\n",
    "    return (-1) ** inv\n",
    "\n",
    "\n",
    "# Precompute the wedge coefficient table for 2+2+3 = 7 form:\n",
    "# For basis forms omega_I = dx^a ^ dx^b and omega_J = dx^c ^ dx^d\n",
    "# and rho_A = dx^e ^ dx^f ^ dx^g:\n",
    "#\n",
    "# (omega_I ^ omega_J ^ rho_A)_{1234567} = sign(a,b,c,d,e,f,g)\n",
    "#   if {a,b} U {c,d} U {e,f,g} = {0,1,2,3,4,5,6} (disjoint union)\n",
    "#   else 0.\n",
    "#\n",
    "# We precompute W[I,J,alpha] for all I,J in IDX_2, alpha in IDX_3.\n",
    "\n",
    "print('  Precomputing wedge coefficient table W[I,J,alpha]...')\n",
    "t_w = time.time()\n",
    "\n",
    "W_table = np.zeros((N_2FORM, N_2FORM, N_3FORM), dtype=np.float64)\n",
    "\n",
    "for I in range(N_2FORM):\n",
    "    a, b = IDX_2[I]\n",
    "    for J in range(N_2FORM):\n",
    "        c, d = IDX_2[J]\n",
    "        # Check disjointness of {a,b} and {c,d}\n",
    "        if len({a, b} & {c, d}) > 0:\n",
    "            continue\n",
    "        for alpha in range(N_3FORM):\n",
    "            e, f, g = IDX_3[alpha]\n",
    "            # Check that {a,b,c,d,e,f,g} = {0,...,6}\n",
    "            all_idx = {a, b, c, d, e, f, g}\n",
    "            if len(all_idx) == 7:\n",
    "                W_table[I, J, alpha] = permutation_sign([a, b, c, d, e, f, g])\n",
    "\n",
    "W_table_t = torch.from_numpy(W_table).to(device=device, dtype=dtype)\n",
    "\n",
    "n_nonzero = np.count_nonzero(W_table)\n",
    "print(f'  W table: {N_2FORM}x{N_2FORM}x{N_3FORM}, nonzero entries: {n_nonzero}')\n",
    "print(f'  Antisymmetry check W[I,J,:] = -W[J,I,:]: ',\n",
    "      np.allclose(W_table, -W_table.transpose(1, 0, 2)))\n",
    "print(f'  ({time.time()-t_w:.1f}s)')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 11: Yukawa Tensor via MC Integration\n# ============================================================\nprint('\\n  Computing Yukawa tensor Y_{IJA}...')\nprint(f'  Shape: ({B2}, {B2}, {B3}) = {B2*B2*B3:,} components')\nprint(f'  MC points: {N_MC_EFF:,} (filtered)')\n\nt_yuk = time.time()\n\n# Y_{IJA} = integral (omega_I ^ omega_J ^ rho_A)\n#         = integral sum_{alpha,beta,gamma} T2[I,alpha] T2[J,beta]\n#           W[alpha,beta,gamma] (T3 @ form3_coeffs)_A,gamma * sqrtdet\n#\n# In the orthonormal basis:\n# omega_I(x) = sum_alpha T2[alpha, I] * e^{IDX_2[alpha]}     (constant forms)\n# rho_A(x)   = sum_a T3[a, A] * form3_coeffs[a, x, :]       (may vary with x)\n#\n# The Yukawa integral:\n# Y_{IJA} = (1/N) sum_x sum_{alpha,beta} T2[alpha,I] T2[beta,J]\n#           * sum_gamma W[alpha,beta,gamma] rho_A_gamma(x) * sqrtdet(x)\n#\n# where rho_A_gamma(x) = sum_a T3[a,A] * form3_coeffs[a, x, gamma]\n\n# Step 1: Transform 3-form coefficients to orthonormal basis\n# rho_orth[A, x, gamma] = sum_a T3[a, A] * form3_coeffs[a, x, gamma]\nprint('  Step 1: Transform 3-forms to orthonormal basis...')\n# T3: (77, n_eff) or (77, 77), form3_coeffs: (77, N_MC_EFF, 35)\n# rho_orth = T3^T @ form3_coeffs (matrix mult on first axis)\nrho_orth = torch.einsum('aA,axg->Axg', T3.T, form3_coeffs)  # (B3, N_MC_EFF, 35)\n\n# Step 2: At each MC point, compute the weighted rho contribution:\n# R[x, gamma] = rho_orth[A, x, gamma] * sqrtdet(x)\n# Then Y_{IJA} = (1/N) sum_x sum_{alpha,beta,gamma}\n#                 T2[alpha,I] T2[beta,J] W[alpha,beta,gamma] R_A[x,gamma]\n\n# Step 3: Contract W with T2 to get effective wedge in orthonormal 2-form basis\n# W_orth[I,J,gamma] = sum_{alpha,beta} T2[alpha,I] T2[beta,J] W[alpha,beta,gamma]\nprint('  Step 2: Contract wedge table with 2-form transform...')\nT2_np = T2.cpu().numpy()\nW_orth = np.einsum('aI,bJ,abg->IJg', T2_np, T2_np, W_table)  # (21, 21, 35)\nW_orth_t = torch.from_numpy(W_orth).to(device=device, dtype=dtype)\n\n# Step 4: MC integration\n# Y_{IJA} = (1/N) sum_x W_orth[I,J,gamma] * rho_orth[A,x,gamma] * sqrtdet(x)\nprint('  Step 3: MC integration...')\n\nY = torch.zeros(B2, B2, B3, device=device, dtype=dtype)\n\nfor batch_start in range(0, N_MC_EFF, BATCH):\n    batch_end = min(batch_start + BATCH, N_MC_EFF)\n    rho_b = rho_orth[:, batch_start:batch_end, :]  # (B3, bs, 35)\n    sd_b = sqrtdet_mc[batch_start:batch_end]        # (bs,)\n    \n    # weighted_rho[A, bs, gamma] = rho_b[A, bs, gamma] * sqrtdet\n    weighted_rho = rho_b * sd_b.unsqueeze(0).unsqueeze(-1)\n    \n    # Sum over x and gamma:\n    # Y[I,J,A] += sum_x sum_gamma W_orth[I,J,gamma] * weighted_rho[A,x,gamma]\n    # = W_orth[I,J,gamma] . sum_x weighted_rho[A,x,gamma]\n    sum_rho = weighted_rho.sum(dim=1)  # (B3, 35)\n    Y += torch.einsum('IJg,Ag->IJA', W_orth_t, sum_rho)\n\nY = Y / N_MC_EFF\n\nelapsed_yuk = time.time() - t_yuk\nprint(f'\\n  Yukawa tensor computed in {elapsed_yuk:.1f}s')\nprint(f'  Shape: {tuple(Y.shape)}')\nprint(f'  ||Y||_F = {torch.norm(Y).item():.6e}')\nprint(f'  max|Y| = {Y.abs().max().item():.6e}')\nprint(f'  Antisymmetry Y[I,J,A]=-Y[J,I,A]: ',\n      torch.allclose(Y, -Y.permute(1,0,2), atol=1e-10))\n\n# Count effective non-zero couplings\nthreshold = 1e-8 * Y.abs().max().item() if Y.abs().max().item() > 0 else 1e-15\nn_nonzero_Y = (Y.abs() > threshold).sum().item()\nprint(f'  Nonzero couplings (>{threshold:.2e}): {n_nonzero_Y:,} / {B2*B2*B3:,}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: Physical Observables\n",
    "\n",
    "Extract fermion mass matrices, mass ratios, and mixing angles from the\n",
    "Yukawa tensor.\n",
    "\n",
    "**Mass matrix**: $M_{IJ}^{(A)} = Y_{IJA} \\cdot v^A$ (VEV contraction)\n",
    "\n",
    "**Mass eigenvalues**: SVD of $M_{IJ}$\n",
    "\n",
    "**Mixing matrix**: CKM-like matrix from bi-unitary diagonalization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 12: Mass Matrices & Eigenvalues\n",
    "# ============================================================\n",
    "print('\\n' + '=' * 70)\n",
    "print('  PHASE 4: Physical Observables')\n",
    "print('=' * 70)\n",
    "\n",
    "Y_np = Y.cpu().numpy()\n",
    "\n",
    "# === Correlation matrix ===\n",
    "# C_{AB} = sum_{I,J} Y_{IJA} Y_{IJB}\n",
    "C = np.einsum('IJA,IJB->AB', Y_np, Y_np)\n",
    "C_eigs = np.linalg.eigvalsh(C)[::-1]\n",
    "n_significant = np.sum(C_eigs > 1e-10 * C_eigs[0])\n",
    "\n",
    "print(f'\\n  Correlation matrix C = Y^T Y:')\n",
    "print(f'    Shape: ({B3}, {B3})')\n",
    "print(f'    Top 10 eigenvalues: {C_eigs[:10]}')\n",
    "print(f'    Significant modes: {n_significant}')\n",
    "\n",
    "# === Flatten to (B2*B2, B3) and SVD ===\n",
    "Y_flat = Y_np.reshape(B2 * B2, B3)\n",
    "U, sigma, Vh = np.linalg.svd(Y_flat, full_matrices=False)\n",
    "\n",
    "print(f'\\n  SVD of Y_flat ({B2*B2}x{B3}):')\n",
    "print(f'    Top 10 singular values: {sigma[:10]}')\n",
    "print(f'    Effective rank (>1e-8*sigma_1): {np.sum(sigma > 1e-8*sigma[0])}')\n",
    "\n",
    "# === Mass matrices from VEV contraction ===\n",
    "# Choose VEV direction: uniform over 3-form moduli (democratic scenario)\n",
    "# v_A = delta_{A,0}  (simplest: single modulus gets VEV)\n",
    "# More physical: v along the volume mode (A=0 is the phi_0 direction)\n",
    "\n",
    "print(f'\\n  --- Mass Matrix Analysis ---')\n",
    "\n",
    "def extract_masses(Y_tensor, vev_direction, label=''):\n",
    "    \"\"\"Extract mass eigenvalues from Yukawa tensor given VEV direction.\"\"\"\n",
    "    M = np.einsum('IJA,A->IJ', Y_tensor, vev_direction)\n",
    "    # Mass matrix is antisymmetric in I,J (from 2-form wedge)\n",
    "    # Physical masses come from M^dagger M\n",
    "    MdagM = M.T @ M\n",
    "    eigs = np.linalg.eigvalsh(MdagM)[::-1]\n",
    "    masses = np.sqrt(np.maximum(eigs, 0))\n",
    "    \n",
    "    # Top 3 generations\n",
    "    m = masses[:3]\n",
    "    if label:\n",
    "        print(f'\\n  {label}:')\n",
    "        print(f'    Top 3 masses: {m}')\n",
    "        if m[0] > 0:\n",
    "            print(f'    Ratios: m2/m1={m[1]/m[0]:.6f}, m3/m1={m[2]/m[0]:.6f}')\n",
    "            if m[2] > 0:\n",
    "                print(f'    Hierarchy: m1/m3={m[0]/m[2]:.6e}')\n",
    "    return masses, M\n",
    "\n",
    "# VEV scenario 1: Single modulus (volume mode)\n",
    "v1 = np.zeros(B3); v1[0] = 1.0\n",
    "masses_v1, M_v1 = extract_masses(Y_np, v1, 'VEV along volume mode (A=0)')\n",
    "\n",
    "# VEV scenario 2: Democratic (equal weight)\n",
    "v2 = np.ones(B3) / np.sqrt(B3)\n",
    "masses_v2, M_v2 = extract_masses(Y_np, v2, 'VEV democratic (uniform over all moduli)')\n",
    "\n",
    "# VEV scenario 3: Fano-aligned (7 Fano triples get enhanced VEV)\n",
    "FANO_TRIPLE_INDICES = []\n",
    "for (i,j,k) in FANO_LINES:\n",
    "    triple = tuple(sorted([i,j,k]))\n",
    "    if triple in IDX_3_MAP:\n",
    "        FANO_TRIPLE_INDICES.append(IDX_3_MAP[triple])\n",
    "v3 = np.zeros(B3)\n",
    "for fi in FANO_TRIPLE_INDICES:\n",
    "    v3[fi] = 1.0\n",
    "v3 /= np.linalg.norm(v3)\n",
    "masses_v3, M_v3 = extract_masses(Y_np, v3, 'VEV along Fano-aligned modes')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 13: CKM-like Mixing Matrix & Koide Formula\n",
    "# ============================================================\n",
    "\n",
    "print('\\n  --- Mixing Matrix & Physical Ratios ---')\n",
    "\n",
    "# Use the VEV scenario with best hierarchy for mixing analysis\n",
    "# Try all and pick the one with largest m1/m3 ratio\n",
    "best_masses = masses_v2  # democratic often gives richer structure\n",
    "best_M = M_v2\n",
    "best_label = 'democratic VEV'\n",
    "\n",
    "for masses, M, label in [(masses_v1, M_v1, 'volume'), (masses_v2, M_v2, 'democratic'),\n",
    "                          (masses_v3, M_v3, 'Fano')]:\n",
    "    if masses[0] > 0 and masses[2] > 0:\n",
    "        ratio = masses[0] / masses[2]\n",
    "        if ratio > (best_masses[0] / best_masses[2] if best_masses[2] > 0 else 0):\n",
    "            best_masses = masses\n",
    "            best_M = M\n",
    "            best_label = label\n",
    "\n",
    "print(f'  Using {best_label} VEV for mixing analysis')\n",
    "\n",
    "# Extract mixing matrix via bi-unitary decomposition\n",
    "# M = U_L @ diag(m) @ U_R^dag\n",
    "# CKM = U_L(up)^dag @ U_L(down)\n",
    "#\n",
    "# For our single Yukawa tensor, we split into \"up-type\" and \"down-type\"\n",
    "# by contracting with different VEV directions:\n",
    "\n",
    "# Up-type: VEV along first local mode\n",
    "v_up = np.zeros(B3); v_up[0] = 1.0\n",
    "M_up = np.einsum('IJA,A->IJ', Y_np, v_up)[:6, :6]  # 6x6 block\n",
    "\n",
    "# Down-type: VEV along second local mode\n",
    "v_down = np.zeros(B3); v_down[1] = 1.0\n",
    "M_down = np.einsum('IJA,A->IJ', Y_np, v_down)[:6, :6]\n",
    "\n",
    "# SVD\n",
    "U_up, s_up, Vh_up = np.linalg.svd(M_up)\n",
    "U_down, s_down, Vh_down = np.linalg.svd(M_down)\n",
    "\n",
    "# CKM-like mixing matrix (3x3 block)\n",
    "V_ckm = U_up[:3, :3].T @ U_down[:3, :3]\n",
    "\n",
    "print(f'\\n  CKM-like mixing matrix (3x3):')\n",
    "for i in range(3):\n",
    "    row = ' '.join(f'{abs(V_ckm[i,j]):.4f}' for j in range(3))\n",
    "    print(f'    |V| = [{row}]')\n",
    "\n",
    "# Mixing angles (standard parameterization)\n",
    "theta_12 = np.arcsin(abs(V_ckm[0, 1]))\n",
    "theta_23 = np.arcsin(abs(V_ckm[1, 2]))\n",
    "theta_13 = np.arcsin(abs(V_ckm[0, 2]))\n",
    "\n",
    "print(f'\\n  Mixing angles:')\n",
    "print(f'    theta_12 = {np.degrees(theta_12):.2f} deg')\n",
    "print(f'    theta_23 = {np.degrees(theta_23):.2f} deg')\n",
    "print(f'    theta_13 = {np.degrees(theta_13):.2f} deg')\n",
    "\n",
    "# Koide formula: Q = (m1 + m2 + m3)^2 / (3 * (m1^2 + m2^2 + m3^2))\n",
    "# Experimental: Q ~ 2/3 for charged leptons\n",
    "m_top3 = best_masses[:3]\n",
    "if np.sum(m_top3**2) > 0:\n",
    "    Q_koide = (np.sum(m_top3))**2 / (3 * np.sum(m_top3**2))\n",
    "else:\n",
    "    Q_koide = 0.0\n",
    "\n",
    "print(f'\\n  Koide formula:')\n",
    "print(f'    Q = (sum m_i)^2 / (3 * sum m_i^2) = {Q_koide:.6f}')\n",
    "print(f'    Experimental (leptons): Q ~ 0.6667')\n",
    "print(f'    Deviation: {abs(Q_koide - 2/3):.4f}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# Cell 14: Spectral Analysis of Yukawa Tensor\n",
    "# ============================================================\n",
    "print('\\n  --- Spectral Decomposition ---')\n",
    "\n",
    "# Tensor decomposition: Y_{IJA} ~ sum_r lambda_r u_r(I) v_r(J) w_r(A)\n",
    "# Use unfolded SVD for rank analysis\n",
    "\n",
    "# Mode-1 unfolding (flatten J,A)\n",
    "Y1 = Y_np.reshape(B2, B2 * B3)\n",
    "_, s1, _ = np.linalg.svd(Y1, full_matrices=False)\n",
    "\n",
    "# Mode-3 unfolding (flatten I,J)\n",
    "Y3 = Y_np.reshape(B2 * B2, B3)\n",
    "_, s3, _ = np.linalg.svd(Y3, full_matrices=False)\n",
    "\n",
    "print(f'\\n  Mode-1 singular values (top 10): {s1[:10]}')\n",
    "print(f'  Mode-3 singular values (top 10): {s3[:10]}')\n",
    "\n",
    "# Effective tensor rank\n",
    "def effective_rank(sigmas):\n",
    "    return np.sum(sigmas > 1e-8 * sigmas[0]) if sigmas[0] > 0 else 0\n",
    "\n",
    "rank_1 = effective_rank(s1)\n",
    "rank_3 = effective_rank(s3)\n",
    "print(f'\\n  Effective rank:')\n",
    "print(f'    Mode-1 (2-form space): {rank_1}')\n",
    "print(f'    Mode-3 (3-form space): {rank_3}')\n",
    "\n",
    "# === Coupling strength distribution ===\n",
    "Y_abs = np.abs(Y_np)\n",
    "Y_sorted = np.sort(Y_abs.ravel())[::-1]\n",
    "n_above = [np.sum(Y_abs > thresh) for thresh in [1e-2, 1e-4, 1e-6, 1e-8]]\n",
    "\n",
    "print(f'\\n  Coupling distribution:')\n",
    "print(f'    |Y| > 1e-2: {n_above[0]:,}')\n",
    "print(f'    |Y| > 1e-4: {n_above[1]:,}')\n",
    "print(f'    |Y| > 1e-6: {n_above[2]:,}')\n",
    "print(f'    |Y| > 1e-8: {n_above[3]:,}')\n",
    "print(f'    Total: {B2*B2*B3:,}')\n",
    "\n",
    "# === Generation structure ===\n",
    "# The 21 2-forms naturally split into groups by the TCS building blocks:\n",
    "# M1 contributes b2(M1)=11 2-forms, M2 contributes b2(M2)=10\n",
    "# Check if the Yukawa tensor has block structure\n",
    "\n",
    "# Block norms\n",
    "Y_M1M1 = np.linalg.norm(Y_np[:B2_M1, :B2_M1, :])\n",
    "Y_M2M2 = np.linalg.norm(Y_np[B2_M1:, B2_M1:, :])\n",
    "Y_M1M2 = np.linalg.norm(Y_np[:B2_M1, B2_M1:, :])\n",
    "\n",
    "print(f'\\n  Block structure (M1={B2_M1}, M2={B2_M2}):')\n",
    "print(f'    ||Y[M1,M1,:]|| = {Y_M1M1:.6e}')\n",
    "print(f'    ||Y[M2,M2,:]|| = {Y_M2M2:.6e}')\n",
    "print(f'    ||Y[M1,M2,:]|| = {Y_M1M2:.6e}  (cross-block)')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# ============================================================\n# Cell 15: Results Summary & Export\n# ============================================================\ntotal_time = time.time() - T_START\n\nprint('\\n' + '=' * 70)\nprint('  YUKAWA TENSOR COMPUTATION — SUMMARY')\nprint('=' * 70)\n\nprint(f'''\n  ATLAS:\n    Parameters: {n_params:,}\n    det(g) mean: {torch.linalg.det(g_mc).mean().item():.6f} (target: {DET_G_TARGET})\n    Metric positive definite: True\n\n  HARMONIC FORMS:\n    2-forms: {B2} (orthonormalized, condition {eig2.max().item()/eig2.min().item():.2f})\n    3-forms: {n_effective} effective / {B3} target\n      35 local + 21 M1-global + 21 M2-global\n\n  YUKAWA TENSOR:\n    Shape: {B2} x {B2} x {B3}\n    ||Y||_F = {torch.norm(Y).item():.6e}\n    Antisymmetric: Y[I,J,A] = -Y[J,I,A]\n    Effective rank (mode-1): {rank_1}\n    Effective rank (mode-3): {rank_3}\n\n  MASS SPECTRUM (democratic VEV):\n    Top 3 masses: {best_masses[:3]}\n    Koide Q = {Q_koide:.4f} (experimental: 0.6667)\n\n  MIXING ANGLES:\n    theta_12 = {np.degrees(theta_12):.2f} deg\n    theta_23 = {np.degrees(theta_23):.2f} deg\n    theta_13 = {np.degrees(theta_13):.2f} deg\n\n  MC SAMPLING:\n    Original: {N_MC:,} points\n    After outlier filter: {N_MC_EFF:,} points\n\n  TIMING:\n    Total: {total_time:.0f}s ({total_time/60:.1f} min)\n''')\n\n# === Save results ===\nresults = {\n    'version': 'Y1',\n    'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n    'atlas': {\n        'total_params': int(n_params),\n        'det_g_mean': float(torch.linalg.det(g_mc).mean().item()),\n        'det_g_target': float(DET_G_TARGET),\n    },\n    'topology': {\n        'b2': int(B2), 'b3': int(B3), 'H_star': int(H_STAR),\n        'b2_M1': int(B2_M1), 'b3_M1': int(B3_M1),\n        'b2_M2': int(B2_M2), 'b3_M2': int(B3_M2),\n    },\n    'harmonic_forms': {\n        'n_2forms': int(B2),\n        'n_3forms_effective': int(n_effective),\n        'S2_condition': float(eig2.max().item() / eig2.min().item()),\n    },\n    'yukawa': {\n        'shape': [int(B2), int(B2), int(B3)],\n        'norm_F': float(torch.norm(Y).item()),\n        'max_abs': float(Y.abs().max().item()),\n        'antisymmetric': bool(torch.allclose(Y, -Y.permute(1,0,2), atol=1e-10)),\n        'rank_mode1': int(rank_1),\n        'rank_mode3': int(rank_3),\n        'svd_top10': s3[:10].tolist(),\n    },\n    'physics': {\n        'masses_top3_democratic': best_masses[:3].tolist(),\n        'koide_Q': float(Q_koide),\n        'theta_12_deg': float(np.degrees(theta_12)),\n        'theta_23_deg': float(np.degrees(theta_23)),\n        'theta_13_deg': float(np.degrees(theta_13)),\n        'V_ckm_abs': np.abs(V_ckm).tolist(),\n    },\n    'block_structure': {\n        'Y_M1M1_norm': float(Y_M1M1),\n        'Y_M2M2_norm': float(Y_M2M2),\n        'Y_M1M2_norm': float(Y_M1M2),\n    },\n    'mc_params': {\n        'n_mc': int(N_MC),\n        'n_mc_effective': int(N_MC_EFF),\n        'batch_size': int(BATCH),\n    },\n    'timing_seconds': float(total_time),\n}\n\nwith open('outputs/gift_yukawa_results.json', 'w') as f:\n    json.dump(results, f, indent=2)\nprint('Saved: outputs/gift_yukawa_results.json')\n\n# Save tensor\ntorch.save(Y.cpu(), 'outputs/yukawa_tensor_Y1.pt')\nprint('Saved: outputs/yukawa_tensor_Y1.pt')\n\nprint('\\n' + '=' * 70)\nprint('  DONE — Phase 3 Yukawa Pipeline Complete')\nprint('=' * 70)",
   "execution_count": null,
   "outputs": []
  }
 ]
}