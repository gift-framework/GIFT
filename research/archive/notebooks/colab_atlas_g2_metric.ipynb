{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gift-framework/GIFT/blob/research/notebooks/colab_atlas_g2_metric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn0OOTiFCxL4"
      },
      "source": [
        "# GIFT Atlas G₂ Metric — 3-Chart TCS Construction + Spectral Bridge\n",
        "\n",
        "**Version**: A1 (2026-02-13)\n",
        "**Hardware**: A100 GPU (Colab)\n",
        "**Duration**: ~60 min total\n",
        "\n",
        "## What This Notebook Does\n",
        "1. **Phase 1**: Train 3 chart PINNs independently (Neck + Bulk_L + Bulk_R)\n",
        "2. **Phase 2**: Schwarz alternating iterations (match at interfaces)\n",
        "3. **Phase 3**: Joint fine-tuning with global torsion penalty\n",
        "4. **Phase 4**: Spectral bridge — Laplacian eigenvalues on K₇\n",
        "\n",
        "## The Atlas Architecture\n",
        "```\n",
        "K₇ = Bulk_L ∪ Neck ∪ Bulk_R\n",
        "\n",
        "Bulk_L: ACyl CY₃(Quintic) × S¹    b₂=11, b₃=40\n",
        "Neck:   K3 × T² × [δ, L-δ]        matching region\n",
        "Bulk_R: ACyl CY₃(CI(2,2,2)) × S¹  b₂=10, b₃=37\n",
        "```\n",
        "\n",
        "## Key GIFT Predictions Tested\n",
        "- det(g) = 65/32 everywhere (all charts)\n",
        "- Torsion ≪ Joyce threshold (0.0288) — now on K₇, not T⁷\n",
        "- λ₁ × H* = dim(G₂) = 14 (master equation)\n",
        "- λₙ ∝ γₙ (Riemann zeta zero correspondence)\n",
        "\n",
        "## What's New vs P1/P2\n",
        "- **3 separate coordinate charts** with explicit TCS transition maps\n",
        "- **Kovalev twist** at right interface (circle swap + HK rotation)\n",
        "- **Asymptotic decay constraints** in bulk regions\n",
        "- **Cholesky-level blending** preserving positive definiteness\n",
        "- Topology is now K₇ (b₃=77), not T⁷ (b₃=35)"
      ],
      "id": "cn0OOTiFCxL4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4wYlFpkCxL6",
        "outputId": "a78070ea-e82e-4e1d-a139-4f658ac1483a"
      },
      "source": [
        "# Setup\n",
        "import os, sys, time, math, json\n",
        "from dataclasses import dataclass, field\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "dtype = torch.float64  # double precision for metric accuracy\n",
        "\n",
        "print(f\"PyTorch {torch.__version__}\")\n",
        "print(f\"Device: {device}\")\n",
        "if device.type == 'cuda':\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    print(f\"Memory: {props.total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 2.9.0+cu128\n",
            "Device: cuda\n",
            "GPU: NVIDIA A100-SXM4-80GB\n",
            "Memory: 85.1 GB\n"
          ]
        }
      ],
      "id": "z4wYlFpkCxL6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5jjOXdbCxL7"
      },
      "source": [
        "## 1. GIFT Topological Constants (Lean-verified)"
      ],
      "id": "J5jjOXdbCxL7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51V3D7nCxL7",
        "outputId": "22ff0a1c-7419-4686-8c58-2cf2eec9dd39"
      },
      "source": [
        "# === Topological constants (zero free parameters) ===\n",
        "B2 = 21                        # b₂(K₇)\n",
        "B3 = 77                        # b₃(K₇)\n",
        "DIM_G2 = 14                   # dim(G₂) holonomy\n",
        "DIM_E8 = 248                  # dim(E₈)\n",
        "RANK_E8 = 8                   # rank(E₈)\n",
        "H_STAR = B2 + B3 + 1          # = 99\n",
        "DET_G_TARGET = 65 / 32        # = 2.03125\n",
        "TORSION_THRESHOLD = 0.0288    # Joyce ε₀\n",
        "SCALE_FACTOR = (65 / 32) ** (1 / 14)  # ≈ 1.0543\n",
        "\n",
        "# === TCS building block Betti numbers ===\n",
        "B2_M1 = 11                    # b₂(Quintic)\n",
        "B3_M1 = 40                    # b₃(Quintic)\n",
        "B2_M2 = 10                    # b₂(CI(2,2,2))\n",
        "B3_M2 = 37                    # b₃(CI(2,2,2))\n",
        "\n",
        "# === Spectral predictions ===\n",
        "LAMBDA_1_PREDICTED = DIM_G2 / H_STAR  # = 14/99 ≈ 0.14141\n",
        "\n",
        "# === Domain layout (coord[0] = t parameter) ===\n",
        "# Overlap widths chosen for smooth Schwarz convergence\n",
        "DOMAIN_BULK_L  = (0.00, 0.40)\n",
        "DOMAIN_NECK    = (0.25, 0.75)\n",
        "DOMAIN_BULK_R  = (0.60, 1.00)\n",
        "OVERLAP_LEFT   = (0.25, 0.40)  # Bulk_L ∩ Neck\n",
        "OVERLAP_RIGHT  = (0.60, 0.75)  # Neck ∩ Bulk_R\n",
        "\n",
        "# === ACyl decay rate ===\n",
        "MU_DECAY = 0.8  # exponential decay rate for ACyl CY metrics\n",
        "\n",
        "print(\"GIFT Atlas Constants:\")\n",
        "print(f\"  b₂={B2}, b₃={B3}, H*={H_STAR}, dim(G₂)={DIM_G2}\")\n",
        "print(f\"  det(g) target = {DET_G_TARGET}\")\n",
        "print(f\"  M₁ (Quintic): b₂={B2_M1}, b₃={B3_M1}\")\n",
        "print(f\"  M₂ (CI(2,2,2)): b₂={B2_M2}, b₃={B3_M2}\")\n",
        "print(f\"  Mayer-Vietoris check: {B2_M1}+{B2_M2}={B2_M1+B2_M2} = b₂={B2} ✓\")\n",
        "print(f\"  Mayer-Vietoris check: {B3_M1}+{B3_M2}={B3_M1+B3_M2} = b₃={B3} ✓\")\n",
        "print(f\"  Predicted λ₁ = {DIM_G2}/{H_STAR} = {LAMBDA_1_PREDICTED:.6f}\")\n",
        "print(f\"  Domain layout: L=[{DOMAIN_BULK_L}] N=[{DOMAIN_NECK}] R=[{DOMAIN_BULK_R}]\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GIFT Atlas Constants:\n",
            "  b₂=21, b₃=77, H*=99, dim(G₂)=14\n",
            "  det(g) target = 2.03125\n",
            "  M₁ (Quintic): b₂=11, b₃=40\n",
            "  M₂ (CI(2,2,2)): b₂=10, b₃=37\n",
            "  Mayer-Vietoris check: 11+10=21 = b₂=21 ✓\n",
            "  Mayer-Vietoris check: 40+37=77 = b₃=77 ✓\n",
            "  Predicted λ₁ = 14/99 = 0.141414\n",
            "  Domain layout: L=[(0.0, 0.4)] N=[(0.25, 0.75)] R=[(0.6, 1.0)]\n"
          ]
        }
      ],
      "id": "J51V3D7nCxL7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRvFO3LVCxL8"
      },
      "source": [
        "## 2. G₂ 3-Form, Generators, and TCS Coordinate System"
      ],
      "id": "LRvFO3LVCxL8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7Jle7NuCxL8",
        "outputId": "2a1ff729-9cc9-46dc-9ade-cbe08bc9cb3f"
      },
      "source": [
        "# Standard associative 3-form on R⁷ (from G2Holonomy.lean)\n",
        "# φ₀ = e¹²³ + e¹⁴⁵ + e¹⁶⁷ + e²⁴⁶ − e²⁵⁷ − e³⁴⁷ − e³⁵⁶\n",
        "#\n",
        "# TCS coordinate convention:\n",
        "#   coord[0] = t   (neck/cylindrical parameter, maps to radial direction)\n",
        "#   coord[1] = θ   (fiber S¹)\n",
        "#   coord[2:6] = (u₁, u₂, u₃, u₄)  (K3 fiber coordinates)\n",
        "#   coord[6] = ψ   (outer S¹)\n",
        "#\n",
        "# The G₂ 3-form in TCS product form:\n",
        "#   φ = dψ ∧ ω_K3 + dψ ∧ dr ∧ dθ + Re(Ω_K3) ∧ dr − Im(Ω_K3) ∧ dθ\n",
        "# In frame: φ = e⁰¹² + e⁰³⁴ + e⁰⁵⁶ + e¹³⁵ − e¹⁴⁶ − e²³⁶ − e²⁴⁵\n",
        "# (with our coordinate ordering: 0=t, 1=θ, 2=u₁, 3=u₂, 4=u₃, 5=u₄, 6=ψ)\n",
        "\n",
        "STANDARD_G2_FORM = [\n",
        "    ((0, 1, 2), +1.0),\n",
        "    ((0, 3, 4), +1.0),\n",
        "    ((0, 5, 6), +1.0),\n",
        "    ((1, 3, 5), +1.0),\n",
        "    ((1, 4, 6), -1.0),\n",
        "    ((2, 3, 6), -1.0),\n",
        "    ((2, 4, 5), -1.0),\n",
        "]\n",
        "\n",
        "FANO_LINES = [(0, 1, 3), (1, 2, 4), (2, 3, 5), (3, 4, 6), (4, 5, 0), (5, 6, 1), (6, 0, 2)]\n",
        "\n",
        "\n",
        "def build_phi0_tensor():\n",
        "    \"\"\"Full 7×7×7 antisymmetric tensor for the standard G₂ form.\"\"\"\n",
        "    phi0 = np.zeros((7, 7, 7), dtype=np.float64)\n",
        "    for (indices, sign) in STANDARD_G2_FORM:\n",
        "        i, j, k = indices\n",
        "        phi0[i, j, k] = sign;  phi0[j, k, i] = sign;  phi0[k, i, j] = sign\n",
        "        phi0[j, i, k] = -sign; phi0[i, k, j] = -sign; phi0[k, j, i] = -sign\n",
        "    return phi0\n",
        "\n",
        "\n",
        "PHI0_TENSOR = build_phi0_tensor()\n",
        "\n",
        "\n",
        "def phi0_components(normalize=True):\n",
        "    \"\"\"Standard G₂ 3-form as 35 independent components.\"\"\"\n",
        "    phi0 = np.zeros(35, dtype=np.float64)\n",
        "    idx = 0\n",
        "    for i in range(7):\n",
        "        for j in range(i + 1, 7):\n",
        "            for k in range(j + 1, 7):\n",
        "                phi0[idx] = PHI0_TENSOR[i, j, k]\n",
        "                idx += 1\n",
        "    if normalize:\n",
        "        phi0 *= SCALE_FACTOR\n",
        "    return phi0\n",
        "\n",
        "\n",
        "def g2_generators():\n",
        "    \"\"\"14 generators of G₂ ⊂ so(7).\"\"\"\n",
        "    gens = np.zeros((14, 7, 7), dtype=np.float64)\n",
        "    for idx, (i, j, k) in enumerate(FANO_LINES):\n",
        "        gens[idx, i, j] = 1;  gens[idx, j, i] = -1\n",
        "    for idx in range(7):\n",
        "        i, j, k = idx, (idx + 1) % 7, (idx + 3) % 7\n",
        "        gens[7 + idx, i, k] = 1;    gens[7 + idx, k, i] = -1\n",
        "        gens[7 + idx, j, k] = 0.5;  gens[7 + idx, k, j] = -0.5\n",
        "    for idx in range(14):\n",
        "        norm = np.linalg.norm(gens[idx])\n",
        "        if norm > 1e-10:\n",
        "            gens[idx] /= norm\n",
        "    return gens\n",
        "\n",
        "\n",
        "def compute_lie_derivatives():\n",
        "    \"\"\"Lie derivatives (L_Xa φ₀) for each G₂ generator. Shape: (14, 35).\"\"\"\n",
        "    generators = g2_generators()\n",
        "    lie_derivs = np.zeros((14, 35), dtype=np.float64)\n",
        "    for a in range(14):\n",
        "        X = generators[a]\n",
        "        idx = 0\n",
        "        for i in range(7):\n",
        "            for j in range(i + 1, 7):\n",
        "                for k in range(j + 1, 7):\n",
        "                    val = 0.0\n",
        "                    for l in range(7):\n",
        "                        val += X[i, l] * PHI0_TENSOR[l, j, k]\n",
        "                        val += X[j, l] * PHI0_TENSOR[i, l, k]\n",
        "                        val += X[k, l] * PHI0_TENSOR[i, j, l]\n",
        "                    lie_derivs[a, idx] = val\n",
        "                    idx += 1\n",
        "    return lie_derivs\n",
        "\n",
        "\n",
        "LIE_DERIVATIVES = compute_lie_derivatives()\n",
        "print(f\"G₂ generators: 14 matrices in so(7)\")\n",
        "print(f\"Lie derivative matrix: {LIE_DERIVATIVES.shape}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G₂ generators: 14 matrices in so(7)\n",
            "Lie derivative matrix: (14, 35)\n"
          ]
        }
      ],
      "id": "F7Jle7NuCxL8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPxrT0gzCxL9"
      },
      "source": [
        "## 3. TCS Transition Maps (Kovalev Twist)\n",
        "\n",
        "The Kovalev twist at the right interface swaps the two S¹ factors\n",
        "and applies a hyper-Kähler rotation (I ↦ J) on the K3 fiber.\n",
        "\n",
        "**Left overlap** (Bulk_L ∩ Neck): identity on all coordinates.\n",
        "**Right overlap** (Neck → Bulk_R transition):\n",
        "  - t: shared global coordinate (no reversal needed)\n",
        "  - θ_bulk = ψ_neck      (circle swap)\n",
        "  - ψ_bulk = θ_neck      (circle swap)\n",
        "  - u_bulk = R⁻¹ · u_neck (inverse HK rotation on K3 fiber)\n",
        "\n",
        "For interface matching, we transform neck coordinates to bulk_R\n",
        "coordinates using R⁻¹, then pull back the bulk_R metric through\n",
        "the transition Jacobian J to compare in neck coordinates."
      ],
      "id": "zPxrT0gzCxL9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPtYHwVLCxL9",
        "outputId": "bb7c831a-37c3-4062-f572-d4717b7348b2"
      },
      "source": [
        "def build_kovalev_twist_jacobian():\n",
        "    \"\"\"\n",
        "    7×7 Jacobian of the Neck → Bulk_R transition map.\n",
        "\n",
        "    Coordinate ordering: (t, θ, u₁, u₂, u₃, u₄, ψ)\n",
        "    Indices:             (0, 1,  2,  3,  4,  5,  6)\n",
        "\n",
        "    The transition map (neck chart → bulk_R chart):\n",
        "      t_bulk = t_neck          → ∂t_bulk/∂t_neck = +1  (shared global t)\n",
        "      θ_bulk = ψ_neck          → ∂θ_bulk/∂ψ_neck = +1  (circle swap)\n",
        "      u_bulk = R⁻¹_HK · u_neck → 4×4 inverse HK rotation\n",
        "      ψ_bulk = θ_neck          → ∂ψ_bulk/∂θ_neck = +1  (circle swap)\n",
        "\n",
        "    Note: t is a shared global coordinate — no reversal needed.\n",
        "    The Kovalev twist only affects transverse coordinates (θ, ψ, K3).\n",
        "    \"\"\"\n",
        "    J = np.zeros((7, 7), dtype=np.float64)\n",
        "\n",
        "    # t → t (shared global coordinate, no reversal)\n",
        "    J[0, 0] = 1.0\n",
        "\n",
        "    # θ_bulk = ψ_neck (circle swap: coord 1 ← coord 6)\n",
        "    J[1, 6] = 1.0\n",
        "\n",
        "    # K3 inverse HK rotation: R⁻¹ where R: (u₁,u₂,u₃,u₄) → (u₃,−u₁,u₄,u₂)\n",
        "    # R⁻¹: (u₁,u₂,u₃,u₄)_neck → (−u₂,u₄,u₁,u₃)_bulk\n",
        "    J[2, 3] = -1.0   # u₁_bulk = −u₂_neck\n",
        "    J[3, 5] = 1.0    # u₂_bulk = u₄_neck\n",
        "    J[4, 2] = 1.0    # u₃_bulk = u₁_neck\n",
        "    J[5, 4] = 1.0    # u₄_bulk = u₃_neck\n",
        "\n",
        "    # ψ_bulk = θ_neck (circle swap: coord 6 ← coord 1)\n",
        "    J[6, 1] = 1.0\n",
        "\n",
        "    return J\n",
        "\n",
        "\n",
        "KOVALEV_JACOBIAN = build_kovalev_twist_jacobian()\n",
        "KOVALEV_JACOBIAN_T = torch.from_numpy(KOVALEV_JACOBIAN).to(dtype)\n",
        "\n",
        "# Verify it's orthogonal (det = ±1, J^T J = I)\n",
        "_JTJ = KOVALEV_JACOBIAN @ KOVALEV_JACOBIAN.T\n",
        "_det_J = np.linalg.det(KOVALEV_JACOBIAN)\n",
        "print(f\"\\nKovalev twist Jacobian:\")\n",
        "print(f\"  det(J) = {_det_J:.0f} (should be ±1)\")\n",
        "print(f\"  ||J^T J - I|| = {np.linalg.norm(_JTJ - np.eye(7)):.2e} (should be ~0)\")\n",
        "\n",
        "\n",
        "def kovalev_twist_coords(x_neck):\n",
        "    \"\"\"\n",
        "    Apply Kovalev transition map: Neck coordinates → Bulk_R coordinates.\n",
        "\n",
        "    x_neck: (N, 7) tensor in Neck chart\n",
        "    Returns: (N, 7) tensor in Bulk_R chart coordinates\n",
        "\n",
        "    The transition map applies:\n",
        "      t: unchanged (shared global coordinate)\n",
        "      circles: θ_bulk = ψ_neck, ψ_bulk = θ_neck (swap)\n",
        "      K3: u_bulk = R⁻¹ · u_neck (inverse hyper-Kahler rotation)\n",
        "    \"\"\"\n",
        "    x_bulk = x_neck.clone()\n",
        "    # t unchanged (both charts use global t)\n",
        "    # x_bulk[:, 0] already correct from clone\n",
        "\n",
        "    # Circle swap: θ_bulk ← ψ_neck, ψ_bulk ← θ_neck\n",
        "    x_bulk[:, 1] = x_neck[:, 6]\n",
        "    x_bulk[:, 6] = x_neck[:, 1]\n",
        "\n",
        "    # K3 inverse HK rotation: (u₁,u₂,u₃,u₄)_neck → (−u₂,u₄,u₁,u₃)_bulk\n",
        "    x_bulk[:, 2] = torch.fmod(-x_neck[:, 3] + 1.0, 1.0)  # u₁_bulk = −u₂_neck (mod 1)\n",
        "    x_bulk[:, 3] = x_neck[:, 5]                            # u₂_bulk = u₄_neck\n",
        "    x_bulk[:, 4] = x_neck[:, 2]                            # u₃_bulk = u₁_neck\n",
        "    x_bulk[:, 5] = x_neck[:, 4]                            # u₄_bulk = u₃_neck\n",
        "\n",
        "    return x_bulk\n",
        "\n",
        "\n",
        "def transform_metric_kovalev(g_bulk_R, device_ref=None):\n",
        "    \"\"\"\n",
        "    Pull back bulk_R metric to neck coordinates via the transition Jacobian.\n",
        "    g_neck_ab = J^T_ai g_bulk_ij J_jb\n",
        "\n",
        "    Since J is orthogonal (|det|=1), this preserves eigenvalues and det.\n",
        "\n",
        "    g_bulk_R: (N, 7, 7) metric in bulk_R chart\n",
        "    Returns: (N, 7, 7) in neck coordinates\n",
        "    \"\"\"\n",
        "    dev = device_ref or g_bulk_R.device\n",
        "    J = KOVALEV_JACOBIAN_T.to(dev)\n",
        "    # g' = J^T @ g @ J (batched)\n",
        "    return torch.einsum('ai,nij,jb->nab', J.T, g_bulk_R, J)\n",
        "\n",
        "\n",
        "# Quick test\n",
        "with torch.no_grad():\n",
        "    _x_test = torch.rand(10, 7, device=device, dtype=dtype)\n",
        "    _x_twisted = kovalev_twist_coords(_x_test)\n",
        "    print(f\"  Twist test: input range [{_x_test.min():.2f}, {_x_test.max():.2f}]\")\n",
        "    print(f\"             output range [{_x_twisted.min():.2f}, {_x_twisted.max():.2f}]\")\n",
        "    del _x_test, _x_twisted"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Kovalev twist Jacobian:\n",
            "  det(J) = -1 (should be ±1)\n",
            "  ||J^T J - I|| = 0.00e+00 (should be ~0)\n",
            "  Twist test: input range [0.01, 0.98]\n",
            "             output range [0.01, 0.98]\n"
          ]
        }
      ],
      "id": "fPtYHwVLCxL9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxX1sVIYCxL-"
      },
      "source": [
        "## 4. Neural Network Architectures\n",
        "\n",
        "Three PINNs, one per chart:\n",
        "- **NeckPINN**: G₂ adjoint parameterization (14 DOF → 35 3-form components)\n",
        "- **BulkCYPINN_L**: Cholesky-parameterized for ACyl CY₃(Quintic) × S¹\n",
        "- **BulkCYPINN_R**: Cholesky-parameterized for ACyl CY₃(CI(2,2,2)) × S¹"
      ],
      "id": "VxX1sVIYCxL-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5Oe6BPdCxL_",
        "outputId": "2a28fe66-04b3-4231-f4ed-9a7b6ecb56a7"
      },
      "source": [
        "class FourierFeatures(nn.Module):\n",
        "    \"\"\"Random Fourier features with periodic-aware encoding.\n",
        "\n",
        "    For S¹ coordinates (θ, ψ = coords 1, 6), uses deterministic harmonics.\n",
        "    For remaining coords, uses random Fourier features.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=7, num_random_freq=24, num_periodic_freq=8, scale=1.0):\n",
        "        super().__init__()\n",
        "        # Random features for non-periodic coords (t, u₁..u₄)\n",
        "        n_nonperiodic = input_dim - 2  # 5 non-periodic coords\n",
        "        B_rand = torch.randn(num_random_freq, n_nonperiodic, dtype=dtype) * scale\n",
        "        self.register_buffer('B_rand', B_rand)\n",
        "\n",
        "        # Deterministic harmonics for S¹ coords (θ, ψ)\n",
        "        k = torch.arange(1, num_periodic_freq + 1, dtype=dtype).unsqueeze(1)\n",
        "        self.register_buffer('k_periodic', k)\n",
        "\n",
        "        self.output_dim = 2 * num_random_freq + 4 * num_periodic_freq\n",
        "        self.num_periodic_freq = num_periodic_freq\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"x: (N, 7) → features: (N, output_dim).\"\"\"\n",
        "        # Non-periodic coords: t, u₁, u₂, u₃, u₄ (indices 0, 2, 3, 4, 5)\n",
        "        x_nonper = torch.stack([x[:, 0], x[:, 2], x[:, 3], x[:, 4], x[:, 5]], dim=1)\n",
        "        proj = 2 * math.pi * x_nonper @ self.B_rand.T\n",
        "        feat_rand = torch.cat([torch.cos(proj), torch.sin(proj)], dim=-1)\n",
        "\n",
        "        # Periodic coords: θ = x[:,1], ψ = x[:,6]\n",
        "        theta = x[:, 1:2] * 2 * math.pi  # scale to [0, 2π)\n",
        "        psi = x[:, 6:7] * 2 * math.pi\n",
        "\n",
        "        # Harmonics: sin(k·θ), cos(k·θ), sin(k·ψ), cos(k·ψ)\n",
        "        k = self.k_periodic.T  # (1, num_freq)\n",
        "        feat_periodic = torch.cat([\n",
        "            torch.sin(theta * k), torch.cos(theta * k),\n",
        "            torch.sin(psi * k), torch.cos(psi * k),\n",
        "        ], dim=-1)\n",
        "\n",
        "        return torch.cat([feat_rand, feat_periodic], dim=-1)\n",
        "\n",
        "\n",
        "class NeckPINN(nn.Module):\n",
        "    \"\"\"\n",
        "    G₂-native PINN for the TCS neck region.\n",
        "\n",
        "    Architecture:\n",
        "        7D coords → Fourier → MLP(256×4) → 14 G₂ adjoint params\n",
        "        → Lie derivatives → 35 3-form components\n",
        "\n",
        "    Ansatz: φ(x) = φ₀ + perturbation_scale × δφ(x)\n",
        "    \"\"\"\n",
        "    def __init__(self, num_random_freq=24, num_periodic_freq=8,\n",
        "                 hidden_dims=None, perturbation_scale=0.2):\n",
        "        super().__init__()\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = [256, 256, 256, 128]\n",
        "        self.perturbation_scale = perturbation_scale\n",
        "\n",
        "        self.register_buffer('phi0', torch.from_numpy(phi0_components(True)).to(dtype))\n",
        "        self.register_buffer('lie_derivs', torch.from_numpy(LIE_DERIVATIVES).to(dtype))\n",
        "\n",
        "        self.fourier = FourierFeatures(7, num_random_freq, num_periodic_freq)\n",
        "        layers = []\n",
        "        in_dim = self.fourier.output_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [nn.Linear(in_dim, h, dtype=dtype), nn.SiLU()]\n",
        "            in_dim = h\n",
        "        layers.append(nn.Linear(in_dim, 14, dtype=dtype))\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"x: (N,7) → φ: (N,35) 3-form components.\"\"\"\n",
        "        adj = self.mlp(self.fourier(x))\n",
        "        delta_phi = adj @ self.lie_derivs\n",
        "        return self.phi0.unsqueeze(0) + self.perturbation_scale * delta_phi\n",
        "\n",
        "    def phi_tensor(self, x):\n",
        "        \"\"\"x: (N,7) → full antisymmetric 3-tensor (N,7,7,7).\"\"\"\n",
        "        comp = self.forward(x)\n",
        "        N = comp.shape[0]\n",
        "        phi = torch.zeros(N, 7, 7, 7, device=x.device, dtype=x.dtype)\n",
        "        idx = 0\n",
        "        for i in range(7):\n",
        "            for j in range(i + 1, 7):\n",
        "                for k in range(j + 1, 7):\n",
        "                    v = comp[:, idx]\n",
        "                    phi[:, i, j, k] = v;  phi[:, j, k, i] = v;  phi[:, k, i, j] = v\n",
        "                    phi[:, j, i, k] = -v; phi[:, i, k, j] = -v; phi[:, k, j, i] = -v\n",
        "                    idx += 1\n",
        "        return phi\n",
        "\n",
        "    def metric(self, x):\n",
        "        \"\"\"g_ij = (1/6) Σ_{k,l} φ_ikl φ_jkl. Returns (N,7,7).\"\"\"\n",
        "        phi = self.phi_tensor(x)\n",
        "        return torch.einsum('nikl,njkl->nij', phi, phi) / 6.0\n",
        "\n",
        "    def det_g(self, x):\n",
        "        return torch.linalg.det(self.metric(x))\n",
        "\n",
        "    def param_count(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "\n",
        "class BulkCYPINN(nn.Module):\n",
        "    \"\"\"\n",
        "    Cholesky-parameterized PINN for ACyl CY₃ × S¹ bulk regions.\n",
        "\n",
        "    Metric: g = (L₀ + perturbation_scale × δL(x)) @ (...)ᵀ\n",
        "    Guaranteed positive-definite by construction.\n",
        "\n",
        "    Warm-start: L₀ encodes the asymptotic CY product metric.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_random_freq=24, num_periodic_freq=8,\n",
        "                 hidden_dims=None, perturbation_scale=0.2,\n",
        "                 base_diag=None):\n",
        "        super().__init__()\n",
        "        if hidden_dims is None:\n",
        "            hidden_dims = [256, 256, 256, 128]\n",
        "        self.perturbation_scale = perturbation_scale\n",
        "\n",
        "        # Base Cholesky factor for CY product metric: diag(1, 1, α, α, α, α, 1)\n",
        "        # where α = (65/32)^(1/14) to get det(g) = 65/32\n",
        "        if base_diag is None:\n",
        "            base_diag = [1.0, 1.0, SCALE_FACTOR, SCALE_FACTOR,\n",
        "                         SCALE_FACTOR, SCALE_FACTOR, 1.0]\n",
        "        L0 = torch.zeros(7, 7, dtype=dtype)\n",
        "        for i in range(7):\n",
        "            L0[i, i] = base_diag[i]\n",
        "\n",
        "        tril_idx = torch.tril_indices(7, 7)\n",
        "        self.register_buffer('tril_row', tril_idx[0])\n",
        "        self.register_buffer('tril_col', tril_idx[1])\n",
        "        self.register_buffer('L0_flat', L0[tril_idx[0], tril_idx[1]])\n",
        "\n",
        "        self.fourier = FourierFeatures(7, num_random_freq, num_periodic_freq)\n",
        "        layers = []\n",
        "        in_dim = self.fourier.output_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [nn.Linear(in_dim, h, dtype=dtype), nn.SiLU()]\n",
        "            in_dim = h\n",
        "        layers.append(nn.Linear(in_dim, 28, dtype=dtype))  # 28 lower-tri elements\n",
        "        self.mlp = nn.Sequential(*layers)\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight, gain=0.01)  # small init\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def cholesky_factor(self, x):\n",
        "        \"\"\"x: (N,7) → L: (N,7,7) lower triangular with positive diagonal.\"\"\"\n",
        "        N = x.shape[0]\n",
        "        delta_L = self.mlp(self.fourier(x))  # (N, 28)\n",
        "        L = torch.zeros(N, 7, 7, device=x.device, dtype=x.dtype)\n",
        "        for i in range(28):\n",
        "            val = self.L0_flat[i] + self.perturbation_scale * delta_L[:, i]\n",
        "            r, c = self.tril_row[i].item(), self.tril_col[i].item()\n",
        "            if r == c:\n",
        "                val = F.softplus(val)  # Enforce positive diagonal\n",
        "            L[:, r, c] = val\n",
        "        return L\n",
        "\n",
        "    def metric(self, x):\n",
        "        \"\"\"g = L @ Lᵀ — guaranteed positive definite.\"\"\"\n",
        "        L = self.cholesky_factor(x)\n",
        "        return torch.bmm(L, L.transpose(1, 2))\n",
        "\n",
        "    def det_g(self, x):\n",
        "        \"\"\"det(g) = (∏ L_ii)².\"\"\"\n",
        "        L = self.cholesky_factor(x)\n",
        "        log_det = 2 * torch.sum(torch.log(torch.diagonal(L, dim1=1, dim2=2)), dim=1)\n",
        "        return torch.exp(log_det)\n",
        "\n",
        "    def param_count(self):\n",
        "        return sum(p.numel() for p in self.parameters())\n",
        "\n",
        "\n",
        "# Instantiate and count parameters\n",
        "_neck = NeckPINN().to(device)\n",
        "_bulk = BulkCYPINN().to(device)\n",
        "print(f\"\\nArchitectures:\")\n",
        "print(f\"  NeckPINN:   {_neck.param_count():,} params\")\n",
        "print(f\"  BulkCYPINN: {_bulk.param_count():,} params\")\n",
        "print(f\"  Total (3 charts): ~{(_neck.param_count() + 2 * _bulk.param_count()):,} params\")\n",
        "del _neck, _bulk"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Architectures:\n",
            "  NeckPINN:   187,022 params\n",
            "  BulkCYPINN: 188,828 params\n",
            "  Total (3 charts): ~564,678 params\n"
          ]
        }
      ],
      "id": "J5Oe6BPdCxL_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-mWSp0cCxMA"
      },
      "source": [
        "## 5. Analytical Warm-Start Targets\n",
        "\n",
        "Each chart has its own analytical metric target for supervised warm-start.\n",
        "This breaks the trivial-solution trap (where constant φ₀ satisfies all losses at zero).\n",
        "\n",
        "- **Neck**: K3 Kummer bumps + neck warping + torus coupling\n",
        "- **Bulk_L**: ACyl CY product metric with exponential approach to cylinder\n",
        "- **Bulk_R**: Same as Bulk_L but with Kovalev twist signature"
      ],
      "id": "e-mWSp0cCxMA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1_bYW4gCxMA",
        "outputId": "4f093c42-4f4d-4ac3-da07-2f1b462612f4"
      },
      "source": [
        "def analytical_neck_metric(x):\n",
        "    \"\"\"\n",
        "    Analytical TCS metric for the neck region [0,1]⁷.\n",
        "\n",
        "    Encodes K₇ = (K3 × T²) × I structure:\n",
        "    - x[:,0] = t (neck parameter)\n",
        "    - x[:,1] = θ (fiber S¹)\n",
        "    - x[:,2:6] = (u₁..u₄) K3 coords with Kummer bumps\n",
        "    - x[:,6] = ψ (outer S¹)\n",
        "    \"\"\"\n",
        "    N = x.shape[0]\n",
        "    g = torch.zeros(N, 7, 7, device=x.device, dtype=x.dtype)\n",
        "\n",
        "    t = 2 * x[:, 0] - 1  # map [0,1] → [-1,1]\n",
        "\n",
        "    # dt² with neck warping (Gaussian bump at center = gluing region)\n",
        "    g[:, 0, 0] = 1.0 + 0.15 * torch.exp(-t ** 2 / 0.18)\n",
        "\n",
        "    # K3 Kummer metric (coords 2-5): identity + bumps at 16 orbifold fixed points\n",
        "    a_sq = 0.005\n",
        "    k3_factor = torch.ones(N, device=x.device, dtype=x.dtype)\n",
        "    for b0 in range(2):\n",
        "        for b1 in range(2):\n",
        "            for b2 in range(2):\n",
        "                for b3 in range(2):\n",
        "                    fp = torch.tensor([b0 * 0.5, b1 * 0.5, b2 * 0.5, b3 * 0.5],\n",
        "                                      device=x.device, dtype=x.dtype)\n",
        "                    dx = x[:, 2:6] - fp.unsqueeze(0)\n",
        "                    dx = dx - torch.round(dx)  # periodic BC\n",
        "                    r2 = (dx ** 2).sum(dim=1)\n",
        "                    k3_factor = k3_factor + 0.3 * torch.exp(-r2 / (2 * a_sq))\n",
        "\n",
        "    for i in range(4):\n",
        "        g[:, 2 + i, 2 + i] = k3_factor\n",
        "\n",
        "    # S¹ factors (θ, ψ) with mild t-dependence\n",
        "    g[:, 1, 1] = 1.0 + 0.05 * torch.cos(2 * math.pi * x[:, 0])\n",
        "    g[:, 6, 6] = 1.0 + 0.05 * torch.sin(2 * math.pi * x[:, 0])\n",
        "\n",
        "    # Off-diagonal: dt-dθ coupling near neck ends (TCS signature)\n",
        "    coupling = 0.03 * torch.exp(-((t.abs() - 0.8) ** 2) / 0.1)\n",
        "    g[:, 0, 1] = coupling;  g[:, 1, 0] = coupling\n",
        "\n",
        "    # Normalize det(g) = 65/32\n",
        "    det_raw = torch.linalg.det(g)\n",
        "    alpha = (DET_G_TARGET / det_raw.abs().clamp(min=1e-10)) ** (1.0 / 14)\n",
        "    g = g * (alpha ** 2).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "def analytical_bulk_metric(x, decay_rate=MU_DECAY, side='left'):\n",
        "    \"\"\"\n",
        "    Analytical ACyl CY₃ × S¹ product metric for a bulk region.\n",
        "\n",
        "    In the cylindrical end, the metric approaches:\n",
        "      g → dt² + dθ² + g_K3(u) + dψ²\n",
        "    with exponential corrections O(e^{-μ|t-t_interface|}).\n",
        "\n",
        "    side='left':  t close to DOMAIN_BULK_L, interface at upper boundary\n",
        "    side='right': t close to DOMAIN_BULK_R, interface at lower boundary\n",
        "    \"\"\"\n",
        "    N = x.shape[0]\n",
        "    g = torch.zeros(N, 7, 7, device=x.device, dtype=x.dtype)\n",
        "\n",
        "    t = x[:, 0]  # in [0, 1] domain\n",
        "\n",
        "    # Distance from interface (where bulk meets neck)\n",
        "    if side == 'left':\n",
        "        dist_from_interface = (OVERLAP_LEFT[1] - t).clamp(min=0)\n",
        "    else:\n",
        "        dist_from_interface = (t - OVERLAP_RIGHT[0]).clamp(min=0)\n",
        "\n",
        "    # Exponential approach to product metric as we move away from interface\n",
        "    decay = torch.exp(-decay_rate * dist_from_interface * 10)  # scale by 10 for unit-interval\n",
        "\n",
        "    # dt² (cylindrical radial)\n",
        "    g[:, 0, 0] = 1.0 + 0.08 * decay\n",
        "\n",
        "    # dθ² (fiber S¹)\n",
        "    g[:, 1, 1] = 1.0 + 0.04 * decay * torch.cos(2 * math.pi * x[:, 1])\n",
        "\n",
        "    # K3 fiber (coords 2-5): simplified Eguchi-Hanson-like structure\n",
        "    # In the bulk, K3 has full Ricci-flat metric (approximated here)\n",
        "    a_sq = 0.008\n",
        "    k3_base = torch.ones(N, device=x.device, dtype=x.dtype)\n",
        "    # 16 Kummer centers (same as neck for matching)\n",
        "    for b0 in range(2):\n",
        "        for b1 in range(2):\n",
        "            for b2 in range(2):\n",
        "                for b3 in range(2):\n",
        "                    fp = torch.tensor([b0 * 0.5, b1 * 0.5, b2 * 0.5, b3 * 0.5],\n",
        "                                      device=x.device, dtype=x.dtype)\n",
        "                    dx = x[:, 2:6] - fp.unsqueeze(0)\n",
        "                    dx = dx - torch.round(dx)\n",
        "                    r2 = (dx ** 2).sum(dim=1)\n",
        "                    k3_base = k3_base + 0.25 * torch.exp(-r2 / (2 * a_sq))\n",
        "\n",
        "    for i in range(4):\n",
        "        g[:, 2 + i, 2 + i] = k3_base\n",
        "\n",
        "    # dψ² (outer S¹)\n",
        "    g[:, 6, 6] = 1.0 + 0.03 * decay * torch.sin(2 * math.pi * x[:, 6])\n",
        "\n",
        "    # Mild off-diagonal coupling (decays away from interface)\n",
        "    od_coupling = 0.02 * decay\n",
        "    g[:, 0, 1] = od_coupling;  g[:, 1, 0] = od_coupling\n",
        "\n",
        "    # Normalize per-sample to det = 65/32\n",
        "    det_raw = torch.linalg.det(g)\n",
        "    alpha = (DET_G_TARGET / det_raw.abs().clamp(min=1e-10)) ** (1.0 / 14)\n",
        "    g = g * (alpha ** 2).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    return g\n",
        "\n",
        "\n",
        "# Verify analytical metrics\n",
        "with torch.no_grad():\n",
        "    _x = torch.rand(500, 7, device=device, dtype=dtype)\n",
        "    for name, fn in [(\"Neck\", analytical_neck_metric),\n",
        "                     (\"Bulk_L\", lambda x: analytical_bulk_metric(x, side='left')),\n",
        "                     (\"Bulk_R\", lambda x: analytical_bulk_metric(x, side='right'))]:\n",
        "        _g = fn(_x)\n",
        "        _d = torch.linalg.det(_g)\n",
        "        _e = torch.linalg.eigvalsh(_g)\n",
        "        print(f\"  {name}: det={_d.mean():.6f}  min_eig={_e.min():.4f}  \"\n",
        "              f\"max_eig={_e.max():.4f}  PD={(_e.min() > 0).item()}\")\n",
        "    del _x, _g, _d, _e"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Neck: det=2.031250  min_eig=0.9606  max_eig=1.2568  PD=True\n",
            "  Bulk_L: det=2.031250  min_eig=0.9702  max_eig=1.1973  PD=True\n",
            "  Bulk_R: det=2.031250  min_eig=0.9758  max_eig=1.1975  PD=True\n"
          ]
        }
      ],
      "id": "i1_bYW4gCxMA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlN9f8SyCxMB"
      },
      "source": [
        "## 6. Loss Functions (Extended for Atlas)"
      ],
      "id": "XlN9f8SyCxMB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC7lscnvCxMB",
        "outputId": "ffa18779-f1bd-48fe-8fb0-074ec63e44b4"
      },
      "source": [
        "def det_loss(model, x, target=DET_G_TARGET):\n",
        "    \"\"\"L_det = ⟨(det(g) - 65/32)²⟩.\"\"\"\n",
        "    return torch.mean((model.det_g(x) - target) ** 2)\n",
        "\n",
        "\n",
        "def torsion_loss_fast(model, x, n_components=14):\n",
        "    \"\"\"Approximate torsion via autograd on 14 sampled 3-form components.\"\"\"\n",
        "    x = x.clone().requires_grad_(True)\n",
        "    phi = model(x)\n",
        "    torsion = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
        "    indices = torch.linspace(0, 34, n_components, dtype=torch.long)\n",
        "    for i in indices:\n",
        "        grad = torch.autograd.grad(\n",
        "            phi[:, i].sum(), x, create_graph=True, retain_graph=True\n",
        "        )[0]\n",
        "        torsion = torsion + torch.mean(grad ** 2)\n",
        "    return torsion / n_components\n",
        "\n",
        "\n",
        "def torsion_loss_full(model, x):\n",
        "    \"\"\"Full torsion: all 35 3-form components.\"\"\"\n",
        "    x = x.clone().requires_grad_(True)\n",
        "    phi = model(x)\n",
        "    torsion = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
        "    for i in range(35):\n",
        "        grad = torch.autograd.grad(\n",
        "            phi[:, i].sum(), x, create_graph=True, retain_graph=True\n",
        "        )[0]\n",
        "        torsion = torsion + torch.mean(grad ** 2)\n",
        "    return torsion / 35.0\n",
        "\n",
        "\n",
        "def positive_definite_loss(model, x):\n",
        "    \"\"\"Penalize negative eigenvalues of g.\"\"\"\n",
        "    g = model.metric(x)\n",
        "    eigs = torch.linalg.eigvalsh(g)\n",
        "    return torch.mean(torch.relu(-eigs) ** 2)\n",
        "\n",
        "\n",
        "def smoothness_loss(model, x, n_pairs=7):\n",
        "    \"\"\"Penalize large metric gradients.\"\"\"\n",
        "    x = x.clone().requires_grad_(True)\n",
        "    g = model.metric(x)\n",
        "    loss = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
        "    for i in range(n_pairs):\n",
        "        grad = torch.autograd.grad(\n",
        "            g[:, i, i].sum(), x, create_graph=True, retain_graph=True\n",
        "        )[0]\n",
        "        loss = loss + torch.mean(grad ** 2)\n",
        "    return loss / n_pairs\n",
        "\n",
        "\n",
        "def ricci_proxy_loss(model, x, eps=0.01):\n",
        "    \"\"\"Proxy for Ricci-flatness via finite-difference curvature.\"\"\"\n",
        "    g0 = model.metric(x)\n",
        "    loss = torch.tensor(0.0, device=x.device, dtype=x.dtype)\n",
        "    for d in range(7):\n",
        "        x_p = x.clone(); x_p[:, d] += eps\n",
        "        x_m = x.clone(); x_m[:, d] -= eps\n",
        "        g_p = model.metric(x_p)\n",
        "        g_m = model.metric(x_m)\n",
        "        d2g = (g_p - 2 * g0 + g_m) / (eps ** 2)\n",
        "        loss = loss + torch.mean(d2g ** 2)\n",
        "    return loss / 7.0\n",
        "\n",
        "\n",
        "def supervised_loss_neck(model, x):\n",
        "    \"\"\"MSE between neck PINN metric and analytical TCS target.\"\"\"\n",
        "    g_pinn = model.metric(x)\n",
        "    with torch.no_grad():\n",
        "        g_target = analytical_neck_metric(x)\n",
        "    return torch.mean((g_pinn - g_target) ** 2)\n",
        "\n",
        "\n",
        "def supervised_loss_bulk(model, x, side='left'):\n",
        "    \"\"\"MSE between bulk PINN metric and analytical CY target.\"\"\"\n",
        "    g_pinn = model.metric(x)\n",
        "    with torch.no_grad():\n",
        "        g_target = analytical_bulk_metric(x, side=side)\n",
        "    return torch.mean((g_pinn - g_target) ** 2)\n",
        "\n",
        "\n",
        "def interface_loss_cholesky(model_a, model_b, x_overlap, transform_fn=None):\n",
        "    \"\"\"\n",
        "    Cholesky-level C⁰ matching at domain interface.\n",
        "\n",
        "    If transform_fn is provided, apply it to model_b's metric before comparing.\n",
        "    This handles the Kovalev twist at the right interface.\n",
        "    \"\"\"\n",
        "    g_a = model_a.metric(x_overlap)\n",
        "    if transform_fn is not None:\n",
        "        x_transformed = transform_fn(x_overlap)\n",
        "        g_b_raw = model_b.metric(x_transformed)\n",
        "        g_b = transform_metric_kovalev(g_b_raw, device_ref=x_overlap.device)\n",
        "    else:\n",
        "        g_b = model_b.metric(x_overlap)\n",
        "    return torch.mean((g_a - g_b) ** 2)\n",
        "\n",
        "\n",
        "def asymptotic_decay_loss(model, x, side='left'):\n",
        "    \"\"\"\n",
        "    Enforce exponential approach to product metric far from interface.\n",
        "\n",
        "    The bulk metric should approach dt² + dθ² + g_K3 + dψ² exponentially\n",
        "    as we move away from the interface region.\n",
        "    \"\"\"\n",
        "    g = model.metric(x)\n",
        "    t = x[:, 0]\n",
        "\n",
        "    # Product metric: block-diagonal\n",
        "    with torch.no_grad():\n",
        "        g_product = analytical_bulk_metric(x, side=side)\n",
        "\n",
        "    # Weight: stronger penalty far from interface\n",
        "    if side == 'left':\n",
        "        weight = torch.exp(-5 * (t - DOMAIN_BULK_L[0]))\n",
        "    else:\n",
        "        weight = torch.exp(-5 * (DOMAIN_BULK_R[1] - t))\n",
        "\n",
        "    diff = (g - g_product) ** 2\n",
        "    return torch.mean(weight.unsqueeze(1).unsqueeze(2) * diff)\n",
        "\n",
        "\n",
        "def hermite_blend(t, t_lo, t_hi):\n",
        "    \"\"\"C¹ Hermite blend: 0 at t_lo, 1 at t_hi.\"\"\"\n",
        "    s = torch.clamp((t - t_lo) / (t_hi - t_lo), 0, 1)\n",
        "    return 3 * s ** 2 - 2 * s ** 3\n",
        "\n",
        "\n",
        "print(\"Loss functions defined.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss functions defined.\n"
          ]
        }
      ],
      "id": "DC7lscnvCxMB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-P2h5CJCxMC"
      },
      "source": [
        "## 7. Sampling Utilities"
      ],
      "id": "D-P2h5CJCxMC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcAZnAhgCxME"
      },
      "source": [
        "def sample_domain(n, domain, dim=7):\n",
        "    \"\"\"Sample points uniformly, restricting coord[0] to the given domain.\"\"\"\n",
        "    x = torch.rand(n, dim, device=device, dtype=dtype)\n",
        "    x[:, 0] = x[:, 0] * (domain[1] - domain[0]) + domain[0]\n",
        "    return x\n",
        "\n",
        "\n",
        "def sample_overlap(n, overlap, dim=7):\n",
        "    \"\"\"Sample points in an overlap region.\"\"\"\n",
        "    return sample_domain(n, overlap, dim)"
      ],
      "execution_count": 8,
      "outputs": [],
      "id": "bcAZnAhgCxME"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_pCqMiuCxMF"
      },
      "source": [
        "## 8. Phase 1 — Independent Chart Training\n",
        "\n",
        "Train each chart's PINN independently:\n",
        "- Neck: supervised warm-start → torsion-free physics\n",
        "- Bulk_L, Bulk_R: supervised warm-start → Ricci-flat physics\n",
        "\n",
        "No interface matching yet (that comes in Phase 2)."
      ],
      "id": "U_pCqMiuCxMF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBHSLarzCxMF"
      },
      "source": [
        "def train_chart(model, chart_name, analytical_target_fn, domain,\n",
        "                is_neck=False, n_epochs=3000, batch_size=1024, verbose=True):\n",
        "    \"\"\"\n",
        "    Train a single chart PINN with 3-phase curriculum:\n",
        "    Phase A: Supervised warm-start from analytical target\n",
        "    Phase B: Blended (supervised + physics)\n",
        "    Phase C: Physics-dominated (det + torsion/Ricci + smoothness)\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    if is_neck:\n",
        "        phases = [\n",
        "            {'name': 'warm-start', 'epochs': int(0.2 * n_epochs), 'lr': 1e-3,\n",
        "             'w_sup': 100.0, 'w_det': 0, 'w_phys': 0, 'w_smooth': 0},\n",
        "            {'name': 'blend', 'epochs': int(0.3 * n_epochs), 'lr': 5e-4,\n",
        "             'w_sup': 20.0, 'w_det': 50, 'w_phys': 0.5, 'w_smooth': 0.05},\n",
        "            {'name': 'physics', 'epochs': int(0.5 * n_epochs), 'lr': 2e-4,\n",
        "             'w_sup': 1.0, 'w_det': 100, 'w_phys': 1.0, 'w_smooth': 0.1},\n",
        "        ]\n",
        "    else:\n",
        "        phases = [\n",
        "            {'name': 'warm-start', 'epochs': int(0.25 * n_epochs), 'lr': 1e-3,\n",
        "             'w_sup': 100.0, 'w_det': 0, 'w_phys': 0, 'w_smooth': 0},\n",
        "            {'name': 'blend', 'epochs': int(0.35 * n_epochs), 'lr': 5e-4,\n",
        "             'w_sup': 15.0, 'w_det': 50, 'w_phys': 0.5, 'w_smooth': 0.05},\n",
        "            {'name': 'physics', 'epochs': int(0.40 * n_epochs), 'lr': 1e-4,\n",
        "             'w_sup': 0.5, 'w_det': 100, 'w_phys': 1.0, 'w_smooth': 0.1},\n",
        "        ]\n",
        "\n",
        "    history = {'loss': [], 'det_err': [], 'phys': [], 'sup': [], 'phase': []}\n",
        "    best_loss = float('inf')\n",
        "    best_state = None\n",
        "    total_ep = 0\n",
        "    t_start = time.time()\n",
        "\n",
        "    for phase in phases:\n",
        "        pname = phase['name']\n",
        "        n_ep = phase['epochs']\n",
        "        if verbose:\n",
        "            print(f\"\\n  [{chart_name}] Phase: {pname} | {n_ep} epochs | lr={phase['lr']}\")\n",
        "\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=phase['lr'], weight_decay=1e-5)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_ep)\n",
        "\n",
        "        for ep in range(n_ep):\n",
        "            x = sample_domain(batch_size, domain)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Supervised loss\n",
        "            L_sup = analytical_target_fn(model, x) if phase['w_sup'] > 0 else torch.tensor(0.0, device=device)\n",
        "\n",
        "            # Physics losses\n",
        "            L_det = det_loss(model, x) if phase['w_det'] > 0 else torch.tensor(0.0, device=device)\n",
        "            if phase['w_phys'] > 0 and is_neck:\n",
        "                L_phys = torsion_loss_fast(model, x)\n",
        "            elif phase['w_phys'] > 0:\n",
        "                L_phys = ricci_proxy_loss(model, x)\n",
        "            else:\n",
        "                L_phys = torch.tensor(0.0, device=device)\n",
        "            L_smooth = smoothness_loss(model, x) if phase['w_smooth'] > 0 else torch.tensor(0.0, device=device)\n",
        "\n",
        "            loss = (phase['w_sup'] * L_sup +\n",
        "                    phase['w_det'] * L_det +\n",
        "                    phase['w_phys'] * L_phys +\n",
        "                    phase['w_smooth'] * L_smooth)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            history['loss'].append(loss.item())\n",
        "            history['det_err'].append(L_det.item())\n",
        "            history['phys'].append(L_phys.item())\n",
        "            history['sup'].append(L_sup.item())\n",
        "            history['phase'].append(pname)\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "\n",
        "            if verbose and (ep % 500 == 0 or ep == n_ep - 1):\n",
        "                elapsed = time.time() - t_start\n",
        "                print(f\"    [{total_ep:5d}] loss={loss.item():.2e}  \"\n",
        "                      f\"det={L_det.item():.2e}  phys={L_phys.item():.2e}  \"\n",
        "                      f\"sup={L_sup.item():.2e}  ({elapsed:.0f}s)\")\n",
        "            total_ep += 1\n",
        "\n",
        "    elapsed = time.time() - t_start\n",
        "    if verbose:\n",
        "        print(f\"  [{chart_name}] Done: {total_ep} epochs in {elapsed:.1f}s, best={best_loss:.2e}\")\n",
        "\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "        model.to(device)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 9,
      "outputs": [],
      "id": "lBHSLarzCxMF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKLosfukCxMF",
        "outputId": "7aad8d81-69d1-4c60-9816-c830f071c6c5"
      },
      "source": [
        "# === Create the 3 chart PINNs ===\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"  PHASE 1: Independent Chart Training\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "neck_pinn = NeckPINN(perturbation_scale=0.2).to(device)\n",
        "bulk_L_pinn = BulkCYPINN(perturbation_scale=0.2).to(device)\n",
        "bulk_R_pinn = BulkCYPINN(perturbation_scale=0.2).to(device)\n",
        "\n",
        "print(f\"Neck PINN: {neck_pinn.param_count():,} params\")\n",
        "print(f\"Bulk L PINN: {bulk_L_pinn.param_count():,} params\")\n",
        "print(f\"Bulk R PINN: {bulk_R_pinn.param_count():,} params\")\n",
        "total_params = neck_pinn.param_count() + bulk_L_pinn.param_count() + bulk_R_pinn.param_count()\n",
        "print(f\"Total: {total_params:,} params\")\n",
        "\n",
        "# Optional: load P2 checkpoint for neck warm-start\n",
        "P2_CHECKPOINT = 'outputs/neck_pinn_seed42.pt'\n",
        "if os.path.exists(P2_CHECKPOINT):\n",
        "    try:\n",
        "        ckpt = torch.load(P2_CHECKPOINT, map_location=device, weights_only=True)\n",
        "        neck_pinn.load_state_dict(ckpt, strict=False)\n",
        "        print(f\"\\n  Loaded P2 checkpoint: {P2_CHECKPOINT}\")\n",
        "        NECK_PRETRAINED = True\n",
        "    except Exception as e:\n",
        "        print(f\"  Could not load P2 checkpoint: {e}\")\n",
        "        NECK_PRETRAINED = False\n",
        "else:\n",
        "    print(f\"\\n  No P2 checkpoint found at {P2_CHECKPOINT}, training from scratch\")\n",
        "    NECK_PRETRAINED = False"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  PHASE 1: Independent Chart Training\n",
            "======================================================================\n",
            "Neck PINN: 187,022 params\n",
            "Bulk L PINN: 188,828 params\n",
            "Bulk R PINN: 188,828 params\n",
            "Total: 564,678 params\n",
            "\n",
            "  No P2 checkpoint found at outputs/neck_pinn_seed42.pt, training from scratch\n"
          ]
        }
      ],
      "id": "DKLosfukCxMF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vr3HaU6CxMG",
        "outputId": "7a77b81e-3e6b-4fc3-871b-326802cf390a"
      },
      "source": [
        "# Train Neck\n",
        "NECK_EPOCHS = 1500 if NECK_PRETRAINED else 3000\n",
        "neck_history = train_chart(\n",
        "    neck_pinn, \"Neck\", supervised_loss_neck, DOMAIN_NECK,\n",
        "    is_neck=True, n_epochs=NECK_EPOCHS\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  [Neck] Phase: warm-start | 600 epochs | lr=0.001\n",
            "    [    0] loss=3.34e-02  det=0.00e+00  phys=0.00e+00  sup=3.34e-04  (5s)\n",
            "    [  500] loss=3.20e-02  det=0.00e+00  phys=0.00e+00  sup=3.20e-04  (20s)\n",
            "    [  599] loss=3.10e-02  det=0.00e+00  phys=0.00e+00  sup=3.10e-04  (24s)\n",
            "\n",
            "  [Neck] Phase: blend | 900 epochs | lr=0.0005\n",
            "    [  600] loss=6.61e-01  det=1.31e-02  phys=3.05e-03  sup=3.09e-04  (24s)\n",
            "    [ 1100] loss=6.70e-03  det=1.51e-07  phys=8.42e-05  sup=3.33e-04  (282s)\n",
            "    [ 1499] loss=6.46e-03  det=1.23e-07  phys=7.27e-05  sup=3.21e-04  (491s)\n",
            "\n",
            "  [Neck] Phase: physics | 1500 epochs | lr=0.0002\n",
            "    [ 1500] loss=4.01e-04  det=1.22e-07  phys=7.21e-05  sup=3.17e-04  (491s)\n",
            "    [ 2000] loss=3.25e-04  det=2.65e-10  phys=7.60e-07  sup=3.24e-04  (746s)\n",
            "    [ 2500] loss=3.29e-04  det=1.46e-10  phys=3.77e-07  sup=3.29e-04  (1003s)\n",
            "    [ 2999] loss=3.30e-04  det=1.23e-10  phys=3.45e-07  sup=3.29e-04  (1259s)\n",
            "  [Neck] Done: 3000 epochs in 1258.8s, best=3.10e-04\n"
          ]
        }
      ],
      "id": "0vr3HaU6CxMG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPGTCAFMCxMG",
        "outputId": "8e356f6a-c3ad-4bff-d202-4e43299983dc"
      },
      "source": [
        "# Train Bulk Left\n",
        "bulk_L_history = train_chart(\n",
        "    bulk_L_pinn, \"Bulk_L\",\n",
        "    lambda model, x: supervised_loss_bulk(model, x, side='left'),\n",
        "    DOMAIN_BULK_L, is_neck=False, n_epochs=2500\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  [Bulk_L] Phase: warm-start | 625 epochs | lr=0.001\n",
            "    [    0] loss=6.57e+00  det=0.00e+00  phys=0.00e+00  sup=6.57e-02  (0s)\n",
            "    [  500] loss=3.20e-03  det=0.00e+00  phys=0.00e+00  sup=3.20e-05  (7s)\n",
            "    [  624] loss=3.38e-03  det=0.00e+00  phys=0.00e+00  sup=3.38e-05  (9s)\n",
            "\n",
            "  [Bulk_L] Phase: blend | 875 epochs | lr=0.0005\n",
            "    [  625] loss=1.64e-03  det=2.25e-05  phys=8.93e-05  sup=3.15e-05  (9s)\n",
            "    [ 1125] loss=3.04e-02  det=5.91e-04  phys=4.61e-04  sup=4.00e-05  (141s)\n",
            "    [ 1499] loss=5.05e-04  det=3.64e-09  phys=7.56e-07  sup=3.36e-05  (240s)\n",
            "\n",
            "  [Bulk_L] Phase: physics | 1000 epochs | lr=0.0001\n",
            "    [ 1500] loss=2.11e-05  det=3.49e-09  phys=7.43e-07  sup=4.00e-05  (240s)\n",
            "    [ 2000] loss=1.42e-03  det=1.37e-05  phys=2.73e-05  sup=3.21e-05  (374s)\n",
            "    [ 2499] loss=1.61e-05  det=2.90e-09  phys=5.83e-07  sup=3.05e-05  (508s)\n",
            "  [Bulk_L] Done: 2500 epochs in 507.5s, best=1.55e-05\n"
          ]
        }
      ],
      "id": "pPGTCAFMCxMG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq_yit72CxMG",
        "outputId": "d939b2df-ed48-441e-d1c7-cf3b7c1a9e80"
      },
      "source": [
        "# Train Bulk Right\n",
        "bulk_R_history = train_chart(\n",
        "    bulk_R_pinn, \"Bulk_R\",\n",
        "    lambda model, x: supervised_loss_bulk(model, x, side='right'),\n",
        "    DOMAIN_BULK_R, is_neck=False, n_epochs=2500\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  [Bulk_R] Phase: warm-start | 625 epochs | lr=0.001\n",
            "    [    0] loss=6.57e+00  det=0.00e+00  phys=0.00e+00  sup=6.57e-02  (0s)\n",
            "    [  500] loss=3.10e-03  det=0.00e+00  phys=0.00e+00  sup=3.10e-05  (7s)\n",
            "    [  624] loss=3.30e-03  det=0.00e+00  phys=0.00e+00  sup=3.30e-05  (9s)\n",
            "\n",
            "  [Bulk_R] Phase: blend | 875 epochs | lr=0.0005\n",
            "    [  625] loss=1.39e-03  det=1.40e-05  phys=4.87e-05  sup=4.46e-05  (9s)\n",
            "    [ 1125] loss=3.30e-02  det=6.37e-04  phys=1.16e-03  sup=3.77e-05  (143s)\n",
            "    [ 1499] loss=5.85e-04  det=8.68e-09  phys=1.46e-06  sup=3.89e-05  (242s)\n",
            "\n",
            "  [Bulk_R] Phase: physics | 1000 epochs | lr=0.0001\n",
            "    [ 1500] loss=1.98e-05  det=7.45e-09  phys=1.44e-06  sup=3.52e-05  (242s)\n",
            "    [ 2000] loss=1.84e-03  det=1.78e-05  phys=4.39e-05  sup=3.48e-05  (374s)\n",
            "    [ 2499] loss=1.69e-05  det=7.30e-09  phys=1.27e-06  sup=2.98e-05  (506s)\n",
            "  [Bulk_R] Done: 2500 epochs in 506.3s, best=1.64e-05\n"
          ]
        }
      ],
      "id": "dq_yit72CxMG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFSVSZHcCxMH"
      },
      "source": [
        "## 9. Phase 1 Validation (Per-Chart)"
      ],
      "id": "ZFSVSZHcCxMH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2jP-KoPCxMH",
        "outputId": "394b21a5-4574-48fb-f08b-c15483334ce8"
      },
      "source": [
        "def validate_chart(model, domain, label, n_samples=20000, chunk_size=5000):\n",
        "    \"\"\"Validate a single chart PINN.\"\"\"\n",
        "    model.eval()\n",
        "    all_det = []\n",
        "    all_min_eig = []\n",
        "    all_cond = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for start in range(0, n_samples, chunk_size):\n",
        "            end = min(start + chunk_size, n_samples)\n",
        "            x = sample_domain(end - start, domain)\n",
        "            g = model.metric(x)\n",
        "            det_g = torch.linalg.det(g)\n",
        "            eigs = torch.linalg.eigvalsh(g)\n",
        "            all_det.append(det_g)\n",
        "            all_min_eig.append(eigs.min(dim=1).values)\n",
        "            all_cond.append(eigs.max(dim=1).values / eigs.min(dim=1).values.clamp(min=1e-10))\n",
        "\n",
        "    det_vals = torch.cat(all_det)\n",
        "    min_eigs = torch.cat(all_min_eig)\n",
        "    cond_vals = torch.cat(all_cond)\n",
        "\n",
        "    det_err = abs(det_vals.mean().item() - DET_G_TARGET) / DET_G_TARGET * 100\n",
        "\n",
        "    # Torsion (for neck only)\n",
        "    if hasattr(model, 'phi_tensor'):\n",
        "        model.train()\n",
        "        x_tor = sample_domain(2000, domain)\n",
        "        tor = torsion_loss_fast(model, x_tor).item()\n",
        "        model.eval()\n",
        "    else:\n",
        "        tor = float('nan')\n",
        "\n",
        "    result = {\n",
        "        'det_mean': float(det_vals.mean().item()),\n",
        "        'det_std': float(det_vals.std().item()),\n",
        "        'det_err_pct': float(det_err),\n",
        "        'min_eig': float(min_eigs.min().item()),\n",
        "        'condition': float(cond_vals.mean().item()),\n",
        "        'pos_def': bool((min_eigs > 0).all().item()),\n",
        "        'torsion': float(tor),\n",
        "    }\n",
        "\n",
        "    print(f\"\\n  {label}:\")\n",
        "    print(f\"    det(g) = {result['det_mean']:.8f} (err={det_err:.4f}%)\")\n",
        "    print(f\"    min_eig = {result['min_eig']:.6f}, cond = {result['condition']:.4f}\")\n",
        "    print(f\"    PD = {result['pos_def']}, torsion = {tor:.2e}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"  Phase 1 Validation\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "val_neck = validate_chart(neck_pinn, DOMAIN_NECK, \"Neck\")\n",
        "val_bulk_L = validate_chart(bulk_L_pinn, DOMAIN_BULK_L, \"Bulk_L\")\n",
        "val_bulk_R = validate_chart(bulk_R_pinn, DOMAIN_BULK_R, \"Bulk_R\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  Phase 1 Validation\n",
            "======================================================================\n",
            "\n",
            "  Neck:\n",
            "    det(g) = 2.03125649 (err=0.0003%)\n",
            "    min_eig = 1.106538, cond = 1.0000\n",
            "    PD = True, torsion = 3.52e-07\n",
            "\n",
            "  Bulk_L:\n",
            "    det(g) = 2.03125072 (err=0.0000%)\n",
            "    min_eig = 1.093401, cond = 1.0258\n",
            "    PD = True, torsion = nan\n",
            "\n",
            "  Bulk_R:\n",
            "    det(g) = 2.03124743 (err=0.0001%)\n",
            "    min_eig = 1.093640, cond = 1.0261\n",
            "    PD = True, torsion = nan\n"
          ]
        }
      ],
      "id": "R2jP-KoPCxMH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LddflJvaCxMH"
      },
      "source": [
        "## 10. Phase 2 — Schwarz Alternating Method\n",
        "\n",
        "Iteratively match charts at their overlapping interfaces.\n",
        "\n",
        "**Left interface** (Bulk_L ∩ Neck): direct metric matching (no twist).\n",
        "**Right interface** (Neck ∩ Bulk_R): matching through Kovalev twist.\n",
        "\n",
        "Protocol:\n",
        "1. Freeze Neck → optimize Bulk_L, Bulk_R with interface matching\n",
        "2. Freeze Bulk_L, Bulk_R → optimize Neck with interface matching\n",
        "3. Log interface error → repeat until convergence"
      ],
      "id": "LddflJvaCxMH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01CTNqxUCxMI"
      },
      "source": [
        "def schwarz_iteration(neck_model, bulk_L_model, bulk_R_model,\n",
        "                      n_schwarz=8, epochs_per_step=300,\n",
        "                      batch_size=1024, verbose=True):\n",
        "    \"\"\"\n",
        "    Schwarz alternating method for 3-chart atlas.\n",
        "\n",
        "    Returns: history dict with interface matching errors per iteration.\n",
        "    \"\"\"\n",
        "    history = {\n",
        "        'iteration': [], 'match_left': [], 'match_right': [],\n",
        "        'det_err_neck': [], 'det_err_left': [], 'det_err_right': [],\n",
        "    }\n",
        "    t_start = time.time()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"  PHASE 2: Schwarz Alternating ({n_schwarz} iterations)\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "    for schwarz_iter in range(n_schwarz):\n",
        "        if verbose:\n",
        "            print(f\"\\n  --- Schwarz iteration {schwarz_iter + 1}/{n_schwarz} ---\")\n",
        "\n",
        "        # === Step A: Freeze Neck, optimize Bulks with matching ===\n",
        "        for p in neck_model.parameters():\n",
        "            p.requires_grad_(False)\n",
        "\n",
        "        for name, bulk_model, domain, overlap, side in [\n",
        "            (\"Bulk_L\", bulk_L_model, DOMAIN_BULK_L, OVERLAP_LEFT, 'left'),\n",
        "            (\"Bulk_R\", bulk_R_model, DOMAIN_BULK_R, OVERLAP_RIGHT, 'right'),\n",
        "        ]:\n",
        "            optimizer = torch.optim.Adam(bulk_model.parameters(), lr=1e-4)\n",
        "            for ep in range(epochs_per_step):\n",
        "                x_bulk = sample_domain(batch_size, domain)\n",
        "                x_ov = sample_overlap(batch_size // 4, overlap)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                L_det = det_loss(bulk_model, x_bulk)\n",
        "                L_ricci = ricci_proxy_loss(bulk_model, x_bulk)\n",
        "                L_decay = asymptotic_decay_loss(bulk_model, x_bulk, side=side)\n",
        "\n",
        "                # Interface matching\n",
        "                if side == 'left':\n",
        "                    L_match = interface_loss_cholesky(\n",
        "                        neck_model, bulk_model, x_ov, transform_fn=None)\n",
        "                else:\n",
        "                    # Right interface: match through Kovalev twist\n",
        "                    L_match = interface_loss_cholesky(\n",
        "                        neck_model, bulk_model, x_ov, transform_fn=kovalev_twist_coords)\n",
        "\n",
        "                loss = 50 * L_det + 0.5 * L_ricci + 5 * L_decay + 100 * L_match\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(bulk_model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "            if verbose:\n",
        "                print(f\"    {name}: det={L_det.item():.2e}  match={L_match.item():.2e}\")\n",
        "\n",
        "        for p in neck_model.parameters():\n",
        "            p.requires_grad_(True)\n",
        "\n",
        "        # === Step B: Freeze Bulks, optimize Neck with matching ===\n",
        "        for p in bulk_L_model.parameters():\n",
        "            p.requires_grad_(False)\n",
        "        for p in bulk_R_model.parameters():\n",
        "            p.requires_grad_(False)\n",
        "\n",
        "        optimizer = torch.optim.Adam(neck_model.parameters(), lr=5e-5)\n",
        "        for ep in range(epochs_per_step):\n",
        "            x_neck = sample_domain(batch_size, DOMAIN_NECK)\n",
        "            x_ov_L = sample_overlap(batch_size // 4, OVERLAP_LEFT)\n",
        "            x_ov_R = sample_overlap(batch_size // 4, OVERLAP_RIGHT)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            L_det = det_loss(neck_model, x_neck)\n",
        "            L_tor = torsion_loss_fast(neck_model, x_neck)\n",
        "\n",
        "            # Left interface: direct\n",
        "            L_match_L = interface_loss_cholesky(\n",
        "                neck_model, bulk_L_model, x_ov_L, transform_fn=None)\n",
        "            # Right interface: Kovalev twist\n",
        "            L_match_R = interface_loss_cholesky(\n",
        "                neck_model, bulk_R_model, x_ov_R, transform_fn=kovalev_twist_coords)\n",
        "\n",
        "            loss = 50 * L_det + 1.0 * L_tor + 100 * (L_match_L + L_match_R)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(neck_model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "        for p in bulk_L_model.parameters():\n",
        "            p.requires_grad_(True)\n",
        "        for p in bulk_R_model.parameters():\n",
        "            p.requires_grad_(True)\n",
        "\n",
        "        # === Log interface errors ===\n",
        "        with torch.no_grad():\n",
        "            x_ov_L = sample_overlap(2000, OVERLAP_LEFT)\n",
        "            x_ov_R = sample_overlap(2000, OVERLAP_RIGHT)\n",
        "\n",
        "            ml = interface_loss_cholesky(\n",
        "                neck_model, bulk_L_model, x_ov_L).item()\n",
        "            mr = interface_loss_cholesky(\n",
        "                neck_model, bulk_R_model, x_ov_R,\n",
        "                transform_fn=kovalev_twist_coords).item()\n",
        "\n",
        "            x_n = sample_domain(2000, DOMAIN_NECK)\n",
        "            x_l = sample_domain(2000, DOMAIN_BULK_L)\n",
        "            x_r = sample_domain(2000, DOMAIN_BULK_R)\n",
        "            de_n = abs(neck_model.det_g(x_n).mean().item() - DET_G_TARGET)\n",
        "            de_l = abs(bulk_L_model.det_g(x_l).mean().item() - DET_G_TARGET)\n",
        "            de_r = abs(bulk_R_model.det_g(x_r).mean().item() - DET_G_TARGET)\n",
        "\n",
        "        history['iteration'].append(schwarz_iter)\n",
        "        history['match_left'].append(float(ml))\n",
        "        history['match_right'].append(float(mr))\n",
        "        history['det_err_neck'].append(float(de_n))\n",
        "        history['det_err_left'].append(float(de_l))\n",
        "        history['det_err_right'].append(float(de_r))\n",
        "\n",
        "        if verbose:\n",
        "            elapsed = time.time() - t_start\n",
        "            print(f\"    Interface: left={ml:.6f}  right={mr:.6f}  ({elapsed:.0f}s)\")\n",
        "\n",
        "        # Early stopping\n",
        "        if ml < 1e-4 and mr < 1e-4:\n",
        "            if verbose:\n",
        "                print(\"    Interfaces converged!\")\n",
        "            break\n",
        "\n",
        "    elapsed = time.time() - t_start\n",
        "    if verbose:\n",
        "        print(f\"\\n  Schwarz complete in {elapsed:.1f}s \"\n",
        "              f\"({schwarz_iter + 1} iterations)\")\n",
        "\n",
        "    return history"
      ],
      "execution_count": 15,
      "outputs": [],
      "id": "01CTNqxUCxMI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpJp_tNDCxMI",
        "outputId": "4fb33884-f51b-4eb3-dd8f-211450072a12"
      },
      "source": [
        "schwarz_history = schwarz_iteration(\n",
        "    neck_pinn, bulk_L_pinn, bulk_R_pinn,\n",
        "    n_schwarz=8, epochs_per_step=300\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  PHASE 2: Schwarz Alternating (8 iterations)\n",
            "======================================================================\n",
            "\n",
            "  --- Schwarz iteration 1/8 ---\n",
            "    Bulk_L: det=2.08e-05  match=3.49e-08\n",
            "    Bulk_R: det=1.33e-04  match=3.58e-07\n",
            "    Interface: left=0.000000  right=0.000000  (147s)\n",
            "    Interfaces converged!\n",
            "\n",
            "  Schwarz complete in 147.0s (1 iterations)\n"
          ]
        }
      ],
      "id": "gpJp_tNDCxMI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGsZ0eQ0CxMI"
      },
      "source": [
        "## 11. Phase 3 — Joint Fine-Tuning\n",
        "\n",
        "All three PINNs trained jointly with global loss:\n",
        "torsion + Ricci + det + matching + decay"
      ],
      "id": "bGsZ0eQ0CxMI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pA0L14zCxMJ"
      },
      "source": [
        "def joint_fine_tune(neck_model, bulk_L_model, bulk_R_model,\n",
        "                    n_epochs=2000, batch_size=1024, verbose=True):\n",
        "    \"\"\"\n",
        "    Joint fine-tuning of all three chart PINNs.\n",
        "\n",
        "    All parameters unfrozen, trained together with global loss.\n",
        "    \"\"\"\n",
        "    all_params = (list(neck_model.parameters()) +\n",
        "                  list(bulk_L_model.parameters()) +\n",
        "                  list(bulk_R_model.parameters()))\n",
        "    optimizer = torch.optim.AdamW(all_params, lr=1e-5, weight_decay=1e-5)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs)\n",
        "\n",
        "    history = {'loss': [], 'det': [], 'torsion': [], 'match_L': [], 'match_R': []}\n",
        "    best_loss = float('inf')\n",
        "    best_states = None\n",
        "    t_start = time.time()\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(f\"  PHASE 3: Joint Fine-Tuning ({n_epochs} epochs)\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "    for ep in range(n_epochs):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Sample all domains\n",
        "        x_neck = sample_domain(batch_size, DOMAIN_NECK)\n",
        "        x_bulk_L = sample_domain(batch_size // 2, DOMAIN_BULK_L)\n",
        "        x_bulk_R = sample_domain(batch_size // 2, DOMAIN_BULK_R)\n",
        "        x_ov_L = sample_overlap(batch_size // 4, OVERLAP_LEFT)\n",
        "        x_ov_R = sample_overlap(batch_size // 4, OVERLAP_RIGHT)\n",
        "\n",
        "        # Neck losses\n",
        "        L_det_N = det_loss(neck_model, x_neck)\n",
        "        L_tor = torsion_loss_fast(neck_model, x_neck)\n",
        "\n",
        "        # Bulk losses\n",
        "        L_det_L = det_loss(bulk_L_model, x_bulk_L)\n",
        "        L_det_R = det_loss(bulk_R_model, x_bulk_R)\n",
        "        L_ricci_L = ricci_proxy_loss(bulk_L_model, x_bulk_L)\n",
        "        L_ricci_R = ricci_proxy_loss(bulk_R_model, x_bulk_R)\n",
        "\n",
        "        # Interface matching\n",
        "        L_match_L = interface_loss_cholesky(\n",
        "            neck_model, bulk_L_model, x_ov_L)\n",
        "        L_match_R = interface_loss_cholesky(\n",
        "            neck_model, bulk_R_model, x_ov_R,\n",
        "            transform_fn=kovalev_twist_coords)\n",
        "\n",
        "        # Global loss\n",
        "        loss = (50 * (L_det_N + L_det_L + L_det_R) +\n",
        "                1.0 * L_tor +\n",
        "                0.3 * (L_ricci_L + L_ricci_R) +\n",
        "                80 * (L_match_L + L_match_R))\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(all_params, 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        history['loss'].append(loss.item())\n",
        "        history['det'].append((L_det_N + L_det_L + L_det_R).item())\n",
        "        history['torsion'].append(L_tor.item())\n",
        "        history['match_L'].append(L_match_L.item())\n",
        "        history['match_R'].append(L_match_R.item())\n",
        "\n",
        "        if loss.item() < best_loss:\n",
        "            best_loss = loss.item()\n",
        "            best_states = {\n",
        "                'neck': {k: v.cpu().clone() for k, v in neck_model.state_dict().items()},\n",
        "                'bulk_L': {k: v.cpu().clone() for k, v in bulk_L_model.state_dict().items()},\n",
        "                'bulk_R': {k: v.cpu().clone() for k, v in bulk_R_model.state_dict().items()},\n",
        "            }\n",
        "\n",
        "        if verbose and (ep % 250 == 0 or ep == n_epochs - 1):\n",
        "            elapsed = time.time() - t_start\n",
        "            print(f\"  [{ep:5d}] loss={loss.item():.2e}  det={L_det_N.item():.2e}  \"\n",
        "                  f\"tor={L_tor.item():.2e}  match_L={L_match_L.item():.2e}  \"\n",
        "                  f\"match_R={L_match_R.item():.2e}  ({elapsed:.0f}s)\")\n",
        "\n",
        "    # Restore best\n",
        "    if best_states is not None:\n",
        "        neck_model.load_state_dict(best_states['neck'])\n",
        "        bulk_L_model.load_state_dict(best_states['bulk_L'])\n",
        "        bulk_R_model.load_state_dict(best_states['bulk_R'])\n",
        "        neck_model.to(device)\n",
        "        bulk_L_model.to(device)\n",
        "        bulk_R_model.to(device)\n",
        "\n",
        "    elapsed = time.time() - t_start\n",
        "    if verbose:\n",
        "        print(f\"\\n  Joint fine-tuning complete in {elapsed:.1f}s, best={best_loss:.2e}\")\n",
        "\n",
        "    return history"
      ],
      "execution_count": 17,
      "outputs": [],
      "id": "1pA0L14zCxMJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGM_7g51CxMJ",
        "outputId": "45d08383-75f8-4753-e50c-69823a536225"
      },
      "source": [
        "joint_history = joint_fine_tune(neck_pinn, bulk_L_pinn, bulk_R_pinn, n_epochs=2000)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  PHASE 3: Joint Fine-Tuning (2000 epochs)\n",
            "======================================================================\n",
            "  [    0] loss=2.85e-03  det=5.75e-11  tor=1.90e-07  match_L=3.04e-08  match_R=2.77e-07  (0s)\n",
            "  [  250] loss=4.01e-06  det=5.31e-11  tor=1.73e-07  match_L=6.89e-11  match_R=5.41e-09  (113s)\n",
            "  [  500] loss=9.55e-06  det=4.38e-11  tor=1.57e-07  match_L=1.09e-10  match_R=5.41e-11  (226s)\n",
            "  [  750] loss=2.35e-06  det=5.27e-11  tor=1.48e-07  match_L=3.97e-12  match_R=2.02e-11  (339s)\n",
            "  [ 1000] loss=1.74e-06  det=4.59e-11  tor=1.41e-07  match_L=7.45e-12  match_R=1.06e-11  (452s)\n",
            "  [ 1250] loss=1.34e-06  det=4.86e-11  tor=1.41e-07  match_L=3.09e-12  match_R=8.86e-12  (565s)\n",
            "  [ 1500] loss=1.12e-06  det=4.91e-11  tor=1.37e-07  match_L=2.75e-12  match_R=5.64e-12  (678s)\n",
            "  [ 1750] loss=1.01e-06  det=4.22e-11  tor=1.32e-07  match_L=1.95e-12  match_R=5.34e-12  (792s)\n",
            "  [ 1999] loss=1.05e-06  det=4.88e-11  tor=1.33e-07  match_L=2.14e-12  match_R=5.07e-12  (905s)\n",
            "\n",
            "  Joint fine-tuning complete in 904.6s, best=9.22e-07\n"
          ]
        }
      ],
      "id": "kGM_7g51CxMJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9jdHDc8CxMJ"
      },
      "source": [
        "## 12. Global Validation\n",
        "\n",
        "Evaluate the assembled atlas across all three charts."
      ],
      "id": "R9jdHDc8CxMJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN3wQ5WECxMJ"
      },
      "source": [
        "def global_validation(neck_model, bulk_L_model, bulk_R_model,\n",
        "                      n_per_chart=20000, verbose=True):\n",
        "    \"\"\"\n",
        "    Comprehensive validation of the 3-chart atlas.\n",
        "\n",
        "    Checks:\n",
        "    - Per-chart det(g), positive-definiteness, condition number\n",
        "    - Interface matching error (both sides)\n",
        "    - Torsion in neck region\n",
        "    - Eigenvalue statistics\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"  GLOBAL VALIDATION\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "    # Per-chart validation\n",
        "    for name, model, domain in [\n",
        "        (\"Neck\", neck_model, DOMAIN_NECK),\n",
        "        (\"Bulk_L\", bulk_L_model, DOMAIN_BULK_L),\n",
        "        (\"Bulk_R\", bulk_R_model, DOMAIN_BULK_R),\n",
        "    ]:\n",
        "        results[name] = validate_chart(model, domain, name, n_samples=n_per_chart)\n",
        "\n",
        "    # Interface errors\n",
        "    with torch.no_grad():\n",
        "        x_ov_L = sample_overlap(5000, OVERLAP_LEFT)\n",
        "        x_ov_R = sample_overlap(5000, OVERLAP_RIGHT)\n",
        "\n",
        "        ml = interface_loss_cholesky(neck_model, bulk_L_model, x_ov_L).item()\n",
        "        mr = interface_loss_cholesky(\n",
        "            neck_model, bulk_R_model, x_ov_R,\n",
        "            transform_fn=kovalev_twist_coords).item()\n",
        "\n",
        "    results['interface_left'] = float(ml)\n",
        "    results['interface_right'] = float(mr)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n  Interface matching:\")\n",
        "        print(f\"    Left  (Bulk_L ∩ Neck): {ml:.6f}\")\n",
        "        print(f\"    Right (Neck ∩ Bulk_R): {mr:.6f} (through Kovalev twist)\")\n",
        "\n",
        "    # Torsion in neck (the critical region)\n",
        "    neck_model.train()\n",
        "    with torch.no_grad():\n",
        "        x_tor = sample_domain(5000, DOMAIN_NECK)\n",
        "    tor = torsion_loss_full(neck_model, x_tor).item()\n",
        "    neck_model.eval()\n",
        "    safety = TORSION_THRESHOLD / max(tor, 1e-10)\n",
        "\n",
        "    results['global_torsion'] = float(tor)\n",
        "    results['joyce_margin'] = float(safety)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n  Global torsion (neck): {tor:.2e}\")\n",
        "        print(f\"  Joyce margin: {safety:,.0f}×\")\n",
        "        print(f\"  Joyce threshold: {TORSION_THRESHOLD}\")\n",
        "\n",
        "    # Overall assessment\n",
        "    all_pd = all(results[c]['pos_def'] for c in ['Neck', 'Bulk_L', 'Bulk_R'])\n",
        "    max_det_err = max(results[c]['det_err_pct'] for c in ['Neck', 'Bulk_L', 'Bulk_R'])\n",
        "    interface_ok = ml < 1e-2 and mr < 1e-2\n",
        "\n",
        "    results['all_positive_definite'] = all_pd\n",
        "    results['max_det_error_pct'] = float(max_det_err)\n",
        "    results['interfaces_converged'] = interface_ok\n",
        "    results['level_A_pass'] = all_pd and max_det_err < 0.1 and interface_ok and safety > 10\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n  LEVEL A ASSESSMENT:\")\n",
        "        print(f\"    All PD: {all_pd}\")\n",
        "        print(f\"    Max det error: {max_det_err:.4f}%\")\n",
        "        print(f\"    Interfaces converged: {interface_ok}\")\n",
        "        print(f\"    Joyce margin > 10: {safety > 10}\")\n",
        "        print(f\"    >>> LEVEL A: {'PASS' if results['level_A_pass'] else 'FAIL'} <<<\")\n",
        "\n",
        "    return results"
      ],
      "execution_count": 19,
      "outputs": [],
      "id": "oN3wQ5WECxMJ"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-dQTEzfCxMJ",
        "outputId": "fcc94ddb-167f-4588-8b97-2b9dc87f2225"
      },
      "source": [
        "global_results = global_validation(neck_pinn, bulk_L_pinn, bulk_R_pinn)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  GLOBAL VALIDATION\n",
            "======================================================================\n",
            "\n",
            "  Neck:\n",
            "    det(g) = 2.03125400 (err=0.0002%)\n",
            "    min_eig = 1.106538, cond = 1.0000\n",
            "    PD = True, torsion = 1.35e-07\n",
            "\n",
            "  Bulk_L:\n",
            "    det(g) = 2.03124997 (err=0.0000%)\n",
            "    min_eig = 1.106510, cond = 1.0000\n",
            "    PD = True, torsion = nan\n",
            "\n",
            "  Bulk_R:\n",
            "    det(g) = 2.03124845 (err=0.0001%)\n",
            "    min_eig = 1.106508, cond = 1.0000\n",
            "    PD = True, torsion = nan\n",
            "\n",
            "  Interface matching:\n",
            "    Left  (Bulk_L ∩ Neck): 0.000000\n",
            "    Right (Neck ∩ Bulk_R): 0.000000 (through Kovalev twist)\n",
            "\n",
            "  Global torsion (neck): 6.88e-06\n",
            "  Joyce margin: 4,188×\n",
            "  Joyce threshold: 0.0288\n",
            "\n",
            "  LEVEL A ASSESSMENT:\n",
            "    All PD: True\n",
            "    Max det error: 0.0002%\n",
            "    Interfaces converged: True\n",
            "    Joyce margin > 10: True\n",
            "    >>> LEVEL A: PASS <<<\n"
          ]
        }
      ],
      "id": "U-dQTEzfCxMJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0--HRrsCxMK"
      },
      "source": [
        "## 13. Phase 4 — Spectral Bridge\n",
        "\n",
        "Compute Laplacian eigenvalues on the assembled K₇ metric.\n",
        "The MC Galerkin method uses basis functions adapted to the K₇ topology.\n",
        "\n",
        "**Key test**: λ₁ × H* = 14  (GIFT master equation)"
      ],
      "id": "D0--HRrsCxMK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3dz10ZWCxMK"
      },
      "source": [
        "def compute_spectral_bridge(neck_model, bulk_L_model, bulk_R_model,\n",
        "                            n_basis=60, n_mc=30000, verbose=True):\n",
        "    \"\"\"\n",
        "    Monte Carlo Galerkin computation of Laplacian eigenvalues.\n",
        "\n",
        "    Uses TCS-adapted basis functions:\n",
        "    - Neck: Fourier modes on K3 × T²\n",
        "    - Bulks: exponentially decaying modes\n",
        "\n",
        "    Returns: eigenvalues and λ₁ × H* comparison.\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 70)\n",
        "        print(\"  PHASE 4: Spectral Bridge\")\n",
        "        print(\"=\" * 70)\n",
        "\n",
        "    def global_metric_at(x):\n",
        "        \"\"\"Evaluate the assembled global metric at point x.\"\"\"\n",
        "        t = x[:, 0]\n",
        "        g = torch.zeros(x.shape[0], 7, 7, device=x.device, dtype=x.dtype)\n",
        "        N = x.shape[0]\n",
        "\n",
        "        # Determine chart membership\n",
        "        in_bulk_L = t < OVERLAP_LEFT[0]\n",
        "        in_bulk_R = t > OVERLAP_RIGHT[1]\n",
        "        in_overlap_L = (t >= OVERLAP_LEFT[0]) & (t <= OVERLAP_LEFT[1])\n",
        "        in_overlap_R = (t >= OVERLAP_RIGHT[0]) & (t <= OVERLAP_RIGHT[1])\n",
        "        in_neck_only = (t > OVERLAP_LEFT[1]) & (t < OVERLAP_RIGHT[0])\n",
        "\n",
        "        # Pure regions\n",
        "        if in_bulk_L.any():\n",
        "            g[in_bulk_L] = bulk_L_model.metric(x[in_bulk_L])\n",
        "        if in_bulk_R.any():\n",
        "            g[in_bulk_R] = bulk_R_model.metric(x[in_bulk_R])\n",
        "        if in_neck_only.any():\n",
        "            g[in_neck_only] = neck_model.metric(x[in_neck_only])\n",
        "\n",
        "        # Left overlap: blend Bulk_L and Neck\n",
        "        if in_overlap_L.any():\n",
        "            x_ov = x[in_overlap_L]\n",
        "            alpha = hermite_blend(x_ov[:, 0], OVERLAP_LEFT[0], OVERLAP_LEFT[1])\n",
        "            g_bulk = bulk_L_model.metric(x_ov)\n",
        "            g_neck = neck_model.metric(x_ov)\n",
        "            a = alpha.unsqueeze(1).unsqueeze(2)\n",
        "            g[in_overlap_L] = (1 - a) * g_bulk + a * g_neck\n",
        "\n",
        "        # Right overlap: blend Neck and Bulk_R (with Kovalev twist)\n",
        "        if in_overlap_R.any():\n",
        "            x_ov = x[in_overlap_R]\n",
        "            alpha = hermite_blend(x_ov[:, 0], OVERLAP_RIGHT[0], OVERLAP_RIGHT[1])\n",
        "            g_neck = neck_model.metric(x_ov)\n",
        "            x_twisted = kovalev_twist_coords(x_ov)\n",
        "            g_bulk_raw = bulk_R_model.metric(x_twisted)\n",
        "            g_bulk = transform_metric_kovalev(g_bulk_raw, device_ref=x_ov.device)\n",
        "            a = alpha.unsqueeze(1).unsqueeze(2)\n",
        "            g[in_overlap_R] = (1 - a) * g_neck + a * g_bulk\n",
        "\n",
        "        return g\n",
        "\n",
        "    # MC sample points uniformly across full [0,1]^7\n",
        "    x_mc = torch.rand(n_mc, 7, device=device, dtype=dtype)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Computing global metric at {n_mc} MC points...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        g_mc = global_metric_at(x_mc)\n",
        "        det_g_mc = torch.linalg.det(g_mc)\n",
        "        g_inv_mc = torch.linalg.inv(g_mc)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"  Global det(g): mean={det_g_mc.mean():.6f}, std={det_g_mc.std():.6f}\")\n",
        "\n",
        "    # Build basis functions: low-frequency TCS-adapted modes\n",
        "    # For K₇ = (CY₃ × S¹) ∪ (CY₃ × S¹), the natural basis is:\n",
        "    # - Products of Fourier modes on S¹ factors × K3 harmonics\n",
        "    # - Exponentially weighted for asymptotic regions\n",
        "    if verbose:\n",
        "        print(f\"  Building {n_basis} TCS-adapted basis functions...\")\n",
        "\n",
        "    basis_vectors = torch.arange(1, n_basis + 1, device=device, dtype=dtype)\n",
        "\n",
        "    # Galerkin matrices: S_ij = <ψ_i, ψ_j>_g  and  K_ij = <∇ψ_i, ∇ψ_j>_g\n",
        "    S = torch.zeros(n_basis, n_basis, device=device, dtype=dtype)\n",
        "    K = torch.zeros(n_basis, n_basis, device=device, dtype=dtype)\n",
        "\n",
        "    # Basis functions: cos/sin modes on different coordinate combinations\n",
        "    # TCS-adapted: separate modes for (t), (θ,ψ), (u₁..u₄)\n",
        "    n_t = 5        # radial modes\n",
        "    n_circle = 10  # S¹ modes (θ, ψ)\n",
        "    n_k3 = n_basis - n_t - n_circle  # K3 modes\n",
        "\n",
        "    def basis_fn(x, idx):\n",
        "        \"\"\"Evaluate basis function idx at points x. Returns (N,) values.\"\"\"\n",
        "        if idx < n_t:\n",
        "            # Radial modes: cos(k·π·t) with boundary tapering\n",
        "            k = idx + 1\n",
        "            return torch.cos(k * math.pi * x[:, 0])\n",
        "        elif idx < n_t + n_circle:\n",
        "            # Circle modes: cos/sin on θ or ψ\n",
        "            j = idx - n_t\n",
        "            if j < 5:\n",
        "                return torch.cos((j + 1) * 2 * math.pi * x[:, 1])\n",
        "            else:\n",
        "                return torch.sin((j - 4) * 2 * math.pi * x[:, 6])\n",
        "        else:\n",
        "            # K3 modes: products of cos on u coordinates\n",
        "            j = idx - n_t - n_circle\n",
        "            coord = j % 4\n",
        "            freq = j // 4 + 1\n",
        "            return torch.cos(freq * 2 * math.pi * x[:, 2 + coord])\n",
        "\n",
        "    def basis_grad(x, idx):\n",
        "        \"\"\"Gradient of basis function idx. Returns (N, 7).\"\"\"\n",
        "        x_req = x.clone().requires_grad_(True)\n",
        "        psi = basis_fn(x_req, idx)\n",
        "        grad = torch.autograd.grad(psi.sum(), x_req, create_graph=False)[0]\n",
        "        return grad\n",
        "\n",
        "    # Assemble Galerkin matrices\n",
        "    if verbose:\n",
        "        print(f\"  Assembling Galerkin matrices ({n_basis}×{n_basis})...\")\n",
        "    t_start = time.time()\n",
        "\n",
        "    # Pre-compute basis values and gradients\n",
        "    basis_vals = []\n",
        "    basis_grads = []\n",
        "    for i in range(n_basis):\n",
        "        basis_vals.append(basis_fn(x_mc, i))\n",
        "        basis_grads.append(basis_grad(x_mc, i))\n",
        "    basis_vals = torch.stack(basis_vals, dim=1)   # (n_mc, n_basis)\n",
        "    basis_grads = torch.stack(basis_grads, dim=1) # (n_mc, n_basis, 7)\n",
        "\n",
        "    # sqrt(det(g)) for volume element\n",
        "    sqrt_det = torch.sqrt(det_g_mc.abs().clamp(min=1e-10))\n",
        "\n",
        "    # S_ij = (1/n_mc) Σ_k ψ_i(x_k) ψ_j(x_k) sqrt(det(g_k))\n",
        "    weighted_basis = basis_vals * sqrt_det.unsqueeze(1)  # (n_mc, n_basis)\n",
        "    S = (weighted_basis.T @ basis_vals) / n_mc\n",
        "\n",
        "    # K_ij = (1/n_mc) Σ_k g^{ab}(x_k) ∂_a ψ_i(x_k) ∂_b ψ_j(x_k) sqrt(det(g_k))\n",
        "    # = (1/n_mc) Σ_k [∇ψ_i · g⁻¹ · ∇ψ_j] sqrt(det)\n",
        "    for i in range(n_basis):\n",
        "        # g^{-1} @ grad_i: (n_mc, 7)\n",
        "        ginv_gradi = torch.einsum('nab,nb->na', g_inv_mc, basis_grads[:, i, :])\n",
        "        for j in range(i, n_basis):\n",
        "            # <∇ψ_i, ∇ψ_j>_g = grad_i · g^{-1} · grad_j\n",
        "            integrand = (ginv_gradi * basis_grads[:, j, :]).sum(dim=1) * sqrt_det\n",
        "            val = integrand.mean()\n",
        "            K[i, j] = val\n",
        "            K[j, i] = val\n",
        "\n",
        "    elapsed = time.time() - t_start\n",
        "    if verbose:\n",
        "        print(f\"  Galerkin matrices assembled in {elapsed:.1f}s\")\n",
        "        print(f\"  S condition: {torch.linalg.cond(S).item():.1f}\")\n",
        "\n",
        "    # Solve generalized eigenvalue problem: K v = λ S v\n",
        "    # Regularize S slightly for numerical stability\n",
        "    S_reg = S + 1e-8 * torch.eye(n_basis, device=device, dtype=dtype)\n",
        "\n",
        "    try:\n",
        "        L_chol = torch.linalg.cholesky(S_reg)\n",
        "        # Transform to standard EVP: L^{-1} K L^{-T} w = λ w\n",
        "        K_transformed = torch.linalg.solve_triangular(\n",
        "            L_chol, torch.linalg.solve_triangular(L_chol, K, upper=False).T, upper=False).T\n",
        "        eigenvalues = torch.linalg.eigvalsh(K_transformed)\n",
        "    except Exception as e:\n",
        "        if verbose:\n",
        "            print(f\"  Cholesky failed ({e}), using eigh on S^{-1}K\")\n",
        "        S_inv = torch.linalg.inv(S_reg)\n",
        "        eigenvalues = torch.linalg.eigvalsh(S_inv @ K)\n",
        "\n",
        "    # Filter positive eigenvalues and sort\n",
        "    pos_eigs = eigenvalues[eigenvalues > 1e-6].sort().values\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n  Eigenvalue spectrum (first 20):\")\n",
        "        for i, ev in enumerate(pos_eigs[:20]):\n",
        "            lxh = ev.item() * H_STAR\n",
        "            marker = \" ← λ₁\" if i == 0 else \"\"\n",
        "            print(f\"    λ_{i + 1} = {ev.item():.6f}  (λ×H* = {lxh:.2f}){marker}\")\n",
        "\n",
        "        if len(pos_eigs) > 0:\n",
        "            lambda_1 = pos_eigs[0].item()\n",
        "            lxh = lambda_1 * H_STAR\n",
        "            print(f\"\\n  === SPECTRAL BRIDGE RESULT ===\")\n",
        "            print(f\"  λ₁ = {lambda_1:.6f}\")\n",
        "            print(f\"  λ₁ × H* = {lxh:.4f}\")\n",
        "            print(f\"  GIFT prediction: {LAMBDA_1_PREDICTED:.6f} × {H_STAR} = {DIM_G2}\")\n",
        "            print(f\"  Deviation: {abs(lxh - DIM_G2) / DIM_G2 * 100:.2f}%\")\n",
        "\n",
        "    spectral_results = {\n",
        "        'eigenvalues': [float(e) for e in pos_eigs[:50].tolist()],\n",
        "        'lambda_1': float(pos_eigs[0].item()) if len(pos_eigs) > 0 else None,\n",
        "        'lambda_1_x_Hstar': float(pos_eigs[0].item() * H_STAR) if len(pos_eigs) > 0 else None,\n",
        "        'n_basis': n_basis,\n",
        "        'n_mc': n_mc,\n",
        "        'S_condition': float(torch.linalg.cond(S).item()),\n",
        "    }\n",
        "\n",
        "    return spectral_results"
      ],
      "execution_count": 21,
      "outputs": [],
      "id": "F3dz10ZWCxMK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipIMIxWCCxMK",
        "outputId": "c83d1423-47e2-4eee-fd4c-8de582381a7b"
      },
      "source": [
        "spectral_results = compute_spectral_bridge(\n",
        "    neck_pinn, bulk_L_pinn, bulk_R_pinn,\n",
        "    n_basis=60, n_mc=30000\n",
        ")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "  PHASE 4: Spectral Bridge\n",
            "======================================================================\n",
            "  Computing global metric at 30000 MC points...\n",
            "  Global det(g): mean=2.031251, std=0.000053\n",
            "  Building 60 TCS-adapted basis functions...\n",
            "  Assembling Galerkin matrices (60×60)...\n",
            "  Galerkin matrices assembled in 0.2s\n",
            "  S condition: 1.2\n",
            "\n",
            "  Eigenvalue spectrum (first 20):\n",
            "    λ_1 = 9.072689  (λ×H* = 898.20) ← λ₁\n",
            "    λ_2 = 34.418045  (λ×H* = 3407.39)\n",
            "    λ_3 = 34.969051  (λ×H* = 3461.94)\n",
            "    λ_4 = 34.996797  (λ×H* = 3464.68)\n",
            "    λ_5 = 35.350577  (λ×H* = 3499.71)\n",
            "    λ_6 = 35.584982  (λ×H* = 3522.91)\n",
            "    λ_7 = 35.875500  (λ×H* = 3551.67)\n",
            "    λ_8 = 36.052364  (λ×H* = 3569.18)\n",
            "    λ_9 = 80.713593  (λ×H* = 7990.65)\n",
            "    λ_10 = 139.570237  (λ×H* = 13817.45)\n",
            "    λ_11 = 142.029795  (λ×H* = 14060.95)\n",
            "    λ_12 = 142.611103  (λ×H* = 14118.50)\n",
            "    λ_13 = 142.942996  (λ×H* = 14151.36)\n",
            "    λ_14 = 143.681905  (λ×H* = 14224.51)\n",
            "    λ_15 = 144.759877  (λ×H* = 14331.23)\n",
            "    λ_16 = 145.824855  (λ×H* = 14436.66)\n",
            "    λ_17 = 222.547518  (λ×H* = 22032.20)\n",
            "    λ_18 = 313.249203  (λ×H* = 31011.67)\n",
            "    λ_19 = 316.400422  (λ×H* = 31323.64)\n",
            "    λ_20 = 320.501072  (λ×H* = 31729.61)\n",
            "\n",
            "  === SPECTRAL BRIDGE RESULT ===\n",
            "  λ₁ = 9.072689\n",
            "  λ₁ × H* = 898.1962\n",
            "  GIFT prediction: 0.141414 × 99 = 14\n",
            "  Deviation: 6315.69%\n"
          ]
        }
      ],
      "id": "ipIMIxWCCxMK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjXr9RPaCxMK"
      },
      "source": [
        "## 14. Visualization"
      ],
      "id": "pjXr9RPaCxMK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egEVe2LMCxML",
        "outputId": "36d04d54-ac4d-40db-e1fb-c463098ae332"
      },
      "source": [
        "try:\n",
        "    import os\n",
        "    import matplotlib\n",
        "    matplotlib.use('Agg')\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
        "    fig.suptitle('GIFT Atlas G₂ Metric — 3-Chart TCS Construction', fontsize=14)\n",
        "\n",
        "    # Panel 1: Schwarz convergence\n",
        "    ax = axes[0, 0]\n",
        "    ax.semilogy(schwarz_history['iteration'], schwarz_history['match_left'], 'b-o', label='Left')\n",
        "    ax.semilogy(schwarz_history['iteration'], schwarz_history['match_right'], 'r-s', label='Right')\n",
        "    ax.axhline(1e-3, color='g', ls='--', alpha=0.5, label='Target')\n",
        "    ax.set_xlabel('Schwarz Iteration')\n",
        "    ax.set_ylabel('Interface Error')\n",
        "    ax.set_title('Schwarz Convergence')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Panel 2: Joint fine-tuning loss\n",
        "    ax = axes[0, 1]\n",
        "    ax.semilogy(joint_history['loss'], alpha=0.5)\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Total Loss')\n",
        "    ax.set_title('Joint Fine-Tuning')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Panel 3: Torsion during joint training\n",
        "    ax = axes[0, 2]\n",
        "    ax.semilogy(joint_history['torsion'], alpha=0.5, color='red')\n",
        "    ax.axhline(TORSION_THRESHOLD, color='k', ls='--', label=f'Joyce ε₀={TORSION_THRESHOLD}')\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Torsion')\n",
        "    ax.set_title('Torsion Convergence')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Panel 4: det(g) across full manifold\n",
        "    ax = axes[1, 0]\n",
        "    with torch.no_grad():\n",
        "        t_range = torch.linspace(0, 1, 200, device=device, dtype=dtype)\n",
        "        det_profile = []\n",
        "        for t_val in t_range:\n",
        "            x_sample = torch.rand(100, 7, device=device, dtype=dtype)\n",
        "            x_sample[:, 0] = t_val\n",
        "            if t_val < OVERLAP_LEFT[0]:\n",
        "                d = bulk_L_pinn.det_g(x_sample).mean().item()\n",
        "            elif t_val > OVERLAP_RIGHT[1]:\n",
        "                d = bulk_R_pinn.det_g(x_sample).mean().item()\n",
        "            else:\n",
        "                d = neck_pinn.det_g(x_sample).mean().item()\n",
        "            det_profile.append(d)\n",
        "    ax.plot(t_range.cpu().numpy(), det_profile, 'b-')\n",
        "    ax.axhline(DET_G_TARGET, color='r', ls='--', label=f'65/32 = {DET_G_TARGET}')\n",
        "    ax.axvspan(*OVERLAP_LEFT, alpha=0.1, color='green', label='Overlap L')\n",
        "    ax.axvspan(*OVERLAP_RIGHT, alpha=0.1, color='orange', label='Overlap R')\n",
        "    ax.set_xlabel('t (radial coordinate)')\n",
        "    ax.set_ylabel('det(g)')\n",
        "    ax.set_title('det(g) Profile Across K₇')\n",
        "    ax.legend(fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Panel 5: Eigenvalue spectrum\n",
        "    ax = axes[1, 1]\n",
        "    if spectral_results['eigenvalues']:\n",
        "        eigs = spectral_results['eigenvalues'][:30]\n",
        "        eigs_x_H = [e * H_STAR for e in eigs]\n",
        "        ax.bar(range(1, len(eigs_x_H) + 1), eigs_x_H, alpha=0.7)\n",
        "        ax.axhline(DIM_G2, color='r', ls='--', label=f'dim(G₂) = {DIM_G2}')\n",
        "        ax.set_xlabel('Eigenvalue index n')\n",
        "        ax.set_ylabel('λₙ × H*')\n",
        "        ax.set_title('Spectral Bridge: λₙ × H*')\n",
        "        ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "    # Panel 6: Summary\n",
        "    ax = axes[1, 2]\n",
        "    ax.axis('off')\n",
        "    summary_text = (\n",
        "        f\"GIFT Atlas G₂ Metric Results\\n\"\n",
        "        f\"{'=' * 35}\\n\\n\"\n",
        "        f\"Topology: K₇ = TCS(Quintic, CI(2,2,2))\\n\"\n",
        "        f\"b₂ = {B2}, b₃ = {B3}, H* = {H_STAR}\\n\\n\"\n",
        "        f\"Neck:   det err = {global_results['Neck']['det_err_pct']:.4f}%\\n\"\n",
        "        f\"Bulk L: det err = {global_results['Bulk_L']['det_err_pct']:.4f}%\\n\"\n",
        "        f\"Bulk R: det err = {global_results['Bulk_R']['det_err_pct']:.4f}%\\n\\n\"\n",
        "        f\"Interface L: {global_results['interface_left']:.6f}\\n\"\n",
        "        f\"Interface R: {global_results['interface_right']:.6f}\\n\\n\"\n",
        "        f\"Torsion: {global_results['global_torsion']:.2e}\\n\"\n",
        "        f\"Joyce margin: {global_results['joyce_margin']:,.0f}×\\n\\n\"\n",
        "    )\n",
        "    if spectral_results['lambda_1'] is not None:\n",
        "        summary_text += (\n",
        "            f\"λ₁ = {spectral_results['lambda_1']:.6f}\\n\"\n",
        "            f\"λ₁ × H* = {spectral_results['lambda_1_x_Hstar']:.4f}\\n\"\n",
        "            f\"GIFT: dim(G₂) = {DIM_G2}\\n\"\n",
        "            f\"Level A: {'PASS' if global_results['level_A_pass'] else 'FAIL'}\\n\"\n",
        "        )\n",
        "    ax.text(0.05, 0.95, summary_text, transform=ax.transAxes,\n",
        "            fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
        "            bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "    plt.savefig('outputs/gift_atlas_results.png', dpi=150, bbox_inches='tight')\n",
        "    print(\"Plot saved: outputs/gift_atlas_results.png\")\n",
        "    plt.close()\n",
        "\n",
        "except ImportError:\n",
        "    print(\"matplotlib not available, skipping visualization\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plot saved: outputs/gift_atlas_results.png\n"
          ]
        }
      ],
      "id": "egEVe2LMCxML"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce6CwTYaCxML"
      },
      "source": [
        "## 15. Save Results"
      ],
      "id": "Ce6CwTYaCxML"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95VxtE4sCxML",
        "outputId": "b2b9890e-624f-4295-8520-3e929b40e77a"
      },
      "source": [
        "# Save checkpoints\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "torch.save(neck_pinn.state_dict(), 'outputs/atlas_neck_pinn.pt')\n",
        "torch.save(bulk_L_pinn.state_dict(), 'outputs/atlas_bulk_L_pinn.pt')\n",
        "torch.save(bulk_R_pinn.state_dict(), 'outputs/atlas_bulk_R_pinn.pt')\n",
        "print(\"Checkpoints saved: atlas_neck_pinn.pt, atlas_bulk_L_pinn.pt, atlas_bulk_R_pinn.pt\")\n",
        "\n",
        "# Save results JSON\n",
        "all_results = {\n",
        "    'version': 'A1',\n",
        "    'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "    'architecture': {\n",
        "        'neck_params': neck_pinn.param_count(),\n",
        "        'bulk_L_params': bulk_L_pinn.param_count(),\n",
        "        'bulk_R_params': bulk_R_pinn.param_count(),\n",
        "        'total_params': total_params,\n",
        "    },\n",
        "    'topology': {\n",
        "        'b2': B2, 'b3': B3, 'H_star': H_STAR,\n",
        "        'b2_M1': B2_M1, 'b3_M1': B3_M1,\n",
        "        'b2_M2': B2_M2, 'b3_M2': B3_M2,\n",
        "    },\n",
        "    'domains': {\n",
        "        'bulk_L': list(DOMAIN_BULK_L),\n",
        "        'neck': list(DOMAIN_NECK),\n",
        "        'bulk_R': list(DOMAIN_BULK_R),\n",
        "        'overlap_L': list(OVERLAP_LEFT),\n",
        "        'overlap_R': list(OVERLAP_RIGHT),\n",
        "    },\n",
        "    'phase1_validation': {\n",
        "        'neck': val_neck,\n",
        "        'bulk_L': val_bulk_L,\n",
        "        'bulk_R': val_bulk_R,\n",
        "    },\n",
        "    'schwarz': {\n",
        "        'n_iterations': len(schwarz_history['iteration']),\n",
        "        'final_match_left': schwarz_history['match_left'][-1] if schwarz_history['match_left'] else None,\n",
        "        'final_match_right': schwarz_history['match_right'][-1] if schwarz_history['match_right'] else None,\n",
        "    },\n",
        "    'global_validation': global_results,\n",
        "    'spectral_bridge': spectral_results,\n",
        "    'level_A_pass': global_results.get('level_A_pass', False),\n",
        "}\n",
        "\n",
        "with open('outputs/gift_atlas_results.json', 'w') as f:\n",
        "    json.dump(all_results, f, indent=2, default=float)\n",
        "print(\"Results saved: outputs/gift_atlas_results.json\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoints saved: atlas_neck_pinn.pt, atlas_bulk_L_pinn.pt, atlas_bulk_R_pinn.pt\n",
            "Results saved: outputs/gift_atlas_results.json\n"
          ]
        }
      ],
      "id": "95VxtE4sCxML"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_diuc5SCxMM"
      },
      "source": [
        "## 16. Summary\n",
        "\n",
        "### What We Built\n",
        "- 3-chart atlas on K₇ = TCS(Quintic, CI(2,2,2)) with Kovalev twist\n",
        "- ~600k total parameters across 3 PINNs\n",
        "- Schwarz alternating method for interface matching\n",
        "- Full spectral bridge via MC Galerkin\n",
        "\n",
        "### Key Results\n",
        "- det(g) = 65/32 across all charts\n",
        "- Interface matching through Kovalev twist\n",
        "- Torsion below Joyce threshold\n",
        "- λ₁ × H* = ? (the decisive test for GIFT)\n",
        "\n",
        "### Next Steps (if Level A PASS)\n",
        "- **A2**: Multi-seed convergence on atlas (Level B)\n",
        "- **A3**: Spectral bridge refinement (more basis functions, adaptive MC)\n",
        "- **A4**: Compare λₙ with Riemann zeros (Level A.5)"
      ],
      "id": "u_diuc5SCxMM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCUUIFksCxMM"
      },
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"  GIFT Atlas G₂ Metric — COMPLETE\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n  Level A: {'PASS' if all_results['level_A_pass'] else 'FAIL'}\")\n",
        "if spectral_results['lambda_1'] is not None:\n",
        "    print(f\"  λ₁ × H* = {spectral_results['lambda_1_x_Hstar']:.4f} (target: {DIM_G2})\")\n",
        "print(f\"\\n  Total parameters: {total_params:,}\")\n",
        "print(f\"  Files saved in outputs/\")\n",
        "print(\"=\" * 70)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "oCUUIFksCxMM"
    }
  ]
}