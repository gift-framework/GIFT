{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K₇ Laplacian Comparison: Δ₀ (Scalar) vs Δ₁ (1-Forms)\n",
    "\n",
    "**Objective**: Test whether the Hodge Laplacian on 1-forms gives λ₁ × H* closer to 13 or 14 than the scalar Laplacian.\n",
    "\n",
    "**GIFT Prediction**: λ₁ × H* = dim(G₂) - 1 = 13 (or possibly 14 = dim(G₂))\n",
    "\n",
    "**Hardware**: A100 GPU recommended for N > 5000 samples\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 1. Setup & Dependencies\n",
    "!pip install -q scipy numpy matplotlib scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix, diags\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.spatial import KDTree\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import time\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, List, Optional\n",
    "\n",
    "# Check GPU\n",
    "import subprocess\n",
    "try:\n",
    "    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader']).decode()\n",
    "    print(f\"GPU detected: {gpu_info.strip()}\")\n",
    "except:\n",
    "    print(\"No GPU detected - running on CPU (slower)\")\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 2. GIFT Constants\n",
    "\n",
    "# Topological invariants\n",
    "DIM_G2 = 14          # dim(G₂) holonomy group\n",
    "DIM_K7 = 7           # dim(K₇) manifold\n",
    "B2 = 21              # Second Betti number of K₇\n",
    "B3 = 77              # Third Betti number of K₇\n",
    "H_STAR = B2 + B3 + 1 # = 99, cohomological dimension\n",
    "\n",
    "# Metric properties\n",
    "DET_G = 65/32        # G₂ metric determinant (exact)\n",
    "\n",
    "# Canonical ratio from TCS construction\n",
    "RATIO_CANONICAL = H_STAR / (6 * DIM_G2)  # = 99/84 = 33/28 ≈ 1.179\n",
    "\n",
    "# Target predictions\n",
    "TARGET_13 = 13       # dim(G₂) - 1\n",
    "TARGET_14 = DIM_G2   # dim(G₂)\n",
    "\n",
    "print(f\"GIFT Constants:\")\n",
    "print(f\"  dim(G₂) = {DIM_G2}\")\n",
    "print(f\"  dim(K₇) = {DIM_K7}\")\n",
    "print(f\"  b₂ = {B2}, b₃ = {B3}\")\n",
    "print(f\"  H* = b₂ + b₃ + 1 = {H_STAR}\")\n",
    "print(f\"  det(g) = {DET_G} = {65}/{32}\")\n",
    "print(f\"  Canonical ratio = {RATIO_CANONICAL:.4f}\")\n",
    "print(f\"\\nTargets: λ₁ × H* = {TARGET_13} or {TARGET_14}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 3. K₇ Manifold Sampling (TCS Construction)\n",
    "\n",
    "def sample_S3(n: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Sample uniformly from 3-sphere.\"\"\"\n",
    "    x = rng.standard_normal((n, 4))\n",
    "    return x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "\n",
    "def sample_T4(n: int, rng: np.random.Generator) -> np.ndarray:\n",
    "    \"\"\"Sample uniformly from 4-torus.\"\"\"\n",
    "    return 2 * np.pi * rng.random((n, 4))\n",
    "\n",
    "def sample_K7_TCS(n: int, ratio: float, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Sample from K₇ using Twisted Connected Sum (TCS) construction.\n",
    "    \n",
    "    K₇ = (S³ × T⁴) ∪_φ (S³ × T⁴) glued along S³ × T³\n",
    "    \n",
    "    Args:\n",
    "        n: Number of samples\n",
    "        ratio: Controls the relative size of S³ vs T⁴ components\n",
    "        seed: Random seed\n",
    "    \n",
    "    Returns:\n",
    "        Array of shape (n, 7) - points on K₇\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # Split samples between two halves\n",
    "    n1 = n // 2\n",
    "    n2 = n - n1\n",
    "    \n",
    "    points = []\n",
    "    \n",
    "    for n_half, sign in [(n1, 1), (n2, -1)]:\n",
    "        # Sample S³ component (rescaled by ratio)\n",
    "        s3 = sample_S3(n_half, rng) * ratio\n",
    "        \n",
    "        # Sample T⁴ component (take 3 coordinates for 7D total)\n",
    "        t4 = sample_T4(n_half, rng)[:, :3]\n",
    "        \n",
    "        # Combine: use first 3 coords of S³ + T³ + 1 coord from S³\n",
    "        # This gives 3 + 3 + 1 = 7 dimensions\n",
    "        half_points = np.column_stack([\n",
    "            s3[:, :3],           # First 3 from S³\n",
    "            t4,                   # 3 from T⁴ (reduced to T³)\n",
    "            sign * s3[:, 3:4]    # Last 1 from S³ (with twist)\n",
    "        ])\n",
    "        points.append(half_points)\n",
    "    \n",
    "    return np.vstack(points)\n",
    "\n",
    "def apply_G2_metric(points: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Apply G₂-invariant metric deformation.\n",
    "    \n",
    "    The metric has det(g) = 65/32 (GIFT prediction).\n",
    "    We apply anisotropic scaling to achieve this determinant.\n",
    "    \"\"\"\n",
    "    # Scale factors to achieve det(g) = 65/32\n",
    "    # det = product of scales^2 in each direction\n",
    "    target_det = DET_G\n",
    "    \n",
    "    # Use G₂-motivated scaling: (1, 1, 1, α, α, α, β) with constraints\n",
    "    # α³ × β = target_det^(1/2) for unit base\n",
    "    alpha = (target_det ** (1/7)) ** 0.5\n",
    "    beta = target_det ** (1/14)\n",
    "    \n",
    "    scales = np.array([1, 1, 1, alpha, alpha, alpha, beta])\n",
    "    \n",
    "    return points * scales\n",
    "\n",
    "# Test sampling\n",
    "test_points = sample_K7_TCS(1000, RATIO_CANONICAL)\n",
    "print(f\"K₇ sampling test: {test_points.shape}\")\n",
    "print(f\"  Mean: {test_points.mean(axis=0)}\")\n",
    "print(f\"  Std:  {test_points.std(axis=0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 4. Reference Manifold Samplers (for Calibration)\n",
    "\n",
    "def sample_sphere(n: int, dim: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"Sample uniformly from S^dim (embedded in R^{dim+1}).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    x = rng.standard_normal((n, dim + 1))\n",
    "    return x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "\n",
    "def sample_torus(n: int, dim: int, seed: int = 42) -> np.ndarray:\n",
    "    \"\"\"Sample uniformly from T^dim (flat torus).\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    return 2 * np.pi * rng.random((n, dim))\n",
    "\n",
    "# Known eigenvalues for calibration\n",
    "REFERENCE_EIGENVALUES = {\n",
    "    'S3': {'lambda1': 3.0, 'dim': 4},    # First nonzero eigenvalue of S³\n",
    "    'S7': {'lambda1': 7.0, 'dim': 8},    # First nonzero eigenvalue of S⁷\n",
    "    'T7': {'lambda1': 1.0, 'dim': 7},    # First nonzero eigenvalue of T⁷ (with 2π period)\n",
    "}\n",
    "\n",
    "print(\"Reference manifolds for calibration:\")\n",
    "for name, info in REFERENCE_EIGENVALUES.items():\n",
    "    print(f\"  {name}: λ₁ = {info['lambda1']}, embedding dim = {info['dim']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 5. Graph Laplacian Construction\n",
    "\n",
    "def build_graph_laplacian(\n",
    "    points: np.ndarray,\n",
    "    k: int = 20,\n",
    "    epsilon: Optional[float] = None\n",
    ") -> csr_matrix:\n",
    "    \"\"\"\n",
    "    Build the graph Laplacian from point cloud.\n",
    "    \n",
    "    Uses k-NN graph with Gaussian weights.\n",
    "    \n",
    "    Args:\n",
    "        points: (N, d) array of points\n",
    "        k: Number of nearest neighbors\n",
    "        epsilon: Bandwidth for Gaussian kernel (auto if None)\n",
    "    \n",
    "    Returns:\n",
    "        Sparse Laplacian matrix L = D - W\n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    \n",
    "    # Build k-NN graph\n",
    "    tree = KDTree(points)\n",
    "    distances, indices = tree.query(points, k=k+1)  # +1 to exclude self\n",
    "    \n",
    "    # Auto-select epsilon based on median distance\n",
    "    if epsilon is None:\n",
    "        epsilon = np.median(distances[:, 1:]) ** 2\n",
    "    \n",
    "    # Build weight matrix with Gaussian kernel\n",
    "    rows, cols, data = [], [], []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j_idx in range(1, k+1):  # Skip self (index 0)\n",
    "            j = indices[i, j_idx]\n",
    "            d = distances[i, j_idx]\n",
    "            w = np.exp(-d**2 / epsilon)\n",
    "            \n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(w)\n",
    "    \n",
    "    W = csr_matrix((data, (rows, cols)), shape=(n, n))\n",
    "    W = (W + W.T) / 2  # Symmetrize\n",
    "    \n",
    "    # Degree matrix\n",
    "    D = diags(np.array(W.sum(axis=1)).flatten())\n",
    "    \n",
    "    # Laplacian L = D - W\n",
    "    L = D - W\n",
    "    \n",
    "    return L, epsilon\n",
    "\n",
    "def compute_scalar_eigenvalues(\n",
    "    L: csr_matrix,\n",
    "    n_eigenvalues: int = 10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute smallest eigenvalues of scalar Laplacian Δ₀.\n",
    "    \n",
    "    Returns:\n",
    "        Array of eigenvalues (sorted, smallest first)\n",
    "    \"\"\"\n",
    "    eigenvalues, _ = eigsh(L, k=n_eigenvalues, which='SM')\n",
    "    return np.sort(eigenvalues)\n",
    "\n",
    "print(\"Graph Laplacian functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 6. Hodge Laplacian on 1-Forms (Δ₁)\n",
    "\n",
    "def build_exterior_derivative(\n",
    "    points: np.ndarray,\n",
    "    k: int = 20,\n",
    "    epsilon: Optional[float] = None\n",
    ") -> Tuple[csr_matrix, float]:\n",
    "    \"\"\"\n",
    "    Build discrete exterior derivative d₀: Ω⁰ → Ω¹.\n",
    "    \n",
    "    For a graph, d₀ is the incidence matrix:\n",
    "    (d₀f)(e_{ij}) = f(j) - f(i) for edge e_{ij}\n",
    "    \n",
    "    Returns:\n",
    "        d0: Sparse matrix (n_edges, n_vertices)\n",
    "        epsilon: Bandwidth used\n",
    "    \"\"\"\n",
    "    n = len(points)\n",
    "    \n",
    "    # Build k-NN graph\n",
    "    tree = KDTree(points)\n",
    "    distances, indices = tree.query(points, k=k+1)\n",
    "    \n",
    "    if epsilon is None:\n",
    "        epsilon = np.median(distances[:, 1:]) ** 2\n",
    "    \n",
    "    # Collect edges (directed, i < j to avoid duplicates)\n",
    "    edges = set()\n",
    "    edge_weights = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j_idx in range(1, k+1):\n",
    "            j = indices[i, j_idx]\n",
    "            d = distances[i, j_idx]\n",
    "            w = np.exp(-d**2 / (2 * epsilon))\n",
    "            \n",
    "            edge = (min(i, j), max(i, j))\n",
    "            if edge not in edges:\n",
    "                edges.add(edge)\n",
    "                edge_weights[edge] = w\n",
    "            else:\n",
    "                # Average weights for bidirectional edges\n",
    "                edge_weights[edge] = (edge_weights[edge] + w) / 2\n",
    "    \n",
    "    edges = sorted(edges)\n",
    "    n_edges = len(edges)\n",
    "    \n",
    "    # Build incidence matrix d₀\n",
    "    rows, cols, data = [], [], []\n",
    "    \n",
    "    for e_idx, (i, j) in enumerate(edges):\n",
    "        w = np.sqrt(edge_weights[(i, j)])\n",
    "        rows.extend([e_idx, e_idx])\n",
    "        cols.extend([i, j])\n",
    "        data.extend([-w, w])  # d₀f(e) = w*(f(j) - f(i))\n",
    "    \n",
    "    d0 = csr_matrix((data, (rows, cols)), shape=(n_edges, n))\n",
    "    \n",
    "    return d0, epsilon, edges, edge_weights\n",
    "\n",
    "def build_hodge_laplacian_1form(\n",
    "    points: np.ndarray,\n",
    "    k: int = 20,\n",
    "    epsilon: Optional[float] = None\n",
    ") -> Tuple[csr_matrix, float]:\n",
    "    \"\"\"\n",
    "    Build Hodge Laplacian on 1-forms: Δ₁ = d₀ᵀd₀ + d₁d₁ᵀ\n",
    "    \n",
    "    For simplicity (no 2-forms), we use: Δ₁ ≈ d₀ᵀd₀\n",
    "    This captures the \"curl-free\" part of 1-forms.\n",
    "    \n",
    "    Returns:\n",
    "        L1: Hodge Laplacian on 1-forms (n_edges × n_edges)\n",
    "        epsilon: Bandwidth used\n",
    "    \"\"\"\n",
    "    d0, epsilon, edges, edge_weights = build_exterior_derivative(points, k, epsilon)\n",
    "    \n",
    "    # Δ₁ = d₀ᵀ d₀ (this is the \"down\" Laplacian on 1-forms)\n",
    "    # Note: Full Hodge Laplacian would include d₁d₁ᵀ term\n",
    "    L1_down = d0 @ d0.T\n",
    "    \n",
    "    # For a more complete approximation, we also add the \"up\" Laplacian\n",
    "    # This requires building d₁, which needs triangles\n",
    "    # For now, we use just the down part (sufficient for gauge theory)\n",
    "    \n",
    "    return L1_down, epsilon, len(edges)\n",
    "\n",
    "def compute_1form_eigenvalues(\n",
    "    L1: csr_matrix,\n",
    "    n_eigenvalues: int = 10\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute smallest eigenvalues of 1-form Laplacian Δ₁.\n",
    "    \"\"\"\n",
    "    # L1 may have many zero eigenvalues (harmonic forms)\n",
    "    # We compute a few more to find the first nonzero\n",
    "    n_compute = min(n_eigenvalues + 50, L1.shape[0] - 1)\n",
    "    eigenvalues, _ = eigsh(L1, k=n_compute, which='SM')\n",
    "    return np.sort(eigenvalues)\n",
    "\n",
    "print(\"Hodge Laplacian functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 7. Calibration Protocol (ε-rescaling)\n",
    "\n",
    "@dataclass\n",
    "class CalibrationResult:\n",
    "    manifold: str\n",
    "    true_lambda1: float\n",
    "    raw_lambda1: float\n",
    "    scale_factor: float\n",
    "    calibrated_lambda1: float\n",
    "    error_percent: float\n",
    "\n",
    "def calibrate_on_reference(\n",
    "    manifold: str,\n",
    "    n: int = 2000,\n",
    "    k: int = 20,\n",
    "    seed: int = 42\n",
    ") -> CalibrationResult:\n",
    "    \"\"\"\n",
    "    Calibrate the graph Laplacian on a reference manifold.\n",
    "    \n",
    "    Returns scale factor to convert raw eigenvalues to true eigenvalues.\n",
    "    \"\"\"\n",
    "    info = REFERENCE_EIGENVALUES[manifold]\n",
    "    true_lambda1 = info['lambda1']\n",
    "    dim = info['dim']\n",
    "    \n",
    "    # Sample manifold\n",
    "    if manifold.startswith('S'):\n",
    "        sphere_dim = int(manifold[1:])\n",
    "        points = sample_sphere(n, sphere_dim, seed)\n",
    "    elif manifold.startswith('T'):\n",
    "        torus_dim = int(manifold[1:])\n",
    "        points = sample_torus(n, torus_dim, seed)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown manifold: {manifold}\")\n",
    "    \n",
    "    # Build Laplacian and compute eigenvalues\n",
    "    L, epsilon = build_graph_laplacian(points, k=k)\n",
    "    eigenvalues = compute_scalar_eigenvalues(L, n_eigenvalues=5)\n",
    "    \n",
    "    # First nonzero eigenvalue (skip the zero eigenvalue)\n",
    "    raw_lambda1 = eigenvalues[1] if eigenvalues[0] < 1e-10 else eigenvalues[0]\n",
    "    \n",
    "    # Scale factor: true / raw\n",
    "    scale_factor = true_lambda1 / raw_lambda1\n",
    "    calibrated = raw_lambda1 * scale_factor\n",
    "    error = abs(calibrated - true_lambda1) / true_lambda1 * 100\n",
    "    \n",
    "    return CalibrationResult(\n",
    "        manifold=manifold,\n",
    "        true_lambda1=true_lambda1,\n",
    "        raw_lambda1=raw_lambda1,\n",
    "        scale_factor=scale_factor,\n",
    "        calibrated_lambda1=calibrated,\n",
    "        error_percent=error\n",
    "    )\n",
    "\n",
    "def run_calibration(n: int = 2000, k: int = 20) -> dict:\n",
    "    \"\"\"Run calibration on all reference manifolds.\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"CALIBRATION ON REFERENCE MANIFOLDS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    results = {}\n",
    "    scale_factors = []\n",
    "    \n",
    "    for manifold in ['S3', 'S7', 'T7']:\n",
    "        result = calibrate_on_reference(manifold, n=n, k=k)\n",
    "        results[manifold] = result\n",
    "        scale_factors.append(result.scale_factor)\n",
    "        \n",
    "        print(f\"\\n{manifold}:\")\n",
    "        print(f\"  True λ₁ = {result.true_lambda1}\")\n",
    "        print(f\"  Raw λ₁  = {result.raw_lambda1:.6f}\")\n",
    "        print(f\"  Scale   = {result.scale_factor:.4f}\")\n",
    "    \n",
    "    # Average scale factor\n",
    "    avg_scale = np.mean(scale_factors)\n",
    "    std_scale = np.std(scale_factors)\n",
    "    \n",
    "    print(f\"\\n\" + \"-\"*60)\n",
    "    print(f\"Average scale factor: {avg_scale:.4f} ± {std_scale:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return results, avg_scale\n",
    "\n",
    "# Run calibration\n",
    "calibration_results, SCALE_FACTOR = run_calibration(n=2000, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 8. Main Experiment: Δ₀ vs Δ₁ on K₇\n",
    "\n",
    "@dataclass\n",
    "class K7Result:\n",
    "    N: int\n",
    "    k: int\n",
    "    ratio: float\n",
    "    \n",
    "    # Scalar Laplacian Δ₀\n",
    "    lambda1_0_raw: float\n",
    "    lambda1_0_scaled: float\n",
    "    product_0: float  # λ₁ × H*\n",
    "    deviation_0_from_13: float\n",
    "    deviation_0_from_14: float\n",
    "    \n",
    "    # 1-Form Laplacian Δ₁\n",
    "    lambda1_1_raw: float\n",
    "    lambda1_1_scaled: float\n",
    "    product_1: float  # λ₁ × H*\n",
    "    deviation_1_from_13: float\n",
    "    deviation_1_from_14: float\n",
    "    \n",
    "    # Metadata\n",
    "    n_edges: int\n",
    "    time_0: float\n",
    "    time_1: float\n",
    "\n",
    "def run_K7_experiment(\n",
    "    N: int = 5000,\n",
    "    k: int = 30,\n",
    "    ratio: float = RATIO_CANONICAL,\n",
    "    scale_factor: float = 1.0,\n",
    "    seed: int = 42,\n",
    "    apply_metric: bool = True\n",
    ") -> K7Result:\n",
    "    \"\"\"\n",
    "    Run the main experiment comparing Δ₀ and Δ₁ on K₇.\n",
    "    \"\"\"\n",
    "    print(f\"\\nSampling K₇ with N={N}, ratio={ratio:.4f}...\")\n",
    "    \n",
    "    # Sample K₇\n",
    "    points = sample_K7_TCS(N, ratio, seed)\n",
    "    if apply_metric:\n",
    "        points = apply_G2_metric(points)\n",
    "    \n",
    "    print(f\"  Points shape: {points.shape}\")\n",
    "    \n",
    "    # === Scalar Laplacian Δ₀ ===\n",
    "    print(\"\\nComputing Δ₀ (scalar Laplacian)...\")\n",
    "    t0 = time.time()\n",
    "    L0, eps0 = build_graph_laplacian(points, k=k)\n",
    "    eigs_0 = compute_scalar_eigenvalues(L0, n_eigenvalues=10)\n",
    "    time_0 = time.time() - t0\n",
    "    \n",
    "    # First nonzero eigenvalue\n",
    "    lambda1_0_raw = eigs_0[1] if eigs_0[0] < 1e-10 else eigs_0[0]\n",
    "    lambda1_0_scaled = lambda1_0_raw * scale_factor\n",
    "    product_0 = lambda1_0_scaled * H_STAR\n",
    "    \n",
    "    print(f\"  λ₁(Δ₀) raw = {lambda1_0_raw:.6f}\")\n",
    "    print(f\"  λ₁(Δ₀) scaled = {lambda1_0_scaled:.6f}\")\n",
    "    print(f\"  λ₁(Δ₀) × H* = {product_0:.4f}\")\n",
    "    print(f\"  Time: {time_0:.2f}s\")\n",
    "    \n",
    "    # === 1-Form Laplacian Δ₁ ===\n",
    "    print(\"\\nComputing Δ₁ (1-form Hodge Laplacian)...\")\n",
    "    t1 = time.time()\n",
    "    L1, eps1, n_edges = build_hodge_laplacian_1form(points, k=k)\n",
    "    eigs_1 = compute_1form_eigenvalues(L1, n_eigenvalues=20)\n",
    "    time_1 = time.time() - t1\n",
    "    \n",
    "    # First nonzero eigenvalue (may have many zeros = harmonic 1-forms)\n",
    "    # For K₇, b₁ = 0, so there should be few harmonic forms\n",
    "    nonzero_mask = eigs_1 > 1e-8\n",
    "    if nonzero_mask.any():\n",
    "        lambda1_1_raw = eigs_1[nonzero_mask][0]\n",
    "    else:\n",
    "        lambda1_1_raw = eigs_1[1]\n",
    "    \n",
    "    lambda1_1_scaled = lambda1_1_raw * scale_factor\n",
    "    product_1 = lambda1_1_scaled * H_STAR\n",
    "    \n",
    "    print(f\"  n_edges = {n_edges}\")\n",
    "    print(f\"  λ₁(Δ₁) raw = {lambda1_1_raw:.6f}\")\n",
    "    print(f\"  λ₁(Δ₁) scaled = {lambda1_1_scaled:.6f}\")\n",
    "    print(f\"  λ₁(Δ₁) × H* = {product_1:.4f}\")\n",
    "    print(f\"  Time: {time_1:.2f}s\")\n",
    "    \n",
    "    # Compute deviations\n",
    "    dev_0_13 = abs(product_0 - TARGET_13) / TARGET_13 * 100\n",
    "    dev_0_14 = abs(product_0 - TARGET_14) / TARGET_14 * 100\n",
    "    dev_1_13 = abs(product_1 - TARGET_13) / TARGET_13 * 100\n",
    "    dev_1_14 = abs(product_1 - TARGET_14) / TARGET_14 * 100\n",
    "    \n",
    "    return K7Result(\n",
    "        N=N, k=k, ratio=ratio,\n",
    "        lambda1_0_raw=lambda1_0_raw,\n",
    "        lambda1_0_scaled=lambda1_0_scaled,\n",
    "        product_0=product_0,\n",
    "        deviation_0_from_13=dev_0_13,\n",
    "        deviation_0_from_14=dev_0_14,\n",
    "        lambda1_1_raw=lambda1_1_raw,\n",
    "        lambda1_1_scaled=lambda1_1_scaled,\n",
    "        product_1=product_1,\n",
    "        deviation_1_from_13=dev_1_13,\n",
    "        deviation_1_from_14=dev_1_14,\n",
    "        n_edges=n_edges,\n",
    "        time_0=time_0,\n",
    "        time_1=time_1\n",
    "    )\n",
    "\n",
    "print(\"Experiment function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 9. Run Main Experiment\n",
    "\n",
    "# Configuration\n",
    "N_SAMPLES = 5000      # Increase for better accuracy (try 10000-20000 on A100)\n",
    "K_NEIGHBORS = 30      # Number of nearest neighbors\n",
    "RATIO = RATIO_CANONICAL  # = 33/28 ≈ 1.179\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"K₇ LAPLACIAN COMPARISON: Δ₀ (SCALAR) vs Δ₁ (1-FORMS)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  N = {N_SAMPLES} samples\")\n",
    "print(f\"  k = {K_NEIGHBORS} neighbors\")\n",
    "print(f\"  ratio = {RATIO:.4f}\")\n",
    "print(f\"  H* = {H_STAR}\")\n",
    "print(f\"  Scale factor = {SCALE_FACTOR:.4f}\")\n",
    "\n",
    "# Run experiment\n",
    "result = run_K7_experiment(\n",
    "    N=N_SAMPLES,\n",
    "    k=K_NEIGHBORS,\n",
    "    ratio=RATIO,\n",
    "    scale_factor=SCALE_FACTOR,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 10. Results Summary & Comparison\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Metric':<25} {'Δ₀ (Scalar)':<20} {'Δ₁ (1-Forms)':<20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'λ₁ (raw)':<25} {result.lambda1_0_raw:<20.6f} {result.lambda1_1_raw:<20.6f}\")\n",
    "print(f\"{'λ₁ (scaled)':<25} {result.lambda1_0_scaled:<20.6f} {result.lambda1_1_scaled:<20.6f}\")\n",
    "print(f\"{'λ₁ × H*':<25} {result.product_0:<20.4f} {result.product_1:<20.4f}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Deviation from 13':<25} {result.deviation_0_from_13:<19.2f}% {result.deviation_1_from_13:<19.2f}%\")\n",
    "print(f\"{'Deviation from 14':<25} {result.deviation_0_from_14:<19.2f}% {result.deviation_1_from_14:<19.2f}%\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Determine winner\n",
    "best_target_0 = TARGET_13 if result.deviation_0_from_13 < result.deviation_0_from_14 else TARGET_14\n",
    "best_target_1 = TARGET_13 if result.deviation_1_from_13 < result.deviation_1_from_14 else TARGET_14\n",
    "best_dev_0 = min(result.deviation_0_from_13, result.deviation_0_from_14)\n",
    "best_dev_1 = min(result.deviation_1_from_13, result.deviation_1_from_14)\n",
    "\n",
    "print(f\"\\n{'Best fit for Δ₀:':<25} {best_target_0} (deviation: {best_dev_0:.2f}%)\")\n",
    "print(f\"{'Best fit for Δ₁:':<25} {best_target_1} (deviation: {best_dev_1:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "if best_dev_1 < best_dev_0:\n",
    "    winner = \"Δ₁ (1-FORMS)\"\n",
    "    improvement = best_dev_0 - best_dev_1\n",
    "else:\n",
    "    winner = \"Δ₀ (SCALAR)\"\n",
    "    improvement = best_dev_1 - best_dev_0\n",
    "\n",
    "print(f\"WINNER: {winner}\")\n",
    "print(f\"Improvement: {improvement:.2f} percentage points\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Physical interpretation\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"PHYSICAL INTERPRETATION\")\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nIf λ₁ × H* = {result.product_1:.2f} (from Δ₁):\")\n",
    "lambda1_physical = result.product_1 / H_STAR\n",
    "mass_gap_MeV = lambda1_physical * 200  # Λ_QCD ≈ 200 MeV\n",
    "print(f\"  λ₁ = {lambda1_physical:.4f}\")\n",
    "print(f\"  Δ_QCD = λ₁ × Λ_QCD = {lambda1_physical:.4f} × 200 MeV = {mass_gap_MeV:.1f} MeV\")\n",
    "print(f\"\\nGIFT prediction: Δ_QCD ≈ (14/99) × 200 = 28.3 MeV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 11. Visualization\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Bar comparison\n",
    "ax1 = axes[0]\n",
    "x = ['Δ₀ (Scalar)', 'Δ₁ (1-Forms)']\n",
    "products = [result.product_0, result.product_1]\n",
    "colors = ['steelblue', 'darkorange']\n",
    "bars = ax1.bar(x, products, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.axhline(y=13, color='red', linestyle='--', linewidth=2, label='Target: 13')\n",
    "ax1.axhline(y=14, color='green', linestyle='--', linewidth=2, label='Target: 14')\n",
    "ax1.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax1.set_title('Laplacian Comparison on K₇', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.set_ylim([0, max(products) * 1.3])\n",
    "for bar, val in zip(bars, products):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "             f'{val:.2f}', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Plot 2: Deviation comparison\n",
    "ax2 = axes[1]\n",
    "x_dev = np.arange(2)\n",
    "width = 0.35\n",
    "dev_13 = [result.deviation_0_from_13, result.deviation_1_from_13]\n",
    "dev_14 = [result.deviation_0_from_14, result.deviation_1_from_14]\n",
    "bars1 = ax2.bar(x_dev - width/2, dev_13, width, label='From 13', color='red', alpha=0.7)\n",
    "bars2 = ax2.bar(x_dev + width/2, dev_14, width, label='From 14', color='green', alpha=0.7)\n",
    "ax2.set_ylabel('Deviation (%)', fontsize=12)\n",
    "ax2.set_title('Deviation from Targets', fontsize=14)\n",
    "ax2.set_xticks(x_dev)\n",
    "ax2.set_xticklabels(['Δ₀', 'Δ₁'])\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: GIFT Constants Context\n",
    "ax3 = axes[2]\n",
    "constants = ['dim(G₂)', 'dim(G₂)-1', 'b₂', 'b₃', 'H*']\n",
    "values = [14, 13, 21, 77, 99]\n",
    "colors_c = ['#2ecc71', '#e74c3c', '#3498db', '#9b59b6', '#f39c12']\n",
    "bars3 = ax3.barh(constants, values, color=colors_c, edgecolor='black')\n",
    "ax3.set_xlabel('Value', fontsize=12)\n",
    "ax3.set_title('GIFT Topological Constants', fontsize=14)\n",
    "for bar, val in zip(bars3, values):\n",
    "    ax3.text(val + 1, bar.get_y() + bar.get_height()/2, \n",
    "             str(val), va='center', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('K7_laplacian_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved as 'K7_laplacian_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 12. Ratio Sweep (Optional - finds optimal ratio)\n",
    "\n",
    "RUN_RATIO_SWEEP = False  # Set to True to run (takes longer)\n",
    "\n",
    "if RUN_RATIO_SWEEP:\n",
    "    print(\"Running ratio sweep...\")\n",
    "    \n",
    "    ratios = np.linspace(0.8, 1.6, 17)\n",
    "    products_0 = []\n",
    "    products_1 = []\n",
    "    \n",
    "    for r in ratios:\n",
    "        res = run_K7_experiment(\n",
    "            N=2000,  # Smaller N for speed\n",
    "            k=20,\n",
    "            ratio=r,\n",
    "            scale_factor=SCALE_FACTOR,\n",
    "            seed=42\n",
    "        )\n",
    "        products_0.append(res.product_0)\n",
    "        products_1.append(res.product_1)\n",
    "        print(f\"ratio={r:.3f}: Δ₀→{res.product_0:.2f}, Δ₁→{res.product_1:.2f}\")\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ratios, products_0, 'o-', label='Δ₀ (Scalar)', linewidth=2, markersize=8)\n",
    "    plt.plot(ratios, products_1, 's-', label='Δ₁ (1-Forms)', linewidth=2, markersize=8)\n",
    "    plt.axhline(y=13, color='red', linestyle='--', linewidth=2, label='Target: 13')\n",
    "    plt.axhline(y=14, color='green', linestyle='--', linewidth=2, label='Target: 14')\n",
    "    plt.axvline(x=RATIO_CANONICAL, color='purple', linestyle=':', linewidth=2, \n",
    "                label=f'Canonical: {RATIO_CANONICAL:.3f}')\n",
    "    plt.xlabel('Ratio (H*/84)', fontsize=12)\n",
    "    plt.ylabel('λ₁ × H*', fontsize=12)\n",
    "    plt.title('λ₁ × H* vs TCS Ratio', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('K7_ratio_sweep.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Ratio sweep skipped. Set RUN_RATIO_SWEEP = True to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 13. Convergence Study (Optional - tests N dependence)\n",
    "\n",
    "RUN_CONVERGENCE = False  # Set to True to run (takes longer)\n",
    "\n",
    "if RUN_CONVERGENCE:\n",
    "    print(\"Running convergence study...\")\n",
    "    \n",
    "    N_values = [1000, 2000, 3000, 5000, 7500, 10000]\n",
    "    products_0_conv = []\n",
    "    products_1_conv = []\n",
    "    \n",
    "    for N in N_values:\n",
    "        res = run_K7_experiment(\n",
    "            N=N,\n",
    "            k=30,\n",
    "            ratio=RATIO_CANONICAL,\n",
    "            scale_factor=SCALE_FACTOR,\n",
    "            seed=42\n",
    "        )\n",
    "        products_0_conv.append(res.product_0)\n",
    "        products_1_conv.append(res.product_1)\n",
    "        print(f\"N={N}: Δ₀→{res.product_0:.3f}, Δ₁→{res.product_1:.3f}\")\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(N_values, products_0_conv, 'o-', label='Δ₀ (Scalar)', linewidth=2, markersize=8)\n",
    "    plt.plot(N_values, products_1_conv, 's-', label='Δ₁ (1-Forms)', linewidth=2, markersize=8)\n",
    "    plt.axhline(y=13, color='red', linestyle='--', linewidth=2, label='Target: 13')\n",
    "    plt.axhline(y=14, color='green', linestyle='--', linewidth=2, label='Target: 14')\n",
    "    plt.xlabel('N (samples)', fontsize=12)\n",
    "    plt.ylabel('λ₁ × H*', fontsize=12)\n",
    "    plt.title('Convergence Study: λ₁ × H* vs Sample Size', fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig('K7_convergence.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Convergence study skipped. Set RUN_CONVERGENCE = True to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 14. Export Results\n",
    "\n",
    "results_dict = {\n",
    "    'config': {\n",
    "        'N': result.N,\n",
    "        'k': result.k,\n",
    "        'ratio': result.ratio,\n",
    "        'H_star': H_STAR,\n",
    "        'scale_factor': SCALE_FACTOR,\n",
    "    },\n",
    "    'scalar_laplacian': {\n",
    "        'lambda1_raw': result.lambda1_0_raw,\n",
    "        'lambda1_scaled': result.lambda1_0_scaled,\n",
    "        'product': result.product_0,\n",
    "        'deviation_from_13': result.deviation_0_from_13,\n",
    "        'deviation_from_14': result.deviation_0_from_14,\n",
    "        'time_seconds': result.time_0,\n",
    "    },\n",
    "    '1form_laplacian': {\n",
    "        'lambda1_raw': result.lambda1_1_raw,\n",
    "        'lambda1_scaled': result.lambda1_1_scaled,\n",
    "        'product': result.product_1,\n",
    "        'deviation_from_13': result.deviation_1_from_13,\n",
    "        'deviation_from_14': result.deviation_1_from_14,\n",
    "        'n_edges': result.n_edges,\n",
    "        'time_seconds': result.time_1,\n",
    "    },\n",
    "    'GIFT_constants': {\n",
    "        'dim_G2': DIM_G2,\n",
    "        'dim_K7': DIM_K7,\n",
    "        'b2': B2,\n",
    "        'b3': B3,\n",
    "        'H_star': H_STAR,\n",
    "        'det_g': DET_G,\n",
    "    },\n",
    "    'conclusion': {\n",
    "        'winner': 'Delta_1' if min(result.deviation_1_from_13, result.deviation_1_from_14) < min(result.deviation_0_from_13, result.deviation_0_from_14) else 'Delta_0',\n",
    "        'best_target_Delta0': 13 if result.deviation_0_from_13 < result.deviation_0_from_14 else 14,\n",
    "        'best_target_Delta1': 13 if result.deviation_1_from_13 < result.deviation_1_from_14 else 14,\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('K7_laplacian_results.json', 'w') as f:\n",
    "    json.dump(results_dict, f, indent=2)\n",
    "\n",
    "print(\"Results saved to 'K7_laplacian_results.json'\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXPERIMENT COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nFiles generated:\")\n",
    "print(\"  - K7_laplacian_comparison.png\")\n",
    "print(\"  - K7_laplacian_results.json\")\n",
    "if RUN_RATIO_SWEEP:\n",
    "    print(\"  - K7_ratio_sweep.png\")\n",
    "if RUN_CONVERGENCE:\n",
    "    print(\"  - K7_convergence.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title 15. Quick Summary for Copy-Paste\n",
    "\n",
    "summary = f\"\"\"\n",
    "============================================================\n",
    "K₇ LAPLACIAN COMPARISON - QUICK SUMMARY\n",
    "============================================================\n",
    "\n",
    "Configuration:\n",
    "  N = {result.N} samples\n",
    "  k = {result.k} neighbors\n",
    "  ratio = {result.ratio:.4f}\n",
    "  H* = {H_STAR}\n",
    "\n",
    "Results:\n",
    "  Δ₀ (Scalar):   λ₁ × H* = {result.product_0:.4f}\n",
    "  Δ₁ (1-Forms):  λ₁ × H* = {result.product_1:.4f}\n",
    "\n",
    "Deviations:\n",
    "  Δ₀ from 13: {result.deviation_0_from_13:.2f}%  |  from 14: {result.deviation_0_from_14:.2f}%\n",
    "  Δ₁ from 13: {result.deviation_1_from_13:.2f}%  |  from 14: {result.deviation_1_from_14:.2f}%\n",
    "\n",
    "Winner: {'Δ₁ (1-Forms)' if min(result.deviation_1_from_13, result.deviation_1_from_14) < min(result.deviation_0_from_13, result.deviation_0_from_14) else 'Δ₀ (Scalar)'}\n",
    "\n",
    "Physical prediction (from Δ₁):\n",
    "  λ₁ = {result.product_1/H_STAR:.4f}\n",
    "  Δ_QCD = {result.product_1/H_STAR * 200:.1f} MeV\n",
    "\n",
    "GIFT target: Δ_QCD ≈ 28.3 MeV (λ₁ = 14/99)\n",
    "============================================================\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
