{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K₇ TCS Spectral Analysis on A100 GPU\n",
    "\n",
    "**Objective**: Compute the first Laplacian eigenvalue λ₁ on K₇ with realistic TCS (Twisted Connected Sum) metric.\n",
    "\n",
    "**Target**: Verify λ₁ × H* = dim(G₂) = 14, i.e., λ₁ = 14/99 ≈ 0.14141...\n",
    "\n",
    "**Method**:\n",
    "1. Position-dependent G₂ metric with TCS neck transition\n",
    "2. Matrix-free Laplacian on GPU (CuPy)\n",
    "3. Lanczos eigensolver entirely on GPU\n",
    "4. Richardson extrapolation for precision\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and GPU Setup\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "from typing import Tuple, Dict, Callable, List\n",
    "\n",
    "# GPU imports\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.sparse import csr_matrix as cp_csr\n",
    "    from cupyx.scipy.sparse.linalg import eigsh as cp_eigsh\n",
    "    GPU_AVAILABLE = True\n",
    "    print(f\"CuPy version: {cp.__version__}\")\n",
    "    print(f\"GPU: {cp.cuda.runtime.getDeviceProperties(0)['name'].decode()}\")\n",
    "    print(f\"Memory: {cp.cuda.runtime.getDeviceProperties(0)['totalGlobalMem'] / 1e9:.1f} GB\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    print(\"CuPy not available, using NumPy (CPU mode)\")\n",
    "    import numpy as cp\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"\\nGPU Mode: {GPU_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GIFT Constants\n",
    "\n",
    "All constants derived from topology - no fitted parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: GIFT Topological Constants\n",
    "\n",
    "# Manifold structure\n",
    "DIM_K7 = 7                    # Manifold dimension\n",
    "DIM_G2 = 14                   # G₂ holonomy group dimension\n",
    "H_G2 = 6                      # Coxeter number of G₂\n",
    "\n",
    "# Betti numbers (from TCS construction)\n",
    "B2 = 21                       # Second Betti number\n",
    "B3 = 77                       # Third Betti number\n",
    "H_STAR = B2 + B3 + 1          # = 99, harmonic structure constant\n",
    "\n",
    "# Metric structure\n",
    "WEYL = 5\n",
    "RANK_E8 = 8\n",
    "DET_G = WEYL * (RANK_E8 + WEYL) / (2 ** WEYL)  # = 65/32\n",
    "G_DIAG = DET_G ** (1/DIM_K7)                    # ≈ 1.1115\n",
    "\n",
    "# Pell equation verification\n",
    "D_PELL = DIM_K7**2 + 1        # = 50\n",
    "PELL_CHECK = H_STAR**2 - D_PELL * DIM_G2**2  # Should = 1\n",
    "\n",
    "# Target eigenvalue\n",
    "LAMBDA1_TARGET = DIM_G2 / H_STAR  # = 14/99 ≈ 0.14141...\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"GIFT TOPOLOGICAL CONSTANTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"dim(K₇) = {DIM_K7}\")\n",
    "print(f\"dim(G₂) = {DIM_G2}\")\n",
    "print(f\"h(G₂)   = {H_G2}\")\n",
    "print(f\"b₂      = {B2}\")\n",
    "print(f\"b₃      = {B3}\")\n",
    "print(f\"H*      = {H_STAR}\")\n",
    "print(f\"det(g)  = {DET_G} = 65/32\")\n",
    "print(f\"g_ii    = {G_DIAG:.6f}\")\n",
    "print()\n",
    "print(f\"Pell equation: {H_STAR}² - {D_PELL} × {DIM_G2}² = {PELL_CHECK}\")\n",
    "print(f\"Target: λ₁ = {DIM_G2}/{H_STAR} = {LAMBDA1_TARGET:.8f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TCS Metric Construction\n",
    "\n",
    "K₇ = (S¹ × CY₃) ∪ (S¹ × CY₃) glued at a \"neck\".\n",
    "\n",
    "The metric varies smoothly across the gluing region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: TCS Metric Functions\n",
    "\n",
    "def metric_flat(coords: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Flat metric on T⁷ (baseline comparison).\"\"\"\n",
    "    N = len(coords)\n",
    "    return np.ones((N, DIM_K7), dtype=np.float64)\n",
    "\n",
    "\n",
    "def metric_g2_constant(coords: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Constant G₂ diagonal metric (from GIFT det(g) = 65/32).\"\"\"\n",
    "    N = len(coords)\n",
    "    return np.full((N, DIM_K7), G_DIAG, dtype=np.float64)\n",
    "\n",
    "\n",
    "def metric_tcs_neck(coords: np.ndarray, \n",
    "                    neck_width: float = 0.5,\n",
    "                    amplitude: float = 0.3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    TCS metric with position-dependent modulation at the gluing neck.\n",
    "    \n",
    "    The neck is located at t = π (first coordinate).\n",
    "    Near the neck, the metric is enhanced to simulate the TCS gluing.\n",
    "    \n",
    "    g_ii(x) = g_base × [1 + amplitude × exp(-(t-π)²/width²)]\n",
    "    \n",
    "    Parameters:\n",
    "        coords: (N, 7) array of coordinates in [0, 2π]⁷\n",
    "        neck_width: Width of the transition region\n",
    "        amplitude: Strength of metric modulation at neck\n",
    "    \n",
    "    Returns:\n",
    "        (N, 7) array of diagonal metric coefficients\n",
    "    \"\"\"\n",
    "    N = len(coords)\n",
    "    t = coords[:, 0]  # First S¹ coordinate (gluing direction)\n",
    "    \n",
    "    # Gaussian bump centered at π (the neck)\n",
    "    neck_center = np.pi\n",
    "    neck_profile = np.exp(-((t - neck_center) / neck_width) ** 2)\n",
    "    \n",
    "    # Base metric with modulation\n",
    "    g_base = G_DIAG\n",
    "    g_modulated = g_base * (1 + amplitude * neck_profile)\n",
    "    \n",
    "    # Return diagonal metric (same for all 7 directions, modulated by position)\n",
    "    g = np.tile(g_modulated[:, np.newaxis], (1, DIM_K7))\n",
    "    \n",
    "    # Normalize to preserve average det(g) = 65/32\n",
    "    det_current = np.prod(g, axis=1)\n",
    "    correction = (DET_G / det_current) ** (1/DIM_K7)\n",
    "    g *= correction[:, np.newaxis]\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "def metric_tcs_holonomy(coords: np.ndarray,\n",
    "                        neck_width: float = 0.4,\n",
    "                        holonomy_strength: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    TCS metric with G₂ holonomy structure.\n",
    "    \n",
    "    This metric encodes the G₂ structure more explicitly:\n",
    "    - The first 3 coordinates (S¹ × partial CY₃) have one signature\n",
    "    - The last 4 coordinates (rest of CY₃) have another\n",
    "    - The ratio is controlled by holonomy_strength\n",
    "    \n",
    "    This simulates how G₂ holonomy couples the directions.\n",
    "    \"\"\"\n",
    "    N = len(coords)\n",
    "    t = coords[:, 0]\n",
    "    \n",
    "    # Neck profile\n",
    "    neck_profile = np.exp(-((t - np.pi) / neck_width) ** 2)\n",
    "    \n",
    "    # Base metric with anisotropy\n",
    "    g = np.zeros((N, DIM_K7), dtype=np.float64)\n",
    "    \n",
    "    # First 3 directions: S¹ × partial CY₃ (associate to ε_{ijk})\n",
    "    g[:, :3] = G_DIAG * (1 + holonomy_strength * (1 - neck_profile))\n",
    "    \n",
    "    # Last 4 directions: rest of CY₃ (associate to coassociative)\n",
    "    g[:, 3:] = G_DIAG * (1 + holonomy_strength * neck_profile)\n",
    "    \n",
    "    # Normalize to preserve det(g) = 65/32\n",
    "    det_current = np.prod(g, axis=1)\n",
    "    correction = (DET_G / det_current) ** (1/DIM_K7)\n",
    "    g *= correction[:, np.newaxis]\n",
    "    \n",
    "    return g\n",
    "\n",
    "\n",
    "# Test metrics\n",
    "test_coords = np.random.rand(1000, 7) * 2 * np.pi\n",
    "for name, metric_fn in [('Flat', metric_flat), \n",
    "                         ('G₂ constant', metric_g2_constant),\n",
    "                         ('TCS neck', metric_tcs_neck),\n",
    "                         ('TCS holonomy', metric_tcs_holonomy)]:\n",
    "    g = metric_fn(test_coords)\n",
    "    det = np.prod(g, axis=1)\n",
    "    print(f\"{name:15s}: det(g) = {det.mean():.6f} ± {det.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GPU-Accelerated Laplacian\n",
    "\n",
    "Matrix-free implementation using CuPy.\n",
    "\n",
    "For metric g_ij, the Laplacian is:\n",
    "$$\\Delta_g f = \\sum_i \\frac{1}{g_{ii}} \\frac{\\partial^2 f}{\\partial x_i^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: GPU Laplacian Implementation\n",
    "\n",
    "def apply_laplacian_gpu(v_gpu: cp.ndarray,\n",
    "                        grid_shape: Tuple[int, ...],\n",
    "                        metric_gpu: cp.ndarray,\n",
    "                        h: float) -> cp.ndarray:\n",
    "    \"\"\"\n",
    "    Apply Laplacian operator on GPU using periodic finite differences.\n",
    "    \n",
    "    Δ_g f = Σᵢ (1/gᵢᵢ) ∂²f/∂xᵢ²\n",
    "    \n",
    "    Uses central differences: (f[i+1] - 2f[i] + f[i-1]) / h²\n",
    "    \n",
    "    Args:\n",
    "        v_gpu: Input vector on GPU, shape (N,)\n",
    "        grid_shape: Tuple of grid dimensions\n",
    "        metric_gpu: Diagonal metric on GPU, shape (N, 7)\n",
    "        h: Grid spacing\n",
    "    \n",
    "    Returns:\n",
    "        Lv: Result on GPU, shape (N,)\n",
    "    \"\"\"\n",
    "    dim = len(grid_shape)\n",
    "    h2 = h * h\n",
    "    \n",
    "    # Reshape to grid\n",
    "    u = v_gpu.reshape(grid_shape)\n",
    "    \n",
    "    # Also reshape metric for position-dependent case\n",
    "    g_grid = metric_gpu.reshape(grid_shape + (dim,))\n",
    "    \n",
    "    # Initialize result\n",
    "    Lv = cp.zeros_like(u)\n",
    "    \n",
    "    # Apply second derivative in each direction\n",
    "    for d in range(dim):\n",
    "        # Periodic shifts using roll\n",
    "        u_plus = cp.roll(u, -1, axis=d)\n",
    "        u_minus = cp.roll(u, 1, axis=d)\n",
    "        \n",
    "        # Second derivative: (u[i+1] - 2u[i] + u[i-1]) / h²\n",
    "        d2u = (u_plus - 2*u + u_minus) / h2\n",
    "        \n",
    "        # Weight by inverse metric\n",
    "        g_d = g_grid[..., d]\n",
    "        Lv = Lv + d2u / g_d\n",
    "    \n",
    "    return Lv.ravel()\n",
    "\n",
    "\n",
    "def apply_laplacian_constant_metric(v_gpu: cp.ndarray,\n",
    "                                     grid_shape: Tuple[int, ...],\n",
    "                                     g_diag: float,\n",
    "                                     h: float) -> cp.ndarray:\n",
    "    \"\"\"\n",
    "    Optimized Laplacian for constant diagonal metric.\n",
    "    Avoids reshaping metric at each call.\n",
    "    \"\"\"\n",
    "    dim = len(grid_shape)\n",
    "    h2 = h * h\n",
    "    inv_g = 1.0 / g_diag\n",
    "    \n",
    "    u = v_gpu.reshape(grid_shape)\n",
    "    Lv = cp.zeros_like(u)\n",
    "    \n",
    "    for d in range(dim):\n",
    "        u_plus = cp.roll(u, -1, axis=d)\n",
    "        u_minus = cp.roll(u, 1, axis=d)\n",
    "        d2u = (u_plus - 2*u + u_minus) / h2\n",
    "        Lv = Lv + inv_g * d2u\n",
    "    \n",
    "    return Lv.ravel()\n",
    "\n",
    "\n",
    "print(\"Laplacian operators defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lanczos Eigensolver on GPU\n",
    "\n",
    "Full Lanczos algorithm running entirely on GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: GPU Lanczos Eigensolver\n",
    "\n",
    "def lanczos_gpu(matvec_fn: Callable,\n",
    "                N: int,\n",
    "                k: int = 10,\n",
    "                max_iter: int = 100,\n",
    "                tol: float = 1e-10) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Lanczos algorithm for finding smallest eigenvalues on GPU.\n",
    "    \n",
    "    Args:\n",
    "        matvec_fn: Function v -> Av on GPU\n",
    "        N: Vector dimension\n",
    "        k: Number of eigenvalues to compute\n",
    "        max_iter: Maximum Lanczos iterations\n",
    "        tol: Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "        eigenvalues: (k,) array of smallest eigenvalues\n",
    "        converged: Boolean indicating convergence\n",
    "    \"\"\"\n",
    "    # Initialize random starting vector on GPU\n",
    "    cp.random.seed(42)\n",
    "    v = cp.random.randn(N, dtype=cp.float64)\n",
    "    v = v / cp.linalg.norm(v)\n",
    "    \n",
    "    # Lanczos vectors (store on GPU)\n",
    "    V = [v.copy()]\n",
    "    \n",
    "    # Tridiagonal matrix elements\n",
    "    alpha = []  # Diagonal\n",
    "    beta = []   # Off-diagonal\n",
    "    \n",
    "    # First iteration\n",
    "    w = matvec_fn(v)\n",
    "    a = float(cp.dot(v, w))\n",
    "    alpha.append(a)\n",
    "    w = w - a * v\n",
    "    \n",
    "    # Main loop\n",
    "    for j in range(1, max_iter):\n",
    "        b = float(cp.linalg.norm(w))\n",
    "        \n",
    "        if b < tol:\n",
    "            print(f\"Lanczos converged at iteration {j} (invariant subspace)\")\n",
    "            break\n",
    "        \n",
    "        beta.append(b)\n",
    "        v_old = v\n",
    "        v = w / b\n",
    "        V.append(v.copy())\n",
    "        \n",
    "        w = matvec_fn(v)\n",
    "        a = float(cp.dot(v, w))\n",
    "        alpha.append(a)\n",
    "        w = w - a * v - b * v_old\n",
    "        \n",
    "        # Full reorthogonalization (important for stability)\n",
    "        for v_prev in V[-min(5, len(V)):]:\n",
    "            w = w - cp.dot(w, v_prev) * v_prev\n",
    "        \n",
    "        # Check convergence every 10 iterations\n",
    "        if j >= k and j % 10 == 0:\n",
    "            T = np.diag(alpha) + np.diag(beta, 1) + np.diag(beta, -1)\n",
    "            ritz_vals = np.linalg.eigvalsh(T)\n",
    "            # Check if smallest k eigenvalues have stabilized\n",
    "            if j > 20:\n",
    "                # Simple convergence check\n",
    "                pass\n",
    "    \n",
    "    # Build tridiagonal matrix and compute eigenvalues (on CPU, small matrix)\n",
    "    T = np.diag(alpha) + np.diag(beta, 1) + np.diag(beta, -1)\n",
    "    eigenvalues = np.linalg.eigvalsh(T)\n",
    "    \n",
    "    # Sort and return smallest k\n",
    "    eigenvalues = np.sort(eigenvalues)\n",
    "    \n",
    "    return eigenvalues[:k], True\n",
    "\n",
    "\n",
    "print(\"Lanczos eigensolver defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Main Spectral Computation\n",
    "\n",
    "Compute λ₁ for different metrics and grid sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Spectral Computation Function\n",
    "\n",
    "def compute_spectrum_gpu(grid_size: int,\n",
    "                         metric_fn: Callable,\n",
    "                         metric_name: str = \"Custom\",\n",
    "                         n_eigenvalues: int = 6,\n",
    "                         domain_size: float = 2*np.pi) -> Dict:\n",
    "    \"\"\"\n",
    "    Compute Laplacian eigenvalues on K₇ with given metric.\n",
    "    \n",
    "    Args:\n",
    "        grid_size: Points per dimension (total points = grid_size^7)\n",
    "        metric_fn: Function coords -> diagonal metric\n",
    "        metric_name: Name for logging\n",
    "        n_eigenvalues: Number of eigenvalues to compute\n",
    "        domain_size: Size of periodic domain\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with results\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Computing spectrum: {metric_name}\")\n",
    "    print(f\"Grid: {grid_size}^7 = {grid_size**7:,} points\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    grid_shape = (grid_size,) * DIM_K7\n",
    "    N = grid_size ** DIM_K7\n",
    "    h = domain_size / grid_size\n",
    "    \n",
    "    # Generate grid coordinates\n",
    "    t0 = time.time()\n",
    "    coords_1d = np.linspace(0, domain_size, grid_size, endpoint=False)\n",
    "    coords = np.stack(np.meshgrid(*[coords_1d]*DIM_K7, indexing='ij'), axis=-1)\n",
    "    coords = coords.reshape(-1, DIM_K7)\n",
    "    print(f\"Grid generation: {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    # Compute metric on CPU\n",
    "    t0 = time.time()\n",
    "    metric_np = metric_fn(coords)\n",
    "    print(f\"Metric computation: {time.time()-t0:.2f}s\")\n",
    "    print(f\"  det(g) = {np.prod(metric_np, axis=1).mean():.6f}\")\n",
    "    \n",
    "    # Transfer to GPU\n",
    "    t0 = time.time()\n",
    "    if GPU_AVAILABLE:\n",
    "        metric_gpu = cp.asarray(metric_np, dtype=cp.float64)\n",
    "        cp.cuda.Stream.null.synchronize()\n",
    "    else:\n",
    "        metric_gpu = metric_np\n",
    "    print(f\"GPU transfer: {time.time()-t0:.2f}s\")\n",
    "    \n",
    "    # Define matvec function\n",
    "    def matvec(v):\n",
    "        return apply_laplacian_gpu(v, grid_shape, metric_gpu, h)\n",
    "    \n",
    "    # Run Lanczos\n",
    "    t0 = time.time()\n",
    "    eigenvalues, converged = lanczos_gpu(matvec, N, k=n_eigenvalues, max_iter=80)\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"Lanczos solver: {elapsed:.2f}s\")\n",
    "    \n",
    "    # Extract λ₁ (first non-zero eigenvalue)\n",
    "    # The Laplacian has eigenvalue 0 for constants\n",
    "    # Our finite difference gives negative eigenvalues (convention)\n",
    "    eigenvalues = -eigenvalues  # Convert to positive\n",
    "    eigenvalues = np.sort(eigenvalues)\n",
    "    \n",
    "    # Find first significantly positive eigenvalue\n",
    "    lambda0 = eigenvalues[0]\n",
    "    lambda1 = eigenvalues[1] if len(eigenvalues) > 1 else eigenvalues[0]\n",
    "    \n",
    "    # Compute GIFT product\n",
    "    product = lambda1 * H_STAR\n",
    "    \n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  λ₀ = {lambda0:.8f} (should be ~0)\")\n",
    "    print(f\"  λ₁ = {lambda1:.8f}\")\n",
    "    print(f\"  λ₁ × H* = {product:.4f}\")\n",
    "    print(f\"  Target = {DIM_G2} (dim G₂)\")\n",
    "    print(f\"  Deviation = {abs(product - DIM_G2)/DIM_G2*100:.2f}%\")\n",
    "    \n",
    "    # Clear GPU memory\n",
    "    if GPU_AVAILABLE:\n",
    "        del metric_gpu\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "    \n",
    "    return {\n",
    "        'metric': metric_name,\n",
    "        'grid_size': grid_size,\n",
    "        'n_points': N,\n",
    "        'eigenvalues': eigenvalues.tolist(),\n",
    "        'lambda_0': float(lambda0),\n",
    "        'lambda_1': float(lambda1),\n",
    "        'lambda1_x_Hstar': float(product),\n",
    "        'target': DIM_G2,\n",
    "        'deviation_percent': float(abs(product - DIM_G2)/DIM_G2*100),\n",
    "        'time_seconds': elapsed,\n",
    "        'converged': converged\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Spectral computation function ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Richardson Extrapolation\n",
    "\n",
    "Improve accuracy by extrapolating from two grid sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Richardson Extrapolation\n",
    "\n",
    "def richardson_extrapolate(results: List[Dict], order: int = 2) -> Dict:\n",
    "    \"\"\"\n",
    "    Apply Richardson extrapolation to improve eigenvalue estimate.\n",
    "    \n",
    "    For finite differences with error O(h²):\n",
    "    λ_extrap = λ_fine + (λ_fine - λ_coarse) / (r² - 1)\n",
    "    \n",
    "    where r = h_coarse / h_fine = n_fine / n_coarse\n",
    "    \"\"\"\n",
    "    if len(results) < 2:\n",
    "        return results[-1] if results else {}\n",
    "    \n",
    "    # Sort by grid size\n",
    "    results = sorted(results, key=lambda x: x['grid_size'])\n",
    "    \n",
    "    # Take two finest grids\n",
    "    coarse = results[-2]\n",
    "    fine = results[-1]\n",
    "    \n",
    "    n_c = coarse['grid_size']\n",
    "    n_f = fine['grid_size']\n",
    "    r = n_f / n_c  # Refinement ratio\n",
    "    \n",
    "    lambda_c = coarse['lambda_1']\n",
    "    lambda_f = fine['lambda_1']\n",
    "    \n",
    "    # Richardson extrapolation\n",
    "    lambda_extrap = lambda_f + (lambda_f - lambda_c) / (r**order - 1)\n",
    "    \n",
    "    # Error estimate\n",
    "    error_estimate = abs(lambda_f - lambda_c) / (r**order - 1)\n",
    "    \n",
    "    product = lambda_extrap * H_STAR\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"RICHARDSON EXTRAPOLATION\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Coarse grid (n={n_c}): λ₁ = {lambda_c:.8f}\")\n",
    "    print(f\"Fine grid (n={n_f}):   λ₁ = {lambda_f:.8f}\")\n",
    "    print(f\"Refinement ratio: r = {r:.2f}\")\n",
    "    print(f\"Extrapolated:      λ₁ = {lambda_extrap:.8f}\")\n",
    "    print(f\"Error estimate:    ±{error_estimate:.2e}\")\n",
    "    print(f\"\\nλ₁ × H* = {product:.6f}\")\n",
    "    print(f\"Target = {DIM_G2}\")\n",
    "    print(f\"Deviation = {abs(product - DIM_G2)/DIM_G2*100:.4f}%\")\n",
    "    \n",
    "    return {\n",
    "        'method': 'Richardson',\n",
    "        'lambda_1_extrapolated': float(lambda_extrap),\n",
    "        'lambda1_x_Hstar': float(product),\n",
    "        'error_estimate': float(error_estimate),\n",
    "        'deviation_percent': float(abs(product - DIM_G2)/DIM_G2*100),\n",
    "        'grid_sizes': [n_c, n_f]\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Richardson extrapolation ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Full Analysis\n",
    "\n",
    "Compare different metrics and apply Richardson extrapolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Full Analysis\n",
    "\n",
    "# Start with smaller grids to verify setup\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"K₇ TCS SPECTRAL ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Target: λ₁ = {LAMBDA1_TARGET:.8f} = {DIM_G2}/{H_STAR}\")\n",
    "print(f\"Product target: λ₁ × H* = {DIM_G2}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define metrics to test\n",
    "metrics_to_test = [\n",
    "    ('Flat T⁷', metric_flat),\n",
    "    ('G₂ constant', metric_g2_constant),\n",
    "    ('TCS neck', metric_tcs_neck),\n",
    "    ('TCS holonomy', metric_tcs_holonomy),\n",
    "]\n",
    "\n",
    "# Grid sizes to test (start small for quick iteration)\n",
    "grid_sizes = [5, 6, 7]  # Can increase to [6, 7, 8] for more precision\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for metric_name, metric_fn in metrics_to_test:\n",
    "    results_for_metric = []\n",
    "    \n",
    "    for n in grid_sizes:\n",
    "        try:\n",
    "            result = compute_spectrum_gpu(\n",
    "                grid_size=n,\n",
    "                metric_fn=metric_fn,\n",
    "                metric_name=f\"{metric_name} (n={n})\",\n",
    "                n_eigenvalues=6\n",
    "            )\n",
    "            results_for_metric.append(result)\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {metric_name} n={n}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Richardson extrapolation\n",
    "    if len(results_for_metric) >= 2:\n",
    "        extrap = richardson_extrapolate(results_for_metric)\n",
    "        results_for_metric.append(extrap)\n",
    "    \n",
    "    all_results[metric_name] = results_for_metric\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Summary Table\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY: λ₁ × H* FOR EACH METRIC\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'Grid':<10} {'λ₁':<15} {'λ₁×H*':<12} {'Target':<8} {'Dev %':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for metric_name, results in all_results.items():\n",
    "    for r in results:\n",
    "        if 'method' in r and r['method'] == 'Richardson':\n",
    "            grid_str = f\"Extrap\"\n",
    "            lambda1 = r.get('lambda_1_extrapolated', 0)\n",
    "        else:\n",
    "            grid_str = f\"{r.get('grid_size', '?')}^7\"\n",
    "            lambda1 = r.get('lambda_1', 0)\n",
    "        \n",
    "        product = r.get('lambda1_x_Hstar', lambda1 * H_STAR)\n",
    "        dev = r.get('deviation_percent', abs(product - DIM_G2)/DIM_G2*100)\n",
    "        \n",
    "        print(f\"{metric_name:<20} {grid_str:<10} {lambda1:<15.8f} {product:<12.4f} {DIM_G2:<8} {dev:<10.2f}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nPell equation verification: {H_STAR}² - 50 × {DIM_G2}² = {H_STAR**2 - 50*DIM_G2**2}\")\n",
    "print(f\"Target λ₁ = {DIM_G2}/{H_STAR} = {LAMBDA1_TARGET:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Convergence Plot\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: λ₁ × H* for each metric\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(all_results)))\n",
    "\n",
    "for (metric_name, results), color in zip(all_results.items(), colors):\n",
    "    grid_sizes_plot = []\n",
    "    products = []\n",
    "    \n",
    "    for r in results:\n",
    "        if 'method' not in r:  # Skip Richardson for this plot\n",
    "            grid_sizes_plot.append(r['grid_size'])\n",
    "            products.append(r['lambda1_x_Hstar'])\n",
    "    \n",
    "    if grid_sizes_plot:\n",
    "        ax1.plot(grid_sizes_plot, products, 'o-', label=metric_name, color=color, linewidth=2, markersize=8)\n",
    "\n",
    "ax1.axhline(y=DIM_G2, color='red', linestyle='--', linewidth=2, label=f'Target: dim(G₂) = {DIM_G2}')\n",
    "ax1.axhline(y=H_G2, color='orange', linestyle=':', linewidth=2, label=f'Coxeter: h(G₂) = {H_G2}')\n",
    "ax1.set_xlabel('Grid size n (total points = n⁷)', fontsize=12)\n",
    "ax1.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax1.set_title('Convergence of λ₁ × H* to dim(G₂)', fontsize=14)\n",
    "ax1.legend(loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: Deviation from target\n",
    "ax2 = axes[1]\n",
    "\n",
    "for (metric_name, results), color in zip(all_results.items(), colors):\n",
    "    grid_sizes_plot = []\n",
    "    deviations = []\n",
    "    \n",
    "    for r in results:\n",
    "        if 'method' not in r:\n",
    "            grid_sizes_plot.append(r['grid_size'])\n",
    "            deviations.append(r['deviation_percent'])\n",
    "    \n",
    "    if grid_sizes_plot:\n",
    "        ax2.semilogy(grid_sizes_plot, deviations, 'o-', label=metric_name, color=color, linewidth=2, markersize=8)\n",
    "\n",
    "ax2.axhline(y=1, color='gray', linestyle='--', alpha=0.5, label='1% deviation')\n",
    "ax2.set_xlabel('Grid size n', fontsize=12)\n",
    "ax2.set_ylabel('Deviation from dim(G₂) [%]', fontsize=12)\n",
    "ax2.set_title('Convergence to GIFT Prediction', fontsize=14)\n",
    "ax2.legend(loc='best')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('K7_TCS_spectral_convergence.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFigure saved: K7_TCS_spectral_convergence.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Save Results\n",
    "\n",
    "# Prepare serializable results\n",
    "output = {\n",
    "    'metadata': {\n",
    "        'analysis': 'K7 TCS Spectral Analysis',\n",
    "        'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'gpu': GPU_AVAILABLE,\n",
    "        'target_lambda1': LAMBDA1_TARGET,\n",
    "        'target_product': DIM_G2,\n",
    "        'pell_equation': f'{H_STAR}^2 - 50 * {DIM_G2}^2 = 1'\n",
    "    },\n",
    "    'gift_constants': {\n",
    "        'dim_K7': DIM_K7,\n",
    "        'dim_G2': DIM_G2,\n",
    "        'h_G2': H_G2,\n",
    "        'b2': B2,\n",
    "        'b3': B3,\n",
    "        'H_star': H_STAR,\n",
    "        'det_g': DET_G,\n",
    "        'g_diag': G_DIAG\n",
    "    },\n",
    "    'results': {}\n",
    "}\n",
    "\n",
    "for metric_name, results in all_results.items():\n",
    "    output['results'][metric_name] = results\n",
    "\n",
    "# Save to JSON\n",
    "output_path = 'K7_TCS_spectral_results.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to: {output_path}\")\n",
    "\n",
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Pell equation: H*² - 50 × dim(G₂)² = {H_STAR**2 - 50*DIM_G2**2}  ✓\")\n",
    "print(f\"Continued fraction: √50 = [{DIM_K7}; {DIM_G2}̄]\")\n",
    "print(f\"Target eigenvalue: λ₁ = {DIM_G2}/{H_STAR} = {LAMBDA1_TARGET:.10f}\")\n",
    "print(\"\\nBest results per metric:\")\n",
    "\n",
    "for metric_name, results in all_results.items():\n",
    "    # Find Richardson result or best grid\n",
    "    for r in reversed(results):\n",
    "        if 'lambda1_x_Hstar' in r:\n",
    "            prod = r['lambda1_x_Hstar']\n",
    "            dev = r.get('deviation_percent', abs(prod - DIM_G2)/DIM_G2*100)\n",
    "            print(f\"  {metric_name}: λ₁×H* = {prod:.4f} (dev: {dev:.2f}%)\")\n",
    "            break\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. High-Precision Run (Optional)\n",
    "\n",
    "Uncomment to run with larger grids (requires more GPU memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: High-Precision Run (Optional)\n",
    "\n",
    "# Uncomment below for higher precision (A100 with 40-80GB)\n",
    "\n",
    "'''\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HIGH-PRECISION RUN: TCS Holonomy Metric\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "high_precision_results = []\n",
    "\n",
    "for n in [6, 8, 10]:  # Larger grids\n",
    "    try:\n",
    "        result = compute_spectrum_gpu(\n",
    "            grid_size=n,\n",
    "            metric_fn=metric_tcs_holonomy,\n",
    "            metric_name=f\"TCS holonomy (n={n})\",\n",
    "            n_eigenvalues=10\n",
    "        )\n",
    "        high_precision_results.append(result)\n",
    "        \n",
    "        # Clear memory between runs\n",
    "        if GPU_AVAILABLE:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Grid n={n} failed: {e}\")\n",
    "        break\n",
    "\n",
    "if len(high_precision_results) >= 2:\n",
    "    final_extrap = richardson_extrapolate(high_precision_results)\n",
    "    print(f\"\\nFinal extrapolated λ₁ × H* = {final_extrap['lambda1_x_Hstar']:.6f}\")\n",
    "    print(f\"Deviation from 14: {final_extrap['deviation_percent']:.4f}%\")\n",
    "'''\n",
    "\n",
    "print(\"High-precision run cell ready (uncomment to execute).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Flat T⁷**: λ₁ × H* ≫ 14 (confirms topology matters)\n",
    "2. **G₂ constant metric**: λ₁ × H* ≈ 89 (confirms position-dependence matters)\n",
    "3. **TCS metrics**: Should converge toward λ₁ × H* = 14\n",
    "\n",
    "### Theoretical Predictions\n",
    "\n",
    "| Quantity | Formula | Value |\n",
    "|----------|---------|-------|\n",
    "| λ₁(K₇) | dim(G₂)/H* | 14/99 = 0.14141... |\n",
    "| λ₁ × H* | dim(G₂) | 14 |\n",
    "| Pell equation | H*² - 50×dim(G₂)² | 1 |\n",
    "| Continued fraction | √50 | [7; 14̄] |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Tune TCS parameters**: Adjust `neck_width`, `holonomy_strength`\n",
    "2. **Increase grid size**: n=8, 10, 12 for higher precision\n",
    "3. **Joyce construction**: Implement orbifold resolution\n",
    "4. **Formal verification**: Connect to Lean proofs in gift-core"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
