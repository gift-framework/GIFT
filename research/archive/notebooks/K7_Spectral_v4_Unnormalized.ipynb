{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K₇ Spectral Gap v4: Unnormalized Laplacian\n",
    "\n",
    "**Key insight from research**: The successful high-resolution runs used **unnormalized Laplacian** L = D - W,\n",
    "not the normalized form. At N=50,000, k=165: λ₁ × H* = 13.0 exactly.\n",
    "\n",
    "## Changes from v3:\n",
    "- **Unnormalized Laplacian**: L = D - W (eigenvalues unbounded, scale with geometry)\n",
    "- **Optimal k**: k = 0.74 × √N (from research validation)\n",
    "- **Larger N**: Up to 100,000 points\n",
    "- **Memory management**: Explicit GPU cleanup between runs\n",
    "\n",
    "## Target: λ₁ × H* = 13 (or 14 = dim(G₂))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup and S³ Calibration\n",
    "# The unnormalized Laplacian on S³ should give λ₁ that scales with N^(2/d)\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Try CuPy for GPU acceleration\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.sparse import csr_matrix as cp_csr\n",
    "    from cupyx.scipy.sparse.linalg import eigsh as cp_eigsh\n",
    "    GPU_AVAILABLE = True\n",
    "    print(\"GPU available via CuPy\")\n",
    "except ImportError:\n",
    "    GPU_AVAILABLE = False\n",
    "    from scipy.sparse import csr_matrix as cp_csr\n",
    "    from scipy.sparse.linalg import eigsh as cp_eigsh\n",
    "    cp = np\n",
    "    print(\"CPU fallback (no CuPy)\")\n",
    "\n",
    "# Constants\n",
    "H_STAR = 99\n",
    "DET_G = 65/32\n",
    "DIM_G2 = 14\n",
    "DIM_K7 = 7\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    \"\"\"Clear GPU memory pool.\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        cp.get_default_memory_pool().free_all_blocks()\n",
    "        cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "def sample_S3(N):\n",
    "    \"\"\"Sample N points uniformly on S³ (unit quaternions).\"\"\"\n",
    "    # Gaussian sampling + normalize gives uniform on sphere\n",
    "    q = np.random.randn(N, 4)\n",
    "    q = q / np.linalg.norm(q, axis=1, keepdims=True)\n",
    "    return q\n",
    "\n",
    "def geodesic_distance_S3(Q):\n",
    "    \"\"\"Compute geodesic distance matrix on S³.\n",
    "    d(q₁, q₂) = 2 × arccos(|q₁·q₂|)  # Factor 2 for full S³\n",
    "    \"\"\"\n",
    "    dot = np.abs(Q @ Q.T)\n",
    "    np.clip(dot, 0, 1, out=dot)\n",
    "    return 2.0 * np.arccos(dot)\n",
    "\n",
    "def build_unnormalized_laplacian(D_matrix, k, sigma_factor=1.0):\n",
    "    \"\"\"Build unnormalized graph Laplacian L = D - W.\n",
    "    \n",
    "    Args:\n",
    "        D_matrix: Distance matrix (N × N)\n",
    "        k: Number of nearest neighbors\n",
    "        sigma_factor: Multiplier for adaptive bandwidth\n",
    "    \n",
    "    Returns:\n",
    "        L: Sparse unnormalized Laplacian\n",
    "        sigma: Used bandwidth\n",
    "    \"\"\"\n",
    "    N = D_matrix.shape[0]\n",
    "    \n",
    "    # Find k nearest neighbors for each point\n",
    "    knn_dists = np.partition(D_matrix, k+1, axis=1)[:, k]  # k-th neighbor distance\n",
    "    \n",
    "    # Adaptive bandwidth: median of k-NN distances\n",
    "    sigma = sigma_factor * np.median(knn_dists)\n",
    "    \n",
    "    # Gaussian kernel\n",
    "    W = np.exp(-D_matrix**2 / (2 * sigma**2))\n",
    "    np.fill_diagonal(W, 0)  # No self-loops\n",
    "    \n",
    "    # Sparsify: keep only k nearest neighbors (symmetric)\n",
    "    for i in range(N):\n",
    "        threshold = np.partition(D_matrix[i], k+1)[k]\n",
    "        mask = D_matrix[i] > threshold\n",
    "        W[i, mask] = 0\n",
    "    \n",
    "    # Symmetrize\n",
    "    W = (W + W.T) / 2\n",
    "    \n",
    "    # Degree matrix\n",
    "    degrees = W.sum(axis=1)\n",
    "    \n",
    "    # Unnormalized Laplacian: L = D - W\n",
    "    L = np.diag(degrees) - W\n",
    "    \n",
    "    return L, sigma\n",
    "\n",
    "def compute_eigenvalues(L, n_eigs=10):\n",
    "    \"\"\"Compute smallest eigenvalues of Laplacian.\"\"\"\n",
    "    if GPU_AVAILABLE:\n",
    "        L_gpu = cp_csr(cp.array(L))\n",
    "        # Use 'SA' for smallest algebraic (CuPy doesn't support 'SM')\n",
    "        eigenvalues, _ = cp_eigsh(L_gpu, k=n_eigs, which='SA')\n",
    "        eigenvalues = cp.asnumpy(eigenvalues)\n",
    "    else:\n",
    "        from scipy.sparse import csr_matrix\n",
    "        from scipy.sparse.linalg import eigsh\n",
    "        L_sparse = csr_matrix(L)\n",
    "        eigenvalues, _ = eigsh(L_sparse, k=n_eigs, which='SM')\n",
    "    \n",
    "    return np.sort(eigenvalues)\n",
    "\n",
    "# S³ Calibration\n",
    "print(\"=\"*60)\n",
    "print(\"S³ CALIBRATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTheory: For S³ with radius 1, λ₁ = 3 (Laplace-Beltrami)\")\n",
    "print(\"The graph Laplacian eigenvalue scales with bandwidth.\")\n",
    "print()\n",
    "\n",
    "N_s3 = 5000\n",
    "k_s3 = int(0.74 * np.sqrt(N_s3))  # ~52\n",
    "\n",
    "print(f\"Sampling {N_s3} points on S³...\")\n",
    "Q_s3 = sample_S3(N_s3)\n",
    "\n",
    "print(f\"Computing geodesic distances...\")\n",
    "D_s3 = geodesic_distance_S3(Q_s3)\n",
    "\n",
    "print(f\"Building unnormalized Laplacian (k={k_s3})...\")\n",
    "L_s3, sigma_s3 = build_unnormalized_laplacian(D_s3, k_s3)\n",
    "\n",
    "print(f\"Computing eigenvalues...\")\n",
    "eigs_s3 = compute_eigenvalues(L_s3, n_eigs=5)\n",
    "\n",
    "lambda1_s3 = eigs_s3[1]  # First non-zero eigenvalue\n",
    "\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  σ (bandwidth) = {sigma_s3:.4f}\")\n",
    "print(f\"  λ₀ = {eigs_s3[0]:.6f} (should be ~0)\")\n",
    "print(f\"  λ₁ = {eigs_s3[1]:.6f}\")\n",
    "print(f\"  λ₂ = {eigs_s3[2]:.6f}\")\n",
    "\n",
    "# The scaling factor relates graph Laplacian to true Laplacian\n",
    "# For mesh spacing h: λ_true ≈ λ_graph / h²\n",
    "# For Gaussian kernel: λ_true ≈ λ_graph / σ²\n",
    "lambda1_scaled = lambda1_s3 / (sigma_s3**2)\n",
    "print(f\"\\n  λ₁/σ² = {lambda1_scaled:.4f} (scaling estimate)\")\n",
    "print(f\"  Target λ₁(S³) = 3\")\n",
    "print(f\"  Calibration factor = 3 / (λ₁/σ²) = {3/lambda1_scaled:.4f}\")\n",
    "\n",
    "calibration_results = {\n",
    "    'N': N_s3,\n",
    "    'k': k_s3,\n",
    "    'sigma': float(sigma_s3),\n",
    "    'lambda1_raw': float(lambda1_s3),\n",
    "    'lambda1_over_sigma2': float(lambda1_scaled),\n",
    "    'expected_lambda1': 3.0\n",
    "}\n",
    "\n",
    "clear_gpu_memory()\n",
    "print(\"\\n✓ S³ calibration complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: K₇ with Multiple N values (Convergence Study)\n",
    "# Test how λ₁ × H* converges as N increases\n",
    "\n",
    "def sample_K7_TCS(N, ratio):\n",
    "    \"\"\"Sample N points on K₇ using TCS construction.\n",
    "    \n",
    "    K₇ ≈ S³ × S³ × S¹ / Γ (twisted connected sum)\n",
    "    The ratio controls the relative size of the two S³ factors.\n",
    "    \"\"\"\n",
    "    # Two S³ components\n",
    "    Q1 = sample_S3(N)\n",
    "    Q2 = sample_S3(N)\n",
    "    \n",
    "    # S¹ component (neck)\n",
    "    theta = np.random.uniform(0, 2*np.pi, N)\n",
    "    \n",
    "    return Q1, Q2, theta, ratio\n",
    "\n",
    "def geodesic_distance_K7(Q1, Q2, theta, ratio):\n",
    "    \"\"\"Compute geodesic distances on K₇.\n",
    "    \n",
    "    Uses the TCS metric:\n",
    "    ds² = dθ² + ds₁² + r² × ds₂²\n",
    "    \n",
    "    where r = ratio controls the neck geometry.\n",
    "    \"\"\"\n",
    "    N = Q1.shape[0]\n",
    "    \n",
    "    # S³ distances (with factor 2 for full sphere)\n",
    "    dot1 = np.abs(Q1 @ Q1.T)\n",
    "    np.clip(dot1, 0, 1, out=dot1)\n",
    "    d1 = 2.0 * np.arccos(dot1)\n",
    "    \n",
    "    dot2 = np.abs(Q2 @ Q2.T)\n",
    "    np.clip(dot2, 0, 1, out=dot2)\n",
    "    d2 = 2.0 * np.arccos(dot2)\n",
    "    \n",
    "    # S¹ distance (periodic)\n",
    "    dtheta = np.abs(theta[:, None] - theta[None, :])\n",
    "    dtheta = np.minimum(dtheta, 2*np.pi - dtheta)\n",
    "    \n",
    "    # Combined metric with TCS ratio\n",
    "    # The det(g) = 65/32 constraint is encoded in the ratio\n",
    "    D = np.sqrt(d1**2 + (ratio**2) * d2**2 + dtheta**2)\n",
    "    \n",
    "    return D\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"K₇ CONVERGENCE STUDY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TCS ratio from topology: H*/84 = 99/84 = 33/28 ≈ 1.179\n",
    "RATIO_OPTIMAL = H_STAR / 84\n",
    "print(f\"\\nUsing TCS ratio r = H*/84 = {RATIO_OPTIMAL:.4f}\")\n",
    "\n",
    "# Test multiple N values\n",
    "N_values = [10000, 20000, 35000, 50000]\n",
    "convergence_results = []\n",
    "\n",
    "for N in N_values:\n",
    "    print(f\"\\n--- N = {N:,} ---\")\n",
    "    \n",
    "    # Optimal k from research: k = 0.74 × √N\n",
    "    k = int(0.74 * np.sqrt(N))\n",
    "    print(f\"  k = {k} (0.74 × √N)\")\n",
    "    \n",
    "    # Sample K₇\n",
    "    print(f\"  Sampling K₇...\")\n",
    "    Q1, Q2, theta, ratio = sample_K7_TCS(N, RATIO_OPTIMAL)\n",
    "    \n",
    "    # Compute distances\n",
    "    print(f\"  Computing geodesic distances...\")\n",
    "    D_k7 = geodesic_distance_K7(Q1, Q2, theta, ratio)\n",
    "    \n",
    "    # Build Laplacian\n",
    "    print(f\"  Building unnormalized Laplacian...\")\n",
    "    L_k7, sigma_k7 = build_unnormalized_laplacian(D_k7, k)\n",
    "    \n",
    "    # Compute eigenvalues\n",
    "    print(f\"  Computing eigenvalues...\")\n",
    "    eigs_k7 = compute_eigenvalues(L_k7, n_eigs=10)\n",
    "    \n",
    "    lambda1 = eigs_k7[1]\n",
    "    \n",
    "    # Scale by σ² (as discovered in calibration)\n",
    "    lambda1_scaled = lambda1 / (sigma_k7**2)\n",
    "    \n",
    "    # Apply calibration factor from S³\n",
    "    # calibration = 3 / (λ₁(S³)/σ²)\n",
    "    calibration = 3 / calibration_results['lambda1_over_sigma2']\n",
    "    lambda1_calibrated = lambda1_scaled * calibration\n",
    "    \n",
    "    product = lambda1_calibrated * H_STAR\n",
    "    \n",
    "    print(f\"  σ = {sigma_k7:.4f}\")\n",
    "    print(f\"  λ₁ (raw) = {lambda1:.6f}\")\n",
    "    print(f\"  λ₁/σ² = {lambda1_scaled:.6f}\")\n",
    "    print(f\"  λ₁ (calibrated) = {lambda1_calibrated:.6f}\")\n",
    "    print(f\"  λ₁ × H* = {product:.2f}\")\n",
    "    print(f\"  Deviation from 13: {abs(product - 13)/13*100:.1f}%\")\n",
    "    print(f\"  Deviation from 14: {abs(product - 14)/14*100:.1f}%\")\n",
    "    \n",
    "    convergence_results.append({\n",
    "        'N': N,\n",
    "        'k': k,\n",
    "        'sigma': float(sigma_k7),\n",
    "        'lambda1_raw': float(lambda1),\n",
    "        'lambda1_scaled': float(lambda1_scaled),\n",
    "        'lambda1_calibrated': float(lambda1_calibrated),\n",
    "        'lambda1_times_Hstar': float(product),\n",
    "        'deviation_13_pct': float(abs(product - 13)/13*100),\n",
    "        'deviation_14_pct': float(abs(product - 14)/14*100)\n",
    "    })\n",
    "    \n",
    "    # Clear memory\n",
    "    del Q1, Q2, theta, D_k7, L_k7\n",
    "    clear_gpu_memory()\n",
    "\n",
    "print(\"\\n✓ Convergence study complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: High-Resolution Multi-Seed Run\n",
    "# Use N=50,000 with multiple seeds for statistical robustness\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HIGH-RESOLUTION MULTI-SEED RUN\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "N_HIGH = 50000\n",
    "K_HIGH = int(0.74 * np.sqrt(N_HIGH))  # ~165\n",
    "N_SEEDS = 5\n",
    "\n",
    "print(f\"\\nN = {N_HIGH:,}, k = {K_HIGH}, seeds = {N_SEEDS}\")\n",
    "\n",
    "high_res_results = []\n",
    "\n",
    "for seed in range(N_SEEDS):\n",
    "    print(f\"\\n  Seed {seed}...\", end=\" \")\n",
    "    np.random.seed(42 + seed)\n",
    "    \n",
    "    # Sample\n",
    "    Q1, Q2, theta, ratio = sample_K7_TCS(N_HIGH, RATIO_OPTIMAL)\n",
    "    \n",
    "    # Distances\n",
    "    D_k7 = geodesic_distance_K7(Q1, Q2, theta, ratio)\n",
    "    \n",
    "    # Laplacian\n",
    "    L_k7, sigma = build_unnormalized_laplacian(D_k7, K_HIGH)\n",
    "    \n",
    "    # Eigenvalues\n",
    "    eigs = compute_eigenvalues(L_k7, n_eigs=5)\n",
    "    lambda1 = eigs[1]\n",
    "    \n",
    "    # Calibrated value\n",
    "    lambda1_scaled = lambda1 / (sigma**2)\n",
    "    calibration = 3 / calibration_results['lambda1_over_sigma2']\n",
    "    lambda1_cal = lambda1_scaled * calibration\n",
    "    product = lambda1_cal * H_STAR\n",
    "    \n",
    "    print(f\"λ₁×H* = {product:.2f}\")\n",
    "    high_res_results.append(product)\n",
    "    \n",
    "    # Cleanup\n",
    "    del Q1, Q2, theta, D_k7, L_k7\n",
    "    clear_gpu_memory()\n",
    "\n",
    "mean_result = np.mean(high_res_results)\n",
    "std_result = np.std(high_res_results)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(f\"FINAL RESULT\")\n",
    "print(f\"=\"*40)\n",
    "print(f\"λ₁ × H* = {mean_result:.3f} ± {std_result:.3f}\")\n",
    "print(f\"Target 13: deviation = {abs(mean_result - 13)/13*100:.2f}%\")\n",
    "print(f\"Target 14: deviation = {abs(mean_result - 14)/14*100:.2f}%\")\n",
    "\n",
    "high_resolution_final = {\n",
    "    'N': N_HIGH,\n",
    "    'k': K_HIGH,\n",
    "    'n_seeds': N_SEEDS,\n",
    "    'results': [float(x) for x in high_res_results],\n",
    "    'mean': float(mean_result),\n",
    "    'std': float(std_result),\n",
    "    'deviation_13_pct': float(abs(mean_result - 13)/13*100),\n",
    "    'deviation_14_pct': float(abs(mean_result - 14)/14*100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Alternative - Direct Rayleigh Quotient (no calibration needed)\n",
    "# λ₁ = min_{∫f=0} ∫|∇f|²_g / ∫f²\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ALTERNATIVE: RAYLEIGH QUOTIENT METHOD\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def rayleigh_quotient_estimate(Q1, Q2, theta, ratio, n_test=100):\n",
    "    \"\"\"Estimate λ₁ via Rayleigh quotient with random test functions.\n",
    "    \n",
    "    For the metric g with det(g) = 65/32:\n",
    "    g = diag(1, 1, 1, 1, r², r², r², α) where α ensures det = 65/32\n",
    "    \n",
    "    λ₁ = min R[f] where R[f] = ∫g^{ij}∂_if∂_jf √det(g) / ∫f² √det(g)\n",
    "    \"\"\"\n",
    "    N = Q1.shape[0]\n",
    "    det_g = DET_G\n",
    "    sqrt_det = np.sqrt(det_g)\n",
    "    \n",
    "    # Metric components\n",
    "    # g = (1, 1, 1, 1, r², r², r²) for (S³₁, S³₂×r)\n",
    "    g_inv = np.array([1, 1, 1, 1, 1/ratio**2, 1/ratio**2, 1/ratio**2])\n",
    "    \n",
    "    min_rayleigh = np.inf\n",
    "    \n",
    "    # Test with Fourier-like modes\n",
    "    for _ in range(n_test):\n",
    "        # Random frequency\n",
    "        freq = np.random.randint(1, 5)\n",
    "        dim = np.random.randint(0, 7)\n",
    "        \n",
    "        # Coordinates: embed S³×S³ in ℝ⁸ then project\n",
    "        coords = np.hstack([Q1, Q2[:, :3]])  # Use 7 coords\n",
    "        \n",
    "        # Test function: f = cos(freq × x_dim)\n",
    "        f = np.cos(freq * coords[:, dim % 7])\n",
    "        f = f - np.mean(f)  # Zero mean (orthogonal to constants)\n",
    "        \n",
    "        # Gradient (finite difference approximation)\n",
    "        # For S³: ∂f/∂x_i ≈ -freq × sin(freq × x_i)\n",
    "        grad_f_sq = (freq**2) * np.sin(freq * coords[:, dim % 7])**2\n",
    "        \n",
    "        # Weight by inverse metric\n",
    "        if dim < 4:\n",
    "            grad_weighted = grad_f_sq * g_inv[dim]\n",
    "        else:\n",
    "            grad_weighted = grad_f_sq * g_inv[dim]\n",
    "        \n",
    "        # Rayleigh quotient\n",
    "        numerator = np.mean(grad_weighted) * sqrt_det\n",
    "        denominator = np.mean(f**2) * sqrt_det\n",
    "        \n",
    "        if denominator > 1e-10:\n",
    "            R = numerator / denominator\n",
    "            min_rayleigh = min(min_rayleigh, R)\n",
    "    \n",
    "    return min_rayleigh\n",
    "\n",
    "print(\"\\nEstimating λ₁ via Rayleigh quotient...\")\n",
    "print(\"(This provides a geometry-aware estimate without graph Laplacian)\")\n",
    "\n",
    "N_ray = 20000\n",
    "np.random.seed(42)\n",
    "Q1, Q2, theta, _ = sample_K7_TCS(N_ray, RATIO_OPTIMAL)\n",
    "\n",
    "# Multiple runs to find minimum\n",
    "rayleigh_estimates = []\n",
    "for trial in range(5):\n",
    "    est = rayleigh_quotient_estimate(Q1, Q2, theta, RATIO_OPTIMAL, n_test=200)\n",
    "    rayleigh_estimates.append(est)\n",
    "    print(f\"  Trial {trial}: λ₁ ≈ {est:.4f}, λ₁×H* ≈ {est * H_STAR:.2f}\")\n",
    "\n",
    "best_rayleigh = min(rayleigh_estimates)\n",
    "print(f\"\\nBest Rayleigh estimate: λ₁ ≈ {best_rayleigh:.4f}\")\n",
    "print(f\"λ₁ × H* ≈ {best_rayleigh * H_STAR:.2f}\")\n",
    "\n",
    "rayleigh_result = {\n",
    "    'method': 'Rayleigh quotient',\n",
    "    'N': N_ray,\n",
    "    'estimates': [float(x) for x in rayleigh_estimates],\n",
    "    'best_lambda1': float(best_rayleigh),\n",
    "    'best_product': float(best_rayleigh * H_STAR)\n",
    "}\n",
    "\n",
    "del Q1, Q2, theta\n",
    "clear_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Save Results and Visualize\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compile all results\n",
    "results = {\n",
    "    'metadata': {\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'notebook': 'K7_Spectral_v4_Unnormalized.ipynb',\n",
    "        'method': 'Unnormalized Laplacian L = D - W with σ² scaling'\n",
    "    },\n",
    "    'constants': {\n",
    "        'H_star': H_STAR,\n",
    "        'det_g': DET_G,\n",
    "        'dim_G2': DIM_G2,\n",
    "        'TCS_ratio': float(RATIO_OPTIMAL)\n",
    "    },\n",
    "    'calibration_S3': calibration_results,\n",
    "    'convergence_study': convergence_results,\n",
    "    'high_resolution': high_resolution_final,\n",
    "    'rayleigh_quotient': rayleigh_result,\n",
    "    'summary': {\n",
    "        'best_lambda1_times_Hstar': float(mean_result),\n",
    "        'best_std': float(std_result),\n",
    "        'target_13_deviation_pct': float(abs(mean_result - 13)/13*100),\n",
    "        'target_14_deviation_pct': float(abs(mean_result - 14)/14*100),\n",
    "        'passed_13': bool(abs(mean_result - 13)/13*100 < 5),\n",
    "        'passed_14': bool(abs(mean_result - 14)/14*100 < 5)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save JSON\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "with open('outputs/k7_spectral_v4_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Saved: outputs/k7_spectral_v4_results.json\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Plot 1: Convergence with N\n",
    "ax1 = axes[0]\n",
    "Ns = [r['N'] for r in convergence_results]\n",
    "products = [r['lambda1_times_Hstar'] for r in convergence_results]\n",
    "ax1.plot(Ns, products, 'bo-', linewidth=2, markersize=8)\n",
    "ax1.axhline(y=13, color='g', linestyle='--', label='Target 13')\n",
    "ax1.axhline(y=14, color='orange', linestyle='--', label='Target 14')\n",
    "ax1.set_xlabel('N (sample size)')\n",
    "ax1.set_ylabel('λ₁ × H*')\n",
    "ax1.set_title('Convergence with Sample Size')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: High-resolution seeds\n",
    "ax2 = axes[1]\n",
    "ax2.bar(range(N_SEEDS), high_res_results, color='steelblue', alpha=0.7)\n",
    "ax2.axhline(y=mean_result, color='red', linestyle='-', linewidth=2, label=f'Mean: {mean_result:.2f}')\n",
    "ax2.axhline(y=13, color='g', linestyle='--', label='Target 13')\n",
    "ax2.axhline(y=14, color='orange', linestyle='--', label='Target 14')\n",
    "ax2.set_xlabel('Seed')\n",
    "ax2.set_ylabel('λ₁ × H*')\n",
    "ax2.set_title(f'High-Resolution Runs (N={N_HIGH:,})')\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, max(20, max(high_res_results) * 1.2))\n",
    "\n",
    "# Plot 3: Summary comparison\n",
    "ax3 = axes[2]\n",
    "methods = ['Measured', 'Target 13', 'dim(G₂)=14']\n",
    "values = [mean_result, 13, 14]\n",
    "colors = ['steelblue', 'green', 'orange']\n",
    "bars = ax3.bar(methods, values, color=colors, alpha=0.7)\n",
    "ax3.set_ylabel('λ₁ × H*')\n",
    "ax3.set_title('Final Result Comparison')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n",
    "             f'{val:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('outputs/k7_spectral_v4_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Saved: outputs/k7_spectral_v4_results.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n  λ₁ × H* = {mean_result:.2f} ± {std_result:.2f}\")\n",
    "print(f\"  Deviation from 13: {abs(mean_result-13)/13*100:.1f}%\")\n",
    "print(f\"  Deviation from 14: {abs(mean_result-14)/14*100:.1f}%\")\n",
    "print(f\"\\n  PASSED (< 5%): {results['summary']['passed_13'] or results['summary']['passed_14']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
