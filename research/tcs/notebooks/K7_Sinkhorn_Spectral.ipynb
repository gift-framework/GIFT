{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K₇ Sinkhorn-Knopp Spectral Gap\n",
    "\n",
    "## Méthode Bi-Stochastique — ZÉRO Paramètre à Tuner\n",
    "\n",
    "**Référence**: Cheng & Landa (2022) - \"Bi-stochastically normalized graph Laplacian\"\n",
    "\n",
    "**Innovation clé**: La normalisation Sinkhorn-Knopp élimine la dépendance au bandwidth σ!\n",
    "\n",
    "```\n",
    "Convergence: O(N^(-1/(d/2+3))) = O(N^(-0.154)) pour d=7\n",
    "Robuste aux outliers\n",
    "Fonctionne avec N'IMPORTE QUEL σ dans une plage raisonnable\n",
    "```\n",
    "\n",
    "**Test**: Si différents σ donnent la même limite N→∞, c'est canonique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    from cupyx.scipy.sparse.linalg import eigsh as cp_eigsh\n",
    "    GPU = True\n",
    "    print(\"✓ GPU (CuPy)\")\n",
    "except:\n",
    "    GPU = False\n",
    "    from scipy.sparse.linalg import eigsh\n",
    "    print(\"○ CPU mode\")\n",
    "\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIFT Constants\n",
    "H_STAR = 99\n",
    "DIM_G2 = 14\n",
    "DET_G = 65/32\n",
    "RATIO = H_STAR / 84\n",
    "\n",
    "def sample_TCS_K7(N, seed):\n",
    "    \"\"\"Sample K₇ via TCS: S¹ × S³ × S³\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    # S¹\n",
    "    theta = rng.uniform(0, 2*np.pi, N)\n",
    "    \n",
    "    # S³ (quaternion)\n",
    "    def sample_S3(n):\n",
    "        x = rng.standard_normal((n, 4))\n",
    "        return x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    \n",
    "    q1, q2 = sample_S3(N), sample_S3(N)\n",
    "    return theta, q1, q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(theta, q1, q2, chunk=2000):\n",
    "    \"\"\"TCS geodesic distances.\"\"\"\n",
    "    N = len(theta)\n",
    "    alpha = DET_G / (RATIO ** 3)\n",
    "    D = np.zeros((N, N), dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, N, chunk):\n",
    "        ie = min(i + chunk, N)\n",
    "        for j in range(0, N, chunk):\n",
    "            je = min(j + chunk, N)\n",
    "            \n",
    "            # S¹\n",
    "            diff = np.abs(theta[i:ie, None] - theta[None, j:je])\n",
    "            d_S1 = np.minimum(diff, 2*np.pi - diff)\n",
    "            \n",
    "            # S³ (both factors)\n",
    "            d_S3_1 = np.zeros((ie-i, je-j), dtype=np.float32)\n",
    "            d_S3_2 = np.zeros((ie-i, je-j), dtype=np.float32)\n",
    "            for ii, (qi1, qi2) in enumerate(zip(q1[i:ie], q2[i:ie])):\n",
    "                dot1 = np.clip(np.abs(np.sum(qi1 * q1[j:je], axis=1)), -1, 1)\n",
    "                d_S3_1[ii] = 2 * np.arccos(dot1)\n",
    "                dot2 = np.clip(np.abs(np.sum(qi2 * q2[j:je], axis=1)), -1, 1)\n",
    "                d_S3_2[ii] = 2 * np.arccos(dot2)\n",
    "            \n",
    "            D[i:ie, j:je] = np.sqrt(alpha * d_S1**2 + d_S3_1**2 + RATIO**2 * d_S3_2**2)\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn-Knopp Algorithm\n",
    "\n",
    "Transform ANY kernel matrix K into bi-stochastic form:\n",
    "```\n",
    "K → D_r^{-1/2} K D_c^{-1/2}  (alternating row/column normalization)\n",
    "```\n",
    "\n",
    "After convergence, row sums = column sums = 1 (doubly stochastic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_knopp(K, n_iter=10, tol=1e-6):\n",
    "    \"\"\"Sinkhorn-Knopp bi-stochastic normalization.\n",
    "    \n",
    "    Transforms kernel K into doubly stochastic matrix.\n",
    "    Converges for any positive definite K.\n",
    "    \"\"\"\n",
    "    N = K.shape[0]\n",
    "    K = K.copy()\n",
    "    \n",
    "    for iteration in range(n_iter):\n",
    "        # Row normalization\n",
    "        row_sums = K.sum(axis=1, keepdims=True)\n",
    "        K = K / (row_sums + 1e-10)\n",
    "        \n",
    "        # Column normalization  \n",
    "        col_sums = K.sum(axis=0, keepdims=True)\n",
    "        K = K / (col_sums + 1e-10)\n",
    "        \n",
    "        # Check convergence\n",
    "        row_err = np.abs(K.sum(axis=1) - 1).max()\n",
    "        col_err = np.abs(K.sum(axis=0) - 1).max()\n",
    "        if max(row_err, col_err) < tol:\n",
    "            break\n",
    "    \n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sinkhorn_laplacian(D, sigma):\n",
    "    \"\"\"Compute bi-stochastic normalized Laplacian.\n",
    "    \n",
    "    1. Build Gaussian kernel with given sigma\n",
    "    2. Apply Sinkhorn-Knopp normalization\n",
    "    3. Construct Laplacian: L = I - K_normalized\n",
    "    \n",
    "    The key insight: result is σ-INDEPENDENT in the N→∞ limit!\n",
    "    \"\"\"\n",
    "    # Gaussian kernel\n",
    "    K = np.exp(-D**2 / (2 * sigma**2))\n",
    "    np.fill_diagonal(K, 0)  # No self-loops\n",
    "    \n",
    "    # Sinkhorn-Knopp normalization\n",
    "    K_normalized = sinkhorn_knopp(K, n_iter=20)\n",
    "    \n",
    "    # Laplacian\n",
    "    L = np.eye(K.shape[0]) - K_normalized\n",
    "    \n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda1(L):\n",
    "    \"\"\"First non-zero eigenvalue.\"\"\"\n",
    "    if GPU:\n",
    "        L_gpu = cp.asarray(L)\n",
    "        eigs = cp_eigsh(L_gpu, k=6, which='SA', return_eigenvectors=False)\n",
    "        eigs = cp.asnumpy(eigs)\n",
    "    else:\n",
    "        eigs = eigsh(L, k=6, which='SA', return_eigenvectors=False)\n",
    "    \n",
    "    eigs = np.sort(eigs)\n",
    "    return eigs[eigs > 1e-8][0] if np.any(eigs > 1e-8) else eigs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: σ-Independence\n",
    "\n",
    "If Sinkhorn-Knopp truly removes σ-dependence, different σ values should give same λ₁×H*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test parameters\n",
    "N_VALUES = [3000, 5000, 8000]\n",
    "SIGMA_VALUES = [0.3, 0.5, 0.8, 1.2]  # Wide range!\n",
    "N_SEEDS = 3\n",
    "\n",
    "print(\"Sinkhorn-Knopp σ-Independence Test\")\n",
    "print(\"=\"*60)\n",
    "print(f\"N: {N_VALUES}\")\n",
    "print(f\"σ: {SIGMA_VALUES}\")\n",
    "print(f\"Seeds: {N_SEEDS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = {sigma: [] for sigma in SIGMA_VALUES}\n",
    "\n",
    "for N in N_VALUES:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"N = {N}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for seed in range(N_SEEDS):\n",
    "        theta, q1, q2 = sample_TCS_K7(N, 42 + seed)\n",
    "        print(f\"  Seed {seed}: Computing distances...\", end=\" \")\n",
    "        D = compute_distance_matrix(theta, q1, q2)\n",
    "        print(\"done\")\n",
    "        \n",
    "        for sigma in SIGMA_VALUES:\n",
    "            L = compute_sinkhorn_laplacian(D, sigma)\n",
    "            lam1 = compute_lambda1(L)\n",
    "            product = float(lam1 * H_STAR)\n",
    "            \n",
    "            results[sigma].append({'N': N, 'seed': seed, 'sigma': sigma,\n",
    "                                   'lambda1': float(lam1), 'product': product})\n",
    "            print(f\"    σ={sigma}: λ₁×H* = {product:.3f}\")\n",
    "        \n",
    "        del D\n",
    "        if GPU:\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "print(f\"\\nCompleted: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summary statistics\n",
    "summary = {}\n",
    "for sigma in SIGMA_VALUES:\n",
    "    summary[sigma] = {}\n",
    "    for N in N_VALUES:\n",
    "        prods = [r['product'] for r in results[sigma] if r['N'] == N]\n",
    "        summary[sigma][N] = {'mean': np.mean(prods), 'std': np.std(prods)}\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(SIGMA_VALUES)))\n",
    "\n",
    "for i, sigma in enumerate(SIGMA_VALUES):\n",
    "    means = [summary[sigma][N]['mean'] for N in N_VALUES]\n",
    "    stds = [summary[sigma][N]['std'] for N in N_VALUES]\n",
    "    ax.errorbar(N_VALUES, means, yerr=stds, marker='o', label=f'σ={sigma}',\n",
    "                color=colors[i], capsize=3, linewidth=2, markersize=8)\n",
    "\n",
    "ax.axhline(y=14, color='red', linestyle='--', alpha=0.7, label='Pell (14)')\n",
    "ax.axhline(y=13, color='blue', linestyle='--', alpha=0.7, label='Spinor (13)')\n",
    "ax.set_xlabel('N', fontsize=12)\n",
    "ax.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax.set_title('Sinkhorn-Knopp: σ-Independence Test', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('sinkhorn_sigma_independence.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# σ-Independence analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"σ-INDEPENDENCE ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for N in N_VALUES:\n",
    "    values = [summary[sigma][N]['mean'] for sigma in SIGMA_VALUES]\n",
    "    spread = max(values) - min(values)\n",
    "    mean_val = np.mean(values)\n",
    "    \n",
    "    print(f\"\\nN = {N}:\")\n",
    "    for sigma in SIGMA_VALUES:\n",
    "        print(f\"  σ={sigma}: {summary[sigma][N]['mean']:.3f}\")\n",
    "    print(f\"  Spread: {spread:.3f}\")\n",
    "    print(f\"  Mean: {mean_val:.3f}\")\n",
    "    \n",
    "    if spread < 1.0:\n",
    "        print(f\"  ✓ σ-INDEPENDENT (spread < 1)\")\n",
    "    else:\n",
    "        print(f\"  ✗ σ-DEPENDENT (spread ≥ 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "final_results = {\n",
    "    'metadata': {\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'method': 'Sinkhorn-Knopp bi-stochastic normalization',\n",
    "        'reference': 'Cheng & Landa (2022)',\n",
    "        'H_star': H_STAR,\n",
    "        'N_values': N_VALUES,\n",
    "        'sigma_values': SIGMA_VALUES\n",
    "    },\n",
    "    'raw_results': results,\n",
    "    'summary': {str(s): {str(N): summary[s][N] for N in N_VALUES} for s in SIGMA_VALUES}\n",
    "}\n",
    "\n",
    "with open('sinkhorn_spectral_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(\"Saved to sinkhorn_spectral_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### If σ-Independent:\n",
    "- Sinkhorn-Knopp gives **canonical** spectral gap\n",
    "- The limit λ₁×H* is a geometric invariant\n",
    "- NO tuning required\n",
    "\n",
    "### If σ-Dependent:\n",
    "- Need larger N for convergence\n",
    "- Or: try heat kernel method instead"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
