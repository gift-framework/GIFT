{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K₇ Heat Kernel Spectral Estimator\n",
    "\n",
    "## Méthode: Trace du Heat Kernel\n",
    "\n",
    "**Principe**: Extraire λ₁ depuis la décroissance exponentielle de Tr(e^{-tL})\n",
    "\n",
    "```\n",
    "Tr(e^{-tL}) = Σₙ e^{-λₙt} = N·e^{-λ₀t} + (N-1)·e^{-λ₁t} + ...\n",
    "           ≈ N + (N-1)·e^{-λ₁t}  pour t petit (λ₀ ≈ 0)\n",
    "```\n",
    "\n",
    "**Avantage**: La trace est une quantité INTRINSÈQUE — indépendante de la base.\n",
    "\n",
    "**Extraction de λ₁**:\n",
    "```\n",
    "log(Tr(e^{-tL}) - N) ≈ log(N-1) - λ₁·t\n",
    "→ Pente = -λ₁\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "from scipy.linalg import expm\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    GPU = True\n",
    "    print(\"✓ GPU (CuPy)\")\n",
    "except:\n",
    "    GPU = False\n",
    "    print(\"○ CPU mode\")\n",
    "\n",
    "print(f\"Started: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIFT Constants\n",
    "H_STAR = 99\n",
    "DIM_G2 = 14\n",
    "DET_G = 65/32\n",
    "RATIO = H_STAR / 84\n",
    "\n",
    "def sample_TCS_K7(N, seed):\n",
    "    \"\"\"Sample K₇ via TCS: S¹ × S³ × S³\"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    theta = rng.uniform(0, 2*np.pi, N)\n",
    "    def sample_S3(n):\n",
    "        x = rng.standard_normal((n, 4))\n",
    "        return x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return theta, sample_S3(N), sample_S3(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_matrix(theta, q1, q2, chunk=1500):\n",
    "    \"\"\"TCS geodesic distances.\"\"\"\n",
    "    N = len(theta)\n",
    "    alpha = DET_G / (RATIO ** 3)\n",
    "    D = np.zeros((N, N), dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, N, chunk):\n",
    "        ie = min(i + chunk, N)\n",
    "        for j in range(0, N, chunk):\n",
    "            je = min(j + chunk, N)\n",
    "            \n",
    "            diff = np.abs(theta[i:ie, None] - theta[None, j:je])\n",
    "            d_S1 = np.minimum(diff, 2*np.pi - diff)\n",
    "            \n",
    "            d_S3_1 = np.zeros((ie-i, je-j), dtype=np.float32)\n",
    "            d_S3_2 = np.zeros((ie-i, je-j), dtype=np.float32)\n",
    "            for ii, (qi1, qi2) in enumerate(zip(q1[i:ie], q2[i:ie])):\n",
    "                dot1 = np.clip(np.abs(np.sum(qi1 * q1[j:je], axis=1)), -1, 1)\n",
    "                d_S3_1[ii] = 2 * np.arccos(dot1)\n",
    "                dot2 = np.clip(np.abs(np.sum(qi2 * q2[j:je], axis=1)), -1, 1)\n",
    "                d_S3_2[ii] = 2 * np.arccos(dot2)\n",
    "            \n",
    "            D[i:ie, j:je] = np.sqrt(alpha * d_S1**2 + d_S3_1**2 + RATIO**2 * d_S3_2**2)\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_normalized_laplacian(D, sigma):\n",
    "    \"\"\"Standard normalized Laplacian.\"\"\"\n",
    "    W = np.exp(-D**2 / (2 * sigma**2))\n",
    "    np.fill_diagonal(W, 0)\n",
    "    \n",
    "    d = W.sum(axis=1)\n",
    "    d_inv_sqrt = 1.0 / np.sqrt(d + 1e-10)\n",
    "    \n",
    "    # L = I - D^{-1/2} W D^{-1/2}\n",
    "    L = np.eye(W.shape[0]) - (d_inv_sqrt[:, None] * W * d_inv_sqrt[None, :])\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Kernel Trace Method\n",
    "\n",
    "Pour une matrice L avec eigenvalues 0 = λ₀ < λ₁ ≤ λ₂ ≤ ...:\n",
    "\n",
    "```\n",
    "Tr(e^{-tL}) = Σₙ e^{-λₙt}\n",
    "```\n",
    "\n",
    "À t modéré, les premiers termes dominent:\n",
    "```\n",
    "Tr(e^{-tL}) ≈ 1 + (multiplicité de λ₁) × e^{-λ₁t} + ...\n",
    "```\n",
    "\n",
    "En pratique, on fit:\n",
    "```\n",
    "log(Tr(e^{-tL}) - 1) vs t  →  pente = -λ₁\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_kernel_trace(L, t):\n",
    "    \"\"\"Compute Tr(e^{-tL}) via matrix exponential.\"\"\"\n",
    "    # For small matrices, direct expm is fine\n",
    "    # For large matrices, use eigendecomposition or Krylov methods\n",
    "    heat = expm(-t * L)\n",
    "    return np.trace(heat)\n",
    "\n",
    "def extract_lambda1_from_heat_trace(L, t_values):\n",
    "    \"\"\"Extract λ₁ from heat kernel trace decay.\n",
    "    \n",
    "    Method: fit log(Tr(e^{-tL}) - 1) vs t\n",
    "    The slope gives -λ₁\n",
    "    \"\"\"\n",
    "    N = L.shape[0]\n",
    "    traces = []\n",
    "    \n",
    "    for t in t_values:\n",
    "        tr = heat_kernel_trace(L, t)\n",
    "        traces.append(tr)\n",
    "    \n",
    "    traces = np.array(traces)\n",
    "    \n",
    "    # Tr(e^{-tL}) - 1 ≈ (N-1)e^{-λ₁t} for normalized Laplacian\n",
    "    # Actually for normalized Laplacian, Tr = N at t=0, and decays\n",
    "    # At t=0: Tr(I) = N, but Tr(e^{-tL}) → multiplicity of λ=0 as t→∞\n",
    "    \n",
    "    # For normalized Laplacian: λ₀ = 0 with mult 1\n",
    "    # So Tr(e^{-tL}) = 1 + Σ_{n≥1} e^{-λₙt}\n",
    "    # At large t: Tr → 1\n",
    "    # Tr - 1 ≈ (N-1)e^{-λ₁t} for λ₁ << λ₂ or when λ₁ dominates\n",
    "    \n",
    "    # Fit: log(Tr - 1) = log(N-1) - λ₁·t\n",
    "    y = np.log(np.maximum(traces - 1, 1e-10))\n",
    "    \n",
    "    # Linear fit\n",
    "    n = len(t_values)\n",
    "    sum_t = sum(t_values)\n",
    "    sum_y = sum(y)\n",
    "    sum_ty = sum(ti*yi for ti, yi in zip(t_values, y))\n",
    "    sum_tt = sum(ti*ti for ti in t_values)\n",
    "    \n",
    "    slope = (n * sum_ty - sum_t * sum_y) / (n * sum_tt - sum_t * sum_t)\n",
    "    intercept = (sum_y - slope * sum_t) / n\n",
    "    \n",
    "    lambda1 = -slope  # slope = -λ₁\n",
    "    \n",
    "    # R² for fit quality\n",
    "    y_pred = [slope * t + intercept for t in t_values]\n",
    "    ss_res = sum((yi - yp)**2 for yi, yp in zip(y, y_pred))\n",
    "    y_mean = sum_y / n\n",
    "    ss_tot = sum((yi - y_mean)**2 for yi in y)\n",
    "    r2 = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "    \n",
    "    return lambda1, r2, traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: use eigendecomposition (more accurate)\n",
    "def extract_lambda1_direct(L):\n",
    "    \"\"\"Direct eigenvalue computation for comparison.\"\"\"\n",
    "    from scipy.linalg import eigvalsh\n",
    "    eigs = eigvalsh(L)\n",
    "    eigs = np.sort(eigs)\n",
    "    # First non-zero eigenvalue\n",
    "    lambda1 = eigs[eigs > 1e-8][0] if np.any(eigs > 1e-8) else eigs[1]\n",
    "    return lambda1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: σ-Independence via Heat Kernel\n",
    "\n",
    "Si le heat kernel extrait le vrai λ₁ de la variété, différents σ devraient donner le même résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (smaller N due to O(N³) expm cost)\n",
    "N_VALUES = [500, 800, 1200]\n",
    "SIGMA_VALUES = [0.4, 0.6, 0.8, 1.0]\n",
    "T_VALUES = [0.5, 1.0, 2.0, 4.0, 8.0]  # Time points for heat kernel\n",
    "N_SEEDS = 3\n",
    "\n",
    "print(\"Heat Kernel Spectral Estimator\")\n",
    "print(\"=\"*60)\n",
    "print(f\"N: {N_VALUES}\")\n",
    "print(f\"σ: {SIGMA_VALUES}\")\n",
    "print(f\"t: {T_VALUES}\")\n",
    "print(f\"Note: Using smaller N due to O(N³) matrix exponential cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = []\n",
    "\n",
    "for N in N_VALUES:\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"N = {N}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    for seed in range(N_SEEDS):\n",
    "        theta, q1, q2 = sample_TCS_K7(N, 42 + seed)\n",
    "        print(f\"  Seed {seed}: Computing distances...\", end=\" \")\n",
    "        D = compute_distance_matrix(theta, q1, q2)\n",
    "        print(\"done\")\n",
    "        \n",
    "        for sigma in SIGMA_VALUES:\n",
    "            L = compute_normalized_laplacian(D, sigma)\n",
    "            \n",
    "            # Heat kernel method\n",
    "            lam1_heat, r2, traces = extract_lambda1_from_heat_trace(L, T_VALUES)\n",
    "            \n",
    "            # Direct method for comparison\n",
    "            lam1_direct = extract_lambda1_direct(L)\n",
    "            \n",
    "            product_heat = float(lam1_heat * H_STAR)\n",
    "            product_direct = float(lam1_direct * H_STAR)\n",
    "            \n",
    "            results.append({\n",
    "                'N': N, 'seed': seed, 'sigma': sigma,\n",
    "                'lambda1_heat': float(lam1_heat),\n",
    "                'lambda1_direct': float(lam1_direct),\n",
    "                'product_heat': product_heat,\n",
    "                'product_direct': product_direct,\n",
    "                'r2': float(r2)\n",
    "            })\n",
    "            \n",
    "            print(f\"    σ={sigma}: Heat={product_heat:.2f}, Direct={product_direct:.2f}, R²={r2:.3f}\")\n",
    "        \n",
    "        del D, L\n",
    "\n",
    "print(f\"\\nCompleted: {datetime.now().strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Analyze results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS: Heat Kernel vs Direct Eigenvalue\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Group by N and sigma\n",
    "for N in N_VALUES:\n",
    "    print(f\"\\nN = {N}:\")\n",
    "    print(f\"  {'σ':>5} | {'Heat λ₁×H*':>12} | {'Direct λ₁×H*':>12} | {'Match?':>8}\")\n",
    "    print(f\"  {'-'*50}\")\n",
    "    \n",
    "    for sigma in SIGMA_VALUES:\n",
    "        heat_vals = [r['product_heat'] for r in results if r['N']==N and r['sigma']==sigma]\n",
    "        direct_vals = [r['product_direct'] for r in results if r['N']==N and r['sigma']==sigma]\n",
    "        \n",
    "        heat_mean = np.mean(heat_vals)\n",
    "        direct_mean = np.mean(direct_vals)\n",
    "        match = \"✓\" if abs(heat_mean - direct_mean) < 1 else \"✗\"\n",
    "        \n",
    "        print(f\"  {sigma:>5.1f} | {heat_mean:>12.2f} | {direct_mean:>12.2f} | {match:>8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# σ-independence test (using direct values which are more reliable)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"σ-INDEPENDENCE TEST (Direct Eigenvalue)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for N in N_VALUES:\n",
    "    print(f\"\\nN = {N}:\")\n",
    "    sigma_means = []\n",
    "    for sigma in SIGMA_VALUES:\n",
    "        vals = [r['product_direct'] for r in results if r['N']==N and r['sigma']==sigma]\n",
    "        mean_val = np.mean(vals)\n",
    "        sigma_means.append(mean_val)\n",
    "        print(f\"  σ={sigma}: λ₁×H* = {mean_val:.2f}\")\n",
    "    \n",
    "    spread = max(sigma_means) - min(sigma_means)\n",
    "    print(f\"  Spread: {spread:.2f}\")\n",
    "    if spread < 2:\n",
    "        print(f\"  ✓ Relatively σ-independent\")\n",
    "    else:\n",
    "        print(f\"  ✗ σ-dependent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize heat trace decay\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Example: show trace decay for one configuration\n",
    "N_example = N_VALUES[-1]\n",
    "theta, q1, q2 = sample_TCS_K7(N_example, 42)\n",
    "D = compute_distance_matrix(theta, q1, q2)\n",
    "\n",
    "ax = axes[0]\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(SIGMA_VALUES)))\n",
    "\n",
    "for i, sigma in enumerate(SIGMA_VALUES):\n",
    "    L = compute_normalized_laplacian(D, sigma)\n",
    "    traces = [heat_kernel_trace(L, t) for t in T_VALUES]\n",
    "    ax.semilogy(T_VALUES, [tr - 1 for tr in traces], 'o-', \n",
    "                label=f'σ={sigma}', color=colors[i], markersize=8)\n",
    "\n",
    "ax.set_xlabel('t', fontsize=12)\n",
    "ax.set_ylabel('Tr(e^{-tL}) - 1', fontsize=12)\n",
    "ax.set_title(f'Heat Kernel Trace Decay (N={N_example})', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Right: λ₁×H* vs σ for each N\n",
    "ax = axes[1]\n",
    "for i, N in enumerate(N_VALUES):\n",
    "    means = []\n",
    "    stds = []\n",
    "    for sigma in SIGMA_VALUES:\n",
    "        vals = [r['product_direct'] for r in results if r['N']==N and r['sigma']==sigma]\n",
    "        means.append(np.mean(vals))\n",
    "        stds.append(np.std(vals))\n",
    "    ax.errorbar(SIGMA_VALUES, means, yerr=stds, marker='o', label=f'N={N}',\n",
    "                capsize=3, linewidth=2, markersize=8)\n",
    "\n",
    "ax.axhline(y=14, color='red', linestyle='--', alpha=0.7, label='Pell (14)')\n",
    "ax.axhline(y=13, color='blue', linestyle='--', alpha=0.7, label='Spinor (13)')\n",
    "ax.set_xlabel('σ', fontsize=12)\n",
    "ax.set_ylabel('λ₁ × H*', fontsize=12)\n",
    "ax.set_title('σ-Dependence (Direct Eigenvalue)', fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('heat_kernel_analysis.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "final_results = {\n",
    "    'metadata': {\n",
    "        'date': datetime.now().isoformat(),\n",
    "        'method': 'Heat kernel trace + direct eigenvalue',\n",
    "        'H_star': H_STAR,\n",
    "        'N_values': N_VALUES,\n",
    "        'sigma_values': SIGMA_VALUES,\n",
    "        't_values': T_VALUES\n",
    "    },\n",
    "    'results': results\n",
    "}\n",
    "\n",
    "with open('heat_kernel_spectral_results.json', 'w') as f:\n",
    "    json.dump(final_results, f, indent=2)\n",
    "\n",
    "print(\"Saved to heat_kernel_spectral_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Le heat kernel trace est une méthode alternative pour extraire λ₁.\n",
    "\n",
    "**Avantages**:\n",
    "- Intrinsèque (ne dépend pas de la base)\n",
    "- Connecté à la géométrie (asymptotics → courbure)\n",
    "\n",
    "**Limitations**:\n",
    "- Coût O(N³) pour l'exponentielle matricielle\n",
    "- Dépend encore du choix de σ pour construire L\n",
    "\n",
    "**Observation**: Le heat kernel ne résout pas le problème fondamental —\n",
    "la construction du graphe Laplacien nécessite toujours un paramètre (k, σ, etc.)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
