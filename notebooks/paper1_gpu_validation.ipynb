{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "name": "Paper1_GPU_Robust_Validation.ipynb"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Robust Statistical Validation\n",
    "## Paper 1: Mollified Prime-Spectral S(T)\n",
    "\n",
    "**8 independent tests** with GPU acceleration via CuPy.\n",
    "Runs in ~5 min on Colab A100.\n",
    "\n",
    "| Test | Description | GPU-accelerated |\n",
    "|------|------------|----------------|\n",
    "| T1 | Honest train/test split | |\n",
    "| T2 | Permutation 50K + effect size | Yes |\n",
    "| T3 | Baseline model comparison | |\n",
    "| T4 | 10-fold cross-validation | |\n",
    "| T5 | Monte Carlo uniqueness 100K | Yes |\n",
    "| T6 | Bayesian BIC | |\n",
    "| T7 | Bootstrap BCa 2K | Yes |\n",
    "| T8 | Window stability | |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cupy-cuda12x mpmath -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from scipy.special import loggamma\n",
    "from scipy.stats import norm, t as t_dist\n",
    "import json, time, warnings, os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f'CuPy {cp.__version__}')\n",
    "props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "print(f\"GPU: {props['name'].decode()}, \"\n",
    "      f\"{props['totalGlobalMem'] / 1e9:.0f} GB\")\n",
    "\n",
    "# ── Configuration ──\n",
    "N_ZEROS      = 10_000\n",
    "N_PERM       = 50_000\n",
    "N_MC         = 100_000\n",
    "N_BOOTSTRAP  = 2_000\n",
    "N_KFOLD      = 10\n",
    "N_BASELINE_RANDOM = 200\n",
    "\n",
    "THETA0_OPT = 1.4091\n",
    "THETA1_OPT = -3.9537\n",
    "THETA_CONST = 0.9941\n",
    "\n",
    "KERNELS = ['cosine','selberg','sharp','linear',\n",
    "           'quadratic','gaussian','cubic']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpmath import zetazero\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def _zz(n):\n",
    "    from mpmath import zetazero as zz\n",
    "    return float(zz(n).imag)\n",
    "\n",
    "print(f'Computing {N_ZEROS} Riemann zeros (parallel)...')\n",
    "t0 = time.time()\n",
    "try:\n",
    "    with Pool(4) as pool:\n",
    "        gammas = np.array(pool.map(_zz, range(1, N_ZEROS+1)))\n",
    "except Exception:\n",
    "    print('  Falling back to sequential...')\n",
    "    gammas = np.array([float(zetazero(i).imag)\n",
    "                       for i in range(1, N_ZEROS+1)])\n",
    "print(f'  Done in {time.time()-t0:.1f}s')\n",
    "print(f'  Range: [{gammas[0]:.3f}, {gammas[-1]:.3f}]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rs_theta(t):\n",
    "    return np.imag(loggamma(0.25 + 0.5j*t)) - 0.5*t*np.log(np.pi)\n",
    "\n",
    "def rs_theta_deriv(t):\n",
    "    return 0.5 * np.log(t / (2*np.pi))\n",
    "\n",
    "def smooth_zeros(g, n_iter=40):\n",
    "    n = np.arange(1, len(g)+1)\n",
    "    target = (n - 1.5) * np.pi\n",
    "    g0 = g.copy()\n",
    "    for _ in range(n_iter):\n",
    "        g0 -= (rs_theta(g0) - target) / rs_theta_deriv(g0)\n",
    "    return g0\n",
    "\n",
    "def sieve_primes(n_max):\n",
    "    is_p = np.ones(n_max+1, dtype=bool); is_p[:2] = False\n",
    "    for i in range(2, int(n_max**0.5)+1):\n",
    "        if is_p[i]: is_p[i*i::i] = False\n",
    "    return np.where(is_p)[0]\n",
    "\n",
    "gammas_smooth = smooth_zeros(gammas)\n",
    "delta_true = gammas - gammas_smooth\n",
    "primes = sieve_primes(10_000)\n",
    "\n",
    "print(f'Zeros: {len(gammas)}, Primes: {len(primes)}')\n",
    "print(f'delta: mean={np.mean(delta_true):.6f}, '\n",
    "      f'std={np.std(delta_true):.6f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CPU functions ──\n",
    "def compute_Sw_cpu(T, pr, theta0=THETA0_OPT, theta1=THETA1_OPT,\n",
    "                   k_max=3, kernel='cosine'):\n",
    "    lp = np.log(pr).astype(np.float64)\n",
    "    lT = np.log(T)\n",
    "    L = theta0*lT + theta1; valid = L > 0\n",
    "    if not np.any(valid): return np.zeros(len(T))\n",
    "    S = np.zeros(len(T)); Tv = T[valid]; Lv = L[valid]\n",
    "    for m in range(1, k_max+1):\n",
    "        pmh = pr.astype(np.float64)**(m/2.0)\n",
    "        x = m*lp[None,:] / Lv[:,None]\n",
    "        if kernel=='cosine':     w = np.where(x<1, np.cos(np.pi*x/2)**2, 0.)\n",
    "        elif kernel=='selberg':  w = np.where(x<1, 1-x**2, 0.)\n",
    "        elif kernel=='sharp':    w = np.where(x<1, 1., 0.)\n",
    "        elif kernel=='linear':   w = np.where(x<1, 1-x, 0.)\n",
    "        elif kernel=='quadratic':w = np.where(x<1, (1-x)**2, 0.)\n",
    "        elif kernel=='gaussian': w = np.exp(-x**2/0.32)\n",
    "        elif kernel=='cubic':    w = np.where(x<1, (1-x)**3, 0.)\n",
    "        sv = np.sin(Tv[:,None]*m*lp[None,:])\n",
    "        S[valid] += np.sum(w*sv/(m*pmh[None,:]), axis=1)\n",
    "    return -S/np.pi\n",
    "\n",
    "def compute_predictions(gs, Sw):\n",
    "    return -np.pi * Sw / rs_theta_deriv(gs)\n",
    "\n",
    "def compute_R2(yt, yp):\n",
    "    ss_r = np.sum((yt-yp)**2); ss_t = np.sum((yt-np.mean(yt))**2)\n",
    "    return float(1 - ss_r/ss_t) if ss_t > 0 else 0.\n",
    "\n",
    "def compute_alpha_R2(dt, dp):\n",
    "    d = np.sum(dp**2)\n",
    "    if d == 0: return 0., -1.\n",
    "    return float(np.sum(dt*dp)/d), compute_R2(dt, dp)\n",
    "\n",
    "def find_theta_star(gs, dt, pr, rng=(0.8,1.2), n_iter=40):\n",
    "    lo, hi = rng\n",
    "    for _ in range(n_iter):\n",
    "        mid = (lo+hi)/2\n",
    "        Sw = compute_Sw_cpu(gs, pr, theta0=mid, theta1=0)\n",
    "        dp = compute_predictions(gs, Sw)\n",
    "        d = np.sum(dp**2)\n",
    "        if d == 0: lo = mid; continue\n",
    "        if np.sum(dt*dp)/d > 1.: lo = mid\n",
    "        else: hi = mid\n",
    "    return (lo+hi)/2\n",
    "\n",
    "# ── Precompute optimal Sw ──\n",
    "t0 = time.time()\n",
    "Sw_opt = compute_Sw_cpu(gammas_smooth, primes)\n",
    "delta_pred = compute_predictions(gammas_smooth, Sw_opt)\n",
    "a_glob, R2_glob = compute_alpha_R2(delta_true, delta_pred)\n",
    "print(f'Global: alpha={a_glob:.6f}, R2={R2_glob:.6f} '\n",
    "      f'({time.time()-t0:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── GPU precomputation ──\n",
    "STEP = 10  # subsample factor for heavy tests\n",
    "gs_sub = gammas_smooth[::STEP]\n",
    "dt_sub = delta_true[::STEP]\n",
    "n_sub = len(gs_sub)\n",
    "\n",
    "log_primes_g = cp.asarray(np.log(primes), dtype=cp.float32)\n",
    "n_primes = len(primes)\n",
    "pm_halves_g = [None]  # index 0 unused\n",
    "for m in range(1, 4):\n",
    "    pm_halves_g.append(\n",
    "        cp.asarray(primes.astype(np.float64)**(m/2.), dtype=cp.float32))\n",
    "\n",
    "# Precompute sin(T*m*log_p) for subsampled zeros (shared by all configs)\n",
    "gs_sub_g = cp.asarray(gs_sub, dtype=cp.float32)\n",
    "sin_pre = [None]  # index 0 unused\n",
    "for m in range(1, 4):\n",
    "    sin_pre.append(\n",
    "        cp.sin(gs_sub_g[:, None] * float(m) * log_primes_g[None, :]))\n",
    "    # shape: (Z_sub, P)  ~4.8 MB each\n",
    "\n",
    "print(f'GPU precomp: {n_sub} zeros, {n_primes} primes')\n",
    "\n",
    "\n",
    "def _apply_kernel_gpu(x, kid):\n",
    "    if kid == 0: return cp.where(x<1, cp.cos(cp.float32(np.pi)*x/2)**2, cp.float32(0))\n",
    "    if kid == 1: return cp.where(x<1, 1-x**2, cp.float32(0))\n",
    "    if kid == 2: return cp.where(x<1, cp.float32(1), cp.float32(0))\n",
    "    if kid == 3: return cp.where(x<1, 1-x, cp.float32(0))\n",
    "    if kid == 4: return cp.where(x<1, (1-x)**2, cp.float32(0))\n",
    "    if kid == 5: return cp.exp(-x**2 / cp.float32(0.32))\n",
    "    return cp.where(x<1, (1-x)**3, cp.float32(0))  # cubic\n",
    "\n",
    "\n",
    "def gpu_batch_mc(theta0_arr, theta1_arr, kernel_ids,\n",
    "                 dt_sub_g, batch_size=2000):\n",
    "    \"\"\"\n",
    "    Batch MC: compute alpha, R2 for many configs on GPU.\n",
    "    Groups by kernel for efficiency.\n",
    "    \"\"\"\n",
    "    n = len(theta0_arr)\n",
    "    alphas = np.full(n, np.nan, dtype=np.float32)\n",
    "    R2s = np.full(n, -1., dtype=np.float32)\n",
    "    log_T = cp.log(gs_sub_g)  # (Z,)\n",
    "    td = cp.float32(0.5) * cp.log(gs_sub_g / cp.float32(2*np.pi))  # theta_deriv\n",
    "    ss_tot = float(cp.sum((dt_sub_g - cp.mean(dt_sub_g))**2))\n",
    "\n",
    "    for kid in range(7):\n",
    "        mask = kernel_ids == kid\n",
    "        idx = np.where(mask)[0]\n",
    "        if len(idx) == 0: continue\n",
    "        for s in range(0, len(idx), batch_size):\n",
    "            e = min(s + batch_size, len(idx))\n",
    "            bi = idx[s:e]; bs = e - s\n",
    "            t0g = cp.asarray(theta0_arr[bi], dtype=cp.float32)\n",
    "            t1g = cp.asarray(theta1_arr[bi], dtype=cp.float32)\n",
    "\n",
    "            L = t0g[:,None]*log_T[None,:] + t1g[:,None]  # (bs, Z)\n",
    "            valid = (L > 0).astype(cp.float32)\n",
    "            S = cp.zeros((bs, n_sub), dtype=cp.float32)\n",
    "\n",
    "            for m in range(1, 4):\n",
    "                inv_L = cp.float32(1.) / cp.maximum(L, cp.float32(1e-10))\n",
    "                x = cp.float32(m) * log_primes_g[None,None,:] * inv_L[:,:,None]\n",
    "                w = _apply_kernel_gpu(x, kid)\n",
    "                S += cp.sum(w * sin_pre[m][None,:,:] /\n",
    "                            (cp.float32(m) * pm_halves_g[m][None,None,:]),\n",
    "                            axis=2) * valid\n",
    "                del x, w\n",
    "\n",
    "            Sw = -S / cp.float32(np.pi)\n",
    "            dp = -cp.float32(np.pi) * Sw / td[None,:]\n",
    "            denom = cp.sum(dp**2, axis=1)\n",
    "            good = denom > 0\n",
    "            al = cp.where(good, cp.sum(dt_sub_g[None,:]*dp, axis=1)/denom, cp.float32(0))\n",
    "            ss_res = cp.sum((dt_sub_g[None,:] - dp)**2, axis=1)\n",
    "            r2 = 1 - ss_res / cp.float32(ss_tot)\n",
    "\n",
    "            alphas[bi] = al.get()\n",
    "            R2s[bi] = r2.get()\n",
    "            del S, Sw, dp, L, valid, denom, al, ss_res, r2\n",
    "            cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "    return alphas, R2s\n",
    "\n",
    "\n",
    "def gpu_batch_bisection(gs_batch_g, dt_batch_g, n_iter=40):\n",
    "    \"\"\"\n",
    "    Batched bisection to find theta* for many replicates on GPU.\n",
    "    gs_batch_g: (B, Z) smoothed zeros for each replicate\n",
    "    dt_batch_g: (B, Z) delta_true for each replicate\n",
    "    Returns: (B,) theta* values\n",
    "    \"\"\"\n",
    "    B = gs_batch_g.shape[0]\n",
    "    lo = cp.full(B, 0.8, dtype=cp.float32)\n",
    "    hi = cp.full(B, 1.2, dtype=cp.float32)\n",
    "    log_T = cp.log(gs_batch_g)  # (B, Z)\n",
    "    td = cp.float32(0.5) * cp.log(gs_batch_g / cp.float32(2*np.pi))  # (B, Z)\n",
    "\n",
    "    for _ in range(n_iter):\n",
    "        mid = (lo + hi) / 2  # (B,)\n",
    "        L = mid[:,None] * log_T  # (B, Z), theta1=0\n",
    "        valid = (L > 0).astype(cp.float32)\n",
    "        S = cp.zeros_like(gs_batch_g)  # (B, Z)\n",
    "\n",
    "        for m in range(1, 4):\n",
    "            inv_L = cp.float32(1.) / cp.maximum(L, cp.float32(1e-10))\n",
    "            x = cp.float32(m) * log_primes_g[None,None,:] * inv_L[:,:,None]\n",
    "            w = cp.where(x<1, cp.cos(cp.float32(np.pi)*x/2)**2, cp.float32(0))\n",
    "            sv = cp.sin(gs_batch_g[:,:,None] * cp.float32(m) * log_primes_g[None,None,:])\n",
    "            S += cp.sum(w * sv / (cp.float32(m) * pm_halves_g[m][None,None,:]),\n",
    "                        axis=2) * valid\n",
    "            del x, w, sv\n",
    "\n",
    "        Sw = -S / cp.float32(np.pi)\n",
    "        dp = -cp.float32(np.pi) * Sw / td\n",
    "        denom = cp.sum(dp**2, axis=1)\n",
    "        alpha = cp.sum(dt_batch_g * dp, axis=1) / cp.maximum(denom, cp.float32(1e-30))\n",
    "        lo = cp.where(alpha > 1, mid, lo)\n",
    "        hi = cp.where(alpha <= 1, mid, hi)\n",
    "        del S, Sw, dp, L, valid, denom, alpha\n",
    "\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    return ((lo + hi) / 2).get().astype(np.float64)\n",
    "\n",
    "print('GPU functions defined.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('TEST 1: HONEST TRAIN/TEST SPLIT')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "\n",
    "mid = len(gammas) // 2\n",
    "gs_tr, gs_te = gammas_smooth[:mid], gammas_smooth[mid:]\n",
    "dt_tr, dt_te = delta_true[:mid], delta_true[mid:]\n",
    "\n",
    "theta_tr = find_theta_star(gs_tr, dt_tr, primes)\n",
    "Sw_tr = compute_Sw_cpu(gs_tr, primes, theta0=theta_tr, theta1=0)\n",
    "dp_tr = compute_predictions(gs_tr, Sw_tr)\n",
    "a_tr, R2_tr = compute_alpha_R2(dt_tr, dp_tr)\n",
    "\n",
    "Sw_te = compute_Sw_cpu(gs_te, primes, theta0=theta_tr, theta1=0)\n",
    "dp_te = compute_predictions(gs_te, Sw_te)\n",
    "a_te, R2_te = compute_alpha_R2(dt_te, dp_te)\n",
    "\n",
    "Sw_te2 = compute_Sw_cpu(gs_te, primes)\n",
    "dp_te2 = compute_predictions(gs_te, Sw_te2)\n",
    "a_te2, R2_te2 = compute_alpha_R2(dt_te, dp_te2)\n",
    "\n",
    "theta_te = find_theta_star(gs_te, dt_te, primes)\n",
    "\n",
    "gap = R2_tr - R2_te\n",
    "t1_pass = abs(gap) < 0.05 and R2_te > 0.85\n",
    "\n",
    "result_t1 = {\n",
    "    'n_train': mid, 'n_test': len(gammas)-mid,\n",
    "    'theta_star_train': float(theta_tr),\n",
    "    'theta_star_test': float(theta_te),\n",
    "    'theta_star_paper': THETA_CONST,\n",
    "    'theta_consistency': float(abs(theta_tr - theta_te)),\n",
    "    'train': {'alpha': a_tr, 'R2': R2_tr},\n",
    "    'test_constant_theta': {'alpha': a_te, 'R2': R2_te},\n",
    "    'test_adaptive_paper': {'alpha': a_te2, 'R2': R2_te2},\n",
    "    'generalization_gap': float(gap),\n",
    "    'passed': bool(t1_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "print(f'  theta_train={theta_tr:.4f}, theta_test={theta_te:.4f}')\n",
    "print(f'  Train:  a={a_tr:.4f}, R2={R2_tr:.4f}')\n",
    "print(f'  Test:   a={a_te:.4f}, R2={R2_te:.4f}')\n",
    "print(f'  Gap: {gap:+.4f}')\n",
    "print(f'  PASSED: {t1_pass}  ({result_t1[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('TEST 2: PERMUTATION (50K, GPU)')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "\n",
    "dt_g = cp.asarray(delta_true, dtype=cp.float32)\n",
    "dp_g = cp.asarray(delta_pred, dtype=cp.float32)\n",
    "R2_real = compute_R2(delta_true, delta_pred)\n",
    "ss_tot_g = cp.sum((dt_g - cp.mean(dt_g))**2)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "R2_null = np.zeros(N_PERM, dtype=np.float32)\n",
    "PBATCH = 5000\n",
    "\n",
    "for s in range(0, N_PERM, PBATCH):\n",
    "    e = min(s+PBATCH, N_PERM); bs = e - s\n",
    "    idx = np.array([rng.permutation(len(delta_true)) for _ in range(bs)])\n",
    "    idx_g = cp.asarray(idx)\n",
    "    dt_perm = dt_g[idx_g]  # (bs, N)\n",
    "    ss_res = cp.sum((dt_perm - dp_g[None,:])**2, axis=1)\n",
    "    R2_null[s:e] = (1 - ss_res / ss_tot_g).get()\n",
    "    del idx_g, dt_perm, ss_res\n",
    "    if (e % 25000) == 0: print(f'    {e}/{N_PERM}...')\n",
    "\n",
    "cp.get_default_memory_pool().free_all_blocks()\n",
    "\n",
    "p_emp = float(np.mean(R2_null >= R2_real))\n",
    "null_m = float(np.mean(R2_null)); null_s = float(np.std(R2_null))\n",
    "z = (R2_real - null_m) / null_s if null_s > 0 else float('inf')\n",
    "p_gauss = float(norm.sf(z)) if np.isfinite(z) else 0.\n",
    "p_up = 3./N_PERM if p_emp == 0 else p_emp\n",
    "cles = float(np.mean(R2_null < R2_real))\n",
    "n_trials = 7 * 100\n",
    "p_sidak = float(1 - (1 - p_up)**n_trials)\n",
    "p_bonf = float(min(1., n_trials * p_up))\n",
    "\n",
    "t2_pass = p_up < 0.001 and z > 10\n",
    "result_t2 = {\n",
    "    'R2_original': float(R2_real),\n",
    "    'R2_null_mean': null_m, 'R2_null_std': null_s,\n",
    "    'R2_null_max': float(np.max(R2_null)),\n",
    "    'z_score': float(z),\n",
    "    'p_empirical': p_emp, 'p_upper_bound': float(p_up),\n",
    "    'p_gaussian_tail': p_gauss,\n",
    "    'n_permutations': N_PERM,\n",
    "    'effect_size': {\n",
    "        'cohens_d': float(z), 'cles': cles,\n",
    "        'interpretation': 'enormous' if z>2 else 'large' if z>0.8 else 'medium',\n",
    "    },\n",
    "    'look_elsewhere': {\n",
    "        'n_trials': n_trials,\n",
    "        'p_sidak': p_sidak, 'p_bonferroni': p_bonf,\n",
    "        'still_significant': bool(p_bonf < 0.05),\n",
    "    },\n",
    "    'passed': bool(t2_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "print(f'  R2={R2_real:.6f} vs null {null_m:.6f}+/-{null_s:.6f}')\n",
    "print(f'  Z={z:.1f}, p<={p_up:.2e}, Cohen d={z:.1f}')\n",
    "print(f'  PASSED: {t2_pass}  ({result_t2[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('TEST 3: BASELINE COMPARISON')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "n = len(delta_true)\n",
    "idx = np.arange(n, dtype=np.float64)\n",
    "\n",
    "R2_f = compute_R2(delta_true, delta_pred)\n",
    "\n",
    "# Linear\n",
    "A = np.column_stack([np.ones(n), idx])\n",
    "c = np.linalg.lstsq(A, delta_true, rcond=None)[0]\n",
    "R2_lin = compute_R2(delta_true, A@c)\n",
    "\n",
    "# Poly 5, 10\n",
    "ix = idx/n\n",
    "for deg, name in [(5,'poly5'), (10,'poly10')]:\n",
    "    Ap = np.column_stack([ix**k for k in range(deg+1)])\n",
    "    cp_ = np.linalg.lstsq(Ap, delta_true, rcond=None)[0]\n",
    "    exec(f'R2_{name} = compute_R2(delta_true, Ap@cp_)')\n",
    "\n",
    "# Random frequency\n",
    "rng3 = np.random.default_rng(777)\n",
    "R2_rand = np.zeros(N_BASELINE_RANDOM)\n",
    "step3 = max(1, n//2000)\n",
    "Ts = gammas_smooth[::step3]; dts = delta_true[::step3]\n",
    "for trial in range(N_BASELINE_RANDOM):\n",
    "    freqs = rng3.uniform(0.5, 10., 50)\n",
    "    amps = 1./np.sqrt(np.arange(1,51))\n",
    "    Sr = np.sum(amps[:,None]*np.sin(freqs[:,None]*Ts[None,:]), axis=0)\n",
    "    if np.std(Sr)>0: Sr = Sr/np.std(Sr)*np.std(dts)\n",
    "    R2_rand[trial] = max(0, compute_R2(dts, Sr))\n",
    "\n",
    "t3_pass = R2_f > R2_poly10 and R2_f > np.max(R2_rand)\n",
    "result_t3 = {\n",
    "    'R2_formula': float(R2_f), 'R2_null': 0.,\n",
    "    'R2_linear': float(R2_lin),\n",
    "    'R2_polynomial_5': float(R2_poly5),\n",
    "    'R2_polynomial_10': float(R2_poly10),\n",
    "    'R2_random_frequency': {\n",
    "        'n_trials': N_BASELINE_RANDOM,\n",
    "        'mean': float(np.mean(R2_rand)),\n",
    "        'max': float(np.max(R2_rand)),\n",
    "        'p99': float(np.percentile(R2_rand, 99)),\n",
    "    },\n",
    "    'formula_beats_all': bool(t3_pass),\n",
    "    'passed': bool(t3_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "print(f'  Formula:      {R2_f:.6f}')\n",
    "print(f'  Linear:       {R2_lin:.6f}')\n",
    "print(f'  Poly-5:       {R2_poly5:.6f}')\n",
    "print(f'  Poly-10:      {R2_poly10:.6f}')\n",
    "print(f'  Random (max): {np.max(R2_rand):.6f}')\n",
    "print(f'  PASSED: {t3_pass}  ({result_t3[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print(f'TEST 4: {N_KFOLD}-FOLD CROSS-VALIDATION')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "n = len(gammas_smooth); fold = n // N_KFOLD\n",
    "R2_folds = []; alpha_folds = []; theta_folds = []\n",
    "\n",
    "for k in range(N_KFOLD):\n",
    "    ts = k*fold; te = (k+1)*fold if k < N_KFOLD-1 else n\n",
    "    mask = np.ones(n, dtype=bool); mask[ts:te] = False\n",
    "    gs_tr_ = gammas_smooth[mask]; dt_tr_ = delta_true[mask]\n",
    "    gs_te_ = gammas_smooth[~mask]; dt_te_ = delta_true[~mask]\n",
    "    step_ = max(1, len(gs_tr_)//1000)\n",
    "    tk = find_theta_star(gs_tr_[::step_], dt_tr_[::step_], primes)\n",
    "    Sw_ = compute_Sw_cpu(gs_te_, primes, theta0=tk, theta1=0)\n",
    "    dp_ = compute_predictions(gs_te_, Sw_)\n",
    "    ak, rk = compute_alpha_R2(dt_te_, dp_)\n",
    "    R2_folds.append(rk); alpha_folds.append(ak)\n",
    "    theta_folds.append(float(tk))\n",
    "    print(f'  Fold {k+1}: theta={tk:.4f}, a={ak:.4f}, R2={rk:.4f}')\n",
    "\n",
    "Ra = np.array(R2_folds); Aa = np.array(alpha_folds)\n",
    "t4_pass = np.mean(Ra)>0.85 and np.std(Ra)<0.05 and np.mean(np.abs(Aa-1))<0.05\n",
    "result_t4 = {\n",
    "    'n_folds': N_KFOLD,\n",
    "    'per_fold': {'R2': [float(x) for x in R2_folds],\n",
    "                 'alpha': [float(x) for x in alpha_folds],\n",
    "                 'theta_star': theta_folds},\n",
    "    'R2_mean': float(np.mean(Ra)), 'R2_std': float(np.std(Ra)),\n",
    "    'alpha_mean': float(np.mean(Aa)), 'alpha_std': float(np.std(Aa)),\n",
    "    'theta_star_mean': float(np.mean(theta_folds)),\n",
    "    'theta_star_std': float(np.std(theta_folds)),\n",
    "    'passed': bool(t4_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "print(f'  R2: {np.mean(Ra):.4f} +/- {np.std(Ra):.4f}')\n",
    "print(f'  PASSED: {t4_pass}  ({result_t4[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('TEST 5: MONTE CARLO UNIQUENESS (100K, GPU)')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "\n",
    "rng5 = np.random.default_rng(123)\n",
    "theta0_s = rng5.uniform(0.3, 2.5, N_MC).astype(np.float32)\n",
    "theta1_s = rng5.uniform(-10., 2., N_MC).astype(np.float32)\n",
    "kernel_ids = rng5.integers(0, 7, N_MC)\n",
    "\n",
    "dt_sub_g = cp.asarray(dt_sub, dtype=cp.float32)\n",
    "\n",
    "alphas_mc, R2s_mc = gpu_batch_mc(\n",
    "    theta0_s, theta1_s, kernel_ids, dt_sub_g, batch_size=2000)\n",
    "\n",
    "elapsed5 = time.time() - t0\n",
    "print(f'  GPU MC completed in {elapsed5:.1f}s')\n",
    "\n",
    "valid5 = ~np.isnan(alphas_mc)\n",
    "close_a = valid5 & (np.abs(alphas_mc - 1.) < 0.01)\n",
    "hi_r2 = valid5 & (R2s_mc > 0.90)\n",
    "vhi_r2 = valid5 & (R2s_mc > 0.93)\n",
    "both5 = close_a & vhi_r2\n",
    "\n",
    "# Optimal on same subsample\n",
    "Sw_sub = compute_Sw_cpu(gs_sub, primes)\n",
    "dp_sub = compute_predictions(gs_sub, Sw_sub)\n",
    "_, R2_opt_sub = compute_alpha_R2(dt_sub, dp_sub)\n",
    "pctile = float(np.mean(R2s_mc[valid5] < R2_opt_sub) * 100)\n",
    "\n",
    "t5_pass = np.mean(both5) < 0.001 and pctile > 99.\n",
    "result_t5 = {\n",
    "    'n_configurations': N_MC,\n",
    "    'theta0_range': [0.3, 2.5], 'theta1_range': [-10., 2.],\n",
    "    'n_kernels': 7,\n",
    "    'frac_close_alpha': float(np.mean(close_a)),\n",
    "    'frac_R2_above_90': float(np.mean(hi_r2)),\n",
    "    'frac_R2_above_93': float(np.mean(vhi_r2)),\n",
    "    'frac_both_criteria': float(np.mean(both5)),\n",
    "    'best_random_R2': float(np.nanmax(R2s_mc)),\n",
    "    'R2_optimal_subsample': float(R2_opt_sub),\n",
    "    'percentile_rank': pctile,\n",
    "    'R2_distribution': {\n",
    "        'mean': float(np.nanmean(R2s_mc[valid5])),\n",
    "        'std': float(np.nanstd(R2s_mc[valid5])),\n",
    "        'p50': float(np.nanpercentile(R2s_mc[valid5], 50)),\n",
    "        'p90': float(np.nanpercentile(R2s_mc[valid5], 90)),\n",
    "        'p99': float(np.nanpercentile(R2s_mc[valid5], 99)),\n",
    "    },\n",
    "    'passed': bool(t5_pass),\n",
    "    'runtime_s': elapsed5,\n",
    "}\n",
    "print(f'  |a-1|<0.01: {np.mean(close_a):.4%}')\n",
    "print(f'  R2>0.93:    {np.mean(vhi_r2):.4%}')\n",
    "print(f'  Both:       {np.mean(both5):.4%}')\n",
    "print(f'  Best random R2: {np.nanmax(R2s_mc):.6f}')\n",
    "print(f'  Optimal R2:     {R2_opt_sub:.6f} (rank {pctile:.2f}%ile)')\n",
    "print(f'  PASSED: {t5_pass}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('TEST 6: BAYESIAN BIC')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "n = len(delta_true)\n",
    "idx_n = np.arange(n, dtype=np.float64) / n\n",
    "models = {}\n",
    "\n",
    "# Formula\n",
    "RSS_f = np.sum((delta_true - delta_pred)**2)\n",
    "BIC_f = n*np.log(RSS_f/n) + 2*np.log(n)\n",
    "models['formula'] = {'k': 2, 'RSS': float(RSS_f), 'BIC': float(BIC_f)}\n",
    "\n",
    "# Null\n",
    "RSS_0 = np.sum((delta_true - np.mean(delta_true))**2)\n",
    "BIC_0 = n*np.log(RSS_0/n) + 1*np.log(n)\n",
    "models['null'] = {'k': 1, 'RSS': float(RSS_0), 'BIC': float(BIC_0)}\n",
    "\n",
    "# Linear\n",
    "A_ = np.column_stack([np.ones(n), np.arange(n)])\n",
    "c_ = np.linalg.lstsq(A_, delta_true, rcond=None)[0]\n",
    "RSS_l = np.sum((delta_true - A_@c_)**2)\n",
    "BIC_l = n*np.log(RSS_l/n) + 2*np.log(n)\n",
    "models['linear'] = {'k': 2, 'RSS': float(RSS_l), 'BIC': float(BIC_l)}\n",
    "\n",
    "# Poly 5, 10\n",
    "for deg in [5, 10]:\n",
    "    Ap = np.column_stack([idx_n**k for k in range(deg+1)])\n",
    "    cp_ = np.linalg.lstsq(Ap, delta_true, rcond=None)[0]\n",
    "    RSS_p = np.sum((delta_true - Ap@cp_)**2)\n",
    "    BIC_p = n*np.log(RSS_p/n) + (deg+1)*np.log(n)\n",
    "    models[f'poly_{deg}'] = {'k': deg+1, 'RSS': float(RSS_p), 'BIC': float(BIC_p)}\n",
    "\n",
    "bayes_factors = {}\n",
    "for nm, m in models.items():\n",
    "    if nm != 'formula':\n",
    "        db = m['BIC'] - BIC_f\n",
    "        lbf = db / (2*np.log(10))\n",
    "        bayes_factors[f'formula_vs_{nm}'] = {\n",
    "            'delta_BIC': float(db), 'log10_BF': float(lbf),\n",
    "            'interpretation': 'decisive' if lbf>2 else 'very_strong' if lbf>1.5\n",
    "               else 'strong' if lbf>1 else 'substantial' if lbf>0.5 else 'inconclusive'\n",
    "        }\n",
    "\n",
    "best_other = min(m['BIC'] for nm,m in models.items() if nm!='formula')\n",
    "t6_pass = BIC_f < best_other\n",
    "\n",
    "result_t6 = {\n",
    "    'models': models, 'bayes_factors': bayes_factors,\n",
    "    'formula_has_lowest_BIC': bool(t6_pass),\n",
    "    'passed': bool(t6_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "for nm, m in models.items():\n",
    "    tag = ' <- BEST' if nm=='formula' and t6_pass else ''\n",
    "    print(f'  {nm:>12s} (k={m[\"k\"]:>2d}): BIC={m[\"BIC\"]:>12.1f}{tag}')\n",
    "for nm, bf in bayes_factors.items():\n",
    "    print(f'    {nm}: log10(BF)={bf[\"log10_BF\"]:.1f} ({bf[\"interpretation\"]})')\n",
    "print(f'  PASSED: {t6_pass}  ({result_t6[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print(f'TEST 7: BOOTSTRAP BCa ({N_BOOTSTRAP}, GPU)')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "\n",
    "# Subsample for bootstrap (every 5th from sub for speed)\n",
    "bs_step = 5\n",
    "gs_bs = gs_sub[::bs_step]; dt_bs = dt_sub[::bs_step]\n",
    "n_bs = len(gs_bs)\n",
    "\n",
    "# Original theta*\n",
    "theta_orig = find_theta_star(gs_bs, dt_bs, primes)\n",
    "Sw_o = compute_Sw_cpu(gs_bs, primes, theta0=theta_orig, theta1=0)\n",
    "dp_o = compute_predictions(gs_bs, Sw_o)\n",
    "a_orig, R2_orig = compute_alpha_R2(dt_bs, dp_o)\n",
    "\n",
    "# Generate all bootstrap indices\n",
    "rng7 = np.random.default_rng(999)\n",
    "boot_idx = np.array([np.sort(rng7.choice(n_bs, n_bs, replace=True))\n",
    "                      for _ in range(N_BOOTSTRAP)])\n",
    "\n",
    "# Batched bisection on GPU\n",
    "BBATCH = 500\n",
    "theta_boots = np.zeros(N_BOOTSTRAP)\n",
    "alpha_boots = np.zeros(N_BOOTSTRAP)\n",
    "R2_boots = np.zeros(N_BOOTSTRAP)\n",
    "\n",
    "gs_bs_np = gs_bs.astype(np.float32)\n",
    "dt_bs_np = dt_bs.astype(np.float32)\n",
    "\n",
    "for s in range(0, N_BOOTSTRAP, BBATCH):\n",
    "    e = min(s + BBATCH, N_BOOTSTRAP)\n",
    "    bi = boot_idx[s:e]  # (bs, n_bs)\n",
    "    gs_b_g = cp.asarray(gs_bs_np[bi])  # (bs, n_bs)\n",
    "    dt_b_g = cp.asarray(dt_bs_np[bi])  # (bs, n_bs)\n",
    "\n",
    "    # Batched bisection\n",
    "    theta_batch = gpu_batch_bisection(gs_b_g, dt_b_g, n_iter=40)\n",
    "    theta_boots[s:e] = theta_batch\n",
    "\n",
    "    # Evaluate at found theta\n",
    "    for i in range(e - s):\n",
    "        Sw_b = compute_Sw_cpu(gs_bs[bi[i]], primes,\n",
    "                              theta0=theta_batch[i], theta1=0)\n",
    "        dp_b = compute_predictions(gs_bs[bi[i]], Sw_b)\n",
    "        alpha_boots[s+i], R2_boots[s+i] = compute_alpha_R2(\n",
    "            dt_bs[bi[i]], dp_b)\n",
    "\n",
    "    del gs_b_g, dt_b_g\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    print(f'  {e}/{N_BOOTSTRAP} resamples ({time.time()-t0:.0f}s)')\n",
    "\n",
    "# BCa correction\n",
    "z0 = norm.ppf(np.mean(theta_boots < theta_orig))\n",
    "if not np.isfinite(z0): z0 = 0.\n",
    "\n",
    "# Jackknife for acceleration\n",
    "n_jack = min(50, n_bs)\n",
    "jack_v = np.zeros(n_jack)\n",
    "jstep = max(1, n_bs // n_jack)\n",
    "for j in range(n_jack):\n",
    "    m_ = np.ones(n_bs, dtype=bool)\n",
    "    m_[j*jstep:min((j+1)*jstep, n_bs)] = False\n",
    "    jack_v[j] = find_theta_star(gs_bs[m_], dt_bs[m_], primes)\n",
    "jm = np.mean(jack_v)\n",
    "num_ = np.sum((jm - jack_v)**3)\n",
    "den_ = 6 * np.sum((jm - jack_v)**2)**1.5\n",
    "a_acc = num_/den_ if den_ > 0 else 0.\n",
    "\n",
    "z_lo = norm.ppf(0.025); z_hi = norm.ppf(0.975)\n",
    "a1 = norm.cdf(z0 + (z0+z_lo)/(1-a_acc*(z0+z_lo)))\n",
    "a2 = norm.cdf(z0 + (z0+z_hi)/(1-a_acc*(z0+z_hi)))\n",
    "ci_lo = float(np.percentile(theta_boots, 100*max(0,a1)))\n",
    "ci_hi = float(np.percentile(theta_boots, 100*min(1,a2)))\n",
    "\n",
    "t7_pass = ci_lo < THETA_CONST < ci_hi and np.std(theta_boots) < 0.01\n",
    "\n",
    "result_t7 = {\n",
    "    'n_bootstrap': N_BOOTSTRAP,\n",
    "    'theta_star': {\n",
    "        'original': float(theta_orig),\n",
    "        'mean': float(np.mean(theta_boots)),\n",
    "        'std': float(np.std(theta_boots)),\n",
    "        'ci95_bca': [ci_lo, ci_hi],\n",
    "        'bca_z0': float(z0), 'bca_acceleration': float(a_acc),\n",
    "        'contains_paper_value': bool(ci_lo < THETA_CONST < ci_hi),\n",
    "    },\n",
    "    'alpha': {'mean': float(np.mean(alpha_boots)),\n",
    "              'std': float(np.std(alpha_boots))},\n",
    "    'R2': {'mean': float(np.mean(R2_boots)),\n",
    "           'std': float(np.std(R2_boots))},\n",
    "    'passed': bool(t7_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "print(f'  theta*={np.mean(theta_boots):.4f}+/-{np.std(theta_boots):.4f}')\n",
    "print(f'  BCa CI: [{ci_lo:.4f}, {ci_hi:.4f}]')\n",
    "print(f'  Contains {THETA_CONST}: {ci_lo < THETA_CONST < ci_hi}')\n",
    "print(f'  PASSED: {t7_pass}  ({result_t7[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*70)\n",
    "print('TEST 8: WINDOW STABILITY (10 windows)')\n",
    "print('='*70)\n",
    "t0 = time.time()\n",
    "n = len(gammas); nw = 10; ws = n // nw\n",
    "wa = []; wr = []; wt = []\n",
    "\n",
    "for w in range(nw):\n",
    "    s = w*ws; e = (w+1)*ws if w < nw-1 else n\n",
    "    aw, rw = compute_alpha_R2(delta_true[s:e], delta_pred[s:e])\n",
    "    wa.append(aw); wr.append(rw)\n",
    "    wt.append(float(gammas[s + (e-s)//2]))\n",
    "    print(f'  Win {w+1}: T~{gammas[s]:.0f}-{gammas[e-1]:.0f}, '\n",
    "          f'a={aw:.4f}, R2={rw:.4f}')\n",
    "\n",
    "wa_ = np.array(wa); wr_ = np.array(wr)\n",
    "ix8 = np.arange(nw, dtype=np.float64)\n",
    "sl, _ = np.polyfit(ix8, wa_, 1)\n",
    "res8 = wa_ - (sl*ix8 + _)\n",
    "se = np.sqrt(np.sum(res8**2)/(nw-2) / np.sum((ix8-ix8.mean())**2))\n",
    "tst = sl/se if se > 0 else 0.\n",
    "p_tr = float(2*t_dist.sf(abs(tst), df=nw-2))\n",
    "\n",
    "t8_pass = (p_tr > 0.05) and np.std(wa_) < 0.03 and np.std(wr_) < 0.05\n",
    "\n",
    "result_t8 = {\n",
    "    'n_windows': nw,\n",
    "    'per_window': {'T_mid': wt, 'alpha': [float(x) for x in wa],\n",
    "                   'R2': [float(x) for x in wr]},\n",
    "    'alpha_summary': {\n",
    "        'mean': float(np.mean(wa_)), 'std': float(np.std(wa_)),\n",
    "        'range': float(np.ptp(wa_)), 'drift_slope': float(sl),\n",
    "        'drift_t_stat': float(tst), 'drift_p_value': p_tr,\n",
    "        'significant_drift': p_tr <= 0.05,\n",
    "    },\n",
    "    'R2_summary': {\n",
    "        'mean': float(np.mean(wr_)), 'std': float(np.std(wr_)),\n",
    "        'range': float(np.ptp(wr_)), 'min': float(np.min(wr_)),\n",
    "    },\n",
    "    'passed': bool(t8_pass),\n",
    "    'runtime_s': time.time()-t0,\n",
    "}\n",
    "print(f'  alpha: {np.mean(wa_):.4f}+/-{np.std(wa_):.4f}')\n",
    "print(f'  R2:    {np.mean(wr_):.4f}+/-{np.std(wr_):.4f}')\n",
    "print(f'  Drift p={p_tr:.3f}')\n",
    "print(f'  PASSED: {t8_pass}  ({result_t8[\"runtime_s\"]:.1f}s)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Assemble results ──\n",
    "results = {\n",
    "    'metadata': {\n",
    "        'n_zeros': N_ZEROS,\n",
    "        'theta0_optimal': THETA0_OPT,\n",
    "        'theta1_optimal': THETA1_OPT,\n",
    "        'theta_constant': THETA_CONST,\n",
    "        'alpha_global': float(a_glob),\n",
    "        'R2_global': float(R2_glob),\n",
    "        'n_primes': len(primes),\n",
    "        'date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'script': 'paper1_gpu_validation.ipynb',\n",
    "        'gpu': cp.cuda.runtime.getDeviceProperties(0)['name'].decode(),\n",
    "    },\n",
    "    'test_1_train_test_split': result_t1,\n",
    "    'test_2_permutation': result_t2,\n",
    "    'test_3_baselines': result_t3,\n",
    "    'test_4_kfold_cv': result_t4,\n",
    "    'test_5_monte_carlo': result_t5,\n",
    "    'test_6_bayesian_bic': result_t6,\n",
    "    'test_7_bootstrap_bca': result_t7,\n",
    "    'test_8_window_stability': result_t8,\n",
    "}\n",
    "\n",
    "test_keys = [k for k in results if k.startswith('test_')]\n",
    "n_pass = sum(1 for k in test_keys if results[k].get('passed'))\n",
    "n_tot = len(test_keys)\n",
    "verdict = 'VALIDATED' if n_pass == n_tot else (\n",
    "    'PARTIALLY_VALIDATED' if n_pass >= n_tot-1 else 'FAILED')\n",
    "\n",
    "results['summary'] = {\n",
    "    'tests_passed': n_pass, 'tests_total': n_tot,\n",
    "    'overall_verdict': verdict,\n",
    "    'per_test': {k: results[k]['passed'] for k in test_keys},\n",
    "}\n",
    "\n",
    "# ── Display ──\n",
    "print()\n",
    "print('=' * 60)\n",
    "print('          VALIDATION VERDICT')\n",
    "print('=' * 60)\n",
    "labels = {\n",
    "    'test_1_train_test_split': 'T1 Train/Test Split',\n",
    "    'test_2_permutation': 'T2 Permutation + LEE',\n",
    "    'test_3_baselines': 'T3 Baseline Comparison',\n",
    "    'test_4_kfold_cv': 'T4 K-Fold CV',\n",
    "    'test_5_monte_carlo': 'T5 Monte Carlo (100K)',\n",
    "    'test_6_bayesian_bic': 'T6 Bayesian BIC',\n",
    "    'test_7_bootstrap_bca': 'T7 Bootstrap BCa',\n",
    "    'test_8_window_stability': 'T8 Window Stability',\n",
    "}\n",
    "for k in test_keys:\n",
    "    st = 'PASS' if results[k]['passed'] else 'FAIL'\n",
    "    rt = results[k].get('runtime_s', 0)\n",
    "    print(f'  {labels.get(k,k):<30s} {st:<6s} ({rt:.1f}s)')\n",
    "print('-' * 60)\n",
    "print(f'  OVERALL: {n_pass}/{n_tot} -> {verdict}')\n",
    "print('=' * 60)\n",
    "\n",
    "# ── Save JSON ──\n",
    "out_path = 'paper1_robust_results.json'\n",
    "with open(out_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=lambda o:\n",
    "        int(o) if isinstance(o, (np.integer,)) else\n",
    "        float(o) if isinstance(o, (np.floating,)) else\n",
    "        bool(o) if isinstance(o, (np.bool_,)) else\n",
    "        o.tolist() if isinstance(o, np.ndarray) else o)\n",
    "print(f'\\nResults saved to {out_path}')\n",
    "\n",
    "# Download link for Colab\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download(out_path)\n",
    "except ImportError:\n",
    "    pass\n"
   ]
  }
 ]
}