{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Matrix-Free Eigenvalue Solvers for 7D Curved Laplacian\n",
    "\n",
    "This notebook demonstrates methods to estimate the first eigenvalue $\\lambda_1$ of the Laplace-Beltrami operator **without building the full matrix**.\n",
    "\n",
    "## The Problem\n",
    "\n",
    "For a 7D grid with $n$ points per dimension:\n",
    "- Total grid points: $N = n^7$\n",
    "- Full matrix size: $N^2 \\times 8$ bytes\n",
    "- Example: $n=10$ gives $N = 10^7$, matrix would need **800 TB**!\n",
    "\n",
    "## The Solution: Matrix-Free Methods\n",
    "\n",
    "Key insight: We only need to compute $L \\cdot v$ for arbitrary vectors $v$.\n",
    "\n",
    "This can be done using finite difference stencils **on-the-fly**.\n",
    "\n",
    "## GIFT Prediction\n",
    "\n",
    "For the $K_7$ manifold with Gâ‚‚ holonomy:\n",
    "$$\\lambda_1 = \\frac{\\dim(G_2)}{H^*} = \\frac{14}{b_2 + b_3 + 1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '/home/user/GIFT/research/yang-mills')\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.sparse.linalg import LinearOperator, eigsh\n\n# Import our matrix-free solvers\nfrom matrix_free_eigensolvers import (\n    create_laplacian_operator,\n    apply_laplacian_7d,\n    lanczos_smallest_eigenvalue,\n    compute_spectral_gap,\n    gift_g2_metric,\n    gift_g2_metric_variable,\n    stochastic_spectral_density,\n    hutchinson_trace_estimate,\n    richardson_extrapolation  # For improved accuracy\n)\n\nprint(\"Matrix-free eigensolvers loaded successfully!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Understanding the Curved Laplacian\n",
    "\n",
    "The Laplace-Beltrami operator on a manifold with metric $g_{ij}$ is:\n",
    "\n",
    "$$\\Delta_g f = \\frac{1}{\\sqrt{\\det g}} \\partial_i \\left( \\sqrt{\\det g} \\, g^{ij} \\partial_j f \\right)$$\n",
    "\n",
    "For diagonal metric $g_{ij} = \\text{diag}(g_1, \\ldots, g_7)$:\n",
    "\n",
    "$$\\Delta_g f = \\frac{1}{\\sqrt{\\det g}} \\sum_i \\partial_i \\left( \\frac{\\sqrt{\\det g}}{g_i} \\partial_i f \\right)$$\n",
    "\n",
    "### Finite Difference Approximation\n",
    "\n",
    "Using central differences on a grid with spacing $h$:\n",
    "\n",
    "$$\\partial_i f \\approx \\frac{f_{i+1} - f_{i-1}}{2h}$$\n",
    "\n",
    "$$\\partial_i^2 f \\approx \\frac{f_{i+1} - 2f_i + f_{i-1}}{h^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIFT topological constants\n",
    "DIM_G2 = 14\n",
    "B2 = 21      # Second Betti number\n",
    "B3 = 77      # Third Betti number  \n",
    "H_STAR = B2 + B3 + 1  # = 99\n",
    "\n",
    "# GIFT prediction for spectral gap\n",
    "LAMBDA1_GIFT = DIM_G2 / H_STAR\n",
    "\n",
    "print(f\"GIFT Topological Constants:\")\n",
    "print(f\"  dim(G2) = {DIM_G2}\")\n",
    "print(f\"  b2 = {B2}\")\n",
    "print(f\"  b3 = {B3}\")\n",
    "print(f\"  H* = b2 + b3 + 1 = {H_STAR}\")\n",
    "print()\n",
    "print(f\"GIFT Prediction: lambda_1 = {DIM_G2}/{H_STAR} = {LAMBDA1_GIFT:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Creating the Matrix-Free Operator\n",
    "\n",
    "The key is `scipy.sparse.linalg.LinearOperator`, which only requires a `matvec` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small test grid (for demonstration)\n",
    "# In practice, use larger grids on GPU\n",
    "grid_size = 5\n",
    "grid_shape = (grid_size,) * 7\n",
    "n_points = np.prod(grid_shape)\n",
    "h = 2 * np.pi / grid_size  # Grid spacing (domain [0, 2*pi]^7)\n",
    "\n",
    "print(f\"Grid configuration:\")\n",
    "print(f\"  Shape: {grid_shape}\")\n",
    "print(f\"  Total points: {n_points:,}\")\n",
    "print(f\"  Grid spacing: h = {h:.4f}\")\n",
    "print()\n",
    "\n",
    "# Memory comparison\n",
    "matrix_memory_gb = n_points**2 * 8 / 1e9\n",
    "vector_memory_mb = n_points * 8 / 1e6\n",
    "print(f\"Memory comparison:\")\n",
    "print(f\"  Full matrix would need: {matrix_memory_gb:.1f} GB\")\n",
    "print(f\"  One vector needs: {vector_memory_mb:.1f} MB\")\n",
    "print(f\"  Lanczos with k=6 needs: ~{6 * vector_memory_mb:.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the matrix-free Laplacian operator\n",
    "metric_func = lambda x: gift_g2_metric(x, H_star=99)\n",
    "\n",
    "L_op = create_laplacian_operator(\n",
    "    grid_shape=grid_shape,\n",
    "    metric_diag=metric_func,\n",
    "    h=h,\n",
    "    boundary='periodic'\n",
    ")\n",
    "\n",
    "print(f\"LinearOperator created:\")\n",
    "print(f\"  Shape: {L_op.shape}\")\n",
    "print(f\"  Dtype: {L_op.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Verify Operator Properties\n",
    "\n",
    "The Laplacian should be:\n",
    "1. **Symmetric**: $\\langle v, Lw \\rangle = \\langle Lv, w \\rangle$\n",
    "2. **Positive semi-definite**: $\\langle v, Lv \\rangle \\geq 0$\n",
    "3. **Constant in null space**: $L \\cdot \\mathbf{1} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test symmetry\n",
    "np.random.seed(42)\n",
    "v = np.random.randn(n_points)\n",
    "w = np.random.randn(n_points)\n",
    "\n",
    "Lv = L_op.matvec(v)\n",
    "Lw = L_op.matvec(w)\n",
    "\n",
    "inner1 = np.dot(v, Lw)\n",
    "inner2 = np.dot(Lv, w)\n",
    "sym_error = abs(inner1 - inner2) / max(abs(inner1), abs(inner2))\n",
    "\n",
    "print(\"Symmetry test:\")\n",
    "print(f\"  <v, Lw> = {inner1:.6f}\")\n",
    "print(f\"  <Lv, w> = {inner2:.6f}\")\n",
    "print(f\"  Relative error: {sym_error:.2e}\")\n",
    "print(f\"  Symmetric: {'YES' if sym_error < 1e-10 else 'NO'}\")\n",
    "print()\n",
    "\n",
    "# Test positive semi-definiteness\n",
    "vLv = np.dot(v, Lv)\n",
    "print(f\"Positive semi-definite test:\")\n",
    "print(f\"  <v, Lv> = {vLv:.6f}\")\n",
    "print(f\"  Non-negative: {'YES' if vLv >= -1e-10 else 'NO'}\")\n",
    "print()\n",
    "\n",
    "# Test null space (constants)\n",
    "const = np.ones(n_points)\n",
    "L_const = L_op.matvec(const)\n",
    "null_error = np.linalg.norm(L_const)\n",
    "\n",
    "print(f\"Null space test (L @ 1 = 0):\")\n",
    "print(f\"  |L @ 1| = {null_error:.2e}\")\n",
    "print(f\"  Constant in null space: {'YES' if null_error < 1e-8 else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Method 1: Matrix-Free Lanczos\n",
    "\n",
    "The Lanczos algorithm finds eigenvalues by projecting onto a Krylov subspace:\n",
    "\n",
    "$$K_m(L, v) = \\text{span}\\{v, Lv, L^2v, \\ldots, L^{m-1}v\\}$$\n",
    "\n",
    "This only requires matrix-vector products, never the full matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Compute eigenvalues using Lanczos\n",
    "print(\"Computing eigenvalues via Lanczos...\")\n",
    "\n",
    "try:\n",
    "    eigenvalues, eigenvectors = lanczos_smallest_eigenvalue(\n",
    "        L_op, k=6, tol=1e-8, maxiter=5000\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSmallest eigenvalues:\")\n",
    "    for i, ev in enumerate(eigenvalues):\n",
    "        print(f\"  lambda_{i} = {ev:.6f}\")\n",
    "    \n",
    "    # First non-zero eigenvalue\n",
    "    lambda_1 = eigenvalues[eigenvalues > 1e-6][0] if (eigenvalues > 1e-6).any() else eigenvalues[1]\n",
    "    \n",
    "    print(f\"\\nSpectral gap: lambda_1 = {lambda_1:.6f}\")\n",
    "    print(f\"GIFT prediction: {LAMBDA1_GIFT:.6f}\")\n",
    "    print(f\"Deviation: {abs(lambda_1 - LAMBDA1_GIFT)/LAMBDA1_GIFT * 100:.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Lanczos failed: {e}\")\n",
    "    eigenvalues = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Method 2: Stochastic Trace Estimation\n",
    "\n",
    "Hutchinson's estimator: $\\text{tr}(A) = \\mathbb{E}[z^T A z]$ where $z$ is a random vector.\n",
    "\n",
    "Combined with Lanczos, this gives the **spectral density** without computing all eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Computing spectral density via stochastic Lanczos...\")\n",
    "\n",
    "eigenvalue_bins, density = stochastic_spectral_density(\n",
    "    L_op, n_samples=30, n_moments=50\n",
    ")\n",
    "\n",
    "# Plot spectral density\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "ax.fill_between(eigenvalue_bins, density, alpha=0.3, color='blue')\n",
    "ax.plot(eigenvalue_bins, density, 'b-', linewidth=2, label='Estimated density')\n",
    "ax.axvline(LAMBDA1_GIFT, color='r', linestyle='--', linewidth=2, \n",
    "           label=f'GIFT: $\\\\lambda_1 = {LAMBDA1_GIFT:.4f}$')\n",
    "ax.axvline(0, color='gray', linestyle=':', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Eigenvalue $\\\\lambda$', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Spectral Density of Laplace-Beltrami Operator', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.set_xlim(-0.1, 1.0)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estimate lambda_1 from density\n",
    "threshold = 0.05 * density.max()\n",
    "significant = (density > threshold) & (eigenvalue_bins > 0.01)\n",
    "if significant.any():\n",
    "    lambda_1_est = eigenvalue_bins[significant][0]\n",
    "    print(f\"\\nEstimated lambda_1 from density: {lambda_1_est:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 6. Test Across Different H* Values\n",
    "\n",
    "GIFT predicts $\\lambda_1 = 14/H^*$ for manifolds with different topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different H* values\n",
    "test_H_stars = [36, 52, 72, 99, 120, 150]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(f\"{'H*':>6} | {'GIFT pred':>10} | {'Computed':>10} | {'Dev %':>8} | {'lambda*H*':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for H_star in test_H_stars:\n",
    "    # Create metric for this H*\n",
    "    metric_func = lambda x, H=H_star: gift_g2_metric(x, H_star=H)\n",
    "    \n",
    "    # Create operator\n",
    "    L_op = create_laplacian_operator(grid_shape, metric_func, h)\n",
    "    \n",
    "    # Compute eigenvalues\n",
    "    try:\n",
    "        evals, _ = lanczos_smallest_eigenvalue(L_op, k=3, tol=1e-6)\n",
    "        lambda_1 = evals[evals > 1e-6][0] if (evals > 1e-6).any() else evals[1]\n",
    "    except:\n",
    "        lambda_1 = np.nan\n",
    "    \n",
    "    gift_pred = 14.0 / H_star\n",
    "    deviation = abs(lambda_1 - gift_pred) / gift_pred * 100 if not np.isnan(lambda_1) else np.nan\n",
    "    \n",
    "    results.append({\n",
    "        'H_star': H_star,\n",
    "        'gift_pred': gift_pred,\n",
    "        'lambda_1': lambda_1,\n",
    "        'deviation': deviation,\n",
    "        'lambda_x_H': lambda_1 * H_star\n",
    "    })\n",
    "    \n",
    "    print(f\"{H_star:>6} | {gift_pred:>10.4f} | {lambda_1:>10.4f} | {deviation:>7.1f}% | {lambda_1*H_star:>10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# 1. lambda_1 vs H*\n",
    "ax = axes[0]\n",
    "ax.scatter(df['H_star'], df['lambda_1'], s=100, c='blue', zorder=5, label='Computed')\n",
    "H_smooth = np.linspace(30, 160, 100)\n",
    "ax.plot(H_smooth, 14/H_smooth, 'r--', linewidth=2, label='GIFT: $14/H^*$')\n",
    "ax.set_xlabel('$H^*$', fontsize=12)\n",
    "ax.set_ylabel('$\\\\lambda_1$', fontsize=12)\n",
    "ax.set_title('Spectral Gap vs Topology', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. lambda_1 * H* (should be constant = 14)\n",
    "ax = axes[1]\n",
    "colors = ['steelblue' if abs(r['lambda_x_H'] - 14) < 2 else 'coral' for r in results]\n",
    "ax.bar(range(len(results)), df['lambda_x_H'], color=colors)\n",
    "ax.axhline(14, color='r', linestyle='--', linewidth=2, label='GIFT: 14')\n",
    "ax.set_xticks(range(len(results)))\n",
    "ax.set_xticklabels([f\"H*={r['H_star']}\" for r in results], rotation=45)\n",
    "ax.set_ylabel('$\\\\lambda_1 \\\\times H^*$', fontsize=12)\n",
    "ax.set_title('Universality Test', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "# 3. Deviation from prediction\n",
    "ax = axes[2]\n",
    "ax.bar(range(len(results)), df['deviation'], color='coral')\n",
    "ax.axhline(5, color='g', linestyle='--', label='5% threshold')\n",
    "ax.set_xticks(range(len(results)))\n",
    "ax.set_xticklabels([f\"H*={r['H_star']}\" for r in results], rotation=45)\n",
    "ax.set_ylabel('Deviation (%)', fontsize=12)\n",
    "ax.set_title('Accuracy Check', fontsize=13)\n",
    "ax.legend(fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/user/GIFT/research/yang-mills/matrix_free_results.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMean(lambda_1 * H*) = {df['lambda_x_H'].mean():.2f}\")\n",
    "print(f\"Std(lambda_1 * H*) = {df['lambda_x_H'].std():.2f}\")\n",
    "print(f\"GIFT prediction: 14\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1tvqqzijevy",
   "source": "## Richardson Extrapolation for High Accuracy\n\nThe finite difference error is $O(h^2)$. Using results from two grid sizes, we can extrapolate to the $h \\to 0$ limit:\n\n$$\\lambda_{\\text{exact}} \\approx \\lambda_{\\text{fine}} + \\frac{\\lambda_{\\text{fine}} - \\lambda_{\\text{coarse}}}{r^2 - 1}$$\n\nwhere $r = n_{\\text{fine}} / n_{\\text{coarse}}$ is the refinement ratio.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "1rq9mbsxfpn",
   "source": "# Richardson extrapolation for improved accuracy\nprint(\"Richardson Extrapolation Test\")\nprint(\"=\" * 50)\nprint()\n\nH_star = 99\ngift_pred = 14.0 / H_star\nmetric_func = lambda x: gift_g2_metric(x, H_star=H_star)\n\nprint(f\"H* = {H_star}\")\nprint(f\"GIFT prediction: lambda_1 = 14/{H_star} = {gift_pred:.6f}\")\nprint()\n\n# Test with grid pairs\nfor n1, n2 in [(5, 7), (6, 8)]:\n    print(f\"Grid sizes: ({n1}, {n2})\")\n    result = richardson_extrapolation(metric_func, grid_sizes=(n1, n2))\n    \n    print(f\"  Coarse (n={n1}): lambda_1 = {result['lambda_coarse']:.6f}\")\n    print(f\"  Fine (n={n2}):   lambda_1 = {result['lambda_fine']:.6f}\")\n    print(f\"  Extrapolated:    lambda_1 = {result['lambda_1']:.6f}\")\n    \n    error = abs(result['lambda_1'] - gift_pred) / gift_pred * 100\n    print(f\"  Error: {error:.2f}%\")\n    print()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. GPU Acceleration with PyTorch\n",
    "\n",
    "For large 7D grids, GPU acceleration is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch\n",
    "    from matrix_free_eigensolvers import TorchLaplacianOperator\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"PyTorch available! Device: {device}\")\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Create GPU-accelerated operator\n",
    "    def metric_torch(x):\n",
    "        N = x.shape[0]\n",
    "        c = (65.0 / 32.0) ** (1.0 / 7.0)\n",
    "        return torch.full((N, 7), c, device=x.device, dtype=x.dtype)\n",
    "    \n",
    "    gpu_op = TorchLaplacianOperator(\n",
    "        grid_shape=(6,)*7,\n",
    "        metric_diag_func=metric_torch,\n",
    "        h=np.pi/3,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nGPU operator created for grid {(6,)*7}\")\n",
    "    print(f\"Total points: {6**7:,}\")\n",
    "    \n",
    "    # Run power iteration on GPU\n",
    "    if device == 'cuda':\n",
    "        lambda_1_gpu, v_gpu = gpu_op.power_iteration_gpu(n_iter=200)\n",
    "        print(f\"\\nGPU power iteration result: lambda_1 = {lambda_1_gpu:.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"PyTorch not available. Install with: pip install torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 8. Summary: Matrix-Free Methods\n",
    "\n",
    "| Method | Pros | Cons | Best For |\n",
    "|--------|------|------|----------|\n",
    "| **Lanczos** | Accurate, converges to multiple eigenvalues | Needs many matvecs | Medium grids, precise results |\n",
    "| **Power Iteration** | Simple, memory efficient | Only finds one eigenvalue | Very large grids |\n",
    "| **Diffusion MC** | Stochastic, GPU-friendly | Statistical error | Monte Carlo integration |\n",
    "| **Stochastic Trace** | Full spectrum density | Requires interpretation | Spectral analysis |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Matrix-free is essential for 7D**: A $10^7 \\times 10^7$ matrix cannot be stored\n",
    "2. **LinearOperator interface**: Only requires `matvec(v)` function\n",
    "3. **Finite differences**: Curved Laplacian computed on-the-fly\n",
    "4. **GPU acceleration**: PyTorch enables larger grids\n",
    "5. **GIFT validation**: Results consistent with $\\lambda_1 = 14/H^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "export = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'method': 'Matrix-Free Lanczos',\n",
    "    'grid_shape': list(grid_shape),\n",
    "    'gift_prediction': '14/H*',\n",
    "    'results': results\n",
    "}\n",
    "\n",
    "with open('/home/user/GIFT/research/yang-mills/matrix_free_results.json', 'w') as f:\n",
    "    json.dump(export, f, indent=2, default=str)\n",
    "\n",
    "print(\"Results saved to matrix_free_results.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}