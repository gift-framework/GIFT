{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Adaptive Cutoff Validation on 2M Odlyzko Zeros\n\n## Context\n\nThe mollified Dirichlet polynomial $S_w(T)$ uses a cutoff $X = T^{\\theta(T)}$.\n\nTwo functional forms for $\\theta(T)$ are tested:\n\n1. **Polynomial**: $\\theta(T) = a - b/\\log T + c/\\log^2 T$ — truncated expansion\n2. **Shifted-log**: $\\theta(T) = a - b/(\\log T + d)$ — resums the full $1/\\log T$ series\n\nThe shifted-log form captures all higher-order Euler product corrections through\nthe geometric series $b/(\\log T + d) = b/\\log T - bd/\\log^2 T + bd^2/\\log^3 T - \\cdots$\n\n**Key discovery**: The formula $\\theta(T) = \\frac{7}{6} - \\frac{\\varphi}{\\log T - 2}$\nuses only GIFT topological constants ($\\dim K_7$, $N_\\text{gen}$, $p_2$, $\\varphi$) with zero free parameters.\n\n## Validation Tests\n\n1. **Phase 1**: Full 2M evaluation with all primes up to 500k\n2. **T5a**: Beat 200 random constant-$\\theta$ baselines\n3. **T5b**: Beat 200 random adaptive baselines (polynomial + shifted-log)\n4. **T7**: Bootstrap 95% CI contains $\\alpha = 1$\n5. **T8**: No significant alpha drift ($p > 0.05$)\n6. **Visualizations**: Window alphas, bootstrap histogram, form comparison\n7. **Final scorecard** with validation summary"
  },
  {
   "cell_type": "code",
   "source": "# ================================================================\n# COLAB SETUP — Mount Google Drive\n# Skip this cell if running locally\n# ================================================================\ntry:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"Google Drive mounted at /content/drive\")\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n    print(\"Not running in Colab — using local filesystem\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nfrom scipy.special import loggamma, lambertw\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport json, time, os, math\n\n# ================================================================\n# CONSTANTS\n# ================================================================\nphi = (1 + math.sqrt(5)) / 2          # Golden ratio φ ≈ 1.61803\nEULER_GAMMA = 0.5772156649015329       # Euler-Mascheroni γ\n\n# ================================================================\n# GPU DETECTION\n# ================================================================\nos.environ.setdefault('CUDA_PATH', '/usr')  # Ubuntu nvrtc path\n\ntry:\n    import cupy as cp\n    _ = cp.maximum(cp.array([1.0]), 0.0)  # test kernel compilation\n    GPU = True\n    mem_free = cp.cuda.Device(0).mem_info[0] // 1024 // 1024\n    print(f\"[GPU] CuPy {cp.__version__}, free={mem_free} MB\")\n    # Adaptive batch sizes based on VRAM\n    if mem_free > 20_000:      # A100 / V100\n        PRIME_BATCH = 1000\n        ZERO_CHUNK = 500_000\n    elif mem_free > 6_000:     # T4 / RTX 3060+\n        PRIME_BATCH = 500\n        ZERO_CHUNK = 200_000\n    else:                      # RTX 2050 / small GPUs\n        PRIME_BATCH = 200\n        ZERO_CHUNK = 100_000\nexcept (ImportError, Exception) as e:\n    GPU = False\n    PRIME_BATCH = 200\n    ZERO_CHUNK = 200_000\n    print(f\"[CPU] No GPU ({e}), using NumPy — expect ~40 min/candidate\")\n\n# ================================================================\n# CONFIGURATION\n# ================================================================\nZEROS_LOCAL = 'outputs/riemann_zeros_2M_genuine.npy'\nZEROS_DRIVE = '/content/drive/MyDrive/riemann_zeros_2M_genuine.npy'\nZEROS_FILE = ZEROS_LOCAL if os.path.exists(ZEROS_LOCAL) else ZEROS_DRIVE\n\nP_MAX = 500_000          # Full prime sieve\nK_MAX = 3                # Prime power cutoff\nN_BOOTSTRAP = 2000       # Bootstrap resamples for T7\nN_RANDOM_CONST = 200     # Random constant baselines for T5a\nN_RANDOM_3D = 200        # Random 3-param baselines for T5b\n\n# Window setup for drift analysis\nN_WINDOWS = 6\n\n# Output\nOUTPUT_DIR = 'outputs'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nprint(f\"\\nConfiguration: P_MAX={P_MAX}, K_MAX={K_MAX}\")\nprint(f\"  Zeros file: {ZEROS_FILE}\")\nprint(f\"  GPU batching: prime_batch={PRIME_BATCH}, zero_chunk={ZERO_CHUNK:,}\")\nmode = \"GPU float64 batched\" if GPU else \"CPU float64 batched\"\nprint(f\"  Mode: {mode}\")\nprint(f\"  Constants: phi={phi:.5f}, gamma={EULER_GAMMA:.7f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Zeros & Compute Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# LOAD ZEROS\n",
    "# ================================================================\n",
    "all_zeros = np.load(ZEROS_FILE)\n",
    "N_TOTAL = len(all_zeros)\n",
    "gamma_n = all_zeros\n",
    "print(f\"Loaded {N_TOTAL:,} zeros, T range: [{gamma_n[0]:.2f}, {gamma_n[-1]:.2f}]\")\n",
    "\n",
    "# ================================================================\n",
    "# RIEMANN-SIEGEL THETA\n",
    "# ================================================================\n",
    "def theta_rs(t):\n",
    "    \"\"\"Riemann-Siegel theta function.\"\"\"\n",
    "    t = np.asarray(t, dtype=np.float64)\n",
    "    return np.imag(loggamma(0.25 + 0.5j * t)) - 0.5 * t * np.log(np.pi)\n",
    "\n",
    "def theta_deriv(t):\n",
    "    \"\"\"theta'(t) ~ 0.5 * log(t / (2*pi)).\"\"\"\n",
    "    return 0.5 * np.log(np.maximum(np.asarray(t, dtype=np.float64), 1.0) / (2 * np.pi))\n",
    "\n",
    "# ================================================================\n",
    "# SMOOTH ZEROS (Newton iteration)\n",
    "# ================================================================\n",
    "def smooth_zeros(N):\n",
    "    \"\"\"Compute gamma0_n where theta_RS(gamma0_n) = (n - 1.5) * pi.\"\"\"\n",
    "    ns = np.arange(1, N + 1, dtype=np.float64)\n",
    "    targets = (ns - 1.5) * np.pi\n",
    "    w = np.real(lambertw(ns / np.e))\n",
    "    t = np.maximum(2 * np.pi * ns / w, 2.0)\n",
    "    for it in range(40):\n",
    "        dt = (theta_rs(t) - targets) / np.maximum(np.abs(theta_deriv(t)), 1e-15)\n",
    "        t -= dt\n",
    "        if np.max(np.abs(dt)) < 1e-12:\n",
    "            print(f\"  Newton converged in {it+1} iterations\")\n",
    "            break\n",
    "    return t\n",
    "\n",
    "print(\"Computing smooth zeros for all 2M zeros...\")\n",
    "t0 = time.time()\n",
    "gamma0 = smooth_zeros(N_TOTAL)\n",
    "delta = gamma_n - gamma0\n",
    "tp = theta_deriv(gamma0)\n",
    "print(f\"  Done in {time.time()-t0:.1f}s\")\n",
    "print(f\"  delta: mean={delta.mean():.6f}, std={delta.std():.6f}\")\n",
    "\n",
    "# ================================================================\n",
    "# PRIME SIEVE\n",
    "# ================================================================\n",
    "def sieve(N):\n",
    "    is_p = np.ones(N + 1, dtype=bool); is_p[:2] = False\n",
    "    for i in range(2, int(N**0.5) + 1):\n",
    "        if is_p[i]: is_p[i*i::i] = False\n",
    "    return np.where(is_p)[0]\n",
    "\n",
    "t0 = time.time()\n",
    "primes = sieve(P_MAX)\n",
    "print(f\"Sieved {len(primes):,} primes up to {P_MAX:,} [{time.time()-t0:.1f}s]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# COSINE-SQUARED KERNEL\n# ================================================================\ndef w_cosine(x):\n    \"\"\"Cosine-squared mollifier: cos^2(pi*x/2) for x < 1, 0 otherwise.\"\"\"\n    return np.where(x < 1.0, np.cos(np.pi * x / 2)**2, 0.0)\n\n# ================================================================\n# MOLLIFIED PRIME SUM — GPU-ACCELERATED\n#\n# Two modes:\n#   POLYNOMIAL:  theta(T) = a - b/logT + c/log^2 T        (d_shift=0)\n#   SHIFTED-LOG: theta(T) = a - b/(logT + d_shift)         (c=0, d_shift!=0)\n#\n# Strategy: chunk over zeros, batch over primes.\n# ================================================================\ndef prime_sum_var(g0, tp_v, primes, k_max, theta_inf, theta_coeff, c_coeff=0.0,\n                  d_shift=0.0, chunk_size=None, batch_size=None, verbose=False):\n    \"\"\"\n    Mollified prime sum with chunked zeros + batched primes.\n    \n    Args:\n        theta_inf: asymptotic theta (= a)\n        theta_coeff: leading correction (= -b)\n        c_coeff: quadratic correction for polynomial mode (= c)\n        d_shift: log shift for shifted-log mode (= d in a - b/(logT + d))\n    \n    When d_shift != 0: theta = theta_inf + theta_coeff / (logT + d_shift)\n    When d_shift == 0: theta = theta_inf + theta_coeff/logT + c_coeff/log^2 T\n    \"\"\"\n    if chunk_size is None:\n        chunk_size = ZERO_CHUNK\n    if batch_size is None:\n        batch_size = PRIME_BATCH\n    \n    xp = cp if GPU else np\n    N = len(g0)\n    result = np.zeros(N, dtype=np.float64)\n    log_primes_np = np.log(primes.astype(np.float64))\n    shifted_mode = (d_shift != 0.0)\n    \n    n_chunks = (N + chunk_size - 1) // chunk_size\n    t_start = time.time()\n    \n    for ic in range(n_chunks):\n        lo = ic * chunk_size\n        hi = min(lo + chunk_size, N)\n        N_c = hi - lo\n        \n        # Move chunk to device\n        g0_c = xp.asarray(g0[lo:hi], dtype=xp.float64)\n        tp_c = xp.asarray(tp_v[lo:hi], dtype=xp.float64)\n        log_g0 = xp.log(xp.maximum(g0_c, 2.0))\n        \n        if shifted_mode:\n            # SHIFTED-LOG: theta = a - b/(logT + d)\n            # theta_coeff = -b, so theta = theta_inf + theta_coeff/(logT + d_shift)\n            denom = log_g0 + xp.float64(d_shift)\n            denom = xp.maximum(denom, 0.1)  # safety: avoid division by zero\n            theta_per = xp.float64(theta_inf) + xp.float64(theta_coeff) / denom\n            theta_per = xp.clip(theta_per, 0.5, 2.0)\n            log_X = theta_per * log_g0\n        elif theta_coeff == 0.0 and c_coeff == 0.0:\n            log_X = xp.float64(theta_inf) * log_g0\n        else:\n            # POLYNOMIAL: theta = a + coeff/logT + c/log^2 T\n            theta_per = xp.float64(theta_inf) + xp.float64(theta_coeff) / log_g0\n            if c_coeff != 0.0:\n                theta_per = theta_per + xp.float64(c_coeff) / log_g0**2\n            theta_per = xp.clip(theta_per, 0.5, 2.0)\n            log_X = theta_per * log_g0\n        \n        S = xp.zeros(N_c, dtype=xp.float64)\n        log_X_max = float(xp.max(log_X))\n        \n        for m in range(1, k_max + 1):\n            cutoff = log_X_max / m\n            j_max = int(np.searchsorted(log_primes_np, cutoff + 0.1))\n            if j_max == 0:\n                continue\n            \n            for b_start in range(0, j_max, batch_size):\n                b_end = min(b_start + batch_size, j_max)\n                \n                logp_b = xp.asarray(log_primes_np[b_start:b_end], dtype=xp.float64)\n                p_b = xp.asarray(primes[b_start:b_end].astype(np.float64))\n                \n                x = (xp.float64(m) * logp_b[:, None]) / log_X[None, :]\n                w = xp.where(x < 1.0, xp.cos(xp.float64(math.pi / 2) * x)**2,\n                             xp.float64(0))\n                phase = g0_c[None, :] * (xp.float64(m) * logp_b[:, None])\n                coeff = xp.float64(1.0 / m) / p_b ** (m / 2.0)\n                S -= xp.sum(w * xp.sin(phase) * coeff[:, None], axis=0)\n                del x, w, phase, coeff\n        \n        chunk_result = -S / tp_c\n        \n        if GPU:\n            result[lo:hi] = cp.asnumpy(chunk_result)\n            cp.get_default_memory_pool().free_all_blocks()\n        else:\n            result[lo:hi] = chunk_result\n        \n        if verbose and n_chunks > 1:\n            elapsed = time.time() - t_start\n            pct = (ic + 1) / n_chunks\n            eta = elapsed / pct * (1 - pct) if pct > 0 else 0\n            print(f\"      [{hi:>10,}/{N:>10,}] {pct*100:5.1f}%  \"\n                  f\"[{elapsed/60:.1f}m, ETA {eta/60:.1f}m]\", flush=True)\n    \n    return result\n\n# ================================================================\n# METRICS (unchanged)\n# ================================================================\ndef compute_alpha_R2(delta, delta_pred):\n    denom = np.dot(delta_pred, delta_pred)\n    alpha = float(np.dot(delta, delta_pred) / denom) if denom > 0 else 0.0\n    residual = delta - delta_pred\n    R2 = float(1.0 - np.var(residual) / np.var(delta))\n    residual_scaled = delta - alpha * delta_pred\n    R2_scaled = float(1.0 - np.var(residual_scaled) / np.var(delta))\n    return alpha, R2, R2_scaled\n\ndef compute_localization(delta, delta_pred, gamma_n):\n    half_gaps = np.diff(gamma_n) / 2.0\n    residual = delta - delta_pred\n    n = min(len(residual) - 1, len(half_gaps))\n    localized = np.abs(residual[1:n+1]) < half_gaps[:n]\n    return float(np.mean(localized))\n\ndef compute_window_alphas(delta, delta_pred, n_windows=6):\n    N = len(delta)\n    bounds = [int(i * N / n_windows) for i in range(n_windows + 1)]\n    alphas = []\n    for i in range(n_windows):\n        lo, hi = bounds[i], bounds[i + 1]\n        d_w = delta[lo:hi]\n        dp_w = delta_pred[lo:hi]\n        denom = np.dot(dp_w, dp_w)\n        alpha = float(np.dot(d_w, dp_w) / denom) if denom > 0 else 0.0\n        alphas.append(alpha)\n    return alphas, bounds\n\ndef compute_drift(alphas):\n    if len(alphas) < 3:\n        return 0.0, 1.0\n    x = np.arange(len(alphas))\n    slope, intercept, r, p, se = stats.linregress(x, alphas)\n    return slope, p\n\ndef bootstrap_alpha(delta, delta_pred, n_boot=2000, ci=0.95, seed=42):\n    rng = np.random.default_rng(seed)\n    N = len(delta)\n    alphas = np.empty(n_boot)\n    for i in range(n_boot):\n        idx = rng.integers(0, N, size=N)\n        d = delta[idx]\n        dp = delta_pred[idx]\n        denom = np.dot(dp, dp)\n        alphas[i] = np.dot(d, dp) / denom if denom > 0 else 0.0\n    lo = np.percentile(alphas, (1 - ci) / 2 * 100)\n    hi = np.percentile(alphas, (1 + ci) / 2 * 100)\n    return alphas, lo, hi\n\ndef clopper_pearson_ci(k, n, alpha=0.05):\n    from scipy.stats import beta as beta_dist\n    lo = beta_dist.ppf(alpha / 2, k, n - k + 1) if k > 0 else 0.0\n    hi = beta_dist.ppf(1 - alpha / 2, k + 1, n - k) if k < n else 1.0\n    return lo, hi\n\nprint(\"Core functions defined (polynomial + shifted-log modes).\")\nprint(f\"Benchmarking on 5k zeros, 669 primes...\")\n_g0 = gamma0[:5000]; _tp = tp[:5000]; _pr = primes[:669]\nt0 = time.time()\n_ = prime_sum_var(_g0, _tp, _pr, K_MAX, 7/6, -phi, d_shift=-2)\nt_bench = time.time() - t0\nprint(f\"  Shifted-log: {t_bench*1000:.0f} ms\")\nt0 = time.time()\n_ = prime_sum_var(_g0, _tp, _pr, K_MAX, 7/6, -(math.e/phi), -2*phi)\nt_poly = time.time() - t0\nprint(f\"  Polynomial:  {t_poly*1000:.0f} ms\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Define Candidate Models\n\nTwo functional forms are tested:\n\n**Polynomial**: $\\theta(T) = a - b/\\log T + c/\\log^2 T$ — truncated expansion\n\n**Shifted-log**: $\\theta(T) = a - b/(\\log T + d)$ — resums the full $1/\\log T$ series\n\nThe shifted-log form arises from the geometric series:\n$$\\frac{b}{\\log T + d} = \\frac{b}{\\log T} - \\frac{bd}{\\log^2 T} + \\frac{bd^2}{\\log^3 T} - \\cdots$$\n\n**Key discovery**: $\\theta(T) = \\frac{7}{6} - \\frac{\\varphi}{\\log T - 2}$ uses only GIFT topological constants:\n- $7/6 = \\dim(K_7) / (2 \\cdot N_\\text{gen})$\n- $\\varphi$ = golden ratio (G$_2$ metric eigenvalue)\n- $2 = p_2$ = Pontryagin class contribution"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# CANDIDATE MODELS\n# Format: (name, a, b, c, d_shift)\n#\n# POLYNOMIAL mode (d_shift=0): theta = a - b/logT + c/log^2 T\n# SHIFTED-LOG mode (d_shift!=0): theta = a - b/(logT + d_shift)\n#\n# prime_sum_var convention: theta_coeff = -b, c_coeff = c\n# ================================================================\nCANDIDATES = [\n    # --- Shifted-log: θ = a − b/(logT + d) ---\n    # GIFT pure: all constants from topology (dim_K7, N_gen, p2, phi)\n    (\"SL: 7/6 - phi/(logT - 2)\",\n     7/6, phi, 0.0, -2.0),\n\n    # Polynomial expansion of GIFT pure: -phi*(-2)^0/logT = -phi/logT, -phi*(-2)/log^2T = 2phi/log^2T\n    # This is the polynomial winner from 3D exploration — included to compare forms\n    (\"SL: 7/6 - (e/phi)/(logT - 2phi^2/e)\",\n     7/6, math.e/phi, 0.0, -2*phi**2/math.e),\n\n    # Euler-Mascheroni shift\n    (\"SL: 7/6 - phi/(logT - gamma)\",\n     7/6, phi, 0.0, -EULER_GAMMA),\n\n    # Alternative a: 13/11 (close to 7/6)\n    (\"SL: 13/11 - phi/(logT - 2)\",\n     13/11, phi, 0.0, -2.0),\n\n    # --- Polynomial: θ = a − b/logT + c/log²T ---\n    # Winner from 3D exploration (α=0.9998 on 2M)\n    (\"POLY: 7/6 - e/phi/logT - 2phi/log2T\",\n     7/6, math.e/phi, -2*phi, 0.0),\n\n    # Second-best polynomial\n    (\"POLY: 7/6 - 13/8/logT - 7/2/log2T\",\n     7/6, 13/8, -7/2, 0.0),\n\n    # Third polynomial\n    (\"POLY: 13/11 - 7/4/logT - 2phi/log2T\",\n     13/11, 7/4, -2*phi, 0.0),\n\n    # --- 2D baselines (no subleading correction) ---\n    (\"[2D] 5/4 - e/logT\",\n     5/4, math.e, 0.0, 0.0),\n\n    (\"[2D] 11/9 - 5/2/logT\",\n     11/9, 5/2, 0.0, 0.0),\n]\n\nprint(f\"Candidates to validate: {len(CANDIDATES)}\")\nprint()\nfor i, (name, a, b, c, d) in enumerate(CANDIDATES):\n    if d != 0:\n        print(f\"  [{i+1:2d}] {name}\")\n        print(f\"       theta = {a:.6f} - {b:.6f}/(logT + ({d:.6f}))\")\n    elif c != 0:\n        print(f\"  [{i+1:2d}] {name}\")\n        print(f\"       theta = {a:.6f} - {b:.6f}/logT + ({c:.6f})/log^2 T\")\n    else:\n        print(f\"  [{i+1:2d}] {name}\")\n        print(f\"       theta = {a:.6f} - {b:.6f}/logT\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Phase 1 — Full 2M Zero Evaluation\n\nRun each candidate on all 2,001,052 zeros with all primes up to 500k.\nBoth polynomial and shifted-log modes are supported transparently."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# FULL 2M EVALUATION — with checkpointing\n# ================================================================\nCHECKPOINT_FILE = os.path.join(OUTPUT_DIR, 'theta_validation_checkpoint.json')\n\n# Try to resume from checkpoint\nphase1_results = []\nstart_idx = 0\n\nif os.path.exists(CHECKPOINT_FILE):\n    with open(CHECKPOINT_FILE) as f:\n        checkpoint = json.load(f)\n    # Verify checkpoint matches current candidates\n    if len(checkpoint) > 0 and checkpoint[0].get('name') == CANDIDATES[0][0]:\n        for cr in checkpoint:\n            cr['delta_pred'] = None  # Will recompute if needed\n            phase1_results.append(cr)\n        start_idx = len(phase1_results)\n        print(f\"Resumed from checkpoint: {start_idx}/{len(CANDIDATES)} candidates done\")\n    else:\n        print(\"Checkpoint from different candidate list — starting fresh\")\nelse:\n    print(\"No checkpoint found, starting fresh\")\n\nprint(\"=\" * 80)\nprint(f\"PHASE 1: Full 2M evaluation ({N_TOTAL:,} zeros, {len(primes):,} primes)\")\nprint(\"=\" * 80)\n\nt_phase1 = time.time()\n\nfor i in range(start_idx, len(CANDIDATES)):\n    name, a, b, c, d_shift = CANDIDATES[i]\n    is_shifted = (d_shift != 0)\n    mode_str = \"shifted-log\" if is_shifted else (\"3-param\" if c != 0 else \"2-param\")\n    \n    print(f\"\\n  [{i+1}/{len(CANDIDATES)}] {name}  ({mode_str})\")\n    if is_shifted:\n        print(f\"    a={a:.8f}  b={b:.8f}  d={d_shift:.8f}\")\n    else:\n        print(f\"    a={a:.8f}  b={b:.8f}  c={c:.8f}\")\n    \n    t0 = time.time()\n    \n    # Compute mollified sum (theta_coeff = -b)\n    delta_pred = prime_sum_var(gamma0, tp, primes, K_MAX,\n                               theta_inf=a, theta_coeff=-b,\n                               c_coeff=c, d_shift=d_shift,\n                               verbose=True)\n    \n    elapsed = time.time() - t0\n    \n    # Metrics\n    alpha, R2, R2_sc = compute_alpha_R2(delta, delta_pred)\n    loc = compute_localization(delta, delta_pred, gamma_n)\n    alphas_w, bounds_w = compute_window_alphas(delta, delta_pred, N_WINDOWS)\n    drift_slope, drift_p = compute_drift(alphas_w)\n    \n    # Check monotonicity\n    diffs = np.diff(alphas_w)\n    is_monotone = all(d <= 0 for d in diffs) or all(d >= 0 for d in diffs)\n    \n    r = {\n        'name': name,\n        'a': float(a), 'b': float(b), 'c': float(c), 'd_shift': float(d_shift),\n        'mode': 'shifted-log' if is_shifted else 'polynomial',\n        'alpha': float(alpha),\n        'abs_alpha_minus_1': float(abs(alpha - 1)),\n        'R2': float(R2),\n        'R2_scaled': float(R2_sc),\n        'localization': float(loc),\n        'drift_slope': float(drift_slope),\n        'drift_p': float(drift_p),\n        'window_alphas': [float(x) for x in alphas_w],\n        'is_monotone': bool(is_monotone),\n        'delta_pred': delta_pred,  # Keep for later phases\n        'elapsed_s': float(elapsed),\n    }\n    phase1_results.append(r)\n    \n    print(f\"    alpha  = {alpha:+.6f}  |alpha-1| = {abs(alpha-1):.6f}\")\n    print(f\"    R2     = {R2:.6f}  R2_sc = {R2_sc:.6f}  loc = {loc:.4f}\")\n    print(f\"    drift  = {drift_slope:+.6f}  (p={drift_p:.4f})  {'monotone' if is_monotone else 'non-monotone'}\")\n    print(f\"    windows = {[f'{x:.4f}' for x in alphas_w]}\")\n    print(f\"    [{elapsed/60:.1f}m]\")\n    \n    # --- CHECKPOINT: save after each candidate ---\n    save_cp = [{k: v for k, v in r.items() if k != 'delta_pred'}\n               for r in phase1_results]\n    with open(CHECKPOINT_FILE, 'w') as f:\n        json.dump(save_cp, f, indent=2)\n    print(f\"    [checkpoint saved: {len(phase1_results)}/{len(CANDIDATES)}]\")\n\ntotal_p1 = time.time() - t_phase1\nprint(f\"\\nPhase 1 complete in {total_p1/3600:.1f}h\")\n\n# Rank by |alpha - 1|\nphase1_ranked = sorted(phase1_results, key=lambda r: r['abs_alpha_minus_1'])\n\n# Only recompute delta_pred for top N candidates needed by T7/T8\nN_TOP_RECOMPUTE = min(5, len(phase1_ranked))\nfor r in phase1_ranked[:N_TOP_RECOMPUTE]:\n    if r['delta_pred'] is None:\n        # Find matching candidate\n        idx = next(j for j, (_, a, b, c, d) in enumerate(CANDIDATES)\n                   if abs(a - r['a']) < 1e-10 and abs(b - r['b']) < 1e-10\n                   and abs(c - r['c']) < 1e-10 and abs(d - r['d_shift']) < 1e-10)\n        name, a, b, c, d_shift = CANDIDATES[idx]\n        print(f\"  Recomputing delta_pred for top candidate: {name}...\")\n        r['delta_pred'] = prime_sum_var(gamma0, tp, primes, K_MAX,\n                                         theta_inf=a, theta_coeff=-b,\n                                         c_coeff=c, d_shift=d_shift,\n                                         verbose=True)\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"RANKING by |alpha - 1|:\")\nprint(\"=\" * 80)\nprint(f\"{'Rk':<4} {'Name':<40} {'alpha':>10} {'|a-1|':>10} {'drift':>10} {'p':>8} {'mode':>10}\")\nprint(\"-\" * 92)\nfor rk, r in enumerate(phase1_ranked, 1):\n    print(f\"{rk:<4} {r['name']:<40} {r['alpha']:>+10.6f} {r['abs_alpha_minus_1']:>10.6f} \"\n          f\"{r['drift_slope']:>+10.6f} {r['drift_p']:>8.4f} {r['mode']:>10}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phase 2 — Monte Carlo Validation (T5)\n",
    "\n",
    "### T5a: Beat 200 random constant-$\\theta$ baselines\n",
    "For each random draw, pick $\\theta \\sim \\text{Uniform}(0.6, 1.5)$ (constant, no correction).\n",
    "Compute $R^2$ on 2M zeros. The candidate must have higher $R^2$ than all 200.\n",
    "\n",
    "### T5b: Beat 200 random 3-parameter baselines\n",
    "For each random draw, pick $(a, b, c) \\sim$ Uniform on reasonable ranges.\n",
    "The candidate must have higher $R^2$ than all 200.\n",
    "\n",
    "Both tests use a **subset** of zeros for speed (every 10th zero = 200k)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# T5 MONTE CARLO BASELINES\n# Use every 10th zero for speed (200k zeros)\n# ================================================================\nSTRIDE_MC = 10\nidx_mc = np.arange(0, N_TOTAL, STRIDE_MC)\ng0_mc = gamma0[idx_mc]\ntp_mc = tp[idx_mc]\ndelta_mc = delta[idx_mc]\ngn_mc = gamma_n[idx_mc]\nN_mc = len(idx_mc)\n\n# Primes subset for MC (use first 5000 primes for speed)\nP_MC = min(5000, len(primes))\nprimes_mc = primes[:P_MC]\n\nprint(f\"Monte Carlo setup: {N_mc:,} zeros (stride {STRIDE_MC}), {P_MC:,} primes\")\n\n# Compute R^2 for the best candidate on MC subset\nbest = phase1_ranked[0]\nprint(f\"\\nBest candidate for T5: {best['name']} ({best['mode']})\")\n\n# Recompute on MC subset for fair comparison\ndp_best_mc = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                           theta_inf=best['a'], theta_coeff=-best['b'],\n                           c_coeff=best['c'], d_shift=best['d_shift'])\n_, R2_best_mc, _ = compute_alpha_R2(delta_mc, dp_best_mc)\nprint(f\"  R^2 (MC subset) = {R2_best_mc:.6f}\")\n\n# ================================================================\n# T5a: Random constant-theta baselines\n# ================================================================\nprint(f\"\\n--- T5a: {N_RANDOM_CONST} random constant-theta baselines ---\")\nrng = np.random.default_rng(2026)\nR2_const = np.empty(N_RANDOM_CONST)\nt0 = time.time()\n\nfor k in range(N_RANDOM_CONST):\n    theta_rand = rng.uniform(0.6, 1.5)\n    dp_rand = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                            theta_rand, 0.0, 0.0)\n    _, R2_rand, _ = compute_alpha_R2(delta_mc, dp_rand)\n    R2_const[k] = R2_rand\n    if (k + 1) % 50 == 0:\n        print(f\"  {k+1}/{N_RANDOM_CONST} [{time.time()-t0:.0f}s]\")\n\nn_beat_const = int(np.sum(R2_best_mc > R2_const))\nT5a_pass = bool(n_beat_const == N_RANDOM_CONST)\nT5a_margin = float(R2_best_mc - np.max(R2_const))\ncp_lo_a, cp_hi_a = clopper_pearson_ci(n_beat_const, N_RANDOM_CONST)\nprint(f\"  Beat {n_beat_const}/{N_RANDOM_CONST} random constant baselines\")\nprint(f\"  Best random R^2: {np.max(R2_const):.6f}\")\nprint(f\"  Candidate R^2:   {R2_best_mc:.6f}\")\nprint(f\"  Margin: {T5a_margin:+.6f}\")\nprint(f\"  Clopper-Pearson 95% CI for p(beat): [{cp_lo_a:.4f}, {cp_hi_a:.4f}]\")\nprint(f\"  T5a: {'PASS' if T5a_pass else 'FAIL'}\")\n\n# ================================================================\n# T5b: Random 3-parameter baselines (polynomial + shifted-log)\n# ================================================================\nprint(f\"\\n--- T5b: {N_RANDOM_3D} random adaptive baselines ---\")\nR2_3d = np.empty(N_RANDOM_3D)\nt0 = time.time()\n\nfor k in range(N_RANDOM_3D):\n    a_rand = rng.uniform(1.0, 1.5)\n    b_rand = rng.uniform(0.5, 6.0)\n    # Mix polynomial and shifted-log randomly (50/50)\n    if rng.random() < 0.5:\n        c_rand = rng.uniform(-10.0, 10.0)\n        dp_rand = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                                a_rand, -b_rand, c_rand, d_shift=0.0)\n    else:\n        d_rand = rng.uniform(-5.0, 2.0)\n        dp_rand = prime_sum_var(g0_mc, tp_mc, primes_mc, K_MAX,\n                                a_rand, -b_rand, 0.0, d_shift=d_rand)\n    _, R2_rand, _ = compute_alpha_R2(delta_mc, dp_rand)\n    R2_3d[k] = R2_rand\n    if (k + 1) % 50 == 0:\n        print(f\"  {k+1}/{N_RANDOM_3D} [{time.time()-t0:.0f}s]\")\n\nn_beat_3d = int(np.sum(R2_best_mc > R2_3d))\nT5b_pass = bool(n_beat_3d == N_RANDOM_3D)\nT5b_margin = float(R2_best_mc - np.max(R2_3d))\ncp_lo_b, cp_hi_b = clopper_pearson_ci(n_beat_3d, N_RANDOM_3D)\nprint(f\"  Beat {n_beat_3d}/{N_RANDOM_3D} random adaptive baselines\")\nprint(f\"  Best random R^2: {np.max(R2_3d):.6f}\")\nprint(f\"  Candidate R^2:   {R2_best_mc:.6f}\")\nprint(f\"  Margin: {T5b_margin:+.6f}\")\nprint(f\"  Clopper-Pearson 95% CI for p(beat): [{cp_lo_b:.4f}, {cp_hi_b:.4f}]\")\nprint(f\"  T5b: {'PASS' if T5b_pass else 'FAIL'}\")\n\nT5_pass = T5a_pass and T5b_pass\nprint(f\"\\n  T5 overall: {'PASS' if T5_pass else 'FAIL'}\")\n\n# LEE correction note\nprint(f\"\\n  Note: With {len(CANDIDATES)} candidates tested, the\")\nprint(f\"  look-elsewhere effect (LEE) should be considered.\")\nprint(f\"  Effective p-value after Bonferroni: p < {0.05/len(CANDIDATES):.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Phase 3 — Bootstrap Confidence Interval (T7)\n",
    "\n",
    "Test: does the 95% bootstrap CI for $\\alpha$ contain 1.0?\n",
    "\n",
    "Applied to the **top candidates** on the full 2M dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# T7: BOOTSTRAP CI for top candidates\n",
    "# ================================================================\n",
    "N_TOP = min(5, len(phase1_ranked))\n",
    "print(f\"T7 Bootstrap CI ({N_BOOTSTRAP} resamples) on top {N_TOP} candidates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "t7_results = {}\n",
    "\n",
    "for i in range(N_TOP):\n",
    "    r = phase1_ranked[i]\n",
    "    name = r['name']\n",
    "    dp = r['delta_pred']\n",
    "    \n",
    "    print(f\"\\n  [{i+1}/{N_TOP}] {name}\")\n",
    "    t0 = time.time()\n",
    "    \n",
    "    boot_alphas, ci_lo, ci_hi = bootstrap_alpha(delta, dp, \n",
    "                                                n_boot=N_BOOTSTRAP, seed=42+i)\n",
    "    \n",
    "    contains_one = bool(ci_lo <= 1.0 <= ci_hi)\n",
    "    elapsed = time.time() - t0\n",
    "    \n",
    "    t7_results[name] = {\n",
    "        'boot_alphas': boot_alphas,\n",
    "        'ci_lo': float(ci_lo),\n",
    "        'ci_hi': float(ci_hi),\n",
    "        'T7_pass': contains_one,\n",
    "    }\n",
    "    \n",
    "    print(f\"    alpha = {r['alpha']:+.6f}\")\n",
    "    print(f\"    95% CI: [{ci_lo:.6f}, {ci_hi:.6f}]\")\n",
    "    print(f\"    Contains 1.0: {'YES -> PASS' if contains_one else 'NO -> FAIL'}\")\n",
    "    print(f\"    [{elapsed:.1f}s]\")\n",
    "\n",
    "# Update phase1 results with T7\n",
    "for r in phase1_results:\n",
    "    if r['name'] in t7_results:\n",
    "        r['T7_pass'] = t7_results[r['name']]['T7_pass']\n",
    "        r['T7_ci_lo'] = t7_results[r['name']]['ci_lo']\n",
    "        r['T7_ci_hi'] = t7_results[r['name']]['ci_hi']\n",
    "    else:\n",
    "        r['T7_pass'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Phase 4 — Drift Analysis (T8)\n",
    "\n",
    "Test: is the alpha drift slope statistically insignificant ($p > 0.05$)?\n",
    "\n",
    "The alpha drift measures how well the correction scales across the full $T$ range.\n",
    "A persistent downward drift suggests the model degrades at high $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# T8: DRIFT ANALYSIS\n",
    "# Extended window analysis with more granular windows\n",
    "# ================================================================\n",
    "N_DRIFT_WINDOWS = 12  # More windows for better drift resolution\n",
    "\n",
    "print(f\"T8 Drift Analysis ({N_DRIFT_WINDOWS} windows) on top {N_TOP} candidates\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "t8_results = {}\n",
    "\n",
    "for i in range(N_TOP):\n",
    "    r = phase1_ranked[i]\n",
    "    name = r['name']\n",
    "    dp = r['delta_pred']\n",
    "    \n",
    "    # Compute with more windows for finer resolution\n",
    "    alphas_fine, bounds_fine = compute_window_alphas(delta, dp, N_DRIFT_WINDOWS)\n",
    "    drift_slope_fine, drift_p_fine = compute_drift(alphas_fine)\n",
    "    \n",
    "    # T-range of each window midpoint\n",
    "    T_mids = []\n",
    "    for j in range(N_DRIFT_WINDOWS):\n",
    "        mid_idx = (bounds_fine[j] + bounds_fine[j+1]) // 2\n",
    "        T_mids.append(float(gamma0[mid_idx]))\n",
    "    \n",
    "    T8_pass = bool(drift_p_fine > 0.05)\n",
    "    \n",
    "    t8_results[name] = {\n",
    "        'alphas_fine': [float(x) for x in alphas_fine],\n",
    "        'T_mids': T_mids,\n",
    "        'drift_slope': float(drift_slope_fine),\n",
    "        'drift_p': float(drift_p_fine),\n",
    "        'T8_pass': T8_pass,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n  [{i+1}/{N_TOP}] {name}\")\n",
    "    print(f\"    drift slope = {drift_slope_fine:+.6f}  (p = {drift_p_fine:.4f})\")\n",
    "    print(f\"    T8: {'PASS' if T8_pass else 'FAIL'}\")\n",
    "    print(f\"    alpha range: [{min(alphas_fine):.4f}, {max(alphas_fine):.4f}]\")\n",
    "    print(f\"    T range: [{T_mids[0]:.0f}, {T_mids[-1]:.0f}]\")\n",
    "\n",
    "# Update phase1 results with T8\n",
    "for r in phase1_results:\n",
    "    if r['name'] in t8_results:\n",
    "        r['T8_pass'] = t8_results[r['name']]['T8_pass']\n",
    "        r['T8_drift_slope_fine'] = t8_results[r['name']]['drift_slope']\n",
    "        r['T8_drift_p_fine'] = t8_results[r['name']]['drift_p']\n",
    "    else:\n",
    "        r['T8_pass'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================\n",
    "# MULTI-PANEL FIGURE\n",
    "# ================================================================\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "fig.suptitle('3D Adaptive Cutoff Validation — 2M Odlyzko Zeros', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Colors for candidates\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, N_TOP))\n",
    "\n",
    "# --- Panel 1: Window alphas for top candidates ---\n",
    "ax = axes[0, 0]\n",
    "ax.set_title('Window Alpha vs Window Index')\n",
    "for i in range(N_TOP):\n",
    "    r = phase1_ranked[i]\n",
    "    name = r['name']\n",
    "    if name in t8_results:\n",
    "        alphas_f = t8_results[name]['alphas_fine']\n",
    "        label = f\"{name} (a={r['alpha']:.4f})\"\n",
    "        ax.plot(range(len(alphas_f)), alphas_f, 'o-', color=colors[i],\n",
    "                label=label, markersize=4, linewidth=1.2)\n",
    "ax.axhline(y=1.0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "ax.set_xlabel('Window index')\n",
    "ax.set_ylabel(r'$\\alpha$')\n",
    "ax.legend(fontsize=7, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Panel 2: Window alphas vs log(T) ---\n",
    "ax = axes[0, 1]\n",
    "ax.set_title(r'Window Alpha vs $\\log T$')\n",
    "for i in range(N_TOP):\n",
    "    r = phase1_ranked[i]\n",
    "    name = r['name']\n",
    "    if name in t8_results:\n",
    "        T_m = t8_results[name]['T_mids']\n",
    "        alphas_f = t8_results[name]['alphas_fine']\n",
    "        ax.plot(np.log(T_m), alphas_f, 'o-', color=colors[i],\n",
    "                label=name, markersize=4, linewidth=1.2)\n",
    "ax.axhline(y=1.0, color='black', linestyle='--', linewidth=0.8, alpha=0.5)\n",
    "ax.set_xlabel(r'$\\log T$')\n",
    "ax.set_ylabel(r'$\\alpha$')\n",
    "ax.legend(fontsize=7, loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Panel 3: Bootstrap histogram for best candidate ---\n",
    "ax = axes[1, 0]\n",
    "best_name = phase1_ranked[0]['name']\n",
    "if best_name in t7_results:\n",
    "    boot = t7_results[best_name]\n",
    "    ax.hist(boot['boot_alphas'], bins=50, density=True, alpha=0.7, color='steelblue',\n",
    "            edgecolor='white', linewidth=0.5)\n",
    "    ax.axvline(x=1.0, color='red', linestyle='--', linewidth=1.5, label=r'$\\alpha = 1$')\n",
    "    ax.axvline(x=boot['ci_lo'], color='orange', linestyle=':', linewidth=1.2, label=f'95% CI')\n",
    "    ax.axvline(x=boot['ci_hi'], color='orange', linestyle=':', linewidth=1.2)\n",
    "    ax.axvline(x=phase1_ranked[0]['alpha'], color='green', linestyle='-', linewidth=1.5,\n",
    "               label=f\"OLS alpha={phase1_ranked[0]['alpha']:.4f}\")\n",
    "    ax.set_title(f'Bootstrap Distribution — {best_name}')\n",
    "    ax.legend(fontsize=8)\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel('Density')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# --- Panel 4: |alpha-1| comparison bar chart ---\n",
    "ax = axes[1, 1]\n",
    "names_short = [r['name'][:25] for r in phase1_ranked]\n",
    "abs_a1 = [r['abs_alpha_minus_1'] for r in phase1_ranked]\n",
    "bar_colors = ['green' if r.get('T7_pass') else 'tomato' for r in phase1_ranked]\n",
    "ax.barh(range(len(phase1_ranked)), abs_a1, color=bar_colors, alpha=0.8)\n",
    "ax.set_yticks(range(len(phase1_ranked)))\n",
    "ax.set_yticklabels(names_short, fontsize=8)\n",
    "ax.set_xlabel(r'$|\\alpha - 1|$')\n",
    "ax.set_title(r'$|\\alpha - 1|$ Ranking (green = T7 pass)')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = os.path.join(OUTPUT_DIR, 'theta_3d_validation.png')\n",
    "plt.savefig(fig_path, dpi=150, bbox_inches='tight')\n",
    "print(f\"Figure saved to {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Shifted-log vs Polynomial vs 2D Comparison\n\nDirect comparison of the best shifted-log, best polynomial, and best 2D candidate.\nShows whether the shifted-log resummation improves over the truncated polynomial."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# SHIFTED-LOG vs POLYNOMIAL vs 2D COMPARISON\n# ================================================================\nresults_sl = [r for r in phase1_results if r['mode'] == 'shifted-log']\nresults_poly = [r for r in phase1_results if r['mode'] == 'polynomial' and r['c'] != 0]\nresults_2d = [r for r in phase1_results if r['mode'] == 'polynomial' and r['c'] == 0]\n\nbest_sl = min(results_sl, key=lambda r: r['abs_alpha_minus_1']) if results_sl else None\nbest_poly = min(results_poly, key=lambda r: r['abs_alpha_minus_1']) if results_poly else None\nbest_2d = min(results_2d, key=lambda r: r['abs_alpha_minus_1']) if results_2d else None\n\nprint(\"=\" * 70)\nprint(\"SHIFTED-LOG vs POLYNOMIAL vs 2D COMPARISON\")\nprint(\"=\" * 70)\n\nfor label, best in [(\"Best shifted-log\", best_sl), (\"Best polynomial\", best_poly), (\"Best 2D\", best_2d)]:\n    if best:\n        print(f\"\\n{label}: {best['name']}\")\n        print(f\"  alpha = {best['alpha']:+.6f}  |alpha-1| = {best['abs_alpha_minus_1']:.6f}\")\n        print(f\"  R2    = {best['R2']:.6f}  drift = {best['drift_slope']:+.6f} (p={best['drift_p']:.4f})\")\n        print(f\"  T7: {best.get('T7_pass', '?')}  T8: {best.get('T8_pass', '?')}\")\n\n# Improvement ratios\nif best_sl and best_poly and best_poly['abs_alpha_minus_1'] > 0:\n    ratio = best_poly['abs_alpha_minus_1'] / best_sl['abs_alpha_minus_1'] if best_sl['abs_alpha_minus_1'] > 0 else float('inf')\n    print(f\"\\n  Shifted-log vs polynomial: {ratio:.1f}x closer to alpha=1\")\nif best_sl and best_2d and best_2d['abs_alpha_minus_1'] > 0:\n    ratio2d = best_2d['abs_alpha_minus_1'] / best_sl['abs_alpha_minus_1'] if best_sl['abs_alpha_minus_1'] > 0 else float('inf')\n    print(f\"  Shifted-log vs 2D:         {ratio2d:.1f}x closer to alpha=1\")\n\n# Window-by-window comparison figure\nfig, ax = plt.subplots(1, 1, figsize=(10, 5))\nplot_items = []\nif best_2d:\n    plot_items.append((best_2d, 'gray', 's-', '2D'))\nif best_poly:\n    plot_items.append((best_poly, 'steelblue', 'D-', 'Poly'))\nif best_sl:\n    plot_items.append((best_sl, 'darkgreen', 'o-', 'SL'))\n\nfor r, color, marker, prefix in plot_items:\n    ax.plot(range(N_WINDOWS), r['window_alphas'], marker, color=color,\n            label=f\"{prefix}: {r['name']}\", markersize=6, linewidth=1.5)\nax.axhline(y=1.0, color='red', linestyle='--', linewidth=1, alpha=0.7)\nax.set_xlabel('Window index', fontsize=12)\nax.set_ylabel(r'$\\alpha$', fontsize=12)\nax.set_title('Shifted-log vs Polynomial vs 2D: Window Alpha Comparison', fontsize=13)\nax.legend(fontsize=9)\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(os.path.join(OUTPUT_DIR, 'theta_sl_vs_poly_vs_2d.png'), dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Validation Scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# VALIDATION SCORECARD\n# ================================================================\nprint(\"\\n\" + \"=\" * 80)\nprint(\"VALIDATION SCORECARD\")\nprint(\"=\" * 80)\n\n# Best candidate\nbest = phase1_ranked[0]\nname = best['name']\n\nprint(f\"\\nCandidate: {name}\")\nif best['d_shift'] != 0:\n    print(f\"  theta(T) = {best['a']:.8f} - {best['b']:.8f}/(logT + ({best['d_shift']:.8f}))\")\nelif best['c'] != 0:\n    print(f\"  theta(T) = {best['a']:.8f} - {best['b']:.8f}/logT + {best['c']:.8f}/log^2 T\")\nelse:\n    print(f\"  theta(T) = {best['a']:.8f} - {best['b']:.8f}/logT\")\nprint(f\"  Mode: {best['mode']}\")\nprint()\n\n# Collect all test results\ntests = {\n    'T5a (beat constant baselines)': T5a_pass,\n    'T5b (beat random adaptive baselines)': T5b_pass,\n    'T5 (combined)': T5_pass,\n}\nif name in t7_results:\n    tests['T7 (bootstrap CI contains 1)'] = t7_results[name]['T7_pass']\nif name in t8_results:\n    tests['T8 (no drift, p > 0.05)'] = t8_results[name]['T8_pass']\n\nn_pass = sum(1 for v in tests.values() if v)\nn_total = len(tests)\n\nprint(f\"  {'Test':<40} {'Result':>8}\")\nprint(f\"  {'-'*48}\")\nfor test_name, passed in tests.items():\n    status = 'PASS' if passed else 'FAIL'\n    symbol = '+' if passed else 'X'\n    print(f\"  [{symbol}] {test_name:<37} {status:>8}\")\n\nprint(f\"\\n  Score: {n_pass}/{n_total} tests passed\")\n\n# Detailed metrics\nprint(f\"\\n  Detailed metrics:\")\nprint(f\"    alpha(2M)       = {best['alpha']:+.6f}\")\nprint(f\"    |alpha - 1|     = {best['abs_alpha_minus_1']:.6f}\")\nprint(f\"    R^2             = {best['R2']:.6f}\")\nprint(f\"    R^2 (scaled)    = {best['R2_scaled']:.6f}\")\nprint(f\"    Localization    = {best['localization']:.4f}\")\nprint(f\"    Drift slope     = {best['drift_slope']:+.6f}  (p = {best['drift_p']:.4f})\")\nif name in t7_results:\n    print(f\"    Bootstrap CI    = [{t7_results[name]['ci_lo']:.6f}, {t7_results[name]['ci_hi']:.6f}]\")\nif name in t8_results:\n    print(f\"    Fine drift      = {t8_results[name]['drift_slope']:+.6f}  (p = {t8_results[name]['drift_p']:.4f})\")\n\n# Highlight if GIFT pure formula wins\nif 'SL: 7/6 - phi/(logT - 2)' in name:\n    print(f\"\\n  *** GIFT-PURE TOPOLOGICAL FORMULA ***\")\n    print(f\"  All constants derived from topology:\")\n    print(f\"    7/6 = dim(K7) / (2 * N_gen)\")\n    print(f\"    phi = golden ratio (G2 metric eigenvalue)\")\n    print(f\"    2   = p2 (Pontryagin class)\")\n    print(f\"  Zero free parameters.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ================================================================\n# SAVE RESULTS\n# ================================================================\n\n# Strip non-serializable data (delta_pred arrays)\nsave_results = []\nfor r in phase1_ranked:\n    sr = {k: v for k, v in r.items() if k != 'delta_pred'}\n    # Add T5, T7, T8 results\n    if r['name'] == phase1_ranked[0]['name']:\n        sr['T5a_pass'] = bool(T5a_pass)\n        sr['T5a_margin'] = float(T5a_margin)\n        sr['T5b_pass'] = bool(T5b_pass)\n        sr['T5b_margin'] = float(T5b_margin)\n        sr['T5_pass'] = bool(T5_pass)\n    if r['name'] in t7_results:\n        sr['T7_ci_lo'] = t7_results[r['name']]['ci_lo']\n        sr['T7_ci_hi'] = t7_results[r['name']]['ci_hi']\n    if r['name'] in t8_results:\n        sr['T8_drift_slope_fine'] = t8_results[r['name']]['drift_slope']\n        sr['T8_drift_p_fine'] = t8_results[r['name']]['drift_p']\n    save_results.append(sr)\n\nout_path = os.path.join(OUTPUT_DIR, 'theta_validation_results.json')\nwith open(out_path, 'w') as f:\n    json.dump(save_results, f, indent=2)\nprint(f\"Results saved to {out_path}\")\n\n# Summary\nprint(f\"\\n{'='*70}\")\nprint(\"SUMMARY\")\nprint(f\"{'='*70}\")\nbest = phase1_ranked[0]\nprint(f\"Best candidate: {best['name']} ({best['mode']})\")\nprint(f\"  alpha(2M) = {best['alpha']:+.6f}\")\npassed_tests = [k for k, v in tests.items() if v]\nfailed_tests = [k for k, v in tests.items() if not v]\nif passed_tests:\n    print(f\"  Passed: {', '.join(passed_tests)}\")\nif failed_tests:\n    print(f\"  Failed: {', '.join(failed_tests)}\")\nprint(f\"\\nAll {len(CANDIDATES)} candidates ranked in {out_path}\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}